Sun Oct 13 22:05:01 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 4090        On  | 00000000:41:00.0 Off |                  Off |
|  0%   38C    P8              11W / 450W |     48MiB / 24564MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A   1770066      G   /usr/lib/xorg/Xorg                           38MiB |
+---------------------------------------------------------------------------------------+
wandb: Currently logged in as: abdelrahman-elsayed (dinesh_saggurthi). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/abdelrahman.elsayed/wandb/run-20241013_220515-d1liaan8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DIAS_modelnone
wandb: ‚≠êÔ∏è View project at https://wandb.ai/dinesh_saggurthi/SVD_exps
wandb: üöÄ View run at https://wandb.ai/dinesh_saggurthi/SVD_exps/runs/d1liaan8
{'data_transforms': {'a_min': 0, 'a_max': 255, 'img_size': 512, 'use_random_crop': False, 'use_rotation': True, 'rotation_angle': 10, 'use_saturation': False, 'saturation': 2, 'use_brightness': True, 'brightness': 2, 'use_horizontal_flip': True, 'use_random_scale': True}, 'data': {'name': 'ArcadeDataset', 'root_path': '/home/abdelrahman.elsayed/DIAS', 'data_split_csv': '/home/abdelrahman.elsayed/DIAS/data_split.csv', 'fold_num': 0, 'label_list': [0, 1], 'label_names': ['Background', 'Vein'], 'volume_channel': 3, 'negative_to_positive_ratio': -1}}
{'sam': {'img_size': 512, 'num_classes': 2, 'sam_type': 'base'}, 'img_type': 'image', 'arch': 'Prompt Adapted SAM', 'use_fdn': False, 'decoder_training': 'none', 'mlp_transform': False, 'prompts': {'USE_TEXT_PROMPT': True, 'NUM_TEXT_REPEAT': 1, 'USE_IMAGE_PROMPT': False, 'USE_SLICE_NUM': False, 'LOCATION': 'prepend', 'DROPOUT': 0, 'NUM_TOKENS': 5}, 'training': {'optimizer': 'adamw', 'lr': '1e-4', 'batch_size': 8, 'num_epochs': 200, 'schedule_step': 200, 'schedule_step_factor': 0.2, 'weight_decay': '1e-2', 'loss': 'focal+dice', 'reg_multiplier': 0}}
HERE
Train dataset size: 20
Val dataset size: 10
Train dataset size: 20
Val dataset size: 10
{'USE_TEXT_PROMPT': True, 'NUM_TEXT_REPEAT': 1, 'USE_IMAGE_PROMPT': False, 'USE_SLICE_NUM': False, 'LOCATION': 'prepend', 'DROPOUT': 0, 'NUM_TOKENS': 5}
Total parameters: 242,767,409
Trainable parameters: 1,034,496
Frozen parameters: 241,732,913

Parameters by module:
*************************************************************************************************************
  sam_encoder:
    Total: 87,293,696
    Trainable: 898,048
    Frozen: 86,395,648
*******************************************************************************************
*************************************************************************************************************
  clip_model:
    Total: 151,277,313
    Trainable: 0
    Frozen: 151,277,313
*******************************************************************************************
*************************************************************************************************************
  prompt_encoder:
    Total: 6,220
    Trainable: 0
    Frozen: 6,220
*******************************************************************************************
*************************************************************************************************************
  mask_decoder:
    Total: 4,058,340
    Trainable: 4,608
    Frozen: 4,053,732
*******************************************************************************************
*************************************************************************************************************
  Text_Embedding_Affine:
    Total: 131,840
    Trainable: 131,840
    Frozen: 0
*******************************************************************************************
./svdtuning/DIAS
Training parameters: 
----------
number of trainable parameters:  1034496
batch size:  5
num epochs:  200
Epoch 0/199
----------
train Epoch 0:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 0:   0%|          | 0/4 [00:02<?, ?it/s, loss=0.999, dice=tensor(0.0002, device='cuda:0')]train Epoch 0:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:02<00:08,  2.91s/it, loss=0.999, dice=tensor(0.0002, device='cuda:0')]train Epoch 0:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:03<00:08,  2.91s/it, loss=0.961, dice=tensor(0.0003, device='cuda:0')]train Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:03<00:02,  1.29s/it, loss=0.961, dice=tensor(0.0003, device='cuda:0')]train Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:03<00:02,  1.29s/it, loss=0.92, dice=tensor(0.0003, device='cuda:0')] train Epoch 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:03<00:00,  1.29it/s, loss=0.92, dice=tensor(0.0003, device='cuda:0')]train Epoch 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:03<00:00,  1.29it/s, loss=0.928, dice=tensor(0.0003, device='cuda:0')]train Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.87it/s, loss=0.928, dice=tensor(0.0003, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                              train Loss: 0.9520 Dice: 0.0001
val Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.927, dice=tensor(0.0357, device='cuda:0')]val Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.43it/s, loss=0.927, dice=tensor(0.0357, device='cuda:0')]val Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.43it/s, loss=0.907, dice=tensor(0.0329, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                            val Loss: 0.9167 Dice: 0.0066
Epoch 1/199
----------
train Epoch 1:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 1:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.886, dice=tensor(0.1085, device='cuda:0')]train Epoch 1:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.886, dice=tensor(0.1085, device='cuda:0')]train Epoch 1:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.901, dice=tensor(0.1152, device='cuda:0')]train Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.901, dice=tensor(0.1152, device='cuda:0')]train Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.908, dice=tensor(0.0809, device='cuda:0')]train Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.908, dice=tensor(0.0809, device='cuda:0')]train Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.922, dice=tensor(0.1032, device='cuda:0')]train Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.922, dice=tensor(0.1032, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                              train Loss: 0.9044 Dice: 0.0206
val Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.915, dice=tensor(0.1290, device='cuda:0')]val Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.915, dice=tensor(0.1290, device='cuda:0')]val Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.922, dice=tensor(0.1476, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                            val Loss: 0.9186 Dice: 0.0295
Epoch 2/199
----------
train Epoch 2:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 2:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.923, dice=tensor(0.0291, device='cuda:0')]train Epoch 2:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.923, dice=tensor(0.0291, device='cuda:0')]train Epoch 2:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.869, dice=tensor(0.1711, device='cuda:0')]train Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.869, dice=tensor(0.1711, device='cuda:0')]train Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.874, dice=tensor(0.1591, device='cuda:0')]train Epoch 2:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.874, dice=tensor(0.1591, device='cuda:0')]train Epoch 2:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.917, dice=tensor(0.1559, device='cuda:0')]train Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.917, dice=tensor(0.1559, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                              train Loss: 0.8957 Dice: 0.0312
val Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.902, dice=tensor(0.0824, device='cuda:0')]val Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.43it/s, loss=0.902, dice=tensor(0.0824, device='cuda:0')]val Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.43it/s, loss=0.926, dice=tensor(0.1953, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                            val Loss: 0.9140 Dice: 0.0391
Epoch 3/199
----------
train Epoch 3:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 3:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.915, dice=tensor(0.1235, device='cuda:0')]train Epoch 3:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.915, dice=tensor(0.1235, device='cuda:0')]train Epoch 3:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.9, dice=tensor(0.1789, device='cuda:0')]  train Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.9, dice=tensor(0.1789, device='cuda:0')]train Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.934, dice=tensor(0.1853, device='cuda:0')]train Epoch 3:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.93it/s, loss=0.934, dice=tensor(0.1853, device='cuda:0')]train Epoch 3:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.93it/s, loss=0.865, dice=tensor(0.1666, device='cuda:0')]train Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.58it/s, loss=0.865, dice=tensor(0.1666, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                              train Loss: 0.9037 Dice: 0.0333
val Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.896, dice=tensor(0.3199, device='cuda:0')]val Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.896, dice=tensor(0.3199, device='cuda:0')]val Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.927, dice=tensor(0.2257, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                            val Loss: 0.9118 Dice: 0.0451
Epoch 4/199
----------
train Epoch 4:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 4:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.89, dice=tensor(0.0411, device='cuda:0')]train Epoch 4:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.89, dice=tensor(0.0411, device='cuda:0')]train Epoch 4:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.89, dice=tensor(0.1467, device='cuda:0')]train Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.89, dice=tensor(0.1467, device='cuda:0')]train Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.892, dice=tensor(0.1275, device='cuda:0')]train Epoch 4:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.892, dice=tensor(0.1275, device='cuda:0')]train Epoch 4:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.897, dice=tensor(0.1565, device='cuda:0')]train Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.897, dice=tensor(0.1565, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                              train Loss: 0.8919 Dice: 0.0313
val Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.895, dice=tensor(0.1807, device='cuda:0')]val Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.895, dice=tensor(0.1807, device='cuda:0')]val Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.92, dice=tensor(0.1964, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                           val Loss: 0.9075 Dice: 0.0393
Epoch 5/199
----------
train Epoch 5:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 5:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.92, dice=tensor(0.2011, device='cuda:0')]train Epoch 5:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.86it/s, loss=0.92, dice=tensor(0.2011, device='cuda:0')]train Epoch 5:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.86it/s, loss=0.888, dice=tensor(0.2114, device='cuda:0')]train Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.16it/s, loss=0.888, dice=tensor(0.2114, device='cuda:0')]train Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.16it/s, loss=0.895, dice=tensor(0.1410, device='cuda:0')]train Epoch 5:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.04it/s, loss=0.895, dice=tensor(0.1410, device='cuda:0')]train Epoch 5:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.04it/s, loss=0.867, dice=tensor(0.1488, device='cuda:0')]train Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.68it/s, loss=0.867, dice=tensor(0.1488, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                              train Loss: 0.8925 Dice: 0.0298
val Epoch 5:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 5:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.922, dice=tensor(0.2438, device='cuda:0')]val Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.78it/s, loss=0.922, dice=tensor(0.2438, device='cuda:0')]val Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.78it/s, loss=0.886, dice=tensor(0.1731, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                            val Loss: 0.9044 Dice: 0.0346
Epoch 6/199
----------
train Epoch 6:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 6:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.909, dice=tensor(0.2101, device='cuda:0')]train Epoch 6:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.91it/s, loss=0.909, dice=tensor(0.2101, device='cuda:0')]train Epoch 6:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.91it/s, loss=0.908, dice=tensor(0.1227, device='cuda:0')]train Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.21it/s, loss=0.908, dice=tensor(0.1227, device='cuda:0')]train Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.21it/s, loss=0.879, dice=tensor(0.0863, device='cuda:0')]train Epoch 6:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.11it/s, loss=0.879, dice=tensor(0.0863, device='cuda:0')]train Epoch 6:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.11it/s, loss=0.841, dice=tensor(0.1204, device='cuda:0')]train Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.73it/s, loss=0.841, dice=tensor(0.1204, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                              train Loss: 0.8843 Dice: 0.0241
val Epoch 6:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 6:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.91, dice=tensor(0.1264, device='cuda:0')]val Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.91, dice=tensor(0.1264, device='cuda:0')]val Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.894, dice=tensor(0.1899, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                            val Loss: 0.9018 Dice: 0.0380
Epoch 7/199
----------
train Epoch 7:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 7:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.884, dice=tensor(0.3193, device='cuda:0')]train Epoch 7:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.884, dice=tensor(0.3193, device='cuda:0')]train Epoch 7:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.892, dice=tensor(0.2433, device='cuda:0')]train Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.892, dice=tensor(0.2433, device='cuda:0')]train Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.855, dice=tensor(0.2414, device='cuda:0')]train Epoch 7:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.855, dice=tensor(0.2414, device='cuda:0')]train Epoch 7:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.901, dice=tensor(0.1839, device='cuda:0')]train Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.901, dice=tensor(0.1839, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                              train Loss: 0.8830 Dice: 0.0368
val Epoch 7:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 7:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.908, dice=tensor(0.2929, device='cuda:0')]val Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.908, dice=tensor(0.2929, device='cuda:0')]val Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.888, dice=tensor(0.2046, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                            val Loss: 0.8981 Dice: 0.0409
Epoch 8/199
----------
train Epoch 8:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 8:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.853, dice=tensor(0.2581, device='cuda:0')]train Epoch 8:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.853, dice=tensor(0.2581, device='cuda:0')]train Epoch 8:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.867, dice=tensor(0.1965, device='cuda:0')]train Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.867, dice=tensor(0.1965, device='cuda:0')]train Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.903, dice=tensor(0.2540, device='cuda:0')]train Epoch 8:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.903, dice=tensor(0.2540, device='cuda:0')]train Epoch 8:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.877, dice=tensor(0.2314, device='cuda:0')]train Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.877, dice=tensor(0.2314, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                              train Loss: 0.8749 Dice: 0.0463
val Epoch 8:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 8:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.891, dice=tensor(0.2571, device='cuda:0')]val Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.891, dice=tensor(0.2571, device='cuda:0')]val Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.903, dice=tensor(0.2212, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                            val Loss: 0.8969 Dice: 0.0442
Epoch 9/199
----------
train Epoch 9:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 9:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.881, dice=tensor(0.0554, device='cuda:0')]train Epoch 9:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.881, dice=tensor(0.0554, device='cuda:0')]train Epoch 9:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.878, dice=tensor(0.0330, device='cuda:0')]train Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.878, dice=tensor(0.0330, device='cuda:0')]train Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.858, dice=tensor(0.0797, device='cuda:0')]train Epoch 9:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.90it/s, loss=0.858, dice=tensor(0.0797, device='cuda:0')]train Epoch 9:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.90it/s, loss=0.876, dice=tensor(0.0770, device='cuda:0')]train Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.876, dice=tensor(0.0770, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                              train Loss: 0.8733 Dice: 0.0154
val Epoch 9:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 9:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.902, dice=tensor(0.2865, device='cuda:0')]val Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.81it/s, loss=0.902, dice=tensor(0.2865, device='cuda:0')]val Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.81it/s, loss=0.882, dice=tensor(0.2908, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                            val Loss: 0.8920 Dice: 0.0582
Epoch 10/199
----------
train Epoch 10:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 10:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.852, dice=tensor(0.0644, device='cuda:0')]train Epoch 10:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.852, dice=tensor(0.0644, device='cuda:0')]train Epoch 10:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.832, dice=tensor(0.1017, device='cuda:0')]train Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.832, dice=tensor(0.1017, device='cuda:0')]train Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.889, dice=tensor(0.1273, device='cuda:0')]train Epoch 10:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.66it/s, loss=0.889, dice=tensor(0.1273, device='cuda:0')]train Epoch 10:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.66it/s, loss=0.864, dice=tensor(0.1096, device='cuda:0')]train Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.35it/s, loss=0.864, dice=tensor(0.1096, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.8591 Dice: 0.0219
val Epoch 10:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 10:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.871, dice=tensor(0.4130, device='cuda:0')]val Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.25it/s, loss=0.871, dice=tensor(0.4130, device='cuda:0')]val Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.25it/s, loss=0.902, dice=tensor(0.4010, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.8867 Dice: 0.0802
Epoch 11/199
----------
train Epoch 11:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 11:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.893, dice=tensor(0.0725, device='cuda:0')]train Epoch 11:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.893, dice=tensor(0.0725, device='cuda:0')]train Epoch 11:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.853, dice=tensor(0.2261, device='cuda:0')]train Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.853, dice=tensor(0.2261, device='cuda:0')]train Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.846, dice=tensor(0.2591, device='cuda:0')]train Epoch 11:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.846, dice=tensor(0.2591, device='cuda:0')]train Epoch 11:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.841, dice=tensor(0.2000, device='cuda:0')]train Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.841, dice=tensor(0.2000, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                               train Loss: 0.8583 Dice: 0.0400
val Epoch 11:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 11:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.87, dice=tensor(0.2160, device='cuda:0')]val Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.87, dice=tensor(0.2160, device='cuda:0')]val Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.896, dice=tensor(0.5067, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.8833 Dice: 0.1013
Epoch 12/199
----------
train Epoch 12:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 12:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.852, dice=tensor(0.0837, device='cuda:0')]train Epoch 12:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.852, dice=tensor(0.0837, device='cuda:0')]train Epoch 12:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.841, dice=tensor(0.7287, device='cuda:0')]train Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.841, dice=tensor(0.7287, device='cuda:0')]train Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.841, dice=tensor(0.6200, device='cuda:0')]train Epoch 12:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.01it/s, loss=0.841, dice=tensor(0.6200, device='cuda:0')]train Epoch 12:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.01it/s, loss=0.841, dice=tensor(0.5335, device='cuda:0')]train Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.65it/s, loss=0.841, dice=tensor(0.5335, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                               train Loss: 0.8436 Dice: 0.1067
val Epoch 12:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 12:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.877, dice=tensor(1.0257, device='cuda:0')]val Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.88it/s, loss=0.877, dice=tensor(1.0257, device='cuda:0')]val Epoch 12:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.88it/s, loss=0.881, dice=tensor(0.7516, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.8794 Dice: 0.1503
Epoch 13/199
----------
train Epoch 13:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 13:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.823, dice=tensor(0.7312, device='cuda:0')]train Epoch 13:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.823, dice=tensor(0.7312, device='cuda:0')]train Epoch 13:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.823, dice=tensor(0.9140, device='cuda:0')]train Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.823, dice=tensor(0.9140, device='cuda:0')]train Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.837, dice=tensor(0.7373, device='cuda:0')]train Epoch 13:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.837, dice=tensor(0.7373, device='cuda:0')]train Epoch 13:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.809, dice=tensor(0.6918, device='cuda:0')]train Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.809, dice=tensor(0.6918, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                               train Loss: 0.8231 Dice: 0.1384
val Epoch 13:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 13:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.873, dice=tensor(0.9563, device='cuda:0')]val Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.873, dice=tensor(0.9563, device='cuda:0')]val Epoch 13:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.878, dice=tensor(0.8545, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.8753 Dice: 0.1709
Epoch 14/199
----------
train Epoch 14:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 14:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.79, dice=tensor(1.3634, device='cuda:0')]train Epoch 14:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.79, dice=tensor(1.3634, device='cuda:0')]train Epoch 14:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.786, dice=tensor(1.5115, device='cuda:0')]train Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.786, dice=tensor(1.5115, device='cuda:0')]train Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.81, dice=tensor(1.2039, device='cuda:0')] train Epoch 14:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.81, dice=tensor(1.2039, device='cuda:0')]train Epoch 14:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.757, dice=tensor(1.4264, device='cuda:0')]train Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.757, dice=tensor(1.4264, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                               train Loss: 0.7858 Dice: 0.2853
val Epoch 14:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 14:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.854, dice=tensor(0.7710, device='cuda:0')]val Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.854, dice=tensor(0.7710, device='cuda:0')]val Epoch 14:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.889, dice=tensor(0.8338, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.8712 Dice: 0.1668
Epoch 15/199
----------
train Epoch 15:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 15:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.77, dice=tensor(1.9982, device='cuda:0')]train Epoch 15:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.41it/s, loss=0.77, dice=tensor(1.9982, device='cuda:0')]train Epoch 15:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.41it/s, loss=0.808, dice=tensor(1.7038, device='cuda:0')]train Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.58it/s, loss=0.808, dice=tensor(1.7038, device='cuda:0')]train Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.58it/s, loss=0.791, dice=tensor(1.4752, device='cuda:0')]train Epoch 15:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.51it/s, loss=0.791, dice=tensor(1.4752, device='cuda:0')]train Epoch 15:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.51it/s, loss=0.738, dice=tensor(1.4885, device='cuda:0')]train Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.23it/s, loss=0.738, dice=tensor(1.4885, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.7770 Dice: 0.2977
val Epoch 15:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 15:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.906, dice=tensor(0.3420, device='cuda:0')]val Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.906, dice=tensor(0.3420, device='cuda:0')]val Epoch 15:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.869, dice=tensor(0.4996, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.8876 Dice: 0.0999
Epoch 16/199
----------
train Epoch 16:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 16:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.81, dice=tensor(1.6404, device='cuda:0')]train Epoch 16:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.81, dice=tensor(1.6404, device='cuda:0')]train Epoch 16:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.648, dice=tensor(2.1223, device='cuda:0')]train Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.648, dice=tensor(2.1223, device='cuda:0')]train Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.618, dice=tensor(2.0562, device='cuda:0')]train Epoch 16:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.618, dice=tensor(2.0562, device='cuda:0')]train Epoch 16:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.785, dice=tensor(1.9811, device='cuda:0')]train Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.785, dice=tensor(1.9811, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.7152 Dice: 0.3962
val Epoch 16:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 16:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.874, dice=tensor(0.6534, device='cuda:0')]val Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.874, dice=tensor(0.6534, device='cuda:0')]val Epoch 16:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.931, dice=tensor(0.3429, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.9027 Dice: 0.0686
Epoch 17/199
----------
train Epoch 17:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 17:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.769, dice=tensor(1.7903, device='cuda:0')]train Epoch 17:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.769, dice=tensor(1.7903, device='cuda:0')]train Epoch 17:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.695, dice=tensor(1.9906, device='cuda:0')]train Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.695, dice=tensor(1.9906, device='cuda:0')]train Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.62, dice=tensor(2.1676, device='cuda:0')] train Epoch 17:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.62, dice=tensor(2.1676, device='cuda:0')]train Epoch 17:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.624, dice=tensor(2.2412, device='cuda:0')]train Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.624, dice=tensor(2.2412, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.6771 Dice: 0.4482
val Epoch 17:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 17:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.909, dice=tensor(0.0065, device='cuda:0')]val Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.909, dice=tensor(0.0065, device='cuda:0')]val Epoch 17:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.885, dice=tensor(0.2661, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.8969 Dice: 0.0532
Epoch 18/199
----------
train Epoch 18:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 18:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.537, dice=tensor(2.0634, device='cuda:0')]train Epoch 18:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.537, dice=tensor(2.0634, device='cuda:0')]train Epoch 18:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.649, dice=tensor(2.2997, device='cuda:0')]train Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.649, dice=tensor(2.2997, device='cuda:0')]train Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.522, dice=tensor(2.4447, device='cuda:0')]train Epoch 18:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.522, dice=tensor(2.4447, device='cuda:0')]train Epoch 18:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.491, dice=tensor(2.5491, device='cuda:0')]train Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.491, dice=tensor(2.5491, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                               train Loss: 0.5500 Dice: 0.5098
val Epoch 18:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 18:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.859, dice=tensor(0.7555, device='cuda:0')]val Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.859, dice=tensor(0.7555, device='cuda:0')]val Epoch 18:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.857, dice=tensor(0.9328, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.8582 Dice: 0.1866
Epoch 19/199
----------
train Epoch 19:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 19:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.666, dice=tensor(1.8966, device='cuda:0')]train Epoch 19:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.666, dice=tensor(1.8966, device='cuda:0')]train Epoch 19:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.57, dice=tensor(2.3074, device='cuda:0')] train Epoch 19:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.57, dice=tensor(2.3074, device='cuda:0')]train Epoch 19:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.57, dice=tensor(2.3499, device='cuda:0')]train Epoch 19:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.57, dice=tensor(2.3499, device='cuda:0')]train Epoch 19:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.518, dice=tensor(2.3281, device='cuda:0')]train Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.518, dice=tensor(2.3281, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.5808 Dice: 0.4656
val Epoch 19:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 19:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.775, dice=tensor(1.7259, device='cuda:0')]val Epoch 19:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.775, dice=tensor(1.7259, device='cuda:0')]val Epoch 19:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.733, dice=tensor(1.4862, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.7539 Dice: 0.2972
Epoch 20/199
----------
train Epoch 20:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 20:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.564, dice=tensor(2.5193, device='cuda:0')]train Epoch 20:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.44it/s, loss=0.564, dice=tensor(2.5193, device='cuda:0')]train Epoch 20:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.44it/s, loss=0.431, dice=tensor(2.6648, device='cuda:0')]train Epoch 20:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.62it/s, loss=0.431, dice=tensor(2.6648, device='cuda:0')]train Epoch 20:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.62it/s, loss=0.442, dice=tensor(2.7623, device='cuda:0')]train Epoch 20:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.56it/s, loss=0.442, dice=tensor(2.7623, device='cuda:0')]train Epoch 20:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.56it/s, loss=0.448, dice=tensor(2.7167, device='cuda:0')]train Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.27it/s, loss=0.448, dice=tensor(2.7167, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.4713 Dice: 0.5433
val Epoch 20:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 20:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.946, dice=tensor(0.3193, device='cuda:0')]val Epoch 20:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.946, dice=tensor(0.3193, device='cuda:0')]val Epoch 20:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.911, dice=tensor(0.3414, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.9285 Dice: 0.0683
Epoch 21/199
----------
train Epoch 21:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 21:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.465, dice=tensor(2.9031, device='cuda:0')]train Epoch 21:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.465, dice=tensor(2.9031, device='cuda:0')]train Epoch 21:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.44, dice=tensor(2.9413, device='cuda:0')] train Epoch 21:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.44, dice=tensor(2.9413, device='cuda:0')]train Epoch 21:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.414, dice=tensor(2.8924, device='cuda:0')]train Epoch 21:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.414, dice=tensor(2.8924, device='cuda:0')]train Epoch 21:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.448, dice=tensor(2.8282, device='cuda:0')]train Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.448, dice=tensor(2.8282, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                               train Loss: 0.4419 Dice: 0.5656
val Epoch 21:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 21:   0%|          | 0/2 [00:00<?, ?it/s, loss=1.02, dice=tensor(0.0369, device='cuda:0')]val Epoch 21:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.85it/s, loss=1.02, dice=tensor(0.0369, device='cuda:0')]val Epoch 21:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.85it/s, loss=1.01, dice=tensor(0.0420, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                            val Loss: 1.0161 Dice: 0.0084
Epoch 22/199
----------
train Epoch 22:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 22:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.424, dice=tensor(3.3294, device='cuda:0')]train Epoch 22:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.424, dice=tensor(3.3294, device='cuda:0')]train Epoch 22:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.399, dice=tensor(3.2005, device='cuda:0')]train Epoch 22:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.399, dice=tensor(3.2005, device='cuda:0')]train Epoch 22:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.467, dice=tensor(3.0643, device='cuda:0')]train Epoch 22:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.80it/s, loss=0.467, dice=tensor(3.0643, device='cuda:0')]train Epoch 22:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.80it/s, loss=0.413, dice=tensor(3.0641, device='cuda:0')]train Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.413, dice=tensor(3.0641, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                               train Loss: 0.4260 Dice: 0.6128
val Epoch 22:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 22:   0%|          | 0/2 [00:00<?, ?it/s, loss=1.01, dice=tensor(0.0406, device='cuda:0')]val Epoch 22:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=1.01, dice=tensor(0.0406, device='cuda:0')]val Epoch 22:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=1.02, dice=tensor(0.0397, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                            val Loss: 1.0170 Dice: 0.0079
Epoch 23/199
----------
train Epoch 23:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 23:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.373, dice=tensor(3.1658, device='cuda:0')]train Epoch 23:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.85it/s, loss=0.373, dice=tensor(3.1658, device='cuda:0')]train Epoch 23:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.85it/s, loss=0.375, dice=tensor(3.1849, device='cuda:0')]train Epoch 23:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.13it/s, loss=0.375, dice=tensor(3.1849, device='cuda:0')]train Epoch 23:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.13it/s, loss=0.484, dice=tensor(3.0379, device='cuda:0')]train Epoch 23:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.03it/s, loss=0.484, dice=tensor(3.0379, device='cuda:0')]train Epoch 23:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.03it/s, loss=0.388, dice=tensor(3.0541, device='cuda:0')]train Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.66it/s, loss=0.388, dice=tensor(3.0541, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.4049 Dice: 0.6108
val Epoch 23:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 23:   0%|          | 0/2 [00:00<?, ?it/s, loss=1.01, dice=tensor(0.0567, device='cuda:0')]val Epoch 23:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=1.01, dice=tensor(0.0567, device='cuda:0')]val Epoch 23:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=1, dice=tensor(0.0836, device='cuda:0')]   /home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                         val Loss: 1.0093 Dice: 0.0167
Epoch 24/199
----------
train Epoch 24:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 24:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.515, dice=tensor(2.5663, device='cuda:0')]train Epoch 24:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.515, dice=tensor(2.5663, device='cuda:0')]train Epoch 24:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.36, dice=tensor(2.9006, device='cuda:0')] train Epoch 24:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.36, dice=tensor(2.9006, device='cuda:0')]train Epoch 24:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.366, dice=tensor(3.0248, device='cuda:0')]train Epoch 24:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.366, dice=tensor(3.0248, device='cuda:0')]train Epoch 24:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.399, dice=tensor(3.0359, device='cuda:0')]train Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.399, dice=tensor(3.0359, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                               train Loss: 0.4101 Dice: 0.6072
val Epoch 24:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 24:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.927, dice=tensor(0.4421, device='cuda:0')]val Epoch 24:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.927, dice=tensor(0.4421, device='cuda:0')]val Epoch 24:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.996, dice=tensor(0.2923, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.9615 Dice: 0.0585
Epoch 25/199
----------
train Epoch 25:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 25:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.412, dice=tensor(3.0715, device='cuda:0')]train Epoch 25:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.412, dice=tensor(3.0715, device='cuda:0')]train Epoch 25:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.35, dice=tensor(3.1804, device='cuda:0')] train Epoch 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.35, dice=tensor(3.1804, device='cuda:0')]train Epoch 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.414, dice=tensor(3.1237, device='cuda:0')]train Epoch 25:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.414, dice=tensor(3.1237, device='cuda:0')]train Epoch 25:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.352, dice=tensor(3.1591, device='cuda:0')]train Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.352, dice=tensor(3.1591, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                               train Loss: 0.3821 Dice: 0.6318
val Epoch 25:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 25:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.871, dice=tensor(0.6865, device='cuda:0')]val Epoch 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.871, dice=tensor(0.6865, device='cuda:0')]val Epoch 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.973, dice=tensor(0.4709, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.9218 Dice: 0.0942
Epoch 26/199
----------
train Epoch 26:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 26:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.392, dice=tensor(2.9845, device='cuda:0')]train Epoch 26:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.392, dice=tensor(2.9845, device='cuda:0')]train Epoch 26:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.422, dice=tensor(2.9764, device='cuda:0')]train Epoch 26:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.422, dice=tensor(2.9764, device='cuda:0')]train Epoch 26:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.359, dice=tensor(3.0767, device='cuda:0')]train Epoch 26:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.359, dice=tensor(3.0767, device='cuda:0')]train Epoch 26:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.343, dice=tensor(3.0951, device='cuda:0')]train Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.343, dice=tensor(3.0951, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                               train Loss: 0.3792 Dice: 0.6190
val Epoch 26:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 26:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.969, dice=tensor(0.2808, device='cuda:0')]val Epoch 26:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.969, dice=tensor(0.2808, device='cuda:0')]val Epoch 26:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.843, dice=tensor(0.5458, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.9057 Dice: 0.1092
Epoch 27/199
----------
train Epoch 27:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 27:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.394, dice=tensor(2.9896, device='cuda:0')]train Epoch 27:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.394, dice=tensor(2.9896, device='cuda:0')]train Epoch 27:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.328, dice=tensor(3.2020, device='cuda:0')]train Epoch 27:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.328, dice=tensor(3.2020, device='cuda:0')]train Epoch 27:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.401, dice=tensor(3.0983, device='cuda:0')]train Epoch 27:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.401, dice=tensor(3.0983, device='cuda:0')]train Epoch 27:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.398, dice=tensor(3.0439, device='cuda:0')]train Epoch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.398, dice=tensor(3.0439, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3805 Dice: 0.6088
val Epoch 27:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 27:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.894, dice=tensor(0.5566, device='cuda:0')]val Epoch 27:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.894, dice=tensor(0.5566, device='cuda:0')]val Epoch 27:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.934, dice=tensor(0.5135, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.9143 Dice: 0.1027
Epoch 28/199
----------
train Epoch 28:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 28:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.374, dice=tensor(3.1970, device='cuda:0')]train Epoch 28:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.374, dice=tensor(3.1970, device='cuda:0')]train Epoch 28:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.337, dice=tensor(3.1869, device='cuda:0')]train Epoch 28:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.337, dice=tensor(3.1869, device='cuda:0')]train Epoch 28:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.463, dice=tensor(3.0479, device='cuda:0')]train Epoch 28:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.463, dice=tensor(3.0479, device='cuda:0')]train Epoch 28:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.339, dice=tensor(3.1263, device='cuda:0')]train Epoch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.339, dice=tensor(3.1263, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                               train Loss: 0.3781 Dice: 0.6253
val Epoch 28:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 28:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.869, dice=tensor(0.7247, device='cuda:0')]val Epoch 28:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.869, dice=tensor(0.7247, device='cuda:0')]val Epoch 28:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.855, dice=tensor(0.7302, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.8619 Dice: 0.1460
Epoch 29/199
----------
train Epoch 29:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 29:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.375, dice=tensor(3.1600, device='cuda:0')]train Epoch 29:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.375, dice=tensor(3.1600, device='cuda:0')]train Epoch 29:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.348, dice=tensor(3.1997, device='cuda:0')]train Epoch 29:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.348, dice=tensor(3.1997, device='cuda:0')]train Epoch 29:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.366, dice=tensor(3.1422, device='cuda:0')]train Epoch 29:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.366, dice=tensor(3.1422, device='cuda:0')]train Epoch 29:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.359, dice=tensor(3.1330, device='cuda:0')]train Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.359, dice=tensor(3.1330, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.3621 Dice: 0.6266
val Epoch 29:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 29:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.835, dice=tensor(0.8511, device='cuda:0')]val Epoch 29:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.835, dice=tensor(0.8511, device='cuda:0')]val Epoch 29:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.731, dice=tensor(1.1129, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.7830 Dice: 0.2226
Epoch 30/199
----------
train Epoch 30:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 30:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.431, dice=tensor(2.9705, device='cuda:0')]train Epoch 30:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.431, dice=tensor(2.9705, device='cuda:0')]train Epoch 30:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.352, dice=tensor(3.1520, device='cuda:0')]train Epoch 30:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.352, dice=tensor(3.1520, device='cuda:0')]train Epoch 30:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.419, dice=tensor(3.0413, device='cuda:0')]train Epoch 30:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.67it/s, loss=0.419, dice=tensor(3.0413, device='cuda:0')]train Epoch 30:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.67it/s, loss=0.316, dice=tensor(3.1415, device='cuda:0')]train Epoch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.37it/s, loss=0.316, dice=tensor(3.1415, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.3794 Dice: 0.6283
val Epoch 30:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 30:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.816, dice=tensor(0.9444, device='cuda:0')]val Epoch 30:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.816, dice=tensor(0.9444, device='cuda:0')]val Epoch 30:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.734, dice=tensor(1.0828, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.7751 Dice: 0.2166
Epoch 31/199
----------
train Epoch 31:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 31:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.359, dice=tensor(3.2058, device='cuda:0')]train Epoch 31:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.359, dice=tensor(3.2058, device='cuda:0')]train Epoch 31:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.347, dice=tensor(3.2381, device='cuda:0')]train Epoch 31:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.347, dice=tensor(3.2381, device='cuda:0')]train Epoch 31:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.349, dice=tensor(3.2494, device='cuda:0')]train Epoch 31:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.92it/s, loss=0.349, dice=tensor(3.2494, device='cuda:0')]train Epoch 31:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.92it/s, loss=0.381, dice=tensor(3.1842, device='cuda:0')]train Epoch 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.381, dice=tensor(3.1842, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3588 Dice: 0.6368
val Epoch 31:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 31:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.598, dice=tensor(1.9210, device='cuda:0')]val Epoch 31:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.598, dice=tensor(1.9210, device='cuda:0')]val Epoch 31:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.842, dice=tensor(1.3941, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.7202 Dice: 0.2788
Epoch 32/199
----------
train Epoch 32:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 32:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.401, dice=tensor(3.0623, device='cuda:0')]train Epoch 32:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.401, dice=tensor(3.0623, device='cuda:0')]train Epoch 32:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.328, dice=tensor(3.2388, device='cuda:0')]train Epoch 32:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.328, dice=tensor(3.2388, device='cuda:0')]train Epoch 32:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.396, dice=tensor(3.1685, device='cuda:0')]train Epoch 32:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.396, dice=tensor(3.1685, device='cuda:0')]train Epoch 32:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.343, dice=tensor(3.2109, device='cuda:0')]train Epoch 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.343, dice=tensor(3.2109, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3666 Dice: 0.6422
val Epoch 32:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 32:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.833, dice=tensor(0.7162, device='cuda:0')]val Epoch 32:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.833, dice=tensor(0.7162, device='cuda:0')]val Epoch 32:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.86, dice=tensor(0.7201, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                            val Loss: 0.8464 Dice: 0.1440
Epoch 33/199
----------
train Epoch 33:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 33:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.37, dice=tensor(3.2009, device='cuda:0')]train Epoch 33:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.37, dice=tensor(3.2009, device='cuda:0')]train Epoch 33:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.345, dice=tensor(3.2098, device='cuda:0')]train Epoch 33:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.345, dice=tensor(3.2098, device='cuda:0')]train Epoch 33:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.334, dice=tensor(3.2655, device='cuda:0')]train Epoch 33:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.334, dice=tensor(3.2655, device='cuda:0')]train Epoch 33:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.379, dice=tensor(3.2363, device='cuda:0')]train Epoch 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.379, dice=tensor(3.2363, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.3572 Dice: 0.6473
val Epoch 33:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 33:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.541, dice=tensor(2.1537, device='cuda:0')]val Epoch 33:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.541, dice=tensor(2.1537, device='cuda:0')]val Epoch 33:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.489, dice=tensor(2.3675, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.5152 Dice: 0.4735
Epoch 34/199
----------
train Epoch 34:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 34:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.388, dice=tensor(3.0654, device='cuda:0')]train Epoch 34:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.388, dice=tensor(3.0654, device='cuda:0')]train Epoch 34:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.351, dice=tensor(3.1678, device='cuda:0')]train Epoch 34:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.351, dice=tensor(3.1678, device='cuda:0')]train Epoch 34:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.377, dice=tensor(3.1610, device='cuda:0')]train Epoch 34:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.92it/s, loss=0.377, dice=tensor(3.1610, device='cuda:0')]train Epoch 34:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.92it/s, loss=0.303, dice=tensor(3.2504, device='cuda:0')]train Epoch 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.303, dice=tensor(3.2504, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.3546 Dice: 0.6501
val Epoch 34:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 34:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.408, dice=tensor(3.1531, device='cuda:0')]val Epoch 34:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.408, dice=tensor(3.1531, device='cuda:0')]val Epoch 34:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.52, dice=tensor(2.8030, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                            val Loss: 0.4640 Dice: 0.5606
Epoch 35/199
----------
train Epoch 35:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 35:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.358, dice=tensor(3.2916, device='cuda:0')]train Epoch 35:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.358, dice=tensor(3.2916, device='cuda:0')]train Epoch 35:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.349, dice=tensor(3.2891, device='cuda:0')]train Epoch 35:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.349, dice=tensor(3.2891, device='cuda:0')]train Epoch 35:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.398, dice=tensor(3.2149, device='cuda:0')]train Epoch 35:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.398, dice=tensor(3.2149, device='cuda:0')]train Epoch 35:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.315, dice=tensor(3.2737, device='cuda:0')]train Epoch 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.315, dice=tensor(3.2737, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3549 Dice: 0.6547
val Epoch 35:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 35:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.527, dice=tensor(2.3098, device='cuda:0')]val Epoch 35:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.527, dice=tensor(2.3098, device='cuda:0')]val Epoch 35:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.458, dice=tensor(2.5853, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.4927 Dice: 0.5171
Epoch 36/199
----------
train Epoch 36:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 36:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.3884, device='cuda:0')]train Epoch 36:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.322, dice=tensor(3.3884, device='cuda:0')]train Epoch 36:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.345, dice=tensor(3.3537, device='cuda:0')]train Epoch 36:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.345, dice=tensor(3.3537, device='cuda:0')]train Epoch 36:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.335, dice=tensor(3.3544, device='cuda:0')]train Epoch 36:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.335, dice=tensor(3.3544, device='cuda:0')]train Epoch 36:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.421, dice=tensor(3.2061, device='cuda:0')]train Epoch 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.421, dice=tensor(3.2061, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                               train Loss: 0.3558 Dice: 0.6412
val Epoch 36:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 36:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.541, dice=tensor(2.2308, device='cuda:0')]val Epoch 36:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.541, dice=tensor(2.2308, device='cuda:0')]val Epoch 36:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.683, dice=tensor(1.8801, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.6119 Dice: 0.3760
Epoch 37/199
----------
train Epoch 37:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 37:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.363, dice=tensor(3.1123, device='cuda:0')]train Epoch 37:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.363, dice=tensor(3.1123, device='cuda:0')]train Epoch 37:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.442, dice=tensor(3.0094, device='cuda:0')]train Epoch 37:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.442, dice=tensor(3.0094, device='cuda:0')]train Epoch 37:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.308, dice=tensor(3.1703, device='cuda:0')]train Epoch 37:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.66it/s, loss=0.308, dice=tensor(3.1703, device='cuda:0')]train Epoch 37:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.66it/s, loss=0.351, dice=tensor(3.1962, device='cuda:0')]train Epoch 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.36it/s, loss=0.351, dice=tensor(3.1962, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                               train Loss: 0.3661 Dice: 0.6392
val Epoch 37:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 37:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.719, dice=tensor(1.3058, device='cuda:0')]val Epoch 37:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.719, dice=tensor(1.3058, device='cuda:0')]val Epoch 37:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.596, dice=tensor(1.6795, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.6572 Dice: 0.3359
Epoch 38/199
----------
train Epoch 38:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 38:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.357, dice=tensor(3.2874, device='cuda:0')]train Epoch 38:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.357, dice=tensor(3.2874, device='cuda:0')]train Epoch 38:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.348, dice=tensor(3.2656, device='cuda:0')]train Epoch 38:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.348, dice=tensor(3.2656, device='cuda:0')]train Epoch 38:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.328, dice=tensor(3.2729, device='cuda:0')]train Epoch 38:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.328, dice=tensor(3.2729, device='cuda:0')]train Epoch 38:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.397, dice=tensor(3.2317, device='cuda:0')]train Epoch 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.397, dice=tensor(3.2317, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3576 Dice: 0.6463
val Epoch 38:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 38:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.854, dice=tensor(0.6647, device='cuda:0')]val Epoch 38:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.854, dice=tensor(0.6647, device='cuda:0')]val Epoch 38:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.806, dice=tensor(0.8003, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.8298 Dice: 0.1601
Epoch 39/199
----------
train Epoch 39:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 39:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.382, dice=tensor(2.9449, device='cuda:0')]train Epoch 39:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.382, dice=tensor(2.9449, device='cuda:0')]train Epoch 39:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.31, dice=tensor(3.1956, device='cuda:0')] train Epoch 39:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.31, dice=tensor(3.1956, device='cuda:0')]train Epoch 39:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.409, dice=tensor(3.1219, device='cuda:0')]train Epoch 39:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.409, dice=tensor(3.1219, device='cuda:0')]train Epoch 39:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.374, dice=tensor(3.1158, device='cuda:0')]train Epoch 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.374, dice=tensor(3.1158, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                               train Loss: 0.3687 Dice: 0.6232
val Epoch 39:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 39:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.946, dice=tensor(0.2540, device='cuda:0')]val Epoch 39:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.45it/s, loss=0.946, dice=tensor(0.2540, device='cuda:0')]val Epoch 39:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.45it/s, loss=0.96, dice=tensor(0.2162, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                            val Loss: 0.9529 Dice: 0.0432
Epoch 40/199
----------
train Epoch 40:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 40:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.3, dice=tensor(3.5310, device='cuda:0')]train Epoch 40:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.3, dice=tensor(3.5310, device='cuda:0')]train Epoch 40:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.401, dice=tensor(3.2809, device='cuda:0')]train Epoch 40:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.401, dice=tensor(3.2809, device='cuda:0')]train Epoch 40:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.368, dice=tensor(3.2606, device='cuda:0')]train Epoch 40:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.368, dice=tensor(3.2606, device='cuda:0')]train Epoch 40:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.362, dice=tensor(3.2243, device='cuda:0')]train Epoch 40: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.362, dice=tensor(3.2243, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                               train Loss: 0.3577 Dice: 0.6449
val Epoch 40:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 40:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.754, dice=tensor(1.1562, device='cuda:0')]val Epoch 40:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.754, dice=tensor(1.1562, device='cuda:0')]val Epoch 40:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.803, dice=tensor(1.0029, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.7786 Dice: 0.2006
Epoch 41/199
----------
train Epoch 41:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 41:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.359, dice=tensor(3.1557, device='cuda:0')]train Epoch 41:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.77it/s, loss=0.359, dice=tensor(3.1557, device='cuda:0')]train Epoch 41:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.77it/s, loss=0.277, dice=tensor(3.3639, device='cuda:0')]train Epoch 41:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.277, dice=tensor(3.3639, device='cuda:0')]train Epoch 41:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.387, dice=tensor(3.2771, device='cuda:0')]train Epoch 41:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.95it/s, loss=0.387, dice=tensor(3.2771, device='cuda:0')]train Epoch 41:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.95it/s, loss=0.386, dice=tensor(3.2443, device='cuda:0')]train Epoch 41: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.59it/s, loss=0.386, dice=tensor(3.2443, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                               train Loss: 0.3523 Dice: 0.6489
val Epoch 41:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 41:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.813, dice=tensor(0.9414, device='cuda:0')]val Epoch 41:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.813, dice=tensor(0.9414, device='cuda:0')]val Epoch 41:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.845, dice=tensor(0.8256, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.8289 Dice: 0.1651
Epoch 42/199
----------
train Epoch 42:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 42:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.352, dice=tensor(3.2891, device='cuda:0')]train Epoch 42:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.352, dice=tensor(3.2891, device='cuda:0')]train Epoch 42:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.391, dice=tensor(3.1526, device='cuda:0')]train Epoch 42:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.391, dice=tensor(3.1526, device='cuda:0')]train Epoch 42:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.296, dice=tensor(3.2822, device='cuda:0')]train Epoch 42:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.296, dice=tensor(3.2822, device='cuda:0')]train Epoch 42:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.386, dice=tensor(3.2377, device='cuda:0')]train Epoch 42: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.386, dice=tensor(3.2377, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.3561 Dice: 0.6475
val Epoch 42:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 42:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.67, dice=tensor(1.6179, device='cuda:0')]val Epoch 42:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.67, dice=tensor(1.6179, device='cuda:0')]val Epoch 42:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.81, dice=tensor(1.2805, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                            val Loss: 0.7402 Dice: 0.2561
Epoch 43/199
----------
train Epoch 43:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 43:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.366, dice=tensor(3.2682, device='cuda:0')]train Epoch 43:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.366, dice=tensor(3.2682, device='cuda:0')]train Epoch 43:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.325, dice=tensor(3.2817, device='cuda:0')]train Epoch 43:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.325, dice=tensor(3.2817, device='cuda:0')]train Epoch 43:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.381, dice=tensor(3.1705, device='cuda:0')]train Epoch 43:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.381, dice=tensor(3.1705, device='cuda:0')]train Epoch 43:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.34, dice=tensor(3.2208, device='cuda:0')] train Epoch 43: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.34, dice=tensor(3.2208, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                              train Loss: 0.3528 Dice: 0.6442
val Epoch 43:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 43:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.681, dice=tensor(1.5485, device='cuda:0')]val Epoch 43:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.681, dice=tensor(1.5485, device='cuda:0')]val Epoch 43:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.64, dice=tensor(1.6971, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                            val Loss: 0.6607 Dice: 0.3394
Epoch 44/199
----------
train Epoch 44:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 44:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.37, dice=tensor(3.2531, device='cuda:0')]train Epoch 44:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.37, dice=tensor(3.2531, device='cuda:0')]train Epoch 44:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.383, dice=tensor(3.1948, device='cuda:0')]train Epoch 44:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.383, dice=tensor(3.1948, device='cuda:0')]train Epoch 44:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s, loss=0.328, dice=tensor(3.2684, device='cuda:0')]train Epoch 44:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.92it/s, loss=0.328, dice=tensor(3.2684, device='cuda:0')]train Epoch 44:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.92it/s, loss=0.317, dice=tensor(3.2928, device='cuda:0')]train Epoch 44: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.58it/s, loss=0.317, dice=tensor(3.2928, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                               train Loss: 0.3494 Dice: 0.6586
val Epoch 44:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 44:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.573, dice=tensor(2.1778, device='cuda:0')]val Epoch 44:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.573, dice=tensor(2.1778, device='cuda:0')]val Epoch 44:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.478, dice=tensor(2.4018, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.5256 Dice: 0.4804
Epoch 45/199
----------
train Epoch 45:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 45:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.439, dice=tensor(2.8439, device='cuda:0')]train Epoch 45:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.439, dice=tensor(2.8439, device='cuda:0')]train Epoch 45:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.369, dice=tensor(2.9874, device='cuda:0')]train Epoch 45:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.369, dice=tensor(2.9874, device='cuda:0')]train Epoch 45:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.326, dice=tensor(3.1191, device='cuda:0')]train Epoch 45:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.326, dice=tensor(3.1191, device='cuda:0')]train Epoch 45:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.322, dice=tensor(3.1929, device='cuda:0')]train Epoch 45: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.322, dice=tensor(3.1929, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                               train Loss: 0.3638 Dice: 0.6386
val Epoch 45:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 45:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.524, dice=tensor(2.4414, device='cuda:0')]val Epoch 45:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.524, dice=tensor(2.4414, device='cuda:0')]val Epoch 45:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.498, dice=tensor(2.4701, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.5111 Dice: 0.4940
Epoch 46/199
----------
train Epoch 46:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 46:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.355, dice=tensor(3.1735, device='cuda:0')]train Epoch 46:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.355, dice=tensor(3.1735, device='cuda:0')]train Epoch 46:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.391, dice=tensor(3.1178, device='cuda:0')]train Epoch 46:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.391, dice=tensor(3.1178, device='cuda:0')]train Epoch 46:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.39, dice=tensor(3.1120, device='cuda:0')] train Epoch 46:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.39, dice=tensor(3.1120, device='cuda:0')]train Epoch 46:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.291, dice=tensor(3.2272, device='cuda:0')]train Epoch 46: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.291, dice=tensor(3.2272, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                               train Loss: 0.3566 Dice: 0.6454
val Epoch 46:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 46:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.478, dice=tensor(2.6792, device='cuda:0')]val Epoch 46:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.478, dice=tensor(2.6792, device='cuda:0')]val Epoch 46:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.368, dice=tensor(2.9846, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.4232 Dice: 0.5969
Epoch 47/199
----------
train Epoch 47:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 47:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.276, dice=tensor(3.6053, device='cuda:0')]train Epoch 47:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.02it/s, loss=0.276, dice=tensor(3.6053, device='cuda:0')]train Epoch 47:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.02it/s, loss=0.379, dice=tensor(3.3806, device='cuda:0')]train Epoch 47:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.33it/s, loss=0.379, dice=tensor(3.3806, device='cuda:0')]train Epoch 47:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.33it/s, loss=0.343, dice=tensor(3.3709, device='cuda:0')]train Epoch 47:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.22it/s, loss=0.343, dice=tensor(3.3709, device='cuda:0')]train Epoch 47:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.22it/s, loss=0.428, dice=tensor(3.2608, device='cuda:0')]train Epoch 47: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.82it/s, loss=0.428, dice=tensor(3.2608, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                               train Loss: 0.3566 Dice: 0.6522
val Epoch 47:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 47:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.389, dice=tensor(3.1208, device='cuda:0')]val Epoch 47:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.389, dice=tensor(3.1208, device='cuda:0')]val Epoch 47:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.418, dice=tensor(3.0841, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.4035 Dice: 0.6168
Epoch 48/199
----------
train Epoch 48:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 48:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.281, dice=tensor(3.6432, device='cuda:0')]train Epoch 48:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.281, dice=tensor(3.6432, device='cuda:0')]train Epoch 48:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.359, dice=tensor(3.4571, device='cuda:0')]train Epoch 48:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.359, dice=tensor(3.4571, device='cuda:0')]train Epoch 48:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.383, dice=tensor(3.3253, device='cuda:0')]train Epoch 48:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.68it/s, loss=0.383, dice=tensor(3.3253, device='cuda:0')]train Epoch 48:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.68it/s, loss=0.387, dice=tensor(3.2690, device='cuda:0')]train Epoch 48: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.387, dice=tensor(3.2690, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.3523 Dice: 0.6538
val Epoch 48:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 48:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.408, dice=tensor(2.9979, device='cuda:0')]val Epoch 48:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.408, dice=tensor(2.9979, device='cuda:0')]val Epoch 48:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.387, dice=tensor(3.0973, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.3977 Dice: 0.6195
Epoch 49/199
----------
train Epoch 49:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 49:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.2506, device='cuda:0')]train Epoch 49:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.48it/s, loss=0.338, dice=tensor(3.2506, device='cuda:0')]train Epoch 49:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.48it/s, loss=0.332, dice=tensor(3.3002, device='cuda:0')]train Epoch 49:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.67it/s, loss=0.332, dice=tensor(3.3002, device='cuda:0')]train Epoch 49:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.67it/s, loss=0.348, dice=tensor(3.3071, device='cuda:0')]train Epoch 49:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.61it/s, loss=0.348, dice=tensor(3.3071, device='cuda:0')]train Epoch 49:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.61it/s, loss=0.341, dice=tensor(3.2957, device='cuda:0')]train Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.31it/s, loss=0.341, dice=tensor(3.2957, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                               train Loss: 0.3399 Dice: 0.6591
val Epoch 49:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 49:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.331, dice=tensor(3.4254, device='cuda:0')]val Epoch 49:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.331, dice=tensor(3.4254, device='cuda:0')]val Epoch 49:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.453, dice=tensor(3.1117, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.3923 Dice: 0.6223
Epoch 50/199
----------
train Epoch 50:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 50:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.4, dice=tensor(3.0593, device='cuda:0')]train Epoch 50:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.82it/s, loss=0.4, dice=tensor(3.0593, device='cuda:0')]train Epoch 50:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.82it/s, loss=0.337, dice=tensor(3.1756, device='cuda:0')]train Epoch 50:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.337, dice=tensor(3.1756, device='cuda:0')]train Epoch 50:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.328, dice=tensor(3.2355, device='cuda:0')]train Epoch 50:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.01it/s, loss=0.328, dice=tensor(3.2355, device='cuda:0')]train Epoch 50:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.01it/s, loss=0.303, dice=tensor(3.3061, device='cuda:0')]train Epoch 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.64it/s, loss=0.303, dice=tensor(3.3061, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                               train Loss: 0.3421 Dice: 0.6612
val Epoch 50:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 50:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.409, dice=tensor(3.0602, device='cuda:0')]val Epoch 50:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.20it/s, loss=0.409, dice=tensor(3.0602, device='cuda:0')]val Epoch 50:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.20it/s, loss=0.364, dice=tensor(3.1103, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.3863 Dice: 0.6221
Epoch 51/199
----------
train Epoch 51:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 51:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.358, dice=tensor(3.1087, device='cuda:0')]train Epoch 51:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.358, dice=tensor(3.1087, device='cuda:0')]train Epoch 51:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.341, dice=tensor(3.2086, device='cuda:0')]train Epoch 51:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.341, dice=tensor(3.2086, device='cuda:0')]train Epoch 51:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.336, dice=tensor(3.2439, device='cuda:0')]train Epoch 51:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.336, dice=tensor(3.2439, device='cuda:0')]train Epoch 51:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.334, dice=tensor(3.2782, device='cuda:0')]train Epoch 51: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.334, dice=tensor(3.2782, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                               train Loss: 0.3422 Dice: 0.6556
val Epoch 51:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 51:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.418, dice=tensor(2.9564, device='cuda:0')]val Epoch 51:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.88it/s, loss=0.418, dice=tensor(2.9564, device='cuda:0')]val Epoch 51:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.88it/s, loss=0.359, dice=tensor(3.1129, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.3886 Dice: 0.6226
Epoch 52/199
----------
train Epoch 52:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 52:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.334, dice=tensor(3.3723, device='cuda:0')]train Epoch 52:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.96it/s, loss=0.334, dice=tensor(3.3723, device='cuda:0')]train Epoch 52:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.96it/s, loss=0.371, dice=tensor(3.2671, device='cuda:0')]train Epoch 52:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.26it/s, loss=0.371, dice=tensor(3.2671, device='cuda:0')]train Epoch 52:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.26it/s, loss=0.308, dice=tensor(3.3136, device='cuda:0')]train Epoch 52:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.15it/s, loss=0.308, dice=tensor(3.3136, device='cuda:0')]train Epoch 52:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.15it/s, loss=0.346, dice=tensor(3.3143, device='cuda:0')]train Epoch 52: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.76it/s, loss=0.346, dice=tensor(3.3143, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3395 Dice: 0.6629
val Epoch 52:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 52:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.393, dice=tensor(3.0672, device='cuda:0')]val Epoch 52:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.393, dice=tensor(3.0672, device='cuda:0')]val Epoch 52:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.386, dice=tensor(3.1192, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3893 Dice: 0.6238
Epoch 53/199
----------
train Epoch 53:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 53:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.304, dice=tensor(3.4774, device='cuda:0')]train Epoch 53:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.304, dice=tensor(3.4774, device='cuda:0')]train Epoch 53:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.303, dice=tensor(3.5075, device='cuda:0')]train Epoch 53:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.303, dice=tensor(3.5075, device='cuda:0')]train Epoch 53:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.376, dice=tensor(3.3864, device='cuda:0')]train Epoch 53:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.96it/s, loss=0.376, dice=tensor(3.3864, device='cuda:0')]train Epoch 53:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.96it/s, loss=0.382, dice=tensor(3.3332, device='cuda:0')]train Epoch 53: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.59it/s, loss=0.382, dice=tensor(3.3332, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.3412 Dice: 0.6666
val Epoch 53:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 53:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.357, dice=tensor(3.3488, device='cuda:0')]val Epoch 53:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.357, dice=tensor(3.3488, device='cuda:0')]val Epoch 53:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.433, dice=tensor(3.1259, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.3951 Dice: 0.6252
Epoch 54/199
----------
train Epoch 54:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 54:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.363, dice=tensor(3.1455, device='cuda:0')]train Epoch 54:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.363, dice=tensor(3.1455, device='cuda:0')]train Epoch 54:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.367, dice=tensor(3.1820, device='cuda:0')]train Epoch 54:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.367, dice=tensor(3.1820, device='cuda:0')]train Epoch 54:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.34, dice=tensor(3.2391, device='cuda:0')] train Epoch 54:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.34, dice=tensor(3.2391, device='cuda:0')]train Epoch 54:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.302, dice=tensor(3.3052, device='cuda:0')]train Epoch 54: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.302, dice=tensor(3.3052, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                               train Loss: 0.3432 Dice: 0.6610
val Epoch 54:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 54:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.391, dice=tensor(3.2023, device='cuda:0')]val Epoch 54:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.391, dice=tensor(3.2023, device='cuda:0')]val Epoch 54:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.414, dice=tensor(3.0863, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.4026 Dice: 0.6173
Epoch 55/199
----------
train Epoch 55:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 55:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.312, dice=tensor(3.4708, device='cuda:0')]train Epoch 55:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.312, dice=tensor(3.4708, device='cuda:0')]train Epoch 55:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.308, dice=tensor(3.4644, device='cuda:0')]train Epoch 55:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.308, dice=tensor(3.4644, device='cuda:0')]train Epoch 55:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.364, dice=tensor(3.3334, device='cuda:0')]train Epoch 55:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.364, dice=tensor(3.3334, device='cuda:0')]train Epoch 55:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.383, dice=tensor(3.2803, device='cuda:0')]train Epoch 55: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.383, dice=tensor(3.2803, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                               train Loss: 0.3418 Dice: 0.6561
val Epoch 55:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 55:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.436, dice=tensor(3.0649, device='cuda:0')]val Epoch 55:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.436, dice=tensor(3.0649, device='cuda:0')]val Epoch 55:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.505, dice=tensor(2.7923, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.4707 Dice: 0.5585
Epoch 56/199
----------
train Epoch 56:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 56:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.34, dice=tensor(3.3605, device='cuda:0')]train Epoch 56:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.34, dice=tensor(3.3605, device='cuda:0')]train Epoch 56:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.31, dice=tensor(3.4074, device='cuda:0')]train Epoch 56:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.31, dice=tensor(3.4074, device='cuda:0')]train Epoch 56:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.335, dice=tensor(3.3727, device='cuda:0')]train Epoch 56:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.94it/s, loss=0.335, dice=tensor(3.3727, device='cuda:0')]train Epoch 56:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.94it/s, loss=0.353, dice=tensor(3.3350, device='cuda:0')]train Epoch 56: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.59it/s, loss=0.353, dice=tensor(3.3350, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                               train Loss: 0.3347 Dice: 0.6670
val Epoch 56:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 56:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.516, dice=tensor(2.2718, device='cuda:0')]val Epoch 56:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.86it/s, loss=0.516, dice=tensor(2.2718, device='cuda:0')]val Epoch 56:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.86it/s, loss=0.561, dice=tensor(2.2095, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.5385 Dice: 0.4419
Epoch 57/199
----------
train Epoch 57:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 57:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.364, dice=tensor(3.1826, device='cuda:0')]train Epoch 57:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.85it/s, loss=0.364, dice=tensor(3.1826, device='cuda:0')]train Epoch 57:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.85it/s, loss=0.347, dice=tensor(3.2289, device='cuda:0')]train Epoch 57:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.14it/s, loss=0.347, dice=tensor(3.2289, device='cuda:0')]train Epoch 57:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.14it/s, loss=0.394, dice=tensor(3.1088, device='cuda:0')]train Epoch 57:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.05it/s, loss=0.394, dice=tensor(3.1088, device='cuda:0')]train Epoch 57:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.05it/s, loss=0.292, dice=tensor(3.2265, device='cuda:0')]train Epoch 57: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.67it/s, loss=0.292, dice=tensor(3.2265, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                               train Loss: 0.3491 Dice: 0.6453
val Epoch 57:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 57:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.411, dice=tensor(3.1784, device='cuda:0')]val Epoch 57:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.411, dice=tensor(3.1784, device='cuda:0')]val Epoch 57:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.474, dice=tensor(2.8917, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.4425 Dice: 0.5783
Epoch 58/199
----------
train Epoch 58:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 58:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.354, dice=tensor(3.2276, device='cuda:0')]train Epoch 58:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.354, dice=tensor(3.2276, device='cuda:0')]train Epoch 58:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.317, dice=tensor(3.3109, device='cuda:0')]train Epoch 58:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.317, dice=tensor(3.3109, device='cuda:0')]train Epoch 58:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.333, dice=tensor(3.3395, device='cuda:0')]train Epoch 58:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.333, dice=tensor(3.3395, device='cuda:0')]train Epoch 58:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.368, dice=tensor(3.2841, device='cuda:0')]train Epoch 58: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.368, dice=tensor(3.2841, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                               train Loss: 0.3432 Dice: 0.6568
val Epoch 58:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 58:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.384, dice=tensor(3.0776, device='cuda:0')]val Epoch 58:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.384, dice=tensor(3.0776, device='cuda:0')]val Epoch 58:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.374, dice=tensor(3.1440, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.3788 Dice: 0.6288
Epoch 59/199
----------
train Epoch 59:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 59:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.346, dice=tensor(3.2913, device='cuda:0')]train Epoch 59:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.346, dice=tensor(3.2913, device='cuda:0')]train Epoch 59:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.345, dice=tensor(3.2668, device='cuda:0')]train Epoch 59:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.345, dice=tensor(3.2668, device='cuda:0')]train Epoch 59:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.312, dice=tensor(3.3350, device='cuda:0')]train Epoch 59:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.312, dice=tensor(3.3350, device='cuda:0')]train Epoch 59:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.388, dice=tensor(3.2827, device='cuda:0')]train Epoch 59: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.388, dice=tensor(3.2827, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                               train Loss: 0.3480 Dice: 0.6565
val Epoch 59:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 59:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.323, dice=tensor(3.4379, device='cuda:0')]val Epoch 59:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.323, dice=tensor(3.4379, device='cuda:0')]val Epoch 59:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.433, dice=tensor(3.1542, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.3777 Dice: 0.6308
Epoch 60/199
----------
train Epoch 60:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 60:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.34, dice=tensor(3.3652, device='cuda:0')]train Epoch 60:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.34, dice=tensor(3.3652, device='cuda:0')]train Epoch 60:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.317, dice=tensor(3.3747, device='cuda:0')]train Epoch 60:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.317, dice=tensor(3.3747, device='cuda:0')]train Epoch 60:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.375, dice=tensor(3.2697, device='cuda:0')]train Epoch 60:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.93it/s, loss=0.375, dice=tensor(3.2697, device='cuda:0')]train Epoch 60:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.93it/s, loss=0.351, dice=tensor(3.2660, device='cuda:0')]train Epoch 60: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.58it/s, loss=0.351, dice=tensor(3.2660, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                               train Loss: 0.3459 Dice: 0.6532
val Epoch 60:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 60:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.328, dice=tensor(3.4277, device='cuda:0')]val Epoch 60:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.328, dice=tensor(3.4277, device='cuda:0')]val Epoch 60:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.438, dice=tensor(3.1442, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.3828 Dice: 0.6288
Epoch 61/199
----------
train Epoch 61:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 61:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.354, dice=tensor(3.2970, device='cuda:0')]train Epoch 61:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.354, dice=tensor(3.2970, device='cuda:0')]train Epoch 61:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.318, dice=tensor(3.3329, device='cuda:0')]train Epoch 61:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.318, dice=tensor(3.3329, device='cuda:0')]train Epoch 61:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.309, dice=tensor(3.3713, device='cuda:0')]train Epoch 61:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.65it/s, loss=0.309, dice=tensor(3.3713, device='cuda:0')]train Epoch 61:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.65it/s, loss=0.353, dice=tensor(3.3484, device='cuda:0')]train Epoch 61: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.35it/s, loss=0.353, dice=tensor(3.3484, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                               train Loss: 0.3334 Dice: 0.6697
val Epoch 61:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 61:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.37, dice=tensor(3.2291, device='cuda:0')]val Epoch 61:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.87it/s, loss=0.37, dice=tensor(3.2291, device='cuda:0')]val Epoch 61:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.87it/s, loss=0.389, dice=tensor(3.1453, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.3792 Dice: 0.6291
Epoch 62/199
----------
train Epoch 62:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 62:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.368, dice=tensor(3.1816, device='cuda:0')]train Epoch 62:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.368, dice=tensor(3.1816, device='cuda:0')]train Epoch 62:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.322, dice=tensor(3.3212, device='cuda:0')]train Epoch 62:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.322, dice=tensor(3.3212, device='cuda:0')]train Epoch 62:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.371, dice=tensor(3.2948, device='cuda:0')]train Epoch 62:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.371, dice=tensor(3.2948, device='cuda:0')]train Epoch 62:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.332, dice=tensor(3.2921, device='cuda:0')]train Epoch 62: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.332, dice=tensor(3.2921, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                               train Loss: 0.3483 Dice: 0.6584
val Epoch 62:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 62:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.405, dice=tensor(3.0113, device='cuda:0')]val Epoch 62:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.83it/s, loss=0.405, dice=tensor(3.0113, device='cuda:0')]val Epoch 62:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.83it/s, loss=0.352, dice=tensor(3.1505, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.3785 Dice: 0.6301
Epoch 63/199
----------
train Epoch 63:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 63:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.299, dice=tensor(3.4931, device='cuda:0')]train Epoch 63:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.299, dice=tensor(3.4931, device='cuda:0')]train Epoch 63:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.355, dice=tensor(3.3296, device='cuda:0')]train Epoch 63:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.355, dice=tensor(3.3296, device='cuda:0')]train Epoch 63:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.352, dice=tensor(3.3249, device='cuda:0')]train Epoch 63:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.94it/s, loss=0.352, dice=tensor(3.3249, device='cuda:0')]train Epoch 63:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.94it/s, loss=0.355, dice=tensor(3.3051, device='cuda:0')]train Epoch 63: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.59it/s, loss=0.355, dice=tensor(3.3051, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3403 Dice: 0.6610
val Epoch 63:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 63:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.394, dice=tensor(3.0438, device='cuda:0')]val Epoch 63:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.394, dice=tensor(3.0438, device='cuda:0')]val Epoch 63:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.361, dice=tensor(3.1518, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.3777 Dice: 0.6304
Epoch 64/199
----------
train Epoch 64:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 64:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.352, dice=tensor(3.2696, device='cuda:0')]train Epoch 64:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.352, dice=tensor(3.2696, device='cuda:0')]train Epoch 64:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.319, dice=tensor(3.3104, device='cuda:0')]train Epoch 64:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.319, dice=tensor(3.3104, device='cuda:0')]train Epoch 64:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.345, dice=tensor(3.3064, device='cuda:0')]train Epoch 64:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.93it/s, loss=0.345, dice=tensor(3.3064, device='cuda:0')]train Epoch 64:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.93it/s, loss=0.326, dice=tensor(3.3135, device='cuda:0')]train Epoch 64: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.58it/s, loss=0.326, dice=tensor(3.3135, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3356 Dice: 0.6627
val Epoch 64:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 64:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.2251, device='cuda:0')]val Epoch 64:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.87it/s, loss=0.345, dice=tensor(3.2251, device='cuda:0')]val Epoch 64:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.87it/s, loss=0.409, dice=tensor(3.1439, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.3771 Dice: 0.6288
Epoch 65/199
----------
train Epoch 65:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 65:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.328, dice=tensor(3.2705, device='cuda:0')]train Epoch 65:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.328, dice=tensor(3.2705, device='cuda:0')]train Epoch 65:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.322, dice=tensor(3.3535, device='cuda:0')]train Epoch 65:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.322, dice=tensor(3.3535, device='cuda:0')]train Epoch 65:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.336, dice=tensor(3.3331, device='cuda:0')]train Epoch 65:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.336, dice=tensor(3.3331, device='cuda:0')]train Epoch 65:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.367, dice=tensor(3.3118, device='cuda:0')]train Epoch 65: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.367, dice=tensor(3.3118, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                               train Loss: 0.3381 Dice: 0.6624
val Epoch 65:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 65:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.36, dice=tensor(3.2965, device='cuda:0')]val Epoch 65:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.36, dice=tensor(3.2965, device='cuda:0')]val Epoch 65:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.417, dice=tensor(3.1012, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.3886 Dice: 0.6202
Epoch 66/199
----------
train Epoch 66:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 66:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.3206, device='cuda:0')]train Epoch 66:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.333, dice=tensor(3.3206, device='cuda:0')]train Epoch 66:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.34, dice=tensor(3.3226, device='cuda:0')] train Epoch 66:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.34, dice=tensor(3.3226, device='cuda:0')]train Epoch 66:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.309, dice=tensor(3.3899, device='cuda:0')]train Epoch 66:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.74it/s, loss=0.309, dice=tensor(3.3899, device='cuda:0')]train Epoch 66:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.74it/s, loss=0.368, dice=tensor(3.3458, device='cuda:0')]train Epoch 66: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.368, dice=tensor(3.3458, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                               train Loss: 0.3375 Dice: 0.6692
val Epoch 66:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 66:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.444, dice=tensor(2.8578, device='cuda:0')]val Epoch 66:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.444, dice=tensor(2.8578, device='cuda:0')]val Epoch 66:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.413, dice=tensor(2.9140, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.4282 Dice: 0.5828
Epoch 67/199
----------
train Epoch 67:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 67:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.303, dice=tensor(3.5146, device='cuda:0')]train Epoch 67:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.83it/s, loss=0.303, dice=tensor(3.5146, device='cuda:0')]train Epoch 67:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.83it/s, loss=0.316, dice=tensor(3.4618, device='cuda:0')]train Epoch 67:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.11it/s, loss=0.316, dice=tensor(3.4618, device='cuda:0')]train Epoch 67:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.11it/s, loss=0.369, dice=tensor(3.3601, device='cuda:0')]train Epoch 67:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.02it/s, loss=0.369, dice=tensor(3.3601, device='cuda:0')]train Epoch 67:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.02it/s, loss=0.369, dice=tensor(3.2954, device='cuda:0')]train Epoch 67: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.66it/s, loss=0.369, dice=tensor(3.2954, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3393 Dice: 0.6591
val Epoch 67:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 67:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.441, dice=tensor(2.9244, device='cuda:0')]val Epoch 67:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.441, dice=tensor(2.9244, device='cuda:0')]val Epoch 67:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.544, dice=tensor(2.6176, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.4926 Dice: 0.5235
Epoch 68/199
----------
train Epoch 68:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 68:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.291, dice=tensor(3.5692, device='cuda:0')]train Epoch 68:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.01it/s, loss=0.291, dice=tensor(3.5692, device='cuda:0')]train Epoch 68:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.01it/s, loss=0.359, dice=tensor(3.3901, device='cuda:0')]train Epoch 68:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.32it/s, loss=0.359, dice=tensor(3.3901, device='cuda:0')]train Epoch 68:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.32it/s, loss=0.356, dice=tensor(3.3411, device='cuda:0')]train Epoch 68:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.20it/s, loss=0.356, dice=tensor(3.3411, device='cuda:0')]train Epoch 68:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.20it/s, loss=0.323, dice=tensor(3.3299, device='cuda:0')]train Epoch 68: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.81it/s, loss=0.323, dice=tensor(3.3299, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3321 Dice: 0.6660
val Epoch 68:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 68:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.483, dice=tensor(2.6781, device='cuda:0')]val Epoch 68:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.483, dice=tensor(2.6781, device='cuda:0')]val Epoch 68:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.549, dice=tensor(2.5067, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.5158 Dice: 0.5013
Epoch 69/199
----------
train Epoch 69:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 69:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.321, dice=tensor(3.3459, device='cuda:0')]train Epoch 69:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.321, dice=tensor(3.3459, device='cuda:0')]train Epoch 69:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.322, dice=tensor(3.3809, device='cuda:0')]train Epoch 69:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.322, dice=tensor(3.3809, device='cuda:0')]train Epoch 69:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.396, dice=tensor(3.2882, device='cuda:0')]train Epoch 69:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.67it/s, loss=0.396, dice=tensor(3.2882, device='cuda:0')]train Epoch 69:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.67it/s, loss=0.317, dice=tensor(3.3311, device='cuda:0')]train Epoch 69: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.36it/s, loss=0.317, dice=tensor(3.3311, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                               train Loss: 0.3387 Dice: 0.6662
val Epoch 69:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 69:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.487, dice=tensor(2.6131, device='cuda:0')]val Epoch 69:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.487, dice=tensor(2.6131, device='cuda:0')]val Epoch 69:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.526, dice=tensor(2.5332, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.5066 Dice: 0.5066
Epoch 70/199
----------
train Epoch 70:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 70:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.326, dice=tensor(3.3855, device='cuda:0')]train Epoch 70:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.326, dice=tensor(3.3855, device='cuda:0')]train Epoch 70:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.358, dice=tensor(3.2923, device='cuda:0')]train Epoch 70:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.09it/s, loss=0.358, dice=tensor(3.2923, device='cuda:0')]train Epoch 70:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.09it/s, loss=0.352, dice=tensor(3.2902, device='cuda:0')]train Epoch 70:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.00it/s, loss=0.352, dice=tensor(3.2902, device='cuda:0')]train Epoch 70:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.00it/s, loss=0.298, dice=tensor(3.3534, device='cuda:0')]train Epoch 70: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.63it/s, loss=0.298, dice=tensor(3.3534, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                               train Loss: 0.3335 Dice: 0.6707
val Epoch 70:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 70:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.496, dice=tensor(2.5858, device='cuda:0')]val Epoch 70:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.32it/s, loss=0.496, dice=tensor(2.5858, device='cuda:0')]val Epoch 70:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.32it/s, loss=0.449, dice=tensor(2.6956, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.4727 Dice: 0.5391
Epoch 71/199
----------
train Epoch 71:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 71:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.309, dice=tensor(3.4208, device='cuda:0')]train Epoch 71:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.42it/s, loss=0.309, dice=tensor(3.4208, device='cuda:0')]train Epoch 71:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.42it/s, loss=0.361, dice=tensor(3.2970, device='cuda:0')]train Epoch 71:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.59it/s, loss=0.361, dice=tensor(3.2970, device='cuda:0')]train Epoch 71:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.59it/s, loss=0.316, dice=tensor(3.3597, device='cuda:0')]train Epoch 71:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.52it/s, loss=0.316, dice=tensor(3.3597, device='cuda:0')]train Epoch 71:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.52it/s, loss=0.364, dice=tensor(3.3228, device='cuda:0')]train Epoch 71: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.24it/s, loss=0.364, dice=tensor(3.3228, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.3378 Dice: 0.6646
val Epoch 71:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 71:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.46, dice=tensor(2.7228, device='cuda:0')]val Epoch 71:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.46, dice=tensor(2.7228, device='cuda:0')]val Epoch 71:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.387, dice=tensor(2.9323, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.4239 Dice: 0.5865
Epoch 72/199
----------
train Epoch 72:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 72:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.294, dice=tensor(3.5591, device='cuda:0')]train Epoch 72:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.294, dice=tensor(3.5591, device='cuda:0')]train Epoch 72:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.353, dice=tensor(3.4139, device='cuda:0')]train Epoch 72:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.353, dice=tensor(3.4139, device='cuda:0')]train Epoch 72:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.416, dice=tensor(3.2566, device='cuda:0')]train Epoch 72:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.416, dice=tensor(3.2566, device='cuda:0')]train Epoch 72:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.309, dice=tensor(3.3014, device='cuda:0')]train Epoch 72: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.309, dice=tensor(3.3014, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                               train Loss: 0.3431 Dice: 0.6603
val Epoch 72:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 72:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.393, dice=tensor(3.0350, device='cuda:0')]val Epoch 72:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.393, dice=tensor(3.0350, device='cuda:0')]val Epoch 72:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.402, dice=tensor(3.0357, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.3978 Dice: 0.6071
Epoch 73/199
----------
train Epoch 73:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 73:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.379, dice=tensor(3.1517, device='cuda:0')]train Epoch 73:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.379, dice=tensor(3.1517, device='cuda:0')]train Epoch 73:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.322, dice=tensor(3.2519, device='cuda:0')]train Epoch 73:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.322, dice=tensor(3.2519, device='cuda:0')]train Epoch 73:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.302, dice=tensor(3.3540, device='cuda:0')]train Epoch 73:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.302, dice=tensor(3.3540, device='cuda:0')]train Epoch 73:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.362, dice=tensor(3.3249, device='cuda:0')]train Epoch 73: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.362, dice=tensor(3.3249, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3415 Dice: 0.6650
val Epoch 73:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 73:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.365, dice=tensor(3.2442, device='cuda:0')]val Epoch 73:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.365, dice=tensor(3.2442, device='cuda:0')]val Epoch 73:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.388, dice=tensor(3.1585, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.3766 Dice: 0.6317
Epoch 74/199
----------
train Epoch 74:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 74:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.367, dice=tensor(3.2113, device='cuda:0')]train Epoch 74:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.367, dice=tensor(3.2113, device='cuda:0')]train Epoch 74:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.303, dice=tensor(3.3591, device='cuda:0')]train Epoch 74:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.303, dice=tensor(3.3591, device='cuda:0')]train Epoch 74:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.344, dice=tensor(3.3431, device='cuda:0')]train Epoch 74:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.344, dice=tensor(3.3431, device='cuda:0')]train Epoch 74:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.334, dice=tensor(3.3376, device='cuda:0')]train Epoch 74: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.334, dice=tensor(3.3376, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                               train Loss: 0.3368 Dice: 0.6675
val Epoch 74:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 74:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.334, dice=tensor(3.4017, device='cuda:0')]val Epoch 74:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.334, dice=tensor(3.4017, device='cuda:0')]val Epoch 74:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.426, dice=tensor(3.1628, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.3801 Dice: 0.6326
Epoch 75/199
----------
train Epoch 75:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 75:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.351, dice=tensor(3.2511, device='cuda:0')]train Epoch 75:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.351, dice=tensor(3.2511, device='cuda:0')]train Epoch 75:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.343, dice=tensor(3.2677, device='cuda:0')]train Epoch 75:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.69it/s, loss=0.343, dice=tensor(3.2677, device='cuda:0')]train Epoch 75:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.69it/s, loss=0.322, dice=tensor(3.3142, device='cuda:0')]train Epoch 75:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.62it/s, loss=0.322, dice=tensor(3.3142, device='cuda:0')]train Epoch 75:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.62it/s, loss=0.325, dice=tensor(3.3375, device='cuda:0')]train Epoch 75: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.32it/s, loss=0.325, dice=tensor(3.3375, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                               train Loss: 0.3354 Dice: 0.6675
val Epoch 75:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 75:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.434, dice=tensor(2.8968, device='cuda:0')]val Epoch 75:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.434, dice=tensor(2.8968, device='cuda:0')]val Epoch 75:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.326, dice=tensor(3.1624, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.3799 Dice: 0.6325
Epoch 76/199
----------
train Epoch 76:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 76:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.307, dice=tensor(3.5043, device='cuda:0')]train Epoch 76:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.307, dice=tensor(3.5043, device='cuda:0')]train Epoch 76:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.34, dice=tensor(3.3667, device='cuda:0')] train Epoch 76:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.34, dice=tensor(3.3667, device='cuda:0')]train Epoch 76:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.387, dice=tensor(3.2955, device='cuda:0')]train Epoch 76:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.387, dice=tensor(3.2955, device='cuda:0')]train Epoch 76:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.333, dice=tensor(3.2953, device='cuda:0')]train Epoch 76: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.333, dice=tensor(3.2953, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                               train Loss: 0.3417 Dice: 0.6591
val Epoch 76:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 76:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.2474, device='cuda:0')]val Epoch 76:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.345, dice=tensor(3.2474, device='cuda:0')]val Epoch 76:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.408, dice=tensor(3.1503, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.3763 Dice: 0.6301
Epoch 77/199
----------
train Epoch 77:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 77:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.342, dice=tensor(3.3538, device='cuda:0')]train Epoch 77:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.77it/s, loss=0.342, dice=tensor(3.3538, device='cuda:0')]train Epoch 77:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.77it/s, loss=0.353, dice=tensor(3.2403, device='cuda:0')]train Epoch 77:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.353, dice=tensor(3.2403, device='cuda:0')]train Epoch 77:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.342, dice=tensor(3.2750, device='cuda:0')]train Epoch 77:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.96it/s, loss=0.342, dice=tensor(3.2750, device='cuda:0')]train Epoch 77:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.96it/s, loss=0.309, dice=tensor(3.3132, device='cuda:0')]train Epoch 77: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.61it/s, loss=0.309, dice=tensor(3.3132, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                               train Loss: 0.3364 Dice: 0.6626
val Epoch 77:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 77:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.418, dice=tensor(3.0007, device='cuda:0')]val Epoch 77:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.418, dice=tensor(3.0007, device='cuda:0')]val Epoch 77:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.346, dice=tensor(3.1291, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.3817 Dice: 0.6258
Epoch 78/199
----------
train Epoch 78:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 78:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.331, dice=tensor(3.3347, device='cuda:0')]train Epoch 78:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.331, dice=tensor(3.3347, device='cuda:0')]train Epoch 78:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.359, dice=tensor(3.1899, device='cuda:0')]train Epoch 78:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.359, dice=tensor(3.1899, device='cuda:0')]train Epoch 78:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.377, dice=tensor(3.1424, device='cuda:0')]train Epoch 78:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.377, dice=tensor(3.1424, device='cuda:0')]train Epoch 78:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.296, dice=tensor(3.2467, device='cuda:0')]train Epoch 78: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.296, dice=tensor(3.2467, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3410 Dice: 0.6493
val Epoch 78:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 78:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.336, dice=tensor(3.3899, device='cuda:0')]val Epoch 78:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.336, dice=tensor(3.3899, device='cuda:0')]val Epoch 78:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.439, dice=tensor(3.1183, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                             val Loss: 0.3876 Dice: 0.6237
Epoch 79/199
----------
train Epoch 79:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 79:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.378, dice=tensor(3.1547, device='cuda:0')]train Epoch 79:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.378, dice=tensor(3.1547, device='cuda:0')]train Epoch 79:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.305, dice=tensor(3.3181, device='cuda:0')]train Epoch 79:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.305, dice=tensor(3.3181, device='cuda:0')]train Epoch 79:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.287, dice=tensor(3.4082, device='cuda:0')]train Epoch 79:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.287, dice=tensor(3.4082, device='cuda:0')]train Epoch 79:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.37, dice=tensor(3.3498, device='cuda:0')] train Epoch 79: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.37, dice=tensor(3.3498, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                              train Loss: 0.3348 Dice: 0.6700
val Epoch 79:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 79:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.35, dice=tensor(3.3375, device='cuda:0')]val Epoch 79:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.35, dice=tensor(3.3375, device='cuda:0')]val Epoch 79:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.414, dice=tensor(3.1348, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.3823 Dice: 0.6270
Epoch 80/199
----------
train Epoch 80:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 80:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.353, dice=tensor(3.3197, device='cuda:0')]train Epoch 80:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.353, dice=tensor(3.3197, device='cuda:0')]train Epoch 80:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.332, dice=tensor(3.3365, device='cuda:0')]train Epoch 80:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.332, dice=tensor(3.3365, device='cuda:0')]train Epoch 80:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.295, dice=tensor(3.3958, device='cuda:0')]train Epoch 80:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.295, dice=tensor(3.3958, device='cuda:0')]train Epoch 80:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.325, dice=tensor(3.3944, device='cuda:0')]train Epoch 80: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.325, dice=tensor(3.3944, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3261 Dice: 0.6789
val Epoch 80:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 80:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.372, dice=tensor(3.2065, device='cuda:0')]val Epoch 80:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.372, dice=tensor(3.2065, device='cuda:0')]val Epoch 80:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.382, dice=tensor(3.1584, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.3768 Dice: 0.6317
Epoch 81/199
----------
train Epoch 81:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 81:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.36, dice=tensor(3.1789, device='cuda:0')]train Epoch 81:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.36, dice=tensor(3.1789, device='cuda:0')]train Epoch 81:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.32, dice=tensor(3.3003, device='cuda:0')]train Epoch 81:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.69it/s, loss=0.32, dice=tensor(3.3003, device='cuda:0')]train Epoch 81:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.69it/s, loss=0.338, dice=tensor(3.3025, device='cuda:0')]train Epoch 81:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.63it/s, loss=0.338, dice=tensor(3.3025, device='cuda:0')]train Epoch 81:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.63it/s, loss=0.369, dice=tensor(3.2790, device='cuda:0')]train Epoch 81: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.33it/s, loss=0.369, dice=tensor(3.2790, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.3465 Dice: 0.6558
val Epoch 81:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 81:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.389, dice=tensor(3.1573, device='cuda:0')]val Epoch 81:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.83it/s, loss=0.389, dice=tensor(3.1573, device='cuda:0')]val Epoch 81:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.83it/s, loss=0.353, dice=tensor(3.1788, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.3711 Dice: 0.6358
Epoch 82/199
----------
train Epoch 82:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 82:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.323, dice=tensor(3.4037, device='cuda:0')]train Epoch 82:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.82it/s, loss=0.323, dice=tensor(3.4037, device='cuda:0')]train Epoch 82:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.82it/s, loss=0.329, dice=tensor(3.3810, device='cuda:0')]train Epoch 82:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.329, dice=tensor(3.3810, device='cuda:0')]train Epoch 82:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.366, dice=tensor(3.3311, device='cuda:0')]train Epoch 82:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.01it/s, loss=0.366, dice=tensor(3.3311, device='cuda:0')]train Epoch 82:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.01it/s, loss=0.316, dice=tensor(3.3517, device='cuda:0')]train Epoch 82: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.64it/s, loss=0.316, dice=tensor(3.3517, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3338 Dice: 0.6703
val Epoch 82:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 82:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.371, dice=tensor(3.2113, device='cuda:0')]val Epoch 82:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.76it/s, loss=0.371, dice=tensor(3.2113, device='cuda:0')]val Epoch 82:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.76it/s, loss=0.369, dice=tensor(3.1803, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.3702 Dice: 0.6361
Epoch 83/199
----------
train Epoch 83:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 83:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.297, dice=tensor(3.5047, device='cuda:0')]train Epoch 83:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.297, dice=tensor(3.5047, device='cuda:0')]train Epoch 83:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.363, dice=tensor(3.3517, device='cuda:0')]train Epoch 83:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.363, dice=tensor(3.3517, device='cuda:0')]train Epoch 83:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.344, dice=tensor(3.3376, device='cuda:0')]train Epoch 83:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.95it/s, loss=0.344, dice=tensor(3.3376, device='cuda:0')]train Epoch 83:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.95it/s, loss=0.314, dice=tensor(3.3591, device='cuda:0')]train Epoch 83: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.60it/s, loss=0.314, dice=tensor(3.3591, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                               train Loss: 0.3298 Dice: 0.6718
val Epoch 83:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 83:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.381, dice=tensor(3.0947, device='cuda:0')]val Epoch 83:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.76it/s, loss=0.381, dice=tensor(3.0947, device='cuda:0')]val Epoch 83:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.76it/s, loss=0.363, dice=tensor(3.1759, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.3720 Dice: 0.6352
Epoch 84/199
----------
train Epoch 84:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 84:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.339, dice=tensor(3.3051, device='cuda:0')]train Epoch 84:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.339, dice=tensor(3.3051, device='cuda:0')]train Epoch 84:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.337, dice=tensor(3.3088, device='cuda:0')]train Epoch 84:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.337, dice=tensor(3.3088, device='cuda:0')]train Epoch 84:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.286, dice=tensor(3.3986, device='cuda:0')]train Epoch 84:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.286, dice=tensor(3.3986, device='cuda:0')]train Epoch 84:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.371, dice=tensor(3.3541, device='cuda:0')]train Epoch 84: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.371, dice=tensor(3.3541, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                               train Loss: 0.3333 Dice: 0.6708
val Epoch 84:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 84:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.411, dice=tensor(2.9804, device='cuda:0')]val Epoch 84:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.411, dice=tensor(2.9804, device='cuda:0')]val Epoch 84:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.34, dice=tensor(3.1690, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                            val Loss: 0.3753 Dice: 0.6338
Epoch 85/199
----------
train Epoch 85:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 85:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.344, dice=tensor(3.2656, device='cuda:0')]train Epoch 85:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.80it/s, loss=0.344, dice=tensor(3.2656, device='cuda:0')]train Epoch 85:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.80it/s, loss=0.363, dice=tensor(3.1928, device='cuda:0')]train Epoch 85:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.08it/s, loss=0.363, dice=tensor(3.1928, device='cuda:0')]train Epoch 85:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.08it/s, loss=0.322, dice=tensor(3.2733, device='cuda:0')]train Epoch 85:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.99it/s, loss=0.322, dice=tensor(3.2733, device='cuda:0')]train Epoch 85:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.99it/s, loss=0.322, dice=tensor(3.3009, device='cuda:0')]train Epoch 85: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.63it/s, loss=0.322, dice=tensor(3.3009, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3377 Dice: 0.6602
val Epoch 85:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 85:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.355, dice=tensor(3.2974, device='cuda:0')]val Epoch 85:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.81it/s, loss=0.355, dice=tensor(3.2974, device='cuda:0')]val Epoch 85:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.81it/s, loss=0.387, dice=tensor(3.1821, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.3711 Dice: 0.6364
Epoch 86/199
----------
train Epoch 86:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 86:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.316, dice=tensor(3.4426, device='cuda:0')]train Epoch 86:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.316, dice=tensor(3.4426, device='cuda:0')]train Epoch 86:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.329, dice=tensor(3.3829, device='cuda:0')]train Epoch 86:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.329, dice=tensor(3.3829, device='cuda:0')]train Epoch 86:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.315, dice=tensor(3.4090, device='cuda:0')]train Epoch 86:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.315, dice=tensor(3.4090, device='cuda:0')]train Epoch 86:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.377, dice=tensor(3.3410, device='cuda:0')]train Epoch 86: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.377, dice=tensor(3.3410, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.3344 Dice: 0.6682
val Epoch 86:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 86:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.379, dice=tensor(3.0933, device='cuda:0')]val Epoch 86:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.379, dice=tensor(3.0933, device='cuda:0')]val Epoch 86:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.358, dice=tensor(3.1899, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3685 Dice: 0.6380
Epoch 87/199
----------
train Epoch 87:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 87:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.344, dice=tensor(3.3069, device='cuda:0')]train Epoch 87:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.82it/s, loss=0.344, dice=tensor(3.3069, device='cuda:0')]train Epoch 87:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.82it/s, loss=0.377, dice=tensor(3.2287, device='cuda:0')]train Epoch 87:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.11it/s, loss=0.377, dice=tensor(3.2287, device='cuda:0')]train Epoch 87:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.11it/s, loss=0.316, dice=tensor(3.2738, device='cuda:0')]train Epoch 87:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.01it/s, loss=0.316, dice=tensor(3.2738, device='cuda:0')]train Epoch 87:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.01it/s, loss=0.303, dice=tensor(3.3369, device='cuda:0')]train Epoch 87: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.64it/s, loss=0.303, dice=tensor(3.3369, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                               train Loss: 0.3351 Dice: 0.6674
val Epoch 87:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 87:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.394, dice=tensor(3.0098, device='cuda:0')]val Epoch 87:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.394, dice=tensor(3.0098, device='cuda:0')]val Epoch 87:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.54it/s, loss=0.346, dice=tensor(3.1763, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.3699 Dice: 0.6353
Epoch 88/199
----------
train Epoch 88:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 88:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.414, dice=tensor(3.0163, device='cuda:0')]train Epoch 88:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.414, dice=tensor(3.0163, device='cuda:0')]train Epoch 88:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.325, dice=tensor(3.1727, device='cuda:0')]train Epoch 88:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.325, dice=tensor(3.1727, device='cuda:0')]train Epoch 88:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.301, dice=tensor(3.2885, device='cuda:0')]train Epoch 88:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.301, dice=tensor(3.2885, device='cuda:0')]train Epoch 88:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.305, dice=tensor(3.3421, device='cuda:0')]train Epoch 88: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.305, dice=tensor(3.3421, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                               train Loss: 0.3361 Dice: 0.6684
val Epoch 88:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 88:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.319, dice=tensor(3.4490, device='cuda:0')]val Epoch 88:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.319, dice=tensor(3.4490, device='cuda:0')]val Epoch 88:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.439, dice=tensor(3.1436, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                             val Loss: 0.3793 Dice: 0.6287
Epoch 89/199
----------
train Epoch 89:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 89:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.305, dice=tensor(3.4757, device='cuda:0')]train Epoch 89:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.305, dice=tensor(3.4757, device='cuda:0')]train Epoch 89:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.407, dice=tensor(3.2687, device='cuda:0')]train Epoch 89:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.407, dice=tensor(3.2687, device='cuda:0')]train Epoch 89:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.307, dice=tensor(3.3459, device='cuda:0')]train Epoch 89:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.307, dice=tensor(3.3459, device='cuda:0')]train Epoch 89:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.334, dice=tensor(3.3566, device='cuda:0')]train Epoch 89: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.334, dice=tensor(3.3566, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3384 Dice: 0.6713
val Epoch 89:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 89:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.351, dice=tensor(3.2245, device='cuda:0')]val Epoch 89:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.351, dice=tensor(3.2245, device='cuda:0')]val Epoch 89:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.404, dice=tensor(3.1408, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                             val Loss: 0.3773 Dice: 0.6282
Epoch 90/199
----------
train Epoch 90:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 90:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.294, dice=tensor(3.5472, device='cuda:0')]train Epoch 90:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.294, dice=tensor(3.5472, device='cuda:0')]train Epoch 90:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.33, dice=tensor(3.4734, device='cuda:0')] train Epoch 90:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.33, dice=tensor(3.4734, device='cuda:0')]train Epoch 90:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.334, dice=tensor(3.3932, device='cuda:0')]train Epoch 90:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.90it/s, loss=0.334, dice=tensor(3.3932, device='cuda:0')]train Epoch 90:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.90it/s, loss=0.354, dice=tensor(3.3507, device='cuda:0')]train Epoch 90: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.354, dice=tensor(3.3507, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                               train Loss: 0.3282 Dice: 0.6701
val Epoch 90:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 90:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.373, dice=tensor(3.1802, device='cuda:0')]val Epoch 90:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.373, dice=tensor(3.1802, device='cuda:0')]val Epoch 90:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.381, dice=tensor(3.1455, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.3768 Dice: 0.6291
Epoch 91/199
----------
train Epoch 91:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 91:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.4417, device='cuda:0')]train Epoch 91:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.322, dice=tensor(3.4417, device='cuda:0')]train Epoch 91:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.37, dice=tensor(3.3337, device='cuda:0')] train Epoch 91:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.37, dice=tensor(3.3337, device='cuda:0')]train Epoch 91:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.296, dice=tensor(3.3869, device='cuda:0')]train Epoch 91:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.90it/s, loss=0.296, dice=tensor(3.3869, device='cuda:0')]train Epoch 91:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.90it/s, loss=0.336, dice=tensor(3.3712, device='cuda:0')]train Epoch 91: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.336, dice=tensor(3.3712, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                               train Loss: 0.3310 Dice: 0.6742
val Epoch 91:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 91:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.392, dice=tensor(3.0510, device='cuda:0')]val Epoch 91:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.392, dice=tensor(3.0510, device='cuda:0')]val Epoch 91:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.36, dice=tensor(3.1521, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                            val Loss: 0.3756 Dice: 0.6304
Epoch 92/199
----------
train Epoch 92:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 92:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.339, dice=tensor(3.3222, device='cuda:0')]train Epoch 92:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.339, dice=tensor(3.3222, device='cuda:0')]train Epoch 92:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.289, dice=tensor(3.4085, device='cuda:0')]train Epoch 92:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.289, dice=tensor(3.4085, device='cuda:0')]train Epoch 92:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.348, dice=tensor(3.3665, device='cuda:0')]train Epoch 92:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.348, dice=tensor(3.3665, device='cuda:0')]train Epoch 92:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.334, dice=tensor(3.3745, device='cuda:0')]train Epoch 92: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.49it/s, loss=0.334, dice=tensor(3.3745, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                               train Loss: 0.3277 Dice: 0.6749
val Epoch 92:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 92:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.389, dice=tensor(3.1025, device='cuda:0')]val Epoch 92:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.389, dice=tensor(3.1025, device='cuda:0')]val Epoch 92:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.367, dice=tensor(3.1364, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3781 Dice: 0.6273
Epoch 93/199
----------
train Epoch 93:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 93:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.351, dice=tensor(3.2402, device='cuda:0')]train Epoch 93:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.351, dice=tensor(3.2402, device='cuda:0')]train Epoch 93:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.319, dice=tensor(3.3473, device='cuda:0')]train Epoch 93:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.319, dice=tensor(3.3473, device='cuda:0')]train Epoch 93:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.364, dice=tensor(3.3110, device='cuda:0')]train Epoch 93:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.74it/s, loss=0.364, dice=tensor(3.3110, device='cuda:0')]train Epoch 93:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.74it/s, loss=0.264, dice=tensor(3.4018, device='cuda:0')]train Epoch 93: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.264, dice=tensor(3.4018, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                               train Loss: 0.3244 Dice: 0.6804
val Epoch 93:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 93:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.406, dice=tensor(3.0290, device='cuda:0')]val Epoch 93:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.84it/s, loss=0.406, dice=tensor(3.0290, device='cuda:0')]val Epoch 93:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.84it/s, loss=0.392, dice=tensor(3.0423, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3993 Dice: 0.6085
Epoch 94/199
----------
train Epoch 94:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 94:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.315, dice=tensor(3.4229, device='cuda:0')]train Epoch 94:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.315, dice=tensor(3.4229, device='cuda:0')]train Epoch 94:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.352, dice=tensor(3.2740, device='cuda:0')]train Epoch 94:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.352, dice=tensor(3.2740, device='cuda:0')]train Epoch 94:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s, loss=0.318, dice=tensor(3.3276, device='cuda:0')]train Epoch 94:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.92it/s, loss=0.318, dice=tensor(3.3276, device='cuda:0')]train Epoch 94:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.92it/s, loss=0.335, dice=tensor(3.3192, device='cuda:0')]train Epoch 94: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.58it/s, loss=0.335, dice=tensor(3.3192, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                               train Loss: 0.3300 Dice: 0.6638
val Epoch 94:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 94:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.357, dice=tensor(3.2031, device='cuda:0')]val Epoch 94:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.357, dice=tensor(3.2031, device='cuda:0')]val Epoch 94:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.45, dice=tensor(3.0101, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                            val Loss: 0.4033 Dice: 0.6020
Epoch 95/199
----------
train Epoch 95:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 95:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.316, dice=tensor(3.4007, device='cuda:0')]train Epoch 95:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.10it/s, loss=0.316, dice=tensor(3.4007, device='cuda:0')]train Epoch 95:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.10it/s, loss=0.376, dice=tensor(3.2991, device='cuda:0')]train Epoch 95:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.39it/s, loss=0.376, dice=tensor(3.2991, device='cuda:0')]train Epoch 95:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.39it/s, loss=0.362, dice=tensor(3.2700, device='cuda:0')]train Epoch 95:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.25it/s, loss=0.362, dice=tensor(3.2700, device='cuda:0')]train Epoch 95:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.25it/s, loss=0.307, dice=tensor(3.3017, device='cuda:0')]train Epoch 95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.84it/s, loss=0.307, dice=tensor(3.3017, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                               train Loss: 0.3403 Dice: 0.6603
val Epoch 95:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 95:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.394, dice=tensor(3.1013, device='cuda:0')]val Epoch 95:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.89it/s, loss=0.394, dice=tensor(3.1013, device='cuda:0')]val Epoch 95:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.89it/s, loss=0.386, dice=tensor(3.0810, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                             val Loss: 0.3899 Dice: 0.6162
Epoch 96/199
----------
train Epoch 96:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 96:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.348, dice=tensor(3.2371, device='cuda:0')]train Epoch 96:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.348, dice=tensor(3.2371, device='cuda:0')]train Epoch 96:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.326, dice=tensor(3.2960, device='cuda:0')]train Epoch 96:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.326, dice=tensor(3.2960, device='cuda:0')]train Epoch 96:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.34, dice=tensor(3.3144, device='cuda:0')] train Epoch 96:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.34, dice=tensor(3.3144, device='cuda:0')]train Epoch 96:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.289, dice=tensor(3.3852, device='cuda:0')]train Epoch 96: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.289, dice=tensor(3.3852, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                               train Loss: 0.3257 Dice: 0.6770
val Epoch 96:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 96:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.352, dice=tensor(3.2836, device='cuda:0')]val Epoch 96:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.352, dice=tensor(3.2836, device='cuda:0')]val Epoch 96:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.402, dice=tensor(3.1463, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3770 Dice: 0.6293
Epoch 97/199
----------
train Epoch 97:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 97:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.315, dice=tensor(3.4240, device='cuda:0')]train Epoch 97:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.315, dice=tensor(3.4240, device='cuda:0')]train Epoch 97:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.333, dice=tensor(3.3940, device='cuda:0')]train Epoch 97:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.333, dice=tensor(3.3940, device='cuda:0')]train Epoch 97:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.304, dice=tensor(3.4273, device='cuda:0')]train Epoch 97:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.304, dice=tensor(3.4273, device='cuda:0')]train Epoch 97:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.356, dice=tensor(3.3830, device='cuda:0')]train Epoch 97: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.37it/s, loss=0.356, dice=tensor(3.3830, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                               train Loss: 0.3270 Dice: 0.6766
val Epoch 97:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 97:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.376, dice=tensor(3.1227, device='cuda:0')]val Epoch 97:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.90it/s, loss=0.376, dice=tensor(3.1227, device='cuda:0')]val Epoch 97:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.90it/s, loss=0.36, dice=tensor(3.1894, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                            val Loss: 0.3679 Dice: 0.6379
Epoch 98/199
----------
train Epoch 98:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 98:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.386, dice=tensor(2.9393, device='cuda:0')]train Epoch 98:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.386, dice=tensor(2.9393, device='cuda:0')]train Epoch 98:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.254, dice=tensor(3.3440, device='cuda:0')]train Epoch 98:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.254, dice=tensor(3.3440, device='cuda:0')]train Epoch 98:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.367, dice=tensor(3.3082, device='cuda:0')]train Epoch 98:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.74it/s, loss=0.367, dice=tensor(3.3082, device='cuda:0')]train Epoch 98:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.74it/s, loss=0.33, dice=tensor(3.3347, device='cuda:0')] train Epoch 98: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.33, dice=tensor(3.3347, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                              train Loss: 0.3343 Dice: 0.6669
val Epoch 98:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 98:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.371, dice=tensor(3.2383, device='cuda:0')]val Epoch 98:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.371, dice=tensor(3.2383, device='cuda:0')]val Epoch 98:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.363, dice=tensor(3.1947, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.3670 Dice: 0.6389
Epoch 99/199
----------
train Epoch 99:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 99:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.335, dice=tensor(3.3401, device='cuda:0')]train Epoch 99:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.335, dice=tensor(3.3401, device='cuda:0')]train Epoch 99:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.352, dice=tensor(3.2563, device='cuda:0')]train Epoch 99:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.352, dice=tensor(3.2563, device='cuda:0')]train Epoch 99:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.295, dice=tensor(3.3363, device='cuda:0')]train Epoch 99:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.97it/s, loss=0.295, dice=tensor(3.3363, device='cuda:0')]train Epoch 99:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.97it/s, loss=0.316, dice=tensor(3.3649, device='cuda:0')]train Epoch 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.62it/s, loss=0.316, dice=tensor(3.3649, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                               train Loss: 0.3245 Dice: 0.6730
val Epoch 99:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 99:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.358, dice=tensor(3.2657, device='cuda:0')]val Epoch 99:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.358, dice=tensor(3.2657, device='cuda:0')]val Epoch 99:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.70it/s, loss=0.38, dice=tensor(3.1923, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                            val Loss: 0.3692 Dice: 0.6385
Epoch 100/199
----------
train Epoch 100:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 100:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.377, dice=tensor(3.1219, device='cuda:0')]train Epoch 100:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.377, dice=tensor(3.1219, device='cuda:0')]train Epoch 100:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.287, dice=tensor(3.3542, device='cuda:0')]train Epoch 100:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.287, dice=tensor(3.3542, device='cuda:0')]train Epoch 100:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.337, dice=tensor(3.2961, device='cuda:0')]train Epoch 100:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.337, dice=tensor(3.2961, device='cuda:0')]train Epoch 100:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.33, dice=tensor(3.3113, device='cuda:0')] train Epoch 100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.33, dice=tensor(3.3113, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                               train Loss: 0.3329 Dice: 0.6623
val Epoch 100:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 100:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.367, dice=tensor(3.1326, device='cuda:0')]val Epoch 100:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.367, dice=tensor(3.1326, device='cuda:0')]val Epoch 100:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.382, dice=tensor(3.1541, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3750 Dice: 0.6308
Epoch 101/199
----------
train Epoch 101:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 101:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.336, dice=tensor(3.3141, device='cuda:0')]train Epoch 101:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.89it/s, loss=0.336, dice=tensor(3.3141, device='cuda:0')]train Epoch 101:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.89it/s, loss=0.308, dice=tensor(3.3812, device='cuda:0')]train Epoch 101:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.19it/s, loss=0.308, dice=tensor(3.3812, device='cuda:0')]train Epoch 101:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.19it/s, loss=0.32, dice=tensor(3.3884, device='cuda:0')] train Epoch 101:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.09it/s, loss=0.32, dice=tensor(3.3884, device='cuda:0')]train Epoch 101:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.09it/s, loss=0.319, dice=tensor(3.3990, device='cuda:0')]train Epoch 101: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.71it/s, loss=0.319, dice=tensor(3.3990, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3209 Dice: 0.6798
val Epoch 101:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 101:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.354, dice=tensor(3.1994, device='cuda:0')]val Epoch 101:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.42it/s, loss=0.354, dice=tensor(3.1994, device='cuda:0')]val Epoch 101:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.42it/s, loss=0.399, dice=tensor(3.1484, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3768 Dice: 0.6297
Epoch 102/199
----------
train Epoch 102:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 102:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.351, dice=tensor(3.2935, device='cuda:0')]train Epoch 102:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.351, dice=tensor(3.2935, device='cuda:0')]train Epoch 102:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.303, dice=tensor(3.4038, device='cuda:0')]train Epoch 102:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.303, dice=tensor(3.4038, device='cuda:0')]train Epoch 102:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.272, dice=tensor(3.4521, device='cuda:0')]train Epoch 102:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.92it/s, loss=0.272, dice=tensor(3.4521, device='cuda:0')]train Epoch 102:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.92it/s, loss=0.376, dice=tensor(3.3799, device='cuda:0')]train Epoch 102: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.58it/s, loss=0.376, dice=tensor(3.3799, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                                train Loss: 0.3253 Dice: 0.6760
val Epoch 102:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 102:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.361, dice=tensor(3.2542, device='cuda:0')]val Epoch 102:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.361, dice=tensor(3.2542, device='cuda:0')]val Epoch 102:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.402, dice=tensor(3.1401, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3817 Dice: 0.6280
Epoch 103/199
----------
train Epoch 103:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 103:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.316, dice=tensor(3.4160, device='cuda:0')]train Epoch 103:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.316, dice=tensor(3.4160, device='cuda:0')]train Epoch 103:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.3, dice=tensor(3.4418, device='cuda:0')]  train Epoch 103:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.3, dice=tensor(3.4418, device='cuda:0')]train Epoch 103:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.335, dice=tensor(3.3934, device='cuda:0')]train Epoch 103:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.81it/s, loss=0.335, dice=tensor(3.3934, device='cuda:0')]train Epoch 103:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.81it/s, loss=0.339, dice=tensor(3.3826, device='cuda:0')]train Epoch 103: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.339, dice=tensor(3.3826, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                                train Loss: 0.3225 Dice: 0.6765
val Epoch 103:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 103:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.369, dice=tensor(3.1737, device='cuda:0')]val Epoch 103:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.81it/s, loss=0.369, dice=tensor(3.1737, device='cuda:0')]val Epoch 103:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.81it/s, loss=0.373, dice=tensor(3.1814, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3709 Dice: 0.6363
Epoch 104/199
----------
train Epoch 104:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 104:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.279, dice=tensor(3.6003, device='cuda:0')]train Epoch 104:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.279, dice=tensor(3.6003, device='cuda:0')]train Epoch 104:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.328, dice=tensor(3.4940, device='cuda:0')]train Epoch 104:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.328, dice=tensor(3.4940, device='cuda:0')]train Epoch 104:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.79it/s, loss=0.324, dice=tensor(3.4634, device='cuda:0')]train Epoch 104:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.71it/s, loss=0.324, dice=tensor(3.4634, device='cuda:0')]train Epoch 104:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.71it/s, loss=0.353, dice=tensor(3.4148, device='cuda:0')]train Epoch 104: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.40it/s, loss=0.353, dice=tensor(3.4148, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                                train Loss: 0.3212 Dice: 0.6830
val Epoch 104:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 104:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.413, dice=tensor(2.9676, device='cuda:0')]val Epoch 104:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.413, dice=tensor(2.9676, device='cuda:0')]val Epoch 104:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.327, dice=tensor(3.1960, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3699 Dice: 0.6392
Epoch 105/199
----------
train Epoch 105:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 105:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.319, dice=tensor(3.4192, device='cuda:0')]train Epoch 105:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.319, dice=tensor(3.4192, device='cuda:0')]train Epoch 105:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.359, dice=tensor(3.3196, device='cuda:0')]train Epoch 105:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.359, dice=tensor(3.3196, device='cuda:0')]train Epoch 105:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.303, dice=tensor(3.3766, device='cuda:0')]train Epoch 105:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.303, dice=tensor(3.3766, device='cuda:0')]train Epoch 105:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.332, dice=tensor(3.3471, device='cuda:0')]train Epoch 105: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.332, dice=tensor(3.3471, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                                train Loss: 0.3281 Dice: 0.6694
val Epoch 105:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 105:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.397, dice=tensor(3.0349, device='cuda:0')]val Epoch 105:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.397, dice=tensor(3.0349, device='cuda:0')]val Epoch 105:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.334, dice=tensor(3.2077, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3657 Dice: 0.6415
Epoch 106/199
----------
train Epoch 106:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 106:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.316, dice=tensor(3.4205, device='cuda:0')]train Epoch 106:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.316, dice=tensor(3.4205, device='cuda:0')]train Epoch 106:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.333, dice=tensor(3.4068, device='cuda:0')]train Epoch 106:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.72it/s, loss=0.333, dice=tensor(3.4068, device='cuda:0')]train Epoch 106:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.72it/s, loss=0.352, dice=tensor(3.3604, device='cuda:0')]train Epoch 106:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.65it/s, loss=0.352, dice=tensor(3.3604, device='cuda:0')]train Epoch 106:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.65it/s, loss=0.305, dice=tensor(3.3941, device='cuda:0')]train Epoch 106: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.33it/s, loss=0.305, dice=tensor(3.3941, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3263 Dice: 0.6788
val Epoch 106:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 106:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.2660, device='cuda:0')]val Epoch 106:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.338, dice=tensor(3.2660, device='cuda:0')]val Epoch 106:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.386, dice=tensor(3.2154, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3620 Dice: 0.6431
Epoch 107/199
----------
train Epoch 107:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 107:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.316, dice=tensor(3.4771, device='cuda:0')]train Epoch 107:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.316, dice=tensor(3.4771, device='cuda:0')]train Epoch 107:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.308, dice=tensor(3.4704, device='cuda:0')]train Epoch 107:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.308, dice=tensor(3.4704, device='cuda:0')]train Epoch 107:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.356, dice=tensor(3.4032, device='cuda:0')]train Epoch 107:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.356, dice=tensor(3.4032, device='cuda:0')]train Epoch 107:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.334, dice=tensor(3.3790, device='cuda:0')]train Epoch 107: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.334, dice=tensor(3.3790, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                                train Loss: 0.3282 Dice: 0.6758
val Epoch 107:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 107:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.337, dice=tensor(3.3835, device='cuda:0')]val Epoch 107:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.337, dice=tensor(3.3835, device='cuda:0')]val Epoch 107:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.392, dice=tensor(3.2148, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3641 Dice: 0.6430
Epoch 108/199
----------
train Epoch 108:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 108:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.314, dice=tensor(3.4044, device='cuda:0')]train Epoch 108:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.314, dice=tensor(3.4044, device='cuda:0')]train Epoch 108:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.329, dice=tensor(3.4003, device='cuda:0')]train Epoch 108:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.329, dice=tensor(3.4003, device='cuda:0')]train Epoch 108:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.332, dice=tensor(3.3835, device='cuda:0')]train Epoch 108:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.332, dice=tensor(3.3835, device='cuda:0')]train Epoch 108:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.322, dice=tensor(3.3850, device='cuda:0')]train Epoch 108: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.322, dice=tensor(3.3850, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3241 Dice: 0.6770
val Epoch 108:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 108:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.361, dice=tensor(3.1888, device='cuda:0')]val Epoch 108:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.361, dice=tensor(3.1888, device='cuda:0')]val Epoch 108:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.366, dice=tensor(3.2111, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3634 Dice: 0.6422
Epoch 109/199
----------
train Epoch 109:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 109:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.325, dice=tensor(3.4251, device='cuda:0')]train Epoch 109:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.325, dice=tensor(3.4251, device='cuda:0')]train Epoch 109:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.327, dice=tensor(3.4094, device='cuda:0')]train Epoch 109:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.327, dice=tensor(3.4094, device='cuda:0')]train Epoch 109:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.316, dice=tensor(3.4057, device='cuda:0')]train Epoch 109:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.316, dice=tensor(3.4057, device='cuda:0')]train Epoch 109:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.316, dice=tensor(3.4022, device='cuda:0')]train Epoch 109: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.316, dice=tensor(3.4022, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3209 Dice: 0.6804
val Epoch 109:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 109:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.408, dice=tensor(2.9858, device='cuda:0')]val Epoch 109:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.408, dice=tensor(2.9858, device='cuda:0')]val Epoch 109:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.322, dice=tensor(3.2101, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3651 Dice: 0.6420
Epoch 110/199
----------
train Epoch 110:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 110:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.352, dice=tensor(3.3097, device='cuda:0')]train Epoch 110:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.352, dice=tensor(3.3097, device='cuda:0')]train Epoch 110:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.316, dice=tensor(3.2911, device='cuda:0')]train Epoch 110:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.316, dice=tensor(3.2911, device='cuda:0')]train Epoch 110:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.333, dice=tensor(3.3100, device='cuda:0')]train Epoch 110:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.94it/s, loss=0.333, dice=tensor(3.3100, device='cuda:0')]train Epoch 110:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.94it/s, loss=0.309, dice=tensor(3.3377, device='cuda:0')]train Epoch 110: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.59it/s, loss=0.309, dice=tensor(3.3377, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                                train Loss: 0.3276 Dice: 0.6675
val Epoch 110:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 110:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.372, dice=tensor(3.2269, device='cuda:0')]val Epoch 110:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.33it/s, loss=0.372, dice=tensor(3.2269, device='cuda:0')]val Epoch 110:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.33it/s, loss=0.353, dice=tensor(3.2140, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3624 Dice: 0.6428
Epoch 111/199
----------
train Epoch 111:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 111:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.311, dice=tensor(3.4454, device='cuda:0')]train Epoch 111:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.311, dice=tensor(3.4454, device='cuda:0')]train Epoch 111:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.345, dice=tensor(3.3936, device='cuda:0')]train Epoch 111:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.345, dice=tensor(3.3936, device='cuda:0')]train Epoch 111:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.325, dice=tensor(3.3720, device='cuda:0')]train Epoch 111:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.94it/s, loss=0.325, dice=tensor(3.3720, device='cuda:0')]train Epoch 111:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.94it/s, loss=0.317, dice=tensor(3.3720, device='cuda:0')]train Epoch 111: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.59it/s, loss=0.317, dice=tensor(3.3720, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                                train Loss: 0.3246 Dice: 0.6744
val Epoch 111:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 111:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.412, dice=tensor(2.9712, device='cuda:0')]val Epoch 111:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.76it/s, loss=0.412, dice=tensor(2.9712, device='cuda:0')]val Epoch 111:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.76it/s, loss=0.315, dice=tensor(3.2188, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3635 Dice: 0.6438
Epoch 112/199
----------
train Epoch 112:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 112:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.2966, device='cuda:0')]train Epoch 112:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.345, dice=tensor(3.2966, device='cuda:0')]train Epoch 112:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.343, dice=tensor(3.3141, device='cuda:0')]train Epoch 112:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.343, dice=tensor(3.3141, device='cuda:0')]train Epoch 112:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.316, dice=tensor(3.3369, device='cuda:0')]train Epoch 112:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.316, dice=tensor(3.3369, device='cuda:0')]train Epoch 112:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.286, dice=tensor(3.3862, device='cuda:0')]train Epoch 112: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.286, dice=tensor(3.3862, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                                train Loss: 0.3224 Dice: 0.6772
val Epoch 112:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 112:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.2294, device='cuda:0')]val Epoch 112:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.345, dice=tensor(3.2294, device='cuda:0')]val Epoch 112:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.377, dice=tensor(3.2195, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3609 Dice: 0.6439
Epoch 113/199
----------
train Epoch 113:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 113:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.323, dice=tensor(3.3654, device='cuda:0')]train Epoch 113:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.323, dice=tensor(3.3654, device='cuda:0')]train Epoch 113:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.49it/s, loss=0.334, dice=tensor(3.2929, device='cuda:0')]train Epoch 113:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.70it/s, loss=0.334, dice=tensor(3.2929, device='cuda:0')]train Epoch 113:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.70it/s, loss=0.317, dice=tensor(3.3427, device='cuda:0')]train Epoch 113:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.63it/s, loss=0.317, dice=tensor(3.3427, device='cuda:0')]train Epoch 113:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.63it/s, loss=0.322, dice=tensor(3.3568, device='cuda:0')]train Epoch 113: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.33it/s, loss=0.322, dice=tensor(3.3568, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3240 Dice: 0.6714
val Epoch 113:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 113:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.38, dice=tensor(3.1872, device='cuda:0')]val Epoch 113:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.38, dice=tensor(3.1872, device='cuda:0')]val Epoch 113:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.341, dice=tensor(3.2167, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3607 Dice: 0.6433
Epoch 114/199
----------
train Epoch 114:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 114:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.3159, device='cuda:0')]train Epoch 114:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.345, dice=tensor(3.3159, device='cuda:0')]train Epoch 114:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.289, dice=tensor(3.4437, device='cuda:0')]train Epoch 114:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.67it/s, loss=0.289, dice=tensor(3.4437, device='cuda:0')]train Epoch 114:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.67it/s, loss=0.298, dice=tensor(3.4656, device='cuda:0')]train Epoch 114:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.60it/s, loss=0.298, dice=tensor(3.4656, device='cuda:0')]train Epoch 114:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.60it/s, loss=0.33, dice=tensor(3.4244, device='cuda:0')] train Epoch 114: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.30it/s, loss=0.33, dice=tensor(3.4244, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                               train Loss: 0.3155 Dice: 0.6849
val Epoch 114:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 114:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.32, dice=tensor(3.4581, device='cuda:0')]val Epoch 114:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.32, dice=tensor(3.4581, device='cuda:0')]val Epoch 114:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.411, dice=tensor(3.2162, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3655 Dice: 0.6432
Epoch 115/199
----------
train Epoch 115:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 115:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.369, dice=tensor(3.1934, device='cuda:0')]train Epoch 115:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.369, dice=tensor(3.1934, device='cuda:0')]train Epoch 115:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.314, dice=tensor(3.3314, device='cuda:0')]train Epoch 115:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.314, dice=tensor(3.3314, device='cuda:0')]train Epoch 115:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.379, dice=tensor(3.2730, device='cuda:0')]train Epoch 115:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.379, dice=tensor(3.2730, device='cuda:0')]train Epoch 115:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.267, dice=tensor(3.3840, device='cuda:0')]train Epoch 115: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.267, dice=tensor(3.3840, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                                train Loss: 0.3323 Dice: 0.6768
val Epoch 115:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 115:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.34, dice=tensor(3.2489, device='cuda:0')]val Epoch 115:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.34, dice=tensor(3.2489, device='cuda:0')]val Epoch 115:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.48it/s, loss=0.381, dice=tensor(3.2165, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3607 Dice: 0.6433
Epoch 116/199
----------
train Epoch 116:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 116:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.289, dice=tensor(3.5883, device='cuda:0')]train Epoch 116:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.289, dice=tensor(3.5883, device='cuda:0')]train Epoch 116:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.337, dice=tensor(3.4204, device='cuda:0')]train Epoch 116:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.337, dice=tensor(3.4204, device='cuda:0')]train Epoch 116:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.334, dice=tensor(3.3603, device='cuda:0')]train Epoch 116:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.74it/s, loss=0.334, dice=tensor(3.3603, device='cuda:0')]train Epoch 116:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.74it/s, loss=0.337, dice=tensor(3.3672, device='cuda:0')]train Epoch 116: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.337, dice=tensor(3.3672, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                                train Loss: 0.3242 Dice: 0.6734
val Epoch 116:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 116:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.381, dice=tensor(3.1016, device='cuda:0')]val Epoch 116:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.381, dice=tensor(3.1016, device='cuda:0')]val Epoch 116:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.344, dice=tensor(3.2211, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3625 Dice: 0.6442
Epoch 117/199
----------
train Epoch 117:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 117:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.3609, device='cuda:0')]train Epoch 117:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.322, dice=tensor(3.3609, device='cuda:0')]train Epoch 117:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.78it/s, loss=0.337, dice=tensor(3.3134, device='cuda:0')]train Epoch 117:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.05it/s, loss=0.337, dice=tensor(3.3134, device='cuda:0')]train Epoch 117:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.05it/s, loss=0.294, dice=tensor(3.4012, device='cuda:0')]train Epoch 117:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.96it/s, loss=0.294, dice=tensor(3.4012, device='cuda:0')]train Epoch 117:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.96it/s, loss=0.353, dice=tensor(3.3710, device='cuda:0')]train Epoch 117: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.61it/s, loss=0.353, dice=tensor(3.3710, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3263 Dice: 0.6742
val Epoch 117:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 117:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.365, dice=tensor(3.2329, device='cuda:0')]val Epoch 117:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.365, dice=tensor(3.2329, device='cuda:0')]val Epoch 117:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.354, dice=tensor(3.2282, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3597 Dice: 0.6456
Epoch 118/199
----------
train Epoch 118:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 118:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.3, dice=tensor(3.5019, device='cuda:0')]train Epoch 118:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.3, dice=tensor(3.5019, device='cuda:0')]train Epoch 118:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.341, dice=tensor(3.3437, device='cuda:0')]train Epoch 118:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.341, dice=tensor(3.3437, device='cuda:0')]train Epoch 118:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.339, dice=tensor(3.3301, device='cuda:0')]train Epoch 118:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.339, dice=tensor(3.3301, device='cuda:0')]train Epoch 118:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.316, dice=tensor(3.3509, device='cuda:0')]train Epoch 118: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.316, dice=tensor(3.3509, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                                train Loss: 0.3239 Dice: 0.6702
val Epoch 118:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 118:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.402, dice=tensor(3.0061, device='cuda:0')]val Epoch 118:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.402, dice=tensor(3.0061, device='cuda:0')]val Epoch 118:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.318, dice=tensor(3.2314, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3600 Dice: 0.6463
Epoch 119/199
----------
train Epoch 119:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 119:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.293, dice=tensor(3.4503, device='cuda:0')]train Epoch 119:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.293, dice=tensor(3.4503, device='cuda:0')]train Epoch 119:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.51it/s, loss=0.291, dice=tensor(3.5022, device='cuda:0')]train Epoch 119:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.291, dice=tensor(3.5022, device='cuda:0')]train Epoch 119:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.71it/s, loss=0.366, dice=tensor(3.3956, device='cuda:0')]train Epoch 119:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.63it/s, loss=0.366, dice=tensor(3.3956, device='cuda:0')]train Epoch 119:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.63it/s, loss=0.342, dice=tensor(3.3793, device='cuda:0')]train Epoch 119: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.33it/s, loss=0.342, dice=tensor(3.3793, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3230 Dice: 0.6759
val Epoch 119:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 119:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.314, dice=tensor(3.4778, device='cuda:0')]val Epoch 119:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.314, dice=tensor(3.4778, device='cuda:0')]val Epoch 119:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.408, dice=tensor(3.2325, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3610 Dice: 0.6465
Epoch 120/199
----------
train Epoch 120:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 120:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.319, dice=tensor(3.3960, device='cuda:0')]train Epoch 120:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.319, dice=tensor(3.3960, device='cuda:0')]train Epoch 120:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.66it/s, loss=0.321, dice=tensor(3.4263, device='cuda:0')]train Epoch 120:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.321, dice=tensor(3.4263, device='cuda:0')]train Epoch 120:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s, loss=0.369, dice=tensor(3.3237, device='cuda:0')]train Epoch 120:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.369, dice=tensor(3.3237, device='cuda:0')]train Epoch 120:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.296, dice=tensor(3.3723, device='cuda:0')]train Epoch 120: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.296, dice=tensor(3.3723, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3262 Dice: 0.6745
val Epoch 120:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 120:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.307, dice=tensor(3.5034, device='cuda:0')]val Epoch 120:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.44it/s, loss=0.307, dice=tensor(3.5034, device='cuda:0')]val Epoch 120:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.44it/s, loss=0.41, dice=tensor(3.2374, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.3582 Dice: 0.6475
Epoch 121/199
----------
train Epoch 121:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 121:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.331, dice=tensor(3.3512, device='cuda:0')]train Epoch 121:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.331, dice=tensor(3.3512, device='cuda:0')]train Epoch 121:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.342, dice=tensor(3.2831, device='cuda:0')]train Epoch 121:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.342, dice=tensor(3.2831, device='cuda:0')]train Epoch 121:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.302, dice=tensor(3.3556, device='cuda:0')]train Epoch 121:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.68it/s, loss=0.302, dice=tensor(3.3556, device='cuda:0')]train Epoch 121:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.68it/s, loss=0.324, dice=tensor(3.3564, device='cuda:0')]train Epoch 121: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.324, dice=tensor(3.3564, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3247 Dice: 0.6713
val Epoch 121:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 121:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.35, dice=tensor(3.2517, device='cuda:0')]val Epoch 121:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.81it/s, loss=0.35, dice=tensor(3.2517, device='cuda:0')]val Epoch 121:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.81it/s, loss=0.367, dice=tensor(3.2322, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3584 Dice: 0.6464
Epoch 122/199
----------
train Epoch 122:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 122:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.301, dice=tensor(3.5154, device='cuda:0')]train Epoch 122:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.301, dice=tensor(3.5154, device='cuda:0')]train Epoch 122:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.329, dice=tensor(3.4482, device='cuda:0')]train Epoch 122:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.329, dice=tensor(3.4482, device='cuda:0')]train Epoch 122:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.301, dice=tensor(3.4519, device='cuda:0')]train Epoch 122:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.66it/s, loss=0.301, dice=tensor(3.4519, device='cuda:0')]train Epoch 122:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.66it/s, loss=0.37, dice=tensor(3.3977, device='cuda:0')] train Epoch 122: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.36it/s, loss=0.37, dice=tensor(3.3977, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                               train Loss: 0.3253 Dice: 0.6795
val Epoch 122:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 122:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.353, dice=tensor(3.2963, device='cuda:0')]val Epoch 122:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.40it/s, loss=0.353, dice=tensor(3.2963, device='cuda:0')]val Epoch 122:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.40it/s, loss=0.368, dice=tensor(3.2320, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3604 Dice: 0.6464
Epoch 123/199
----------
train Epoch 123:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 123:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.293, dice=tensor(3.5877, device='cuda:0')]train Epoch 123:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.293, dice=tensor(3.5877, device='cuda:0')]train Epoch 123:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.57it/s, loss=0.358, dice=tensor(3.4187, device='cuda:0')]train Epoch 123:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.358, dice=tensor(3.4187, device='cuda:0')]train Epoch 123:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.329, dice=tensor(3.3867, device='cuda:0')]train Epoch 123:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.72it/s, loss=0.329, dice=tensor(3.3867, device='cuda:0')]train Epoch 123:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.72it/s, loss=0.298, dice=tensor(3.4267, device='cuda:0')]train Epoch 123: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.298, dice=tensor(3.4267, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3193 Dice: 0.6853
val Epoch 123:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 123:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.342, dice=tensor(3.3460, device='cuda:0')]val Epoch 123:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.342, dice=tensor(3.3460, device='cuda:0')]val Epoch 123:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.385, dice=tensor(3.2292, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3632 Dice: 0.6458
Epoch 124/199
----------
train Epoch 124:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 124:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.301, dice=tensor(3.4543, device='cuda:0')]train Epoch 124:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.301, dice=tensor(3.4543, device='cuda:0')]train Epoch 124:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.361, dice=tensor(3.3465, device='cuda:0')]train Epoch 124:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.361, dice=tensor(3.3465, device='cuda:0')]train Epoch 124:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.336, dice=tensor(3.3326, device='cuda:0')]train Epoch 124:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.90it/s, loss=0.336, dice=tensor(3.3326, device='cuda:0')]train Epoch 124:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.90it/s, loss=0.317, dice=tensor(3.3582, device='cuda:0')]train Epoch 124: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.317, dice=tensor(3.3582, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3284 Dice: 0.6716
val Epoch 124:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 124:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.387, dice=tensor(3.1385, device='cuda:0')]val Epoch 124:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.36it/s, loss=0.387, dice=tensor(3.1385, device='cuda:0')]val Epoch 124:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.36it/s, loss=0.33, dice=tensor(3.2261, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                             val Loss: 0.3586 Dice: 0.6452
Epoch 125/199
----------
train Epoch 125:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 125:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.334, dice=tensor(3.4036, device='cuda:0')]train Epoch 125:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.334, dice=tensor(3.4036, device='cuda:0')]train Epoch 125:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.269, dice=tensor(3.5089, device='cuda:0')]train Epoch 125:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.269, dice=tensor(3.5089, device='cuda:0')]train Epoch 125:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.357, dice=tensor(3.4188, device='cuda:0')]train Epoch 125:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.357, dice=tensor(3.4188, device='cuda:0')]train Epoch 125:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.311, dice=tensor(3.4236, device='cuda:0')]train Epoch 125: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.311, dice=tensor(3.4236, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                                                                train Loss: 0.3178 Dice: 0.6847
val Epoch 125:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 125:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.329, dice=tensor(3.4150, device='cuda:0')]val Epoch 125:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.329, dice=tensor(3.4150, device='cuda:0')]val Epoch 125:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.4, dice=tensor(3.2398, device='cuda:0')]  /home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                            val Loss: 0.3644 Dice: 0.6480
Epoch 126/199
----------
train Epoch 126:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 126:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.295, dice=tensor(3.5493, device='cuda:0')]train Epoch 126:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.50it/s, loss=0.295, dice=tensor(3.5493, device='cuda:0')]train Epoch 126:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.50it/s, loss=0.314, dice=tensor(3.4707, device='cuda:0')]train Epoch 126:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.70it/s, loss=0.314, dice=tensor(3.4707, device='cuda:0')]train Epoch 126:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.70it/s, loss=0.36, dice=tensor(3.3897, device='cuda:0')] train Epoch 126:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.62it/s, loss=0.36, dice=tensor(3.3897, device='cuda:0')]train Epoch 126:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.62it/s, loss=0.321, dice=tensor(3.3695, device='cuda:0')]train Epoch 126: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.32it/s, loss=0.321, dice=tensor(3.3695, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3223 Dice: 0.6739
val Epoch 126:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 126:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.324, dice=tensor(3.3521, device='cuda:0')]val Epoch 126:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.324, dice=tensor(3.3521, device='cuda:0')]val Epoch 126:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.395, dice=tensor(3.2435, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3596 Dice: 0.6487
Epoch 127/199
----------
train Epoch 127:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 127:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.4239, device='cuda:0')]train Epoch 127:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.15it/s, loss=0.333, dice=tensor(3.4239, device='cuda:0')]train Epoch 127:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.15it/s, loss=0.282, dice=tensor(3.5132, device='cuda:0')]train Epoch 127:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.46it/s, loss=0.282, dice=tensor(3.5132, device='cuda:0')]train Epoch 127:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.46it/s, loss=0.337, dice=tensor(3.4336, device='cuda:0')]train Epoch 127:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.31it/s, loss=0.337, dice=tensor(3.4336, device='cuda:0')]train Epoch 127:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.31it/s, loss=0.346, dice=tensor(3.3994, device='cuda:0')]train Epoch 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  4.88it/s, loss=0.346, dice=tensor(3.3994, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3245 Dice: 0.6799
val Epoch 127:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 127:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.37, dice=tensor(3.1998, device='cuda:0')]val Epoch 127:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.37, dice=tensor(3.1998, device='cuda:0')]val Epoch 127:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.80it/s, loss=0.341, dice=tensor(3.2429, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3555 Dice: 0.6486
Epoch 128/199
----------
train Epoch 128:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 128:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.327, dice=tensor(3.3868, device='cuda:0')]train Epoch 128:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.327, dice=tensor(3.3868, device='cuda:0')]train Epoch 128:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.295, dice=tensor(3.4316, device='cuda:0')]train Epoch 128:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.295, dice=tensor(3.4316, device='cuda:0')]train Epoch 128:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.299, dice=tensor(3.4556, device='cuda:0')]train Epoch 128:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.299, dice=tensor(3.4556, device='cuda:0')]train Epoch 128:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.357, dice=tensor(3.4118, device='cuda:0')]train Epoch 128: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.357, dice=tensor(3.4118, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3194 Dice: 0.6824
val Epoch 128:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 128:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.336, dice=tensor(3.3724, device='cuda:0')]val Epoch 128:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.336, dice=tensor(3.3724, device='cuda:0')]val Epoch 128:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.373, dice=tensor(3.2549, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3548 Dice: 0.6510
Epoch 129/199
----------
train Epoch 129:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 129:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.354, dice=tensor(3.2926, device='cuda:0')]train Epoch 129:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.354, dice=tensor(3.2926, device='cuda:0')]train Epoch 129:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.295, dice=tensor(3.4124, device='cuda:0')]train Epoch 129:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.295, dice=tensor(3.4124, device='cuda:0')]train Epoch 129:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.335, dice=tensor(3.3755, device='cuda:0')]train Epoch 129:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.335, dice=tensor(3.3755, device='cuda:0')]train Epoch 129:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.289, dice=tensor(3.4231, device='cuda:0')]train Epoch 129: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.289, dice=tensor(3.4231, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3183 Dice: 0.6846
val Epoch 129:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 129:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.352, dice=tensor(3.2194, device='cuda:0')]val Epoch 129:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.352, dice=tensor(3.2194, device='cuda:0')]val Epoch 129:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.356, dice=tensor(3.2563, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3541 Dice: 0.6513
Epoch 130/199
----------
train Epoch 130:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 130:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.339, dice=tensor(3.3022, device='cuda:0')]train Epoch 130:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.339, dice=tensor(3.3022, device='cuda:0')]train Epoch 130:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.259, dice=tensor(3.5142, device='cuda:0')]train Epoch 130:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.259, dice=tensor(3.5142, device='cuda:0')]train Epoch 130:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.357, dice=tensor(3.4365, device='cuda:0')]train Epoch 130:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.80it/s, loss=0.357, dice=tensor(3.4365, device='cuda:0')]train Epoch 130:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.80it/s, loss=0.356, dice=tensor(3.3631, device='cuda:0')]train Epoch 130: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.356, dice=tensor(3.3631, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                                train Loss: 0.3279 Dice: 0.6726
val Epoch 130:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 130:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.307, dice=tensor(3.5148, device='cuda:0')]val Epoch 130:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.307, dice=tensor(3.5148, device='cuda:0')]val Epoch 130:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.407, dice=tensor(3.2543, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3574 Dice: 0.6509
Epoch 131/199
----------
train Epoch 131:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 131:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.348, dice=tensor(3.2963, device='cuda:0')]train Epoch 131:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.77it/s, loss=0.348, dice=tensor(3.2963, device='cuda:0')]train Epoch 131:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.77it/s, loss=0.319, dice=tensor(3.3624, device='cuda:0')]train Epoch 131:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.319, dice=tensor(3.3624, device='cuda:0')]train Epoch 131:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s, loss=0.296, dice=tensor(3.4162, device='cuda:0')]train Epoch 131:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.95it/s, loss=0.296, dice=tensor(3.4162, device='cuda:0')]train Epoch 131:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.95it/s, loss=0.299, dice=tensor(3.4319, device='cuda:0')]train Epoch 131: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.58it/s, loss=0.299, dice=tensor(3.4319, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                                train Loss: 0.3156 Dice: 0.6864
val Epoch 131:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 131:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.313, dice=tensor(3.4924, device='cuda:0')]val Epoch 131:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.313, dice=tensor(3.4924, device='cuda:0')]val Epoch 131:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.409, dice=tensor(3.2477, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3610 Dice: 0.6495
Epoch 132/199
----------
train Epoch 132:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 132:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.287, dice=tensor(3.5744, device='cuda:0')]train Epoch 132:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.287, dice=tensor(3.5744, device='cuda:0')]train Epoch 132:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.304, dice=tensor(3.4951, device='cuda:0')]train Epoch 132:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.304, dice=tensor(3.4951, device='cuda:0')]train Epoch 132:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.355, dice=tensor(3.4311, device='cuda:0')]train Epoch 132:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.355, dice=tensor(3.4311, device='cuda:0')]train Epoch 132:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.326, dice=tensor(3.4275, device='cuda:0')]train Epoch 132: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.326, dice=tensor(3.4275, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3180 Dice: 0.6855
val Epoch 132:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 132:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.363, dice=tensor(3.1819, device='cuda:0')]val Epoch 132:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.363, dice=tensor(3.1819, device='cuda:0')]val Epoch 132:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.355, dice=tensor(3.2398, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3589 Dice: 0.6480
Epoch 133/199
----------
train Epoch 133:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 133:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.306, dice=tensor(3.4438, device='cuda:0')]train Epoch 133:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.80it/s, loss=0.306, dice=tensor(3.4438, device='cuda:0')]train Epoch 133:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.80it/s, loss=0.328, dice=tensor(3.4071, device='cuda:0')]train Epoch 133:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.08it/s, loss=0.328, dice=tensor(3.4071, device='cuda:0')]train Epoch 133:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.08it/s, loss=0.271, dice=tensor(3.4937, device='cuda:0')]train Epoch 133:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.99it/s, loss=0.271, dice=tensor(3.4937, device='cuda:0')]train Epoch 133:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.99it/s, loss=0.365, dice=tensor(3.4295, device='cuda:0')]train Epoch 133: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.63it/s, loss=0.365, dice=tensor(3.4295, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                                train Loss: 0.3173 Dice: 0.6859
val Epoch 133:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 133:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.389, dice=tensor(3.0737, device='cuda:0')]val Epoch 133:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.389, dice=tensor(3.0737, device='cuda:0')]val Epoch 133:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.63it/s, loss=0.328, dice=tensor(3.2422, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3588 Dice: 0.6484
Epoch 134/199
----------
train Epoch 134:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 134:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.312, dice=tensor(3.4399, device='cuda:0')]train Epoch 134:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.312, dice=tensor(3.4399, device='cuda:0')]train Epoch 134:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.31, dice=tensor(3.4773, device='cuda:0')] train Epoch 134:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.31, dice=tensor(3.4773, device='cuda:0')]train Epoch 134:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.81it/s, loss=0.328, dice=tensor(3.4411, device='cuda:0')]train Epoch 134:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.328, dice=tensor(3.4411, device='cuda:0')]train Epoch 134:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.312, dice=tensor(3.4297, device='cuda:0')]train Epoch 134: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.312, dice=tensor(3.4297, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                                                                train Loss: 0.3156 Dice: 0.6859
val Epoch 134:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 134:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.395, dice=tensor(3.0694, device='cuda:0')]val Epoch 134:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.42it/s, loss=0.395, dice=tensor(3.0694, device='cuda:0')]val Epoch 134:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.42it/s, loss=0.325, dice=tensor(3.2495, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3603 Dice: 0.6499
Epoch 135/199
----------
train Epoch 135:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 135:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.329, dice=tensor(3.3140, device='cuda:0')]train Epoch 135:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.329, dice=tensor(3.3140, device='cuda:0')]train Epoch 135:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.72it/s, loss=0.308, dice=tensor(3.3746, device='cuda:0')]train Epoch 135:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.308, dice=tensor(3.3746, device='cuda:0')]train Epoch 135:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.312, dice=tensor(3.3943, device='cuda:0')]train Epoch 135:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.312, dice=tensor(3.3943, device='cuda:0')]train Epoch 135:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.324, dice=tensor(3.3988, device='cuda:0')]train Epoch 135: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.324, dice=tensor(3.3988, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3180 Dice: 0.6798
val Epoch 135:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 135:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.34, dice=tensor(3.3647, device='cuda:0')]val Epoch 135:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.34, dice=tensor(3.3647, device='cuda:0')]val Epoch 135:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.38, dice=tensor(3.2504, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                             val Loss: 0.3599 Dice: 0.6501
Epoch 136/199
----------
train Epoch 136:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 136:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.279, dice=tensor(3.6414, device='cuda:0')]train Epoch 136:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.82it/s, loss=0.279, dice=tensor(3.6414, device='cuda:0')]train Epoch 136:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.82it/s, loss=0.326, dice=tensor(3.5111, device='cuda:0')]train Epoch 136:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.326, dice=tensor(3.5111, device='cuda:0')]train Epoch 136:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.10it/s, loss=0.378, dice=tensor(3.3837, device='cuda:0')]train Epoch 136:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.01it/s, loss=0.378, dice=tensor(3.3837, device='cuda:0')]train Epoch 136:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.01it/s, loss=0.322, dice=tensor(3.3844, device='cuda:0')]train Epoch 136: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.63it/s, loss=0.322, dice=tensor(3.3844, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                                train Loss: 0.3262 Dice: 0.6769
val Epoch 136:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 136:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.3030, device='cuda:0')]val Epoch 136:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.333, dice=tensor(3.3030, device='cuda:0')]val Epoch 136:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.373, dice=tensor(3.2581, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3534 Dice: 0.6516
Epoch 137/199
----------
train Epoch 137:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 137:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.334, dice=tensor(3.3210, device='cuda:0')]train Epoch 137:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.91it/s, loss=0.334, dice=tensor(3.3210, device='cuda:0')]train Epoch 137:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.91it/s, loss=0.301, dice=tensor(3.3837, device='cuda:0')]train Epoch 137:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.21it/s, loss=0.301, dice=tensor(3.3837, device='cuda:0')]train Epoch 137:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.21it/s, loss=0.336, dice=tensor(3.3816, device='cuda:0')]train Epoch 137:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.10it/s, loss=0.336, dice=tensor(3.3816, device='cuda:0')]train Epoch 137:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.10it/s, loss=0.296, dice=tensor(3.4203, device='cuda:0')]train Epoch 137: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.73it/s, loss=0.296, dice=tensor(3.4203, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                                train Loss: 0.3167 Dice: 0.6841
val Epoch 137:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 137:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.335, dice=tensor(3.2957, device='cuda:0')]val Epoch 137:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.335, dice=tensor(3.2957, device='cuda:0')]val Epoch 137:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.372, dice=tensor(3.2617, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3531 Dice: 0.6523
Epoch 138/199
----------
train Epoch 138:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 138:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.344, dice=tensor(3.3244, device='cuda:0')]train Epoch 138:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.44it/s, loss=0.344, dice=tensor(3.3244, device='cuda:0')]train Epoch 138:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.44it/s, loss=0.326, dice=tensor(3.3378, device='cuda:0')]train Epoch 138:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.62it/s, loss=0.326, dice=tensor(3.3378, device='cuda:0')]train Epoch 138:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.62it/s, loss=0.311, dice=tensor(3.3750, device='cuda:0')]train Epoch 138:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.55it/s, loss=0.311, dice=tensor(3.3750, device='cuda:0')]train Epoch 138:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.55it/s, loss=0.286, dice=tensor(3.4217, device='cuda:0')]train Epoch 138: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.26it/s, loss=0.286, dice=tensor(3.4217, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3168 Dice: 0.6843
val Epoch 138:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 138:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.342, dice=tensor(3.3323, device='cuda:0')]val Epoch 138:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.342, dice=tensor(3.3323, device='cuda:0')]val Epoch 138:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.77it/s, loss=0.367, dice=tensor(3.2523, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3543 Dice: 0.6505
Epoch 139/199
----------
train Epoch 139:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 139:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.378, dice=tensor(3.1476, device='cuda:0')]train Epoch 139:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.378, dice=tensor(3.1476, device='cuda:0')]train Epoch 139:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.278, dice=tensor(3.3840, device='cuda:0')]train Epoch 139:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.278, dice=tensor(3.3840, device='cuda:0')]train Epoch 139:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.306, dice=tensor(3.4132, device='cuda:0')]train Epoch 139:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.306, dice=tensor(3.4132, device='cuda:0')]train Epoch 139:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.331, dice=tensor(3.3942, device='cuda:0')]train Epoch 139: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.331, dice=tensor(3.3942, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                                train Loss: 0.3230 Dice: 0.6788
val Epoch 139:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 139:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.329, dice=tensor(3.4008, device='cuda:0')]val Epoch 139:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.329, dice=tensor(3.4008, device='cuda:0')]val Epoch 139:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.391, dice=tensor(3.2434, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3599 Dice: 0.6487
Epoch 140/199
----------
train Epoch 140:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 140:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.29, dice=tensor(3.5214, device='cuda:0')]train Epoch 140:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.29, dice=tensor(3.5214, device='cuda:0')]train Epoch 140:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.328, dice=tensor(3.4253, device='cuda:0')]train Epoch 140:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.328, dice=tensor(3.4253, device='cuda:0')]train Epoch 140:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.301, dice=tensor(3.4553, device='cuda:0')]train Epoch 140:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.301, dice=tensor(3.4553, device='cuda:0')]train Epoch 140:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.335, dice=tensor(3.4293, device='cuda:0')]train Epoch 140: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.335, dice=tensor(3.4293, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                                train Loss: 0.3138 Dice: 0.6859
val Epoch 140:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 140:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.398, dice=tensor(3.0521, device='cuda:0')]val Epoch 140:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.41it/s, loss=0.398, dice=tensor(3.0521, device='cuda:0')]val Epoch 140:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.41it/s, loss=0.326, dice=tensor(3.2350, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3617 Dice: 0.6470
Epoch 141/199
----------
train Epoch 141:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 141:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.309, dice=tensor(3.4476, device='cuda:0')]train Epoch 141:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.309, dice=tensor(3.4476, device='cuda:0')]train Epoch 141:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.333, dice=tensor(3.3715, device='cuda:0')]train Epoch 141:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.333, dice=tensor(3.3715, device='cuda:0')]train Epoch 141:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.346, dice=tensor(3.3607, device='cuda:0')]train Epoch 141:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.346, dice=tensor(3.3607, device='cuda:0')]train Epoch 141:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.292, dice=tensor(3.4076, device='cuda:0')]train Epoch 141: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.292, dice=tensor(3.4076, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                                train Loss: 0.3201 Dice: 0.6815
val Epoch 141:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 141:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.344, dice=tensor(3.2797, device='cuda:0')]val Epoch 141:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.344, dice=tensor(3.2797, device='cuda:0')]val Epoch 141:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.68it/s, loss=0.364, dice=tensor(3.2492, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3544 Dice: 0.6498
Epoch 142/199
----------
train Epoch 142:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 142:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.295, dice=tensor(3.4885, device='cuda:0')]train Epoch 142:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.295, dice=tensor(3.4885, device='cuda:0')]train Epoch 142:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.327, dice=tensor(3.4619, device='cuda:0')]train Epoch 142:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.327, dice=tensor(3.4619, device='cuda:0')]train Epoch 142:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.319, dice=tensor(3.4508, device='cuda:0')]train Epoch 142:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.319, dice=tensor(3.4508, device='cuda:0')]train Epoch 142:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.319, dice=tensor(3.4346, device='cuda:0')]train Epoch 142: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.319, dice=tensor(3.4346, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3150 Dice: 0.6869
val Epoch 142:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 142:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.358, dice=tensor(3.1921, device='cuda:0')]val Epoch 142:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.358, dice=tensor(3.1921, device='cuda:0')]val Epoch 142:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.356, dice=tensor(3.2400, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3571 Dice: 0.6480
Epoch 143/199
----------
train Epoch 143:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 143:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.308, dice=tensor(3.4315, device='cuda:0')]train Epoch 143:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.308, dice=tensor(3.4315, device='cuda:0')]train Epoch 143:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.338, dice=tensor(3.3994, device='cuda:0')]train Epoch 143:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.338, dice=tensor(3.3994, device='cuda:0')]train Epoch 143:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.319, dice=tensor(3.4112, device='cuda:0')]train Epoch 143:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.319, dice=tensor(3.4112, device='cuda:0')]train Epoch 143:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.304, dice=tensor(3.4221, device='cuda:0')]train Epoch 143: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.304, dice=tensor(3.4221, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3172 Dice: 0.6844
val Epoch 143:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 143:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.343, dice=tensor(3.2678, device='cuda:0')]val Epoch 143:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.343, dice=tensor(3.2678, device='cuda:0')]val Epoch 143:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.366, dice=tensor(3.2562, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3544 Dice: 0.6512
Epoch 144/199
----------
train Epoch 144:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 144:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.341, dice=tensor(3.2841, device='cuda:0')]train Epoch 144:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.341, dice=tensor(3.2841, device='cuda:0')]train Epoch 144:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.287, dice=tensor(3.4402, device='cuda:0')]train Epoch 144:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.287, dice=tensor(3.4402, device='cuda:0')]train Epoch 144:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s, loss=0.349, dice=tensor(3.3660, device='cuda:0')]train Epoch 144:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.83it/s, loss=0.349, dice=tensor(3.3660, device='cuda:0')]train Epoch 144:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.83it/s, loss=0.311, dice=tensor(3.3863, device='cuda:0')]train Epoch 144: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.311, dice=tensor(3.3863, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                                train Loss: 0.3222 Dice: 0.6773
val Epoch 144:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 144:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.368, dice=tensor(3.1499, device='cuda:0')]val Epoch 144:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.368, dice=tensor(3.1499, device='cuda:0')]val Epoch 144:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.49it/s, loss=0.34, dice=tensor(3.2587, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                             val Loss: 0.3541 Dice: 0.6517
Epoch 145/199
----------
train Epoch 145:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 145:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.376, dice=tensor(3.1084, device='cuda:0')]train Epoch 145:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.376, dice=tensor(3.1084, device='cuda:0')]train Epoch 145:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.323, dice=tensor(3.2569, device='cuda:0')]train Epoch 145:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.323, dice=tensor(3.2569, device='cuda:0')]train Epoch 145:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.293, dice=tensor(3.3594, device='cuda:0')]train Epoch 145:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.293, dice=tensor(3.3594, device='cuda:0')]train Epoch 145:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.33, dice=tensor(3.3620, device='cuda:0')] train Epoch 145: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.33, dice=tensor(3.3620, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                               train Loss: 0.3304 Dice: 0.6724
val Epoch 145:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 145:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.432, dice=tensor(2.8857, device='cuda:0')]val Epoch 145:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.432, dice=tensor(2.8857, device='cuda:0')]val Epoch 145:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.366, dice=tensor(3.0396, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3989 Dice: 0.6079
Epoch 146/199
----------
train Epoch 146:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 146:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.317, dice=tensor(3.3636, device='cuda:0')]train Epoch 146:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.317, dice=tensor(3.3636, device='cuda:0')]train Epoch 146:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.316, dice=tensor(3.4023, device='cuda:0')]train Epoch 146:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.316, dice=tensor(3.4023, device='cuda:0')]train Epoch 146:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.84it/s, loss=0.342, dice=tensor(3.3870, device='cuda:0')]train Epoch 146:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.76it/s, loss=0.342, dice=tensor(3.3870, device='cuda:0')]train Epoch 146:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.76it/s, loss=0.299, dice=tensor(3.4000, device='cuda:0')]train Epoch 146: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.43it/s, loss=0.299, dice=tensor(3.4000, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                                train Loss: 0.3185 Dice: 0.6800
val Epoch 146:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 146:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.463, dice=tensor(2.7174, device='cuda:0')]val Epoch 146:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.463, dice=tensor(2.7174, device='cuda:0')]val Epoch 146:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.394, dice=tensor(2.8972, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.4287 Dice: 0.5794
Epoch 147/199
----------
train Epoch 147:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 147:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.4085, device='cuda:0')]train Epoch 147:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.322, dice=tensor(3.4085, device='cuda:0')]train Epoch 147:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.307, dice=tensor(3.4167, device='cuda:0')]train Epoch 147:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.307, dice=tensor(3.4167, device='cuda:0')]train Epoch 147:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.396, dice=tensor(3.2992, device='cuda:0')]train Epoch 147:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.396, dice=tensor(3.2992, device='cuda:0')]train Epoch 147:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.286, dice=tensor(3.3679, device='cuda:0')]train Epoch 147: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.44it/s, loss=0.286, dice=tensor(3.3679, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                                train Loss: 0.3279 Dice: 0.6736
val Epoch 147:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 147:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.404, dice=tensor(3.0656, device='cuda:0')]val Epoch 147:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.404, dice=tensor(3.0656, device='cuda:0')]val Epoch 147:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.407, dice=tensor(3.0098, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.4059 Dice: 0.6020
Epoch 148/199
----------
train Epoch 148:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 148:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.328, dice=tensor(3.3711, device='cuda:0')]train Epoch 148:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.328, dice=tensor(3.3711, device='cuda:0')]train Epoch 148:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.326, dice=tensor(3.3677, device='cuda:0')]train Epoch 148:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.326, dice=tensor(3.3677, device='cuda:0')]train Epoch 148:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.315, dice=tensor(3.3704, device='cuda:0')]train Epoch 148:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.93it/s, loss=0.315, dice=tensor(3.3704, device='cuda:0')]train Epoch 148:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.93it/s, loss=0.294, dice=tensor(3.4161, device='cuda:0')]train Epoch 148: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.58it/s, loss=0.294, dice=tensor(3.4161, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3158 Dice: 0.6832
val Epoch 148:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 148:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.378, dice=tensor(3.1742, device='cuda:0')]val Epoch 148:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.378, dice=tensor(3.1742, device='cuda:0')]val Epoch 148:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.411, dice=tensor(3.0698, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3941 Dice: 0.6140
Epoch 149/199
----------
train Epoch 149:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 149:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.323, dice=tensor(3.4444, device='cuda:0')]train Epoch 149:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.323, dice=tensor(3.4444, device='cuda:0')]train Epoch 149:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.61it/s, loss=0.293, dice=tensor(3.4910, device='cuda:0')]train Epoch 149:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.293, dice=tensor(3.4910, device='cuda:0')]train Epoch 149:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.356, dice=tensor(3.3685, device='cuda:0')]train Epoch 149:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.77it/s, loss=0.356, dice=tensor(3.3685, device='cuda:0')]train Epoch 149:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.77it/s, loss=0.306, dice=tensor(3.3845, device='cuda:0')]train Epoch 149: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.46it/s, loss=0.306, dice=tensor(3.3845, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                                train Loss: 0.3193 Dice: 0.6769
val Epoch 149:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 149:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.399, dice=tensor(3.0324, device='cuda:0')]val Epoch 149:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.399, dice=tensor(3.0324, device='cuda:0')]val Epoch 149:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.47it/s, loss=0.342, dice=tensor(3.1851, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3707 Dice: 0.6370
Epoch 150/199
----------
train Epoch 150:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 150:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.328, dice=tensor(3.4037, device='cuda:0')]train Epoch 150:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.328, dice=tensor(3.4037, device='cuda:0')]train Epoch 150:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.341, dice=tensor(3.3527, device='cuda:0')]train Epoch 150:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.341, dice=tensor(3.3527, device='cuda:0')]train Epoch 150:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.286, dice=tensor(3.4336, device='cuda:0')]train Epoch 150:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.89it/s, loss=0.286, dice=tensor(3.4336, device='cuda:0')]train Epoch 150:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.89it/s, loss=0.356, dice=tensor(3.3602, device='cuda:0')]train Epoch 150: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.356, dice=tensor(3.3602, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                                train Loss: 0.3277 Dice: 0.6720
val Epoch 150:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 150:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.337, dice=tensor(3.3079, device='cuda:0')]val Epoch 150:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.37it/s, loss=0.337, dice=tensor(3.3079, device='cuda:0')]val Epoch 150:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.37it/s, loss=0.366, dice=tensor(3.2591, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3516 Dice: 0.6518
Epoch 151/199
----------
train Epoch 151:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 151:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.302, dice=tensor(3.5432, device='cuda:0')]train Epoch 151:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.302, dice=tensor(3.5432, device='cuda:0')]train Epoch 151:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.348, dice=tensor(3.4168, device='cuda:0')]train Epoch 151:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.348, dice=tensor(3.4168, device='cuda:0')]train Epoch 151:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.279, dice=tensor(3.4651, device='cuda:0')]train Epoch 151:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.279, dice=tensor(3.4651, device='cuda:0')]train Epoch 151:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.318, dice=tensor(3.4482, device='cuda:0')]train Epoch 151: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.318, dice=tensor(3.4482, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                                                                train Loss: 0.3117 Dice: 0.6896
val Epoch 151:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 151:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.371, dice=tensor(3.1559, device='cuda:0')]val Epoch 151:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.371, dice=tensor(3.1559, device='cuda:0')]val Epoch 151:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.337, dice=tensor(3.2620, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3540 Dice: 0.6524
Epoch 152/199
----------
train Epoch 152:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 152:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.345, dice=tensor(3.3042, device='cuda:0')]train Epoch 152:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.345, dice=tensor(3.3042, device='cuda:0')]train Epoch 152:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.56it/s, loss=0.341, dice=tensor(3.3107, device='cuda:0')]train Epoch 152:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.341, dice=tensor(3.3107, device='cuda:0')]train Epoch 152:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.78it/s, loss=0.318, dice=tensor(3.3472, device='cuda:0')]train Epoch 152:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.70it/s, loss=0.318, dice=tensor(3.3472, device='cuda:0')]train Epoch 152:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.70it/s, loss=0.273, dice=tensor(3.4214, device='cuda:0')]train Epoch 152: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.39it/s, loss=0.273, dice=tensor(3.4214, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                                train Loss: 0.3193 Dice: 0.6843
val Epoch 152:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 152:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.352, dice=tensor(3.2170, device='cuda:0')]val Epoch 152:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.86it/s, loss=0.352, dice=tensor(3.2170, device='cuda:0')]val Epoch 152:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.86it/s, loss=0.347, dice=tensor(3.2794, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3494 Dice: 0.6559
Epoch 153/199
----------
train Epoch 153:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 153:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.29, dice=tensor(3.5317, device='cuda:0')]train Epoch 153:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.29, dice=tensor(3.5317, device='cuda:0')]train Epoch 153:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.36, dice=tensor(3.3870, device='cuda:0')]train Epoch 153:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.36, dice=tensor(3.3870, device='cuda:0')]train Epoch 153:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.278, dice=tensor(3.4614, device='cuda:0')]train Epoch 153:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.278, dice=tensor(3.4614, device='cuda:0')]train Epoch 153:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.33, dice=tensor(3.4369, device='cuda:0')] train Epoch 153: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.33, dice=tensor(3.4369, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                               train Loss: 0.3148 Dice: 0.6874
val Epoch 153:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 153:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.39, dice=tensor(3.0752, device='cuda:0')]val Epoch 153:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.39, dice=tensor(3.0752, device='cuda:0')]val Epoch 153:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.312, dice=tensor(3.2813, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3510 Dice: 0.6563
Epoch 154/199
----------
train Epoch 154:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 154:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.356, dice=tensor(3.1792, device='cuda:0')]train Epoch 154:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.356, dice=tensor(3.1792, device='cuda:0')]train Epoch 154:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.282, dice=tensor(3.3596, device='cuda:0')]train Epoch 154:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.282, dice=tensor(3.3596, device='cuda:0')]train Epoch 154:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.304, dice=tensor(3.4088, device='cuda:0')]train Epoch 154:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.304, dice=tensor(3.4088, device='cuda:0')]train Epoch 154:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.32, dice=tensor(3.4155, device='cuda:0')] train Epoch 154: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.32, dice=tensor(3.4155, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                               train Loss: 0.3154 Dice: 0.6831
val Epoch 154:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 154:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.392, dice=tensor(3.0651, device='cuda:0')]val Epoch 154:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.392, dice=tensor(3.0651, device='cuda:0')]val Epoch 154:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.66it/s, loss=0.309, dice=tensor(3.2837, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3505 Dice: 0.6567
Epoch 155/199
----------
train Epoch 155:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 155:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.272, dice=tensor(3.6069, device='cuda:0')]train Epoch 155:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.272, dice=tensor(3.6069, device='cuda:0')]train Epoch 155:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.321, dice=tensor(3.5310, device='cuda:0')]train Epoch 155:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.321, dice=tensor(3.5310, device='cuda:0')]train Epoch 155:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.367, dice=tensor(3.4234, device='cuda:0')]train Epoch 155:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.367, dice=tensor(3.4234, device='cuda:0')]train Epoch 155:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.3, dice=tensor(3.4420, device='cuda:0')]  train Epoch 155: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.3, dice=tensor(3.4420, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                              train Loss: 0.3149 Dice: 0.6884
val Epoch 155:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 155:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.32, dice=tensor(3.4532, device='cuda:0')]val Epoch 155:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.32, dice=tensor(3.4532, device='cuda:0')]val Epoch 155:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.62it/s, loss=0.384, dice=tensor(3.2743, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3523 Dice: 0.6549
Epoch 156/199
----------
train Epoch 156:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 156:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.288, dice=tensor(3.5516, device='cuda:0')]train Epoch 156:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.288, dice=tensor(3.5516, device='cuda:0')]train Epoch 156:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.337, dice=tensor(3.4342, device='cuda:0')]train Epoch 156:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.337, dice=tensor(3.4342, device='cuda:0')]train Epoch 156:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.301, dice=tensor(3.4558, device='cuda:0')]train Epoch 156:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.68it/s, loss=0.301, dice=tensor(3.4558, device='cuda:0')]train Epoch 156:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.68it/s, loss=0.332, dice=tensor(3.4412, device='cuda:0')]train Epoch 156: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.37it/s, loss=0.332, dice=tensor(3.4412, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                                train Loss: 0.3144 Dice: 0.6882
val Epoch 156:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 156:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.337, dice=tensor(3.3861, device='cuda:0')]val Epoch 156:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.337, dice=tensor(3.3861, device='cuda:0')]val Epoch 156:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.368, dice=tensor(3.2742, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
                                                                                                              val Loss: 0.3527 Dice: 0.6548
Epoch 157/199
----------
train Epoch 157:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 157:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.315, dice=tensor(3.4253, device='cuda:0')]train Epoch 157:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.315, dice=tensor(3.4253, device='cuda:0')]train Epoch 157:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.333, dice=tensor(3.3928, device='cuda:0')]train Epoch 157:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.333, dice=tensor(3.3928, device='cuda:0')]train Epoch 157:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.359, dice=tensor(3.3508, device='cuda:0')]train Epoch 157:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.359, dice=tensor(3.3508, device='cuda:0')]train Epoch 157:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.278, dice=tensor(3.4155, device='cuda:0')]train Epoch 157: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.52it/s, loss=0.278, dice=tensor(3.4155, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                                                                train Loss: 0.3212 Dice: 0.6831
val Epoch 157:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 157:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.318, dice=tensor(3.4663, device='cuda:0')]val Epoch 157:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.318, dice=tensor(3.4663, device='cuda:0')]val Epoch 157:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.79it/s, loss=0.39, dice=tensor(3.2751, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.3537 Dice: 0.6550
Epoch 158/199
----------
train Epoch 158:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 158:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.311, dice=tensor(3.4396, device='cuda:0')]train Epoch 158:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.48it/s, loss=0.311, dice=tensor(3.4396, device='cuda:0')]train Epoch 158:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.48it/s, loss=0.299, dice=tensor(3.4667, device='cuda:0')]train Epoch 158:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.67it/s, loss=0.299, dice=tensor(3.4667, device='cuda:0')]train Epoch 158:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.67it/s, loss=0.339, dice=tensor(3.4278, device='cuda:0')]train Epoch 158:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.60it/s, loss=0.339, dice=tensor(3.4278, device='cuda:0')]train Epoch 158:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.60it/s, loss=0.313, dice=tensor(3.4170, device='cuda:0')]train Epoch 158: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.29it/s, loss=0.313, dice=tensor(3.4170, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3153 Dice: 0.6834
val Epoch 158:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 158:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.355, dice=tensor(3.3037, device='cuda:0')]val Epoch 158:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.355, dice=tensor(3.3037, device='cuda:0')]val Epoch 158:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.74it/s, loss=0.359, dice=tensor(3.2494, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3570 Dice: 0.6499
Epoch 159/199
----------
train Epoch 159:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 159:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.303, dice=tensor(3.4637, device='cuda:0')]train Epoch 159:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.303, dice=tensor(3.4637, device='cuda:0')]train Epoch 159:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.343, dice=tensor(3.3903, device='cuda:0')]train Epoch 159:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.343, dice=tensor(3.3903, device='cuda:0')]train Epoch 159:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s, loss=0.308, dice=tensor(3.4068, device='cuda:0')]train Epoch 159:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.86it/s, loss=0.308, dice=tensor(3.4068, device='cuda:0')]train Epoch 159:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.86it/s, loss=0.297, dice=tensor(3.4412, device='cuda:0')]train Epoch 159: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.297, dice=tensor(3.4412, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                                train Loss: 0.3128 Dice: 0.6882
val Epoch 159:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 159:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.331, dice=tensor(3.4176, device='cuda:0')]val Epoch 159:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.331, dice=tensor(3.4176, device='cuda:0')]val Epoch 159:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.55it/s, loss=0.399, dice=tensor(3.2481, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3649 Dice: 0.6496
Epoch 160/199
----------
train Epoch 160:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 160:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.328, dice=tensor(3.3129, device='cuda:0')]train Epoch 160:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.328, dice=tensor(3.3129, device='cuda:0')]train Epoch 160:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.309, dice=tensor(3.3887, device='cuda:0')]train Epoch 160:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.67it/s, loss=0.309, dice=tensor(3.3887, device='cuda:0')]train Epoch 160:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.67it/s, loss=0.354, dice=tensor(3.3096, device='cuda:0')]train Epoch 160:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.60it/s, loss=0.354, dice=tensor(3.3096, device='cuda:0')]train Epoch 160:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.60it/s, loss=0.288, dice=tensor(3.3742, device='cuda:0')]train Epoch 160: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.30it/s, loss=0.288, dice=tensor(3.3742, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                                train Loss: 0.3195 Dice: 0.6748
val Epoch 160:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 160:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.357, dice=tensor(3.1963, device='cuda:0')]val Epoch 160:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.357, dice=tensor(3.1963, device='cuda:0')]val Epoch 160:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.363, dice=tensor(3.2396, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3599 Dice: 0.6479
Epoch 161/199
----------
train Epoch 161:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 161:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.321, dice=tensor(3.4138, device='cuda:0')]train Epoch 161:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.321, dice=tensor(3.4138, device='cuda:0')]train Epoch 161:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.292, dice=tensor(3.4866, device='cuda:0')]train Epoch 161:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.292, dice=tensor(3.4866, device='cuda:0')]train Epoch 161:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.292, dice=tensor(3.5076, device='cuda:0')]train Epoch 161:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.80it/s, loss=0.292, dice=tensor(3.5076, device='cuda:0')]train Epoch 161:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.80it/s, loss=0.346, dice=tensor(3.4494, device='cuda:0')]train Epoch 161: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.346, dice=tensor(3.4494, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                                train Loss: 0.3127 Dice: 0.6899
val Epoch 161:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 161:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.372, dice=tensor(3.1389, device='cuda:0')]val Epoch 161:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.372, dice=tensor(3.1389, device='cuda:0')]val Epoch 161:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.333, dice=tensor(3.2700, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3528 Dice: 0.6540
Epoch 162/199
----------
train Epoch 162:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 162:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.342, dice=tensor(3.3190, device='cuda:0')]train Epoch 162:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.342, dice=tensor(3.3190, device='cuda:0')]train Epoch 162:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.353, dice=tensor(3.2941, device='cuda:0')]train Epoch 162:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.353, dice=tensor(3.2941, device='cuda:0')]train Epoch 162:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.273, dice=tensor(3.4100, device='cuda:0')]train Epoch 162:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.273, dice=tensor(3.4100, device='cuda:0')]train Epoch 162:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.293, dice=tensor(3.4451, device='cuda:0')]train Epoch 162: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.37it/s, loss=0.293, dice=tensor(3.4451, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                                train Loss: 0.3155 Dice: 0.6890
val Epoch 162:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 162:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.367, dice=tensor(3.2608, device='cuda:0')]val Epoch 162:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.367, dice=tensor(3.2608, device='cuda:0')]val Epoch 162:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.335, dice=tensor(3.2758, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3508 Dice: 0.6552
Epoch 163/199
----------
train Epoch 163:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 163:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.34, dice=tensor(3.3125, device='cuda:0')]train Epoch 163:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.34, dice=tensor(3.3125, device='cuda:0')]train Epoch 163:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.63it/s, loss=0.311, dice=tensor(3.3715, device='cuda:0')]train Epoch 163:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.311, dice=tensor(3.3715, device='cuda:0')]train Epoch 163:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.87it/s, loss=0.317, dice=tensor(3.4002, device='cuda:0')]train Epoch 163:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.80it/s, loss=0.317, dice=tensor(3.4002, device='cuda:0')]train Epoch 163:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.80it/s, loss=0.287, dice=tensor(3.4453, device='cuda:0')]train Epoch 163: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.287, dice=tensor(3.4453, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3138 Dice: 0.6891
val Epoch 163:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 163:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.348, dice=tensor(3.3301, device='cuda:0')]val Epoch 163:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.348, dice=tensor(3.3301, device='cuda:0')]val Epoch 163:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.352, dice=tensor(3.2785, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3501 Dice: 0.6557
Epoch 164/199
----------
train Epoch 164:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 164:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.347, dice=tensor(3.3005, device='cuda:0')]train Epoch 164:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.347, dice=tensor(3.3005, device='cuda:0')]train Epoch 164:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.53it/s, loss=0.332, dice=tensor(3.3243, device='cuda:0')]train Epoch 164:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.332, dice=tensor(3.3243, device='cuda:0')]train Epoch 164:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.74it/s, loss=0.275, dice=tensor(3.4259, device='cuda:0')]train Epoch 164:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.66it/s, loss=0.275, dice=tensor(3.4259, device='cuda:0')]train Epoch 164:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.66it/s, loss=0.32, dice=tensor(3.4123, device='cuda:0')] train Epoch 164: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.35it/s, loss=0.32, dice=tensor(3.4123, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                               train Loss: 0.3184 Dice: 0.6825
val Epoch 164:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 164:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.305, dice=tensor(3.5296, device='cuda:0')]val Epoch 164:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.90it/s, loss=0.305, dice=tensor(3.5296, device='cuda:0')]val Epoch 164:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.90it/s, loss=0.401, dice=tensor(3.2753, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3534 Dice: 0.6551
Epoch 165/199
----------
train Epoch 165:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 165:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.362, dice=tensor(3.1960, device='cuda:0')]train Epoch 165:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.362, dice=tensor(3.1960, device='cuda:0')]train Epoch 165:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.295, dice=tensor(3.3441, device='cuda:0')]train Epoch 165:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.295, dice=tensor(3.3441, device='cuda:0')]train Epoch 165:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s, loss=0.323, dice=tensor(3.3738, device='cuda:0')]train Epoch 165:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.90it/s, loss=0.323, dice=tensor(3.3738, device='cuda:0')]train Epoch 165:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.90it/s, loss=0.283, dice=tensor(3.4309, device='cuda:0')]train Epoch 165: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.283, dice=tensor(3.4309, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                                train Loss: 0.3158 Dice: 0.6862
val Epoch 165:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 165:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.358, dice=tensor(3.1945, device='cuda:0')]val Epoch 165:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.358, dice=tensor(3.1945, device='cuda:0')]val Epoch 165:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.342, dice=tensor(3.2780, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3502 Dice: 0.6556
Epoch 166/199
----------
train Epoch 166:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 166:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.306, dice=tensor(3.4803, device='cuda:0')]train Epoch 166:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.306, dice=tensor(3.4803, device='cuda:0')]train Epoch 166:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.60it/s, loss=0.278, dice=tensor(3.5504, device='cuda:0')]train Epoch 166:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.278, dice=tensor(3.5504, device='cuda:0')]train Epoch 166:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.83it/s, loss=0.312, dice=tensor(3.5051, device='cuda:0')]train Epoch 166:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.75it/s, loss=0.312, dice=tensor(3.5051, device='cuda:0')]train Epoch 166:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.75it/s, loss=0.363, dice=tensor(3.4290, device='cuda:0')]train Epoch 166: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.363, dice=tensor(3.4290, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                                train Loss: 0.3147 Dice: 0.6858
val Epoch 166:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 166:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.301, dice=tensor(3.5307, device='cuda:0')]val Epoch 166:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  3.01it/s, loss=0.301, dice=tensor(3.5307, device='cuda:0')]val Epoch 166:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  3.01it/s, loss=0.396, dice=tensor(3.2818, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3484 Dice: 0.6564
Epoch 167/199
----------
train Epoch 167:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 167:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.352, dice=tensor(3.3066, device='cuda:0')]train Epoch 167:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.352, dice=tensor(3.3066, device='cuda:0')]train Epoch 167:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.287, dice=tensor(3.4680, device='cuda:0')]train Epoch 167:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.287, dice=tensor(3.4680, device='cuda:0')]train Epoch 167:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.33, dice=tensor(3.4431, device='cuda:0')] train Epoch 167:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.93it/s, loss=0.33, dice=tensor(3.4431, device='cuda:0')]train Epoch 167:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.93it/s, loss=0.293, dice=tensor(3.4545, device='cuda:0')]train Epoch 167: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.58it/s, loss=0.293, dice=tensor(3.4545, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                                train Loss: 0.3154 Dice: 0.6909
val Epoch 167:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 167:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.381, dice=tensor(3.1201, device='cuda:0')]val Epoch 167:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.381, dice=tensor(3.1201, device='cuda:0')]val Epoch 167:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.323, dice=tensor(3.2828, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3519 Dice: 0.6566
Epoch 168/199
----------
train Epoch 168:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 168:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.292, dice=tensor(3.5716, device='cuda:0')]train Epoch 168:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.292, dice=tensor(3.5716, device='cuda:0')]train Epoch 168:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.35, dice=tensor(3.4407, device='cuda:0')] train Epoch 168:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.35, dice=tensor(3.4407, device='cuda:0')]train Epoch 168:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.294, dice=tensor(3.4606, device='cuda:0')]train Epoch 168:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.294, dice=tensor(3.4606, device='cuda:0')]train Epoch 168:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.307, dice=tensor(3.4667, device='cuda:0')]train Epoch 168: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.307, dice=tensor(3.4667, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                                train Loss: 0.3106 Dice: 0.6933
val Epoch 168:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 168:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.342, dice=tensor(3.3634, device='cuda:0')]val Epoch 168:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.342, dice=tensor(3.3634, device='cuda:0')]val Epoch 168:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.53it/s, loss=0.356, dice=tensor(3.2839, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3491 Dice: 0.6568
Epoch 169/199
----------
train Epoch 169:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 169:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.329, dice=tensor(3.3926, device='cuda:0')]train Epoch 169:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.329, dice=tensor(3.3926, device='cuda:0')]train Epoch 169:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.81it/s, loss=0.307, dice=tensor(3.4212, device='cuda:0')]train Epoch 169:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.09it/s, loss=0.307, dice=tensor(3.4212, device='cuda:0')]train Epoch 169:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.09it/s, loss=0.326, dice=tensor(3.4090, device='cuda:0')]train Epoch 169:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.00it/s, loss=0.326, dice=tensor(3.4090, device='cuda:0')]train Epoch 169:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.00it/s, loss=0.28, dice=tensor(3.4604, device='cuda:0')] train Epoch 169: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.65it/s, loss=0.28, dice=tensor(3.4604, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
                                                                                                               train Loss: 0.3105 Dice: 0.6921
val Epoch 169:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 169:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.39, dice=tensor(3.0842, device='cuda:0')]val Epoch 169:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.39, dice=tensor(3.0842, device='cuda:0')]val Epoch 169:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.313, dice=tensor(3.2853, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3514 Dice: 0.6571
Epoch 170/199
----------
train Epoch 170:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 170:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.27, dice=tensor(3.6471, device='cuda:0')]train Epoch 170:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.27, dice=tensor(3.6471, device='cuda:0')]train Epoch 170:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.68it/s, loss=0.358, dice=tensor(3.3994, device='cuda:0')]train Epoch 170:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.358, dice=tensor(3.3994, device='cuda:0')]train Epoch 170:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s, loss=0.321, dice=tensor(3.4027, device='cuda:0')]train Epoch 170:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.85it/s, loss=0.321, dice=tensor(3.4027, device='cuda:0')]train Epoch 170:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.85it/s, loss=0.327, dice=tensor(3.4038, device='cuda:0')]train Epoch 170: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.327, dice=tensor(3.4038, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3190 Dice: 0.6808
val Epoch 170:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 170:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.375, dice=tensor(3.1434, device='cuda:0')]val Epoch 170:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.28it/s, loss=0.375, dice=tensor(3.1434, device='cuda:0')]val Epoch 170:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.28it/s, loss=0.321, dice=tensor(3.2917, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3482 Dice: 0.6583
Epoch 171/199
----------
train Epoch 171:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 171:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.278, dice=tensor(3.6170, device='cuda:0')]train Epoch 171:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.278, dice=tensor(3.6170, device='cuda:0')]train Epoch 171:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.76it/s, loss=0.348, dice=tensor(3.4512, device='cuda:0')]train Epoch 171:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.348, dice=tensor(3.4512, device='cuda:0')]train Epoch 171:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s, loss=0.342, dice=tensor(3.3923, device='cuda:0')]train Epoch 171:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.95it/s, loss=0.342, dice=tensor(3.3923, device='cuda:0')]train Epoch 171:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.95it/s, loss=0.301, dice=tensor(3.4060, device='cuda:0')]train Epoch 171: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.60it/s, loss=0.301, dice=tensor(3.4060, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                                train Loss: 0.3171 Dice: 0.6812
val Epoch 171:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 171:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.366, dice=tensor(3.1822, device='cuda:0')]val Epoch 171:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.366, dice=tensor(3.1822, device='cuda:0')]val Epoch 171:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.46it/s, loss=0.33, dice=tensor(3.2938, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                             val Loss: 0.3484 Dice: 0.6588
Epoch 172/199
----------
train Epoch 172:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 172:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.3501, device='cuda:0')]train Epoch 172:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.333, dice=tensor(3.3501, device='cuda:0')]train Epoch 172:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.75it/s, loss=0.365, dice=tensor(3.3005, device='cuda:0')]train Epoch 172:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.365, dice=tensor(3.3005, device='cuda:0')]train Epoch 172:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.268, dice=tensor(3.4360, device='cuda:0')]train Epoch 172:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.93it/s, loss=0.268, dice=tensor(3.4360, device='cuda:0')]train Epoch 172:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.93it/s, loss=0.317, dice=tensor(3.4126, device='cuda:0')]train Epoch 172: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.59it/s, loss=0.317, dice=tensor(3.4126, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3207 Dice: 0.6825
val Epoch 172:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 172:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.369, dice=tensor(3.2249, device='cuda:0')]val Epoch 172:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.369, dice=tensor(3.2249, device='cuda:0')]val Epoch 172:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.317, dice=tensor(3.2954, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3433 Dice: 0.6591
Epoch 173/199
----------
train Epoch 173:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 173:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.324, dice=tensor(3.3837, device='cuda:0')]train Epoch 173:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.324, dice=tensor(3.3837, device='cuda:0')]train Epoch 173:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.69it/s, loss=0.338, dice=tensor(3.3641, device='cuda:0')]train Epoch 173:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.338, dice=tensor(3.3641, device='cuda:0')]train Epoch 173:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.287, dice=tensor(3.4308, device='cuda:0')]train Epoch 173:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.287, dice=tensor(3.4308, device='cuda:0')]train Epoch 173:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.29, dice=tensor(3.4545, device='cuda:0')] train Epoch 173: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.29, dice=tensor(3.4545, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                                                               train Loss: 0.3098 Dice: 0.6909
val Epoch 173:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 173:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.353, dice=tensor(3.3149, device='cuda:0')]val Epoch 173:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.353, dice=tensor(3.3149, device='cuda:0')]val Epoch 173:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.34, dice=tensor(3.2932, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3461 Dice: 0.6586
Epoch 174/199
----------
train Epoch 174:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 174:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.292, dice=tensor(3.5712, device='cuda:0')]train Epoch 174:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.292, dice=tensor(3.5712, device='cuda:0')]train Epoch 174:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.287, dice=tensor(3.5645, device='cuda:0')]train Epoch 174:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.287, dice=tensor(3.5645, device='cuda:0')]train Epoch 174:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.76it/s, loss=0.371, dice=tensor(3.4450, device='cuda:0')]train Epoch 174:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.371, dice=tensor(3.4450, device='cuda:0')]train Epoch 174:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.305, dice=tensor(3.4134, device='cuda:0')]train Epoch 174: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.305, dice=tensor(3.4134, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                                                                train Loss: 0.3136 Dice: 0.6827
val Epoch 174:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 174:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.348, dice=tensor(3.2265, device='cuda:0')]val Epoch 174:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.348, dice=tensor(3.2265, device='cuda:0')]val Epoch 174:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.349, dice=tensor(3.2837, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                              val Loss: 0.3484 Dice: 0.6567
Epoch 175/199
----------
train Epoch 175:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 175:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.3240, device='cuda:0')]train Epoch 175:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.333, dice=tensor(3.3240, device='cuda:0')]train Epoch 175:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.296, dice=tensor(3.4288, device='cuda:0')]train Epoch 175:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.296, dice=tensor(3.4288, device='cuda:0')]train Epoch 175:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s, loss=0.296, dice=tensor(3.4644, device='cuda:0')]train Epoch 175:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.296, dice=tensor(3.4644, device='cuda:0')]train Epoch 175:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.342, dice=tensor(3.4136, device='cuda:0')]train Epoch 175: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.55it/s, loss=0.342, dice=tensor(3.4136, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                                train Loss: 0.3169 Dice: 0.6827
val Epoch 175:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 175:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.38, dice=tensor(3.1262, device='cuda:0')]val Epoch 175:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.38, dice=tensor(3.1262, device='cuda:0')]val Epoch 175:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.65it/s, loss=0.321, dice=tensor(3.2888, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3506 Dice: 0.6578
Epoch 176/199
----------
train Epoch 176:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 176:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.319, dice=tensor(3.4079, device='cuda:0')]train Epoch 176:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.44it/s, loss=0.319, dice=tensor(3.4079, device='cuda:0')]train Epoch 176:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.44it/s, loss=0.296, dice=tensor(3.4719, device='cuda:0')]train Epoch 176:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.62it/s, loss=0.296, dice=tensor(3.4719, device='cuda:0')]train Epoch 176:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.62it/s, loss=0.297, dice=tensor(3.4693, device='cuda:0')]train Epoch 176:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.55it/s, loss=0.297, dice=tensor(3.4693, device='cuda:0')]train Epoch 176:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.55it/s, loss=0.322, dice=tensor(3.4675, device='cuda:0')]train Epoch 176: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.26it/s, loss=0.322, dice=tensor(3.4675, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
                                                                                                                train Loss: 0.3086 Dice: 0.6935
val Epoch 176:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 176:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.378, dice=tensor(3.1345, device='cuda:0')]val Epoch 176:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.378, dice=tensor(3.1345, device='cuda:0')]val Epoch 176:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.71it/s, loss=0.321, dice=tensor(3.2938, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3495 Dice: 0.6588
Epoch 177/199
----------
train Epoch 177:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 177:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.346, dice=tensor(3.3385, device='cuda:0')]train Epoch 177:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.346, dice=tensor(3.3385, device='cuda:0')]train Epoch 177:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.65it/s, loss=0.282, dice=tensor(3.4677, device='cuda:0')]train Epoch 177:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.282, dice=tensor(3.4677, device='cuda:0')]train Epoch 177:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.89it/s, loss=0.335, dice=tensor(3.4312, device='cuda:0')]train Epoch 177:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.82it/s, loss=0.335, dice=tensor(3.4312, device='cuda:0')]train Epoch 177:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.82it/s, loss=0.275, dice=tensor(3.4728, device='cuda:0')]train Epoch 177: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.275, dice=tensor(3.4728, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                                train Loss: 0.3096 Dice: 0.6946
val Epoch 177:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 177:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.361, dice=tensor(3.2104, device='cuda:0')]val Epoch 177:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.78it/s, loss=0.361, dice=tensor(3.2104, device='cuda:0')]val Epoch 177:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.78it/s, loss=0.332, dice=tensor(3.3004, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3467 Dice: 0.6601
Epoch 178/199
----------
train Epoch 178:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 178:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.321, dice=tensor(3.4195, device='cuda:0')]train Epoch 178:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.46it/s, loss=0.321, dice=tensor(3.4195, device='cuda:0')]train Epoch 178:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.46it/s, loss=0.343, dice=tensor(3.3730, device='cuda:0')]train Epoch 178:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.66it/s, loss=0.343, dice=tensor(3.3730, device='cuda:0')]train Epoch 178:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.66it/s, loss=0.318, dice=tensor(3.3562, device='cuda:0')]train Epoch 178:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.59it/s, loss=0.318, dice=tensor(3.3562, device='cuda:0')]train Epoch 178:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.59it/s, loss=0.272, dice=tensor(3.4367, device='cuda:0')]train Epoch 178: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.30it/s, loss=0.272, dice=tensor(3.4367, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                                                                train Loss: 0.3136 Dice: 0.6873
val Epoch 178:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 178:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.316, dice=tensor(3.4642, device='cuda:0')]val Epoch 178:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.316, dice=tensor(3.4642, device='cuda:0')]val Epoch 178:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.375, dice=tensor(3.3023, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                              val Loss: 0.3457 Dice: 0.6605
Epoch 179/199
----------
train Epoch 179:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 179:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.334, dice=tensor(3.3862, device='cuda:0')]train Epoch 179:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.334, dice=tensor(3.3862, device='cuda:0')]train Epoch 179:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.343, dice=tensor(3.3500, device='cuda:0')]train Epoch 179:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.343, dice=tensor(3.3500, device='cuda:0')]train Epoch 179:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.3, dice=tensor(3.4109, device='cuda:0')]  train Epoch 179:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.72it/s, loss=0.3, dice=tensor(3.4109, device='cuda:0')]train Epoch 179:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.72it/s, loss=0.299, dice=tensor(3.4352, device='cuda:0')]train Epoch 179: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.41it/s, loss=0.299, dice=tensor(3.4352, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3191 Dice: 0.6870
val Epoch 179:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 179:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.331, dice=tensor(3.3893, device='cuda:0')]val Epoch 179:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.76it/s, loss=0.331, dice=tensor(3.3893, device='cuda:0')]val Epoch 179:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.76it/s, loss=0.358, dice=tensor(3.3025, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3444 Dice: 0.6605
Epoch 180/199
----------
train Epoch 180:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 180:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.3480, device='cuda:0')]train Epoch 180:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.338, dice=tensor(3.3480, device='cuda:0')]train Epoch 180:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.47it/s, loss=0.351, dice=tensor(3.3429, device='cuda:0')]train Epoch 180:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.66it/s, loss=0.351, dice=tensor(3.3429, device='cuda:0')]train Epoch 180:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.66it/s, loss=0.314, dice=tensor(3.3662, device='cuda:0')]train Epoch 180:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.59it/s, loss=0.314, dice=tensor(3.3662, device='cuda:0')]train Epoch 180:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.59it/s, loss=0.272, dice=tensor(3.4360, device='cuda:0')]train Epoch 180: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.30it/s, loss=0.272, dice=tensor(3.4360, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                                train Loss: 0.3187 Dice: 0.6872
val Epoch 180:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 180:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.333, dice=tensor(3.3056, device='cuda:0')]val Epoch 180:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.333, dice=tensor(3.3056, device='cuda:0')]val Epoch 180:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.56it/s, loss=0.356, dice=tensor(3.3058, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3445 Dice: 0.6612
Epoch 181/199
----------
train Epoch 181:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 181:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.316, dice=tensor(3.4526, device='cuda:0')]train Epoch 181:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.316, dice=tensor(3.4526, device='cuda:0')]train Epoch 181:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.74it/s, loss=0.322, dice=tensor(3.4251, device='cuda:0')]train Epoch 181:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.322, dice=tensor(3.4251, device='cuda:0')]train Epoch 181:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s, loss=0.3, dice=tensor(3.4454, device='cuda:0')]  train Epoch 181:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.92it/s, loss=0.3, dice=tensor(3.4454, device='cuda:0')]train Epoch 181:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.92it/s, loss=0.291, dice=tensor(3.4624, device='cuda:0')]train Epoch 181: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.59it/s, loss=0.291, dice=tensor(3.4624, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                                                                train Loss: 0.3072 Dice: 0.6925
val Epoch 181:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 181:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.33, dice=tensor(3.4194, device='cuda:0')]val Epoch 181:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.33, dice=tensor(3.4194, device='cuda:0')]val Epoch 181:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.364, dice=tensor(3.3037, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3470 Dice: 0.6607
Epoch 182/199
----------
train Epoch 182:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 182:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.308, dice=tensor(3.4462, device='cuda:0')]train Epoch 182:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.308, dice=tensor(3.4462, device='cuda:0')]train Epoch 182:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.285, dice=tensor(3.5142, device='cuda:0')]train Epoch 182:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.285, dice=tensor(3.5142, device='cuda:0')]train Epoch 182:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.388, dice=tensor(3.3765, device='cuda:0')]train Epoch 182:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.388, dice=tensor(3.3765, device='cuda:0')]train Epoch 182:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.298, dice=tensor(3.4075, device='cuda:0')]train Epoch 182: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.56it/s, loss=0.298, dice=tensor(3.4075, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                                train Loss: 0.3199 Dice: 0.6815
val Epoch 182:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 182:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.336, dice=tensor(3.3856, device='cuda:0')]val Epoch 182:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.336, dice=tensor(3.3856, device='cuda:0')]val Epoch 182:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.67it/s, loss=0.35, dice=tensor(3.3109, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
                                                                                                             val Loss: 0.3430 Dice: 0.6622
Epoch 183/199
----------
train Epoch 183:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 183:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.31, dice=tensor(3.4142, device='cuda:0')]train Epoch 183:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.31, dice=tensor(3.4142, device='cuda:0')]train Epoch 183:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.325, dice=tensor(3.3429, device='cuda:0')]train Epoch 183:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.325, dice=tensor(3.3429, device='cuda:0')]train Epoch 183:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.265, dice=tensor(3.4644, device='cuda:0')]train Epoch 183:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.265, dice=tensor(3.4644, device='cuda:0')]train Epoch 183:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.342, dice=tensor(3.4349, device='cuda:0')]train Epoch 183: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.51it/s, loss=0.342, dice=tensor(3.4349, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3104 Dice: 0.6870
val Epoch 183:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 183:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.322, dice=tensor(3.4493, device='cuda:0')]val Epoch 183:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.322, dice=tensor(3.4493, device='cuda:0')]val Epoch 183:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.60it/s, loss=0.371, dice=tensor(3.3141, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
                                                                                                              val Loss: 0.3464 Dice: 0.6628
Epoch 184/199
----------
train Epoch 184:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 184:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.295, dice=tensor(3.5814, device='cuda:0')]train Epoch 184:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.295, dice=tensor(3.5814, device='cuda:0')]train Epoch 184:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.73it/s, loss=0.279, dice=tensor(3.5673, device='cuda:0')]train Epoch 184:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.279, dice=tensor(3.5673, device='cuda:0')]train Epoch 184:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s, loss=0.309, dice=tensor(3.5342, device='cuda:0')]train Epoch 184:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.91it/s, loss=0.309, dice=tensor(3.5342, device='cuda:0')]train Epoch 184:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.91it/s, loss=0.348, dice=tensor(3.4793, device='cuda:0')]train Epoch 184: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.57it/s, loss=0.348, dice=tensor(3.4793, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                                                                train Loss: 0.3080 Dice: 0.6959
val Epoch 184:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 184:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.336, dice=tensor(3.2980, device='cuda:0')]val Epoch 184:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.336, dice=tensor(3.2980, device='cuda:0')]val Epoch 184:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.51it/s, loss=0.348, dice=tensor(3.3146, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3423 Dice: 0.6629
Epoch 185/199
----------
train Epoch 185:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 185:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.307, dice=tensor(3.4830, device='cuda:0')]train Epoch 185:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.307, dice=tensor(3.4830, device='cuda:0')]train Epoch 185:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.283, dice=tensor(3.5249, device='cuda:0')]train Epoch 185:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.283, dice=tensor(3.5249, device='cuda:0')]train Epoch 185:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.315, dice=tensor(3.4877, device='cuda:0')]train Epoch 185:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.98it/s, loss=0.315, dice=tensor(3.4877, device='cuda:0')]train Epoch 185:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.98it/s, loss=0.315, dice=tensor(3.4834, device='cuda:0')]train Epoch 185: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.62it/s, loss=0.315, dice=tensor(3.4834, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                                                                train Loss: 0.3052 Dice: 0.6967
val Epoch 185:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 185:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.331, dice=tensor(3.3205, device='cuda:0')]val Epoch 185:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.35it/s, loss=0.331, dice=tensor(3.3205, device='cuda:0')]val Epoch 185:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.35it/s, loss=0.354, dice=tensor(3.3144, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3425 Dice: 0.6629
Epoch 186/199
----------
train Epoch 186:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 186:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.316, dice=tensor(3.4644, device='cuda:0')]train Epoch 186:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.316, dice=tensor(3.4644, device='cuda:0')]train Epoch 186:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.55it/s, loss=0.282, dice=tensor(3.5280, device='cuda:0')]train Epoch 186:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.282, dice=tensor(3.5280, device='cuda:0')]train Epoch 186:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.77it/s, loss=0.345, dice=tensor(3.4688, device='cuda:0')]train Epoch 186:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.69it/s, loss=0.345, dice=tensor(3.4688, device='cuda:0')]train Epoch 186:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.69it/s, loss=0.304, dice=tensor(3.4483, device='cuda:0')]train Epoch 186: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.38it/s, loss=0.304, dice=tensor(3.4483, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                                train Loss: 0.3117 Dice: 0.6897
val Epoch 186:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 186:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.355, dice=tensor(3.2747, device='cuda:0')]val Epoch 186:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.355, dice=tensor(3.2747, device='cuda:0')]val Epoch 186:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.59it/s, loss=0.327, dice=tensor(3.3135, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3409 Dice: 0.6627
Epoch 187/199
----------
train Epoch 187:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 187:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.293, dice=tensor(3.3661, device='cuda:0')]train Epoch 187:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.293, dice=tensor(3.3661, device='cuda:0')]train Epoch 187:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.52it/s, loss=0.295, dice=tensor(3.4526, device='cuda:0')]train Epoch 187:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.295, dice=tensor(3.4526, device='cuda:0')]train Epoch 187:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.73it/s, loss=0.357, dice=tensor(3.3882, device='cuda:0')]train Epoch 187:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.66it/s, loss=0.357, dice=tensor(3.3882, device='cuda:0')]train Epoch 187:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.66it/s, loss=0.319, dice=tensor(3.3982, device='cuda:0')]train Epoch 187: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.36it/s, loss=0.319, dice=tensor(3.3982, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                                train Loss: 0.3162 Dice: 0.6796
val Epoch 187:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 187:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.349, dice=tensor(3.3058, device='cuda:0')]val Epoch 187:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.349, dice=tensor(3.3058, device='cuda:0')]val Epoch 187:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.69it/s, loss=0.336, dice=tensor(3.3093, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3422 Dice: 0.6619
Epoch 188/199
----------
train Epoch 188:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 188:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.331, dice=tensor(3.3300, device='cuda:0')]train Epoch 188:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.331, dice=tensor(3.3300, device='cuda:0')]train Epoch 188:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.71it/s, loss=0.294, dice=tensor(3.4460, device='cuda:0')]train Epoch 188:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.294, dice=tensor(3.4460, device='cuda:0')]train Epoch 188:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s, loss=0.334, dice=tensor(3.3831, device='cuda:0')]train Epoch 188:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.88it/s, loss=0.334, dice=tensor(3.3831, device='cuda:0')]train Epoch 188:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.88it/s, loss=0.313, dice=tensor(3.3845, device='cuda:0')]train Epoch 188: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.53it/s, loss=0.313, dice=tensor(3.3845, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                                train Loss: 0.3176 Dice: 0.6769
val Epoch 188:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 188:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.332, dice=tensor(3.4027, device='cuda:0')]val Epoch 188:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.35it/s, loss=0.332, dice=tensor(3.4027, device='cuda:0')]val Epoch 188:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.35it/s, loss=0.358, dice=tensor(3.3045, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
                                                                                                              val Loss: 0.3449 Dice: 0.6609
Epoch 189/199
----------
train Epoch 189:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 189:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.292, dice=tensor(3.5090, device='cuda:0')]train Epoch 189:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.292, dice=tensor(3.5090, device='cuda:0')]train Epoch 189:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.327, dice=tensor(3.4645, device='cuda:0')]train Epoch 189:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.327, dice=tensor(3.4645, device='cuda:0')]train Epoch 189:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.86it/s, loss=0.313, dice=tensor(3.4503, device='cuda:0')]train Epoch 189:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.79it/s, loss=0.313, dice=tensor(3.4503, device='cuda:0')]train Epoch 189:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.79it/s, loss=0.299, dice=tensor(3.4654, device='cuda:0')]train Epoch 189: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.47it/s, loss=0.299, dice=tensor(3.4654, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3077 Dice: 0.6931
val Epoch 189:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 189:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.37, dice=tensor(3.1623, device='cuda:0')]val Epoch 189:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.37, dice=tensor(3.1623, device='cuda:0')]val Epoch 189:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.61it/s, loss=0.318, dice=tensor(3.3062, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3444 Dice: 0.6612
Epoch 190/199
----------
train Epoch 190:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 190:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.311, dice=tensor(3.4832, device='cuda:0')]train Epoch 190:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.311, dice=tensor(3.4832, device='cuda:0')]train Epoch 190:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s, loss=0.299, dice=tensor(3.5014, device='cuda:0')]train Epoch 190:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.299, dice=tensor(3.5014, device='cuda:0')]train Epoch 190:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.82it/s, loss=0.281, dice=tensor(3.5384, device='cuda:0')]train Epoch 190:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.74it/s, loss=0.281, dice=tensor(3.5384, device='cuda:0')]train Epoch 190:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.74it/s, loss=0.365, dice=tensor(3.4579, device='cuda:0')]train Epoch 190: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.365, dice=tensor(3.4579, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3141 Dice: 0.6916
val Epoch 190:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 190:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.317, dice=tensor(3.4584, device='cuda:0')]val Epoch 190:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.317, dice=tensor(3.4584, device='cuda:0')]val Epoch 190:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.50it/s, loss=0.369, dice=tensor(3.3109, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3432 Dice: 0.6622
Epoch 191/199
----------
train Epoch 191:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 191:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.348, dice=tensor(3.3133, device='cuda:0')]train Epoch 191:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.348, dice=tensor(3.3133, device='cuda:0')]train Epoch 191:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.70it/s, loss=0.281, dice=tensor(3.4396, device='cuda:0')]train Epoch 191:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.281, dice=tensor(3.4396, device='cuda:0')]train Epoch 191:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s, loss=0.29, dice=tensor(3.4841, device='cuda:0')] train Epoch 191:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.87it/s, loss=0.29, dice=tensor(3.4841, device='cuda:0')]train Epoch 191:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.87it/s, loss=0.332, dice=tensor(3.4531, device='cuda:0')]train Epoch 191: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.54it/s, loss=0.332, dice=tensor(3.4531, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                                                                train Loss: 0.3127 Dice: 0.6906
val Epoch 191:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 191:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.366, dice=tensor(3.1827, device='cuda:0')]val Epoch 191:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.366, dice=tensor(3.1827, device='cuda:0')]val Epoch 191:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.57it/s, loss=0.32, dice=tensor(3.3105, device='cuda:0')] /home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
                                                                                                             val Loss: 0.3430 Dice: 0.6621
Epoch 192/199
----------
train Epoch 192:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 192:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.328, dice=tensor(3.3994, device='cuda:0')]train Epoch 192:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.328, dice=tensor(3.3994, device='cuda:0')]train Epoch 192:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.67it/s, loss=0.3, dice=tensor(3.4148, device='cuda:0')]  train Epoch 192:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.3, dice=tensor(3.4148, device='cuda:0')]train Epoch 192:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.92it/s, loss=0.265, dice=tensor(3.5024, device='cuda:0')]train Epoch 192:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.84it/s, loss=0.265, dice=tensor(3.5024, device='cuda:0')]train Epoch 192:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.84it/s, loss=0.328, dice=tensor(3.4764, device='cuda:0')]train Epoch 192: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.50it/s, loss=0.328, dice=tensor(3.4764, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                                                                train Loss: 0.3050 Dice: 0.6953
val Epoch 192:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 192:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.341, dice=tensor(3.2741, device='cuda:0')]val Epoch 192:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.341, dice=tensor(3.2741, device='cuda:0')]val Epoch 192:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.73it/s, loss=0.346, dice=tensor(3.3065, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
                                                                                                              val Loss: 0.3433 Dice: 0.6613
Epoch 193/199
----------
train Epoch 193:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 193:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.334, dice=tensor(3.3734, device='cuda:0')]train Epoch 193:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.40it/s, loss=0.334, dice=tensor(3.3734, device='cuda:0')]train Epoch 193:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.40it/s, loss=0.361, dice=tensor(3.3169, device='cuda:0')]train Epoch 193:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.57it/s, loss=0.361, dice=tensor(3.3169, device='cuda:0')]train Epoch 193:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:00,  2.57it/s, loss=0.292, dice=tensor(3.3833, device='cuda:0')]train Epoch 193:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.50it/s, loss=0.292, dice=tensor(3.3833, device='cuda:0')]train Epoch 193:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.50it/s, loss=0.287, dice=tensor(3.4328, device='cuda:0')]train Epoch 193: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.21it/s, loss=0.287, dice=tensor(3.4328, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                                                                train Loss: 0.3185 Dice: 0.6866
val Epoch 193:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 193:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.378, dice=tensor(3.1344, device='cuda:0')]val Epoch 193:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.378, dice=tensor(3.1344, device='cuda:0')]val Epoch 193:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.75it/s, loss=0.312, dice=tensor(3.3099, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3452 Dice: 0.6620
Epoch 194/199
----------
train Epoch 194:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 194:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.306, dice=tensor(3.4449, device='cuda:0')]train Epoch 194:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.306, dice=tensor(3.4449, device='cuda:0')]train Epoch 194:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.54it/s, loss=0.278, dice=tensor(3.5387, device='cuda:0')]train Epoch 194:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.278, dice=tensor(3.5387, device='cuda:0')]train Epoch 194:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.75it/s, loss=0.288, dice=tensor(3.5548, device='cuda:0')]train Epoch 194:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.68it/s, loss=0.288, dice=tensor(3.5548, device='cuda:0')]train Epoch 194:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.68it/s, loss=0.389, dice=tensor(3.4460, device='cuda:0')]train Epoch 194: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.37it/s, loss=0.389, dice=tensor(3.4460, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                                                                train Loss: 0.3153 Dice: 0.6892
val Epoch 194:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 194:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.297, dice=tensor(3.5453, device='cuda:0')]val Epoch 194:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.297, dice=tensor(3.5453, device='cuda:0')]val Epoch 194:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.387, dice=tensor(3.3112, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3419 Dice: 0.6622
Epoch 195/199
----------
train Epoch 195:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 195:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.363, dice=tensor(3.2156, device='cuda:0')]train Epoch 195:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.363, dice=tensor(3.2156, device='cuda:0')]train Epoch 195:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.64it/s, loss=0.314, dice=tensor(3.3413, device='cuda:0')]train Epoch 195:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.314, dice=tensor(3.3413, device='cuda:0')]train Epoch 195:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.88it/s, loss=0.325, dice=tensor(3.3370, device='cuda:0')]train Epoch 195:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.80it/s, loss=0.325, dice=tensor(3.3370, device='cuda:0')]train Epoch 195:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.80it/s, loss=0.254, dice=tensor(3.4351, device='cuda:0')]train Epoch 195: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.48it/s, loss=0.254, dice=tensor(3.4351, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
                                                                                                                train Loss: 0.3139 Dice: 0.6870
val Epoch 195:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 195:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.332, dice=tensor(3.3084, device='cuda:0')]val Epoch 195:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.332, dice=tensor(3.3084, device='cuda:0')]val Epoch 195:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.72it/s, loss=0.352, dice=tensor(3.3142, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
                                                                                                              val Loss: 0.3419 Dice: 0.6628
Epoch 196/199
----------
train Epoch 196:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 196:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.293, dice=tensor(3.5333, device='cuda:0')]train Epoch 196:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.86it/s, loss=0.293, dice=tensor(3.5333, device='cuda:0')]train Epoch 196:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.86it/s, loss=0.3, dice=tensor(3.4983, device='cuda:0')]  train Epoch 196:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.14it/s, loss=0.3, dice=tensor(3.4983, device='cuda:0')]train Epoch 196:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.14it/s, loss=0.323, dice=tensor(3.4749, device='cuda:0')]train Epoch 196:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  4.04it/s, loss=0.323, dice=tensor(3.4749, device='cuda:0')]train Epoch 196:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  4.04it/s, loss=0.298, dice=tensor(3.4961, device='cuda:0')]train Epoch 196: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.66it/s, loss=0.298, dice=tensor(3.4961, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                                                                train Loss: 0.3037 Dice: 0.6992
val Epoch 196:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 196:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.338, dice=tensor(3.2948, device='cuda:0')]val Epoch 196:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.338, dice=tensor(3.2948, device='cuda:0')]val Epoch 196:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.52it/s, loss=0.347, dice=tensor(3.3095, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              val Loss: 0.3424 Dice: 0.6619
Epoch 197/199
----------
train Epoch 197:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 197:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.272, dice=tensor(3.6661, device='cuda:0')]train Epoch 197:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.272, dice=tensor(3.6661, device='cuda:0')]train Epoch 197:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.62it/s, loss=0.307, dice=tensor(3.5979, device='cuda:0')]train Epoch 197:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.307, dice=tensor(3.5979, device='cuda:0')]train Epoch 197:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.85it/s, loss=0.353, dice=tensor(3.4656, device='cuda:0')]train Epoch 197:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.78it/s, loss=0.353, dice=tensor(3.4656, device='cuda:0')]train Epoch 197:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.78it/s, loss=0.309, dice=tensor(3.4691, device='cuda:0')]train Epoch 197: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.45it/s, loss=0.309, dice=tensor(3.4691, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3105 Dice: 0.6938
val Epoch 197:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 197:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.32, dice=tensor(3.3637, device='cuda:0')]val Epoch 197:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.32, dice=tensor(3.3637, device='cuda:0')]val Epoch 197:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.64it/s, loss=0.366, dice=tensor(3.3047, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
                                                                                                              val Loss: 0.3431 Dice: 0.6609
Epoch 198/199
----------
train Epoch 198:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 198:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.304, dice=tensor(3.4319, device='cuda:0')]train Epoch 198:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.304, dice=tensor(3.4319, device='cuda:0')]train Epoch 198:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.58it/s, loss=0.318, dice=tensor(3.4576, device='cuda:0')]train Epoch 198:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.318, dice=tensor(3.4576, device='cuda:0')]train Epoch 198:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.80it/s, loss=0.317, dice=tensor(3.4436, device='cuda:0')]train Epoch 198:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.73it/s, loss=0.317, dice=tensor(3.4436, device='cuda:0')]train Epoch 198:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.73it/s, loss=0.301, dice=tensor(3.4633, device='cuda:0')]train Epoch 198: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.42it/s, loss=0.301, dice=tensor(3.4633, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                                                                train Loss: 0.3098 Dice: 0.6927
val Epoch 198:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 198:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.346, dice=tensor(3.3435, device='cuda:0')]val Epoch 198:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.346, dice=tensor(3.3435, device='cuda:0')]val Epoch 198:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.58it/s, loss=0.344, dice=tensor(3.2987, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                                              val Loss: 0.3451 Dice: 0.6597
Epoch 199/199
----------
train Epoch 199:   0%|          | 0/4 [00:00<?, ?it/s]train Epoch 199:   0%|          | 0/4 [00:00<?, ?it/s, loss=0.284, dice=tensor(3.5595, device='cuda:0')]train Epoch 199:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.284, dice=tensor(3.5595, device='cuda:0')]train Epoch 199:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.79it/s, loss=0.348, dice=tensor(3.4333, device='cuda:0')]train Epoch 199:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.348, dice=tensor(3.4333, device='cuda:0')]train Epoch 199:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.06it/s, loss=0.296, dice=tensor(3.4558, device='cuda:0')]train Epoch 199:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.97it/s, loss=0.296, dice=tensor(3.4558, device='cuda:0')]train Epoch 199:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.97it/s, loss=0.286, dice=tensor(3.4912, device='cuda:0')]train Epoch 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  4.62it/s, loss=0.286, dice=tensor(3.4912, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                                                                train Loss: 0.3036 Dice: 0.6982
val Epoch 199:   0%|          | 0/2 [00:00<?, ?it/s]val Epoch 199:   0%|          | 0/2 [00:00<?, ?it/s, loss=0.335, dice=tensor(3.3056, device='cuda:0')]val Epoch 199:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.82it/s, loss=0.335, dice=tensor(3.3056, device='cuda:0')]val Epoch 199:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  2.82it/s, loss=0.354, dice=tensor(3.2989, device='cuda:0')]/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
                                                                                                              wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: train_dice ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   val_dice ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÜ‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   val_loss ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb: best_val_dice 0.66271
wandb: best_val_loss 0.34093
wandb:         epoch 199
wandb:    train_dice 0.69824
wandb:    train_loss 0.3036
wandb:      val_dice 0.65978
wandb:      val_loss 0.34437
wandb: 
wandb: üöÄ View run DIAS_modelnone at: https://wandb.ai/dinesh_saggurthi/SVD_exps/runs/d1liaan8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241013_220515-d1liaan8/logs
val Loss: 0.3444 Dice: 0.6598
Best val loss: 0.340928, best val dice: 0.662706
Model saved at: ./modelsDIAS/final_model.pth
Starting RLHF fine-tuning...
{'USE_TEXT_PROMPT': True, 'NUM_TEXT_REPEAT': 1, 'USE_IMAGE_PROMPT': False, 'USE_SLICE_NUM': False, 'LOCATION': 'prepend', 'DROPOUT': 0, 'NUM_TOKENS': 5}
Epoch 0/39
----------
Epoch 0:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/3 [00:02<?, ?it/s, loss=-63]Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:02<00:05,  2.52s/it, loss=-63]Epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:02<00:05,  2.52s/it, loss=-64.3]Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  1.24s/it, loss=-64.3]Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:03<00:01,  1.24s/it, loss=-66.2]Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.29it/s, loss=-66.2]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08036006987094879

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08036006987094879

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07905721664428711

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4554712474346161

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08035945892333984

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07905721664428711

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 33.637794494628906
Max value: 89.66521453857422
Mean value: 63.04478073120117

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08036006987094879

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08036006987094879

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08036006987094879

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4554712474346161

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 33.637794494628906
Max value: 89.66521453857422
Mean value: 63.04478073120117

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -63.044883728027344
Max value: -63.044883728027344
Mean value: -63.044883728027344
sam_encoder.pos_embed grad: -1.931920595721337e-10
sam_encoder.blocks.0.norm1.weight grad: -1.1291806004010141e-05
sam_encoder.blocks.0.norm1.bias grad: 1.4548585568263661e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.7171175841212971e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.3292153034381045e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.936859007400926e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.1590308304221253e-06
sam_encoder.blocks.0.norm2.weight grad: 2.371143455093261e-05
sam_encoder.blocks.0.norm2.bias grad: -7.365549208770972e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 5.3177072913968004e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.385581632959656e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.239547474251594e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 6.831072596469312e-07
sam_encoder.blocks.1.norm1.weight grad: -9.045538718055468e-06
sam_encoder.blocks.1.norm1.bias grad: -4.628380338544957e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.0920386728230369e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 3.184485422025318e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.0160408692172496e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.0449457477079704e-07
sam_encoder.blocks.1.norm2.weight grad: 8.678923222760204e-06
sam_encoder.blocks.1.norm2.bias grad: 1.1405821709331576e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 7.811297109583393e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.7479717371315928e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 4.505727702053264e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 7.253729563672096e-07
sam_encoder.blocks.2.norm1.weight grad: -2.6367156351625454e-06
sam_encoder.blocks.2.norm1.bias grad: -1.1906704457942396e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.970604444068158e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 9.467134987062309e-08
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.443119567236863e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.1981963982398156e-06
sam_encoder.blocks.2.norm2.weight grad: -3.584034402592806e-06
sam_encoder.blocks.2.norm2.bias grad: 2.9061575332889333e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.275299609915237e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -6.240706511562166e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.492492285455228e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -8.679874099470908e-07
sam_encoder.blocks.3.norm1.weight grad: -7.250575436046347e-06
sam_encoder.blocks.3.norm1.bias grad: -2.894275439757621e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.162067059747642e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.8628954257546866e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -8.315900572597457e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 6.716286407026928e-07
sam_encoder.blocks.3.norm2.weight grad: -7.438787719138418e-08
sam_encoder.blocks.3.norm2.bias grad: 5.314051122695673e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 8.174874892574735e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.397695707008097e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.719287752166565e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 6.403112706721004e-07
sam_encoder.blocks.4.norm1.weight grad: -1.0700792699935846e-05
sam_encoder.blocks.4.norm1.bias grad: -1.5239154436130775e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -6.474906967923744e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.7812687929108506e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.0407027275505243e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -4.674849378716317e-07
sam_encoder.blocks.4.norm2.weight grad: -4.290761353331618e-06
sam_encoder.blocks.4.norm2.bias grad: 1.497093535363092e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.763572183539509e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.0113613408720994e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 5.786338874713692e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -3.8550169279005786e-07
sam_encoder.blocks.5.norm1.weight grad: -7.779397492413409e-06
sam_encoder.blocks.5.norm1.bias grad: 2.441866854496766e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -5.2426671572902706e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.4820359410805395e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -4.921639629174024e-08
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.3593529502031743e-06
sam_encoder.blocks.5.norm2.weight grad: -2.879847670556046e-06
sam_encoder.blocks.5.norm2.bias grad: -1.7844002968558925e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -6.438116315621301e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.9862720535002154e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -9.555772066960344e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.922860282225884e-07
sam_encoder.blocks.6.norm1.weight grad: -9.23189872992225e-07
sam_encoder.blocks.6.norm1.bias grad: 3.0445844458881766e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.1867768989759497e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -9.805905847315444e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.031822176235437e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -6.558780114573892e-07
sam_encoder.blocks.6.norm2.weight grad: -2.3306026264435786e-07
sam_encoder.blocks.6.norm2.bias grad: -2.146025508409366e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 3.8173760685822344e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.7782115214213263e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.4265324352891184e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.802891003739205e-07
sam_encoder.blocks.7.norm1.weight grad: -1.7598431441001594e-06
sam_encoder.blocks.7.norm1.bias grad: 1.8014029592450242e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.1823931345134042e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 7.86485429671302e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.113971393351676e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.329445803501585e-07
sam_encoder.blocks.7.norm2.weight grad: 1.953835180756869e-06
sam_encoder.blocks.7.norm2.bias grad: -5.438021162262885e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.1558670394151704e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 6.274055976973614e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.003101942842477e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.867389856779482e-07
sam_encoder.blocks.8.norm1.weight grad: -6.11824862062349e-06
sam_encoder.blocks.8.norm1.bias grad: 1.5708450291640474e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -8.03703733254224e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.899155106206308e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -4.28477449077036e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -8.492457936881692e-07
sam_encoder.blocks.8.norm2.weight grad: 1.6212134141824208e-06
sam_encoder.blocks.8.norm2.bias grad: -1.9699707536346978e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.7139116152975475e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 8.738167593946855e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 8.040310603973921e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.8994592210219707e-07
sam_encoder.blocks.9.norm1.weight grad: -1.876272449408134e-06
sam_encoder.blocks.9.norm1.bias grad: -4.3949816586064117e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -9.725495146994945e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 5.447008106784779e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.599391280000418e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.0474641385371797e-06
sam_encoder.blocks.9.norm2.weight grad: 1.4982568927734974e-06
sam_encoder.blocks.9.norm2.bias grad: -1.638452317820338e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.8083221675624372e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.773661774175707e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.783673037105473e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.114434316055849e-07
sam_encoder.blocks.10.norm1.weight grad: 2.178506974814809e-06
sam_encoder.blocks.10.norm1.bias grad: -1.0221715456282254e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.377056262048427e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 9.856879614744685e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.142547034760355e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 7.303646043510525e-07
sam_encoder.blocks.10.norm2.weight grad: 2.770273965779779e-07
sam_encoder.blocks.10.norm2.bias grad: -2.137964429493877e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.240017468262522e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.551255195408885e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -9.93400476545503e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.5859911779189133e-07
sam_encoder.blocks.11.norm1.weight grad: -2.415389417365077e-06
sam_encoder.blocks.11.norm1.bias grad: 2.9305738280527294e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.2778822312830016e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.8827710707446386e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -3.6687023907688854e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -3.0981556164988433e-07
sam_encoder.blocks.11.norm2.weight grad: 3.973230832343688e-06
sam_encoder.blocks.11.norm2.bias grad: 4.520677521213656e-08
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.348831458220957e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.6268249680706504e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -4.531994761691749e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.5578555689899076e-07
sam_encoder.neck.conv1.trainable_scale grad: 2.2759195417165756e-08
sam_encoder.neck.conv1.trainable_shift grad: -2.3172900910140015e-05
sam_encoder.neck.conv2.trainable_scale grad: -4.784315024153329e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.2367981728166342e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00014790867862757295
mask_decoder.transformer.layers.0.norm1.bias grad: 2.6811903808265924e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.002803236246109009
mask_decoder.transformer.layers.0.norm2.bias grad: -6.702600512653589e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 7.958271453389898e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.2955155398231e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 7.785391062498093e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -7.703420124016702e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 7.116718916222453e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.6225376384682022e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -2.604889050417114e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 8.221594180213287e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.0695162422489375e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 7.071239815559238e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 4.034925041196402e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -6.510707316920161e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.6184647392947227e-05
mask_decoder.transformer.norm_final_attn.bias grad: 9.434686944587156e-06
Text_Embedding_Affine.0.weight grad: 3.166102362922585e-12
Text_Embedding_Affine.0.bias grad: 2.1985344100805548e-11
Text_Embedding_Affine.2.weight grad: 1.4622703048416952e-10
Text_Embedding_Affine.2.bias grad: -2.2749190975446254e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0903003141283989

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0903003141283989

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08343267440795898

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.429221510887146

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09037160873413086

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08343267440795898

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 48.92854309082031
Max value: 82.00472259521484
Mean value: 65.30218505859375

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0901673287153244

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0901673287153244

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0901673287153244

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4194128215312958

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.4562895596027374
Max value: 6.999995708465576
Mean value: 1.0133113861083984

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 48.92854309082031
Max value: 82.00472259521484
Mean value: 65.30218505859375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.6055908203125
Max value: -65.6055908203125
Mean value: -65.6055908203125
sam_encoder.pos_embed grad: 9.190937788616793e-09
sam_encoder.blocks.0.norm1.weight grad: 1.6842562899910263e-06
sam_encoder.blocks.0.norm1.bias grad: 8.804212484392338e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.746286554611288e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.425081445129763e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -3.6162191463517956e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.5899286154308356e-06
sam_encoder.blocks.0.norm2.weight grad: 5.35764320375165e-06
sam_encoder.blocks.0.norm2.bias grad: 4.622746416771406e-07
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.1278911188128404e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.4699661480553914e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.8345263015362434e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.7298368675255915e-06
sam_encoder.blocks.1.norm1.weight grad: -2.8690392355201766e-05
sam_encoder.blocks.1.norm1.bias grad: 2.2296014776657103e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.979290446906816e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.482978516127332e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -4.589754098560661e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.3779142540879548e-06
sam_encoder.blocks.1.norm2.weight grad: 6.221844159881584e-06
sam_encoder.blocks.1.norm2.bias grad: -2.278133251820691e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 9.134710126090795e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.032922450074693e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.865457529173e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.682672291281051e-06
sam_encoder.blocks.2.norm1.weight grad: -2.8429192298062844e-06
sam_encoder.blocks.2.norm1.bias grad: 5.165527454664698e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.287908612037427e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.7648913320253996e-08
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.400956873316318e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.5802564803379937e-06
sam_encoder.blocks.2.norm2.weight grad: 2.791192673612386e-05
sam_encoder.blocks.2.norm2.bias grad: -1.545753730169963e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.77162164618494e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 5.757476174039766e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.504116754513234e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.359488917136332e-06
sam_encoder.blocks.3.norm1.weight grad: 7.844736501283478e-06
sam_encoder.blocks.3.norm1.bias grad: -1.0569056030362844e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.369244384681224e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.935305135702947e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.928293037664844e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.2385779629985336e-06
sam_encoder.blocks.3.norm2.weight grad: 2.1937445126241073e-05
sam_encoder.blocks.3.norm2.bias grad: -3.030909283552319e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.1997365618299227e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 4.8800620788824745e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.289098797016777e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.4281384867208544e-06
sam_encoder.blocks.4.norm1.weight grad: -1.0292125807609409e-05
sam_encoder.blocks.4.norm1.bias grad: -5.540844995266525e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -5.336033609637525e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.8964477703775628e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.930215254717041e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.2489681466831826e-07
sam_encoder.blocks.4.norm2.weight grad: -1.880472518678289e-05
sam_encoder.blocks.4.norm2.bias grad: -1.1093243301729672e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.3407831829681527e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.766040779533796e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -8.795593089416798e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.956102194839332e-07
sam_encoder.blocks.5.norm1.weight grad: -1.283392612094758e-05
sam_encoder.blocks.5.norm1.bias grad: -1.490612339694053e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.02371795946965e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -5.070217412139755e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.10425469049369e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.4791725106988451e-06
sam_encoder.blocks.5.norm2.weight grad: -1.1470298886706587e-05
sam_encoder.blocks.5.norm2.bias grad: -4.123554390389472e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.196639449422946e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.9306576177768875e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.8033269952866249e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.0613323411234887e-06
sam_encoder.blocks.6.norm1.weight grad: -1.1931260814890265e-05
sam_encoder.blocks.6.norm1.bias grad: -3.936447683372535e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -7.75249191065086e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.7685291570378467e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.3303662146645365e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.6033898191381013e-06
sam_encoder.blocks.6.norm2.weight grad: -2.8660629141086247e-06
sam_encoder.blocks.6.norm2.bias grad: 3.4107906685676426e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -9.641014457884012e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.111554183808039e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 6.805057637393475e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 9.74598151515238e-07
sam_encoder.blocks.7.norm1.weight grad: -9.269622751162387e-06
sam_encoder.blocks.7.norm1.bias grad: 1.4889532167217112e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -7.975417247507721e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.654353693287703e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.4900101582024945e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.5892322810250334e-06
sam_encoder.blocks.7.norm2.weight grad: -1.378787146677496e-07
sam_encoder.blocks.7.norm2.bias grad: -2.9553061153819726e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.440104592300486e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.0783579682538402e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.3369212865654845e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 7.314065442187712e-07
sam_encoder.blocks.8.norm1.weight grad: -6.600190317840315e-06
sam_encoder.blocks.8.norm1.bias grad: 5.962668865322485e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -7.410289981635287e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -3.442142769927159e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.7671843529096805e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.1156936327315634e-06
sam_encoder.blocks.8.norm2.weight grad: -8.268870260508265e-06
sam_encoder.blocks.8.norm2.bias grad: 2.0793777366634458e-08
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -9.281943675887305e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -4.244673618813977e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.9340008040890098e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.588523658341728e-07
sam_encoder.blocks.9.norm1.weight grad: -5.178060291655129e-06
sam_encoder.blocks.9.norm1.bias grad: -4.3108411773573607e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.9711266001395416e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.4409862362517742e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.1033562259399332e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.4646307135990355e-06
sam_encoder.blocks.9.norm2.weight grad: -1.397068626829423e-05
sam_encoder.blocks.9.norm2.bias grad: -2.4751623186602956e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.1480525245133322e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -5.815055828861659e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.6289721972716507e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.3150915947335307e-06
sam_encoder.blocks.10.norm1.weight grad: -3.7945801523164846e-06
sam_encoder.blocks.10.norm1.bias grad: -1.3896783457312267e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.3312782104767393e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.1088978908446734e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.406276908255677e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.0650846427040506e-08
sam_encoder.blocks.10.norm2.weight grad: -1.876813439594116e-05
sam_encoder.blocks.10.norm2.bias grad: -5.0947869567607995e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -9.964478522306308e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.403417162597179e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.5384312064270489e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -9.360646799905226e-07
sam_encoder.blocks.11.norm1.weight grad: -2.1520520022022538e-05
sam_encoder.blocks.11.norm1.bias grad: 2.1042103526269784e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.93396772374399e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.340204367598744e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.128195322053216e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.361835064832121e-08
sam_encoder.blocks.11.norm2.weight grad: -1.881963908090256e-05
sam_encoder.blocks.11.norm2.bias grad: -6.736752311553573e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -8.233995686168782e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -4.0133709262590855e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.8137245660909684e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -6.679777015961008e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.9111439542029984e-06
sam_encoder.neck.conv1.trainable_shift grad: -2.1394967916421592e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.96811743080616e-06
sam_encoder.neck.conv2.trainable_shift grad: -2.2716474632034078e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -4.896661630482413e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 2.0535371731966734e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.006195407826453447
mask_decoder.transformer.layers.0.norm2.bias grad: -4.1281396988779306e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00010144620318897069
mask_decoder.transformer.layers.0.norm3.bias grad: 1.1636135241133161e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 6.043542452971451e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.3395119822234847e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.556416049832478e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -3.7541581150435377e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 6.0561051213881e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 1.2887920092907734e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.652664599940181e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.243914685910568e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00019750394858419895
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00015505639021284878
mask_decoder.transformer.norm_final_attn.weight grad: 2.3926553694764152e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.385343239235226e-05
Text_Embedding_Affine.0.weight grad: -2.1520493720394995e-12
Text_Embedding_Affine.0.bias grad: -1.3747095128913145e-10
Text_Embedding_Affine.2.weight grad: -8.501999104737479e-11
Text_Embedding_Affine.2.bias grad: -5.055168003309518e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10260926187038422

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10260926187038422

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09340190887451172

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4796762466430664

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10270118713378906

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09340190887451172

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 61.160621643066406
Max value: 80.8159408569336
Mean value: 69.59284210205078

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1012607216835022

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1012607216835022

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1012607216835022

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.46503302454948425

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.19213123619556427
Max value: 12.999996185302734
Mean value: 1.0251272916793823

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 61.160621643066406
Max value: 80.8159408569336
Mean value: 69.59284210205078

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -69.87589263916016
Max value: -69.87589263916016
Mean value: -69.87589263916016
sam_encoder.pos_embed grad: -1.2000032079129141e-08
sam_encoder.blocks.0.norm1.weight grad: 6.790281531721121e-06
sam_encoder.blocks.0.norm1.bias grad: 1.20274125947617e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.53683219600498e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.570889930415433e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.2863684989715694e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -5.539478706850787e-07
sam_encoder.blocks.0.norm2.weight grad: 1.6404204870923422e-05
sam_encoder.blocks.0.norm2.bias grad: 1.4221792298485525e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.6786113923881203e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.32837987318635e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.5753023035358638e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -6.884708909637993e-06
sam_encoder.blocks.1.norm1.weight grad: -1.3204879678596626e-06
sam_encoder.blocks.1.norm1.bias grad: -2.3792747469997266e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.533744231594028e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 5.732267709390726e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.6595662347972393e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 9.513289001006342e-07
sam_encoder.blocks.1.norm2.weight grad: 8.62001979839988e-06
sam_encoder.blocks.1.norm2.bias grad: 8.298275133711286e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.342380518413847e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.7646592596065602e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.988223630178254e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.3265392908579088e-06
sam_encoder.blocks.2.norm1.weight grad: 7.3816677286231425e-06
sam_encoder.blocks.2.norm1.bias grad: -5.047286322223954e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.144668764638482e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.9927289801889856e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.974948973947903e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.88805994791619e-07
sam_encoder.blocks.2.norm2.weight grad: -7.720935172983445e-06
sam_encoder.blocks.2.norm2.bias grad: -1.8785120801112498e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.7259891289286315e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.148228643112816e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.5773437098687282e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 2.7057899387727957e-07
sam_encoder.blocks.3.norm1.weight grad: 1.2905451285405434e-06
sam_encoder.blocks.3.norm1.bias grad: -6.168510935822269e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.1910038892892771e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.594753709672659e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.0165251751459436e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 7.102848371687287e-07
sam_encoder.blocks.3.norm2.weight grad: 1.8936377728095977e-06
sam_encoder.blocks.3.norm2.bias grad: 1.8002296542363183e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.4984767605928937e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 4.927232453155739e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 4.290479409974068e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 6.757104529242497e-07
sam_encoder.blocks.4.norm1.weight grad: 1.6882266208995134e-05
sam_encoder.blocks.4.norm1.bias grad: 2.8146678232587874e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 8.741113560972735e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.0575748749251943e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 4.936775440000929e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 4.095724762009922e-06
sam_encoder.blocks.4.norm2.weight grad: -3.063966505578719e-05
sam_encoder.blocks.4.norm2.bias grad: -2.0997875253669918e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.9856292055919766e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -7.58845271775499e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.1706385976140155e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -8.307931409490266e-08
sam_encoder.blocks.5.norm1.weight grad: 9.113994565268513e-06
sam_encoder.blocks.5.norm1.bias grad: -2.066364231723128e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 5.639889423036948e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 7.364794214481662e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.21056665800279e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.435449798416812e-06
sam_encoder.blocks.5.norm2.weight grad: -1.1840829756692983e-05
sam_encoder.blocks.5.norm2.bias grad: -1.141817028837977e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.4363569031702355e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.3923042843089206e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.794114036281826e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.6102869671594817e-07
sam_encoder.blocks.6.norm1.weight grad: 3.6924027426721295e-06
sam_encoder.blocks.6.norm1.bias grad: 4.040494332002709e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.529853873056709e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 6.887307790748309e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.5757057099108351e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.805536946150823e-07
sam_encoder.blocks.6.norm2.weight grad: -9.974348358809948e-06
sam_encoder.blocks.6.norm2.bias grad: -4.085773525730474e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -7.108177669579163e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.982520982186543e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.1536425148506169e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -7.405275255223387e-07
sam_encoder.blocks.7.norm1.weight grad: 3.4556439914013026e-06
sam_encoder.blocks.7.norm1.bias grad: 1.4207223557605175e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.8779772972266073e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.572870360178058e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.981699824682437e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 5.931472628617485e-07
sam_encoder.blocks.7.norm2.weight grad: 1.779400690793409e-06
sam_encoder.blocks.7.norm2.bias grad: 1.5971841094142292e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.0054962988069747e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.8680642810409154e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -8.606451729065157e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -8.286405090984772e-07
sam_encoder.blocks.8.norm1.weight grad: 6.070751624065451e-06
sam_encoder.blocks.8.norm1.bias grad: -1.4272004591475707e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.092893050255952e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.1465655208885437e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.502407253108686e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.2919064122106647e-06
sam_encoder.blocks.8.norm2.weight grad: 1.7958731177714071e-06
sam_encoder.blocks.8.norm2.bias grad: 2.2946437638893258e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.3598782970802858e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 6.34192247161991e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.9329465317241556e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.3728414905453974e-07
sam_encoder.blocks.9.norm1.weight grad: 2.63121864918503e-06
sam_encoder.blocks.9.norm1.bias grad: 7.550261216238141e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.4837263506706222e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 9.255667237084708e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 9.539321581542026e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.8497266296435555e-07
sam_encoder.blocks.9.norm2.weight grad: 5.579067874350585e-06
sam_encoder.blocks.9.norm2.bias grad: 8.426570161645941e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.156572231295286e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.7498193756182445e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 5.810712764287018e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.52014052900995e-07
sam_encoder.blocks.10.norm1.weight grad: 6.954498530831188e-06
sam_encoder.blocks.10.norm1.bias grad: 1.162852981906326e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.5665514133143006e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.5827775996513083e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.7244127548110555e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.123010613620863e-07
sam_encoder.blocks.10.norm2.weight grad: 8.18116131995339e-06
sam_encoder.blocks.10.norm2.bias grad: 1.564053377478558e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 5.4165625442692544e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.7546038861837587e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 5.875004944755347e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.3783032493108749e-08
sam_encoder.blocks.11.norm1.weight grad: 1.688914926489815e-05
sam_encoder.blocks.11.norm1.bias grad: -4.254526118074864e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.2626168199858512e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.01804777286452e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.83461179403821e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.007690116239246e-06
sam_encoder.blocks.11.norm2.weight grad: 1.1692412954289466e-05
sam_encoder.blocks.11.norm2.bias grad: 1.6382431340389303e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.637240403506439e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.5556088328594342e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.369753353079432e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 8.862786415875235e-08
sam_encoder.neck.conv1.trainable_scale grad: 2.02214550881763e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.2151365808676928e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.2396594684105366e-07
sam_encoder.neck.conv2.trainable_shift grad: 6.922788998053875e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -3.564239159459248e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -6.759364623576403e-08
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005404218565672636
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00015723248361609876
mask_decoder.transformer.layers.0.norm3.weight grad: 1.3263988876133226e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.0203668352914974e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.8506928326096386e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.6866906662471592e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.8439978854730725e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 2.948067731267656e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -7.889016706030816e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 1.2388611139613204e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -2.181440322601702e-06
mask_decoder.transformer.layers.1.norm3.bias grad: 2.2567974156118e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -5.081559356767684e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00011072502820752561
mask_decoder.transformer.norm_final_attn.weight grad: 5.4266838560579345e-06
mask_decoder.transformer.norm_final_attn.bias grad: 3.6833027934335405e-06
Text_Embedding_Affine.0.weight grad: 3.000578951972699e-12
Text_Embedding_Affine.0.bias grad: 1.471100047334417e-10
Text_Embedding_Affine.2.weight grad: 2.4501269069165943e-12
Text_Embedding_Affine.2.bias grad: 1.771716597431805e-06
Epoch 0 finished with average loss: -66.1755
Epoch 1/39
----------
Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s, loss=-66.1]Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.04it/s, loss=-66.1]Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.04it/s, loss=-69.8]Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.63it/s, loss=-69.8]Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.63it/s, loss=-68.3]Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.27it/s, loss=-68.3]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09055618941783905

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09055618941783905

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08680343627929688

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4481312930583954

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09056615829467773

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08680343627929688

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 50.5517578125
Max value: 78.19976806640625
Mean value: 66.09419250488281

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09055618941783905

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09055618941783905

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09055618941783905

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4481312930583954

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 50.5517578125
Max value: 78.19976806640625
Mean value: 66.09419250488281

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -66.09432220458984
Max value: -66.09432220458984
Mean value: -66.09432220458984
sam_encoder.pos_embed grad: -6.040923317129909e-11
sam_encoder.blocks.0.norm1.weight grad: 5.511330414265103e-07
sam_encoder.blocks.0.norm1.bias grad: 8.92114985617809e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.265397137714899e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.01537397717766e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 7.131816204264396e-08
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -8.419495856060166e-08
sam_encoder.blocks.0.norm2.weight grad: 4.285905561118852e-06
sam_encoder.blocks.0.norm2.bias grad: 7.033094334474299e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.9040388679059106e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.9048638932872564e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -4.5175165723776445e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.847470336244442e-07
sam_encoder.blocks.1.norm1.weight grad: -4.59618149761809e-06
sam_encoder.blocks.1.norm1.bias grad: -8.871235763763252e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 9.4699197461523e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 6.951883619876753e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.9999947653559502e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 8.593964366809814e-07
sam_encoder.blocks.1.norm2.weight grad: 3.8039565879444126e-06
sam_encoder.blocks.1.norm2.bias grad: -3.932503744863425e-08
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.31918976776069e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.0081727168653742e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 2.4511041374353226e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 5.620227057079319e-07
sam_encoder.blocks.2.norm1.weight grad: 3.0881633392709773e-06
sam_encoder.blocks.2.norm1.bias grad: -4.1063231037696823e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.500243226677412e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 9.359773116557335e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 4.904827619611751e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.6146391241563833e-07
sam_encoder.blocks.2.norm2.weight grad: 3.862111043417826e-06
sam_encoder.blocks.2.norm2.bias grad: -9.407624474988552e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 3.104073584836442e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 4.822901473744423e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.0335584192944225e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.1993177767853922e-07
sam_encoder.blocks.3.norm1.weight grad: -5.1781898946501315e-06
sam_encoder.blocks.3.norm1.bias grad: 5.670378868671833e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.6614976630080491e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.155864417043631e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.190557317291677e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 5.028761620451405e-07
sam_encoder.blocks.3.norm2.weight grad: 7.406915301544359e-06
sam_encoder.blocks.3.norm2.bias grad: 5.299144959280966e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.945609700575005e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.1312450826371787e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -9.844659132340894e-08
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.6266233160422416e-07
sam_encoder.blocks.4.norm1.weight grad: -8.85634926817147e-06
sam_encoder.blocks.4.norm1.bias grad: -1.152744744103984e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -5.362995580071583e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.4571405699825846e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.5230109511321643e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -6.640525498369243e-07
sam_encoder.blocks.4.norm2.weight grad: -2.0470058643695666e-06
sam_encoder.blocks.4.norm2.bias grad: 2.902878804889042e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.2315945241425652e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.838834222198329e-09
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 5.25069026480196e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.782022079372837e-07
sam_encoder.blocks.5.norm1.weight grad: -6.9792495196452364e-06
sam_encoder.blocks.5.norm1.bias grad: -9.729674275149591e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.6900644317938713e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.8189177214699157e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.1468087990351705e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -7.546161100435711e-07
sam_encoder.blocks.5.norm2.weight grad: -1.6924834653764265e-06
sam_encoder.blocks.5.norm2.bias grad: 2.6223269742331468e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.0983949323417619e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.106478914105537e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -9.408349654904669e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.057095341318927e-07
sam_encoder.blocks.6.norm1.weight grad: -9.354865824207081e-07
sam_encoder.blocks.6.norm1.bias grad: 3.685886440507602e-08
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -8.959333968050487e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -6.07309289080149e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.3933623083394195e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.528182392325107e-07
sam_encoder.blocks.6.norm2.weight grad: 1.23796576190216e-06
sam_encoder.blocks.6.norm2.bias grad: 6.666679723821289e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.605649117664143e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 6.465913315878424e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 6.433087378354685e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.916080911243625e-07
sam_encoder.blocks.7.norm1.weight grad: -7.610780698996678e-07
sam_encoder.blocks.7.norm1.bias grad: 1.1266449746472063e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -9.192081051878631e-08
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 5.39172106073238e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 4.615041007127729e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -5.561425950872945e-07
sam_encoder.blocks.7.norm2.weight grad: 1.4019209402249544e-06
sam_encoder.blocks.7.norm2.bias grad: -1.8159198589273728e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 7.35387118311337e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 7.264772534654185e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.7612364899832755e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.748658343738498e-07
sam_encoder.blocks.8.norm1.weight grad: -4.18226500187302e-06
sam_encoder.blocks.8.norm1.bias grad: 1.8346374872635351e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -4.23870915255975e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.4184173551257118e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -7.97182764245008e-08
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.93764421396736e-07
sam_encoder.blocks.8.norm2.weight grad: 8.669028375152266e-07
sam_encoder.blocks.8.norm2.bias grad: -6.197896595949715e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 9.571801911079092e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 5.192579237700556e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 5.735890908908914e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.5912108608517883e-07
sam_encoder.blocks.9.norm1.weight grad: -1.4386750990524888e-06
sam_encoder.blocks.9.norm1.bias grad: 3.5682472088183204e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -7.136794692996773e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.0537105172024894e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.121954227301103e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -5.670191285389592e-07
sam_encoder.blocks.9.norm2.weight grad: 2.7611440600594506e-07
sam_encoder.blocks.9.norm2.bias grad: -6.839615025455714e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 5.782421794719994e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 8.423465658324858e-08
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.4234033680368157e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.697834299349779e-07
sam_encoder.blocks.10.norm1.weight grad: 1.1540242894625408e-06
sam_encoder.blocks.10.norm1.bias grad: -4.391975494399958e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.467417746425781e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 5.082119969301857e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 4.925201437799842e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.000748958787881e-07
sam_encoder.blocks.10.norm2.weight grad: -7.765961527184118e-07
sam_encoder.blocks.10.norm2.bias grad: -1.4191953141562408e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 7.004445592428965e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.079053894656681e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -6.997397576924413e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.782949479751551e-07
sam_encoder.blocks.11.norm1.weight grad: -3.6674580314866034e-06
sam_encoder.blocks.11.norm1.bias grad: -1.6806325220386498e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.1762886060751043e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.0875353357041604e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.3752866695758712e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -6.256725271214236e-08
sam_encoder.blocks.11.norm2.weight grad: 2.644719643285498e-08
sam_encoder.blocks.11.norm2.bias grad: -1.1493793863337487e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.2006897804894834e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.6922268148155126e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -8.992818720798823e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.2902047192019381e-07
sam_encoder.neck.conv1.trainable_scale grad: -3.124748673144495e-07
sam_encoder.neck.conv1.trainable_shift grad: -6.559382200066466e-06
sam_encoder.neck.conv2.trainable_scale grad: -4.6269610720628407e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.0544094038777985e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00014102942077443004
mask_decoder.transformer.layers.0.norm1.bias grad: -4.293433448765427e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0029594996012747288
mask_decoder.transformer.layers.0.norm2.bias grad: -2.4067354388535023e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 5.528905603569001e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.2363860150799155e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.724394213757478e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -5.188258000998758e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 5.967660035821609e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.2749236450181343e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -2.4253349693026394e-06
mask_decoder.transformer.layers.1.norm2.bias grad: 7.009108958300203e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.177224061801098e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.996303661959246e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 4.030018317280337e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -5.4834959883010015e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.235203853866551e-05
mask_decoder.transformer.norm_final_attn.bias grad: 7.569069111923454e-06
Text_Embedding_Affine.0.weight grad: 8.029748740923104e-12
Text_Embedding_Affine.0.bias grad: 1.4321127617122897e-10
Text_Embedding_Affine.2.weight grad: 4.237100947879213e-11
Text_Embedding_Affine.2.bias grad: -7.65156619308982e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0909540057182312

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0909540057182312

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08879423141479492

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.41619178652763367

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09096240997314453

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08879423141479492

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 61.78583526611328
Max value: 91.51791381835938
Mean value: 73.20918273925781

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09093884378671646

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09093884378671646

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09093884378671646

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.40912726521492004

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.6671257615089417
Max value: 3.3617911338806152
Mean value: 1.0087831020355225

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 61.78583526611328
Max value: 91.51791381835938
Mean value: 73.20918273925781

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -73.51942443847656
Max value: -73.51942443847656
Mean value: -73.51942443847656
sam_encoder.pos_embed grad: 1.058753706928428e-08
sam_encoder.blocks.0.norm1.weight grad: 2.2530872229253873e-05
sam_encoder.blocks.0.norm1.bias grad: -2.8214758458489086e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.875160473398864e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 6.007579145261843e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.2320637097218423e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.784423773187882e-07
sam_encoder.blocks.0.norm2.weight grad: -2.8131387807661667e-05
sam_encoder.blocks.0.norm2.bias grad: -1.049456750479294e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 5.3943685998092405e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.867543910018867e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.463219061610289e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 7.876666927586484e-07
sam_encoder.blocks.1.norm1.weight grad: -1.0148896762984805e-05
sam_encoder.blocks.1.norm1.bias grad: 4.342969987192191e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.0829872887115926e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.551338073113584e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.3760616133804433e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.7872424652741756e-06
sam_encoder.blocks.1.norm2.weight grad: 1.7683072428553714e-06
sam_encoder.blocks.1.norm2.bias grad: 1.0686653695302084e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.736004484584555e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.3005960681766737e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.820419806288555e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.2497303032432683e-06
sam_encoder.blocks.2.norm1.weight grad: -4.466099198907614e-06
sam_encoder.blocks.2.norm1.bias grad: 2.21409618461621e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.420566488581244e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 7.430787718476495e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.5790567431395175e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.044094220669649e-07
sam_encoder.blocks.2.norm2.weight grad: 1.0402047337265685e-05
sam_encoder.blocks.2.norm2.bias grad: 4.2993069655494764e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 7.455766535713337e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.7266714823781513e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -5.177982529858127e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.964143393706763e-06
sam_encoder.blocks.3.norm1.weight grad: -1.79803555511171e-06
sam_encoder.blocks.3.norm1.bias grad: -5.161930857866537e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.545058578107273e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.081618620446534e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.913263753929641e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -9.843661246122792e-07
sam_encoder.blocks.3.norm2.weight grad: 3.8718153518857434e-06
sam_encoder.blocks.3.norm2.bias grad: -5.021103334001964e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.9539365894161165e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 4.185150146440719e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.4260968984890496e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.1983929653069936e-06
sam_encoder.blocks.4.norm1.weight grad: -1.1828279639303219e-05
sam_encoder.blocks.4.norm1.bias grad: -8.093562428257428e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -8.577088010497391e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.5861173778830562e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.637678102881182e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.8320415620109998e-06
sam_encoder.blocks.4.norm2.weight grad: 1.4183767689246451e-06
sam_encoder.blocks.4.norm2.bias grad: 4.090245965926442e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 3.041328682229505e-07
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 8.707403935659386e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.1244152037525055e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -3.822372036665911e-07
sam_encoder.blocks.5.norm1.weight grad: -1.2848085134464782e-05
sam_encoder.blocks.5.norm1.bias grad: -1.1587873814278282e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -8.767754479777068e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.5659795735700754e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.9140705919417087e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -3.4195616080978652e-06
sam_encoder.blocks.5.norm2.weight grad: 2.935896873168531e-06
sam_encoder.blocks.5.norm2.bias grad: 2.7590531317400746e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.5305230363082956e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 7.853594752305071e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.5763087048981106e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 6.418701445909392e-07
sam_encoder.blocks.6.norm1.weight grad: -2.8531376301543787e-06
sam_encoder.blocks.6.norm1.bias grad: -3.7178640468482627e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.290214752065367e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -9.74449903878849e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -9.399686859978829e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -7.220289717224659e-07
sam_encoder.blocks.6.norm2.weight grad: 2.846508323273156e-06
sam_encoder.blocks.6.norm2.bias grad: 1.5484073401239584e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 3.18929551212932e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.1642640629361267e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.4483060795100755e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 8.278202017208969e-07
sam_encoder.blocks.7.norm1.weight grad: -2.5368651677126763e-06
sam_encoder.blocks.7.norm1.bias grad: 1.9252563987492977e-08
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -2.1432867924886523e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -6.399926633093855e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.5384219977931934e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.2582002000272041e-06
sam_encoder.blocks.7.norm2.weight grad: 6.166802677398664e-07
sam_encoder.blocks.7.norm2.bias grad: -1.5717200767539907e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -9.129894351644907e-08
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 4.7351755938507267e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.173780901808641e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 3.875513812090503e-07
sam_encoder.blocks.8.norm1.weight grad: 7.556706691502768e-07
sam_encoder.blocks.8.norm1.bias grad: 1.1123663625767222e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.91601747146342e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 6.938898877706379e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.0810518890357343e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.1627710136963287e-06
sam_encoder.blocks.8.norm2.weight grad: -2.1520379505091114e-06
sam_encoder.blocks.8.norm2.bias grad: -4.155726855969988e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.0115961635601707e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -9.27692667573865e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -7.165251076912682e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -9.639562392749212e-08
sam_encoder.blocks.9.norm1.weight grad: -4.67670543002896e-06
sam_encoder.blocks.9.norm1.bias grad: -5.352837888494832e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.2247096442006296e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.109663799070404e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.5001030331332e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.1236999171160278e-06
sam_encoder.blocks.9.norm2.weight grad: -6.9559623625536915e-06
sam_encoder.blocks.9.norm2.bias grad: -1.3151527582522249e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -6.051767741155345e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.707815383473644e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.7059726360457717e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -8.026788123061124e-07
sam_encoder.blocks.10.norm1.weight grad: -3.115216259175213e-06
sam_encoder.blocks.10.norm1.bias grad: -1.025513938657241e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -9.814662007556763e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -4.784620841746801e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.4831243788648862e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -9.648712051557595e-08
sam_encoder.blocks.10.norm2.weight grad: -1.1280149010417517e-05
sam_encoder.blocks.10.norm2.bias grad: -3.0265409804997034e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -6.193353328853846e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.2286088753608055e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.6523449630767573e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -8.517573633071152e-07
sam_encoder.blocks.11.norm1.weight grad: -1.228829933097586e-05
sam_encoder.blocks.11.norm1.bias grad: 1.6920739653869532e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.6060623642697465e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.476628643918957e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -6.196555659698788e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -7.721541237515339e-07
sam_encoder.blocks.11.norm2.weight grad: -1.1755982086469885e-05
sam_encoder.blocks.11.norm2.bias grad: -4.102651928405976e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -4.9931518333323766e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.1420855773612857e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.1713607364072232e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.5874796822099597e-07
sam_encoder.neck.conv1.trainable_scale grad: -7.754351827315986e-07
sam_encoder.neck.conv1.trainable_shift grad: -3.0229391995817423e-05
sam_encoder.neck.conv2.trainable_scale grad: -8.195565897040069e-07
sam_encoder.neck.conv2.trainable_shift grad: 5.98313727095956e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -9.484841575613245e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 5.664333002641797e-09
mask_decoder.transformer.layers.0.norm2.weight grad: 0.006081638392060995
mask_decoder.transformer.layers.0.norm2.bias grad: 4.1198276448994875e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 6.77471689414233e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.7345726266503334e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 2.7602012778515927e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -8.059050742303953e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 4.735178663395345e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -3.835210918623488e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00015383330173790455
mask_decoder.transformer.layers.1.norm2.bias grad: 2.8166617994429544e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.1772727854549885e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.15328099229373e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.000147893006214872
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00012594048166647553
mask_decoder.transformer.norm_final_attn.weight grad: 1.5665900718886405e-05
mask_decoder.transformer.norm_final_attn.bias grad: 9.00723989616381e-06
Text_Embedding_Affine.0.weight grad: 5.865056270509816e-12
Text_Embedding_Affine.0.bias grad: 1.6524705215292812e-10
Text_Embedding_Affine.2.weight grad: 1.479119743352797e-10
Text_Embedding_Affine.2.bias grad: -1.965255432878621e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07737423479557037

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07737423479557037

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0673837661743164

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3895273208618164

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0774087905883789

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0673837661743164

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 61.99903869628906
Max value: 70.52879333496094
Mean value: 64.97648620605469

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07696957886219025

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07696957886219025

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07696957886219025

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.37289366126060486

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.5448060631752014
Max value: 8.999992370605469
Mean value: 1.0256290435791016

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 61.99903869628906
Max value: 70.52879333496094
Mean value: 64.97648620605469

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.33109283447266
Max value: -65.33109283447266
Mean value: -65.33109283447266
sam_encoder.pos_embed grad: -1.7098988891461886e-09
sam_encoder.blocks.0.norm1.weight grad: 1.8434817320667207e-05
sam_encoder.blocks.0.norm1.bias grad: 3.118582026218064e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 7.746046321699396e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.1556520576050389e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 9.450546713196672e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 4.152934707235545e-07
sam_encoder.blocks.0.norm2.weight grad: 9.101733303396031e-05
sam_encoder.blocks.0.norm2.bias grad: -9.58646705839783e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.978452201001346e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.6246643781414605e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.5175777409458533e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.4191029385510774e-07
sam_encoder.blocks.1.norm1.weight grad: -1.8988357624039054e-05
sam_encoder.blocks.1.norm1.bias grad: -3.098976549154031e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -8.305898518301547e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.474637312843697e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.138286946428707e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.093376785225701e-06
sam_encoder.blocks.1.norm2.weight grad: -2.2867634470458142e-06
sam_encoder.blocks.1.norm2.bias grad: 3.7335385059122927e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.317304617667105e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.2839946066378616e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.1335801900713705e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.55745566796395e-06
sam_encoder.blocks.2.norm1.weight grad: -1.7594455130165443e-05
sam_encoder.blocks.2.norm1.bias grad: -1.8388527678325772e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.2806277482013684e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.067390144271485e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -9.286992280976847e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.507886610052083e-06
sam_encoder.blocks.2.norm2.weight grad: 2.3072334442986175e-05
sam_encoder.blocks.2.norm2.bias grad: -1.0981875675497577e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.5588064343319274e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.9807036955608055e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -5.518285888683749e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 8.030285414406535e-08
sam_encoder.blocks.3.norm1.weight grad: 9.366668564325664e-06
sam_encoder.blocks.3.norm1.bias grad: -1.190087914437754e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.814925548795145e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.919056103361072e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -7.426589490933111e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.7801816031569615e-06
sam_encoder.blocks.3.norm2.weight grad: 3.5598393878899515e-05
sam_encoder.blocks.3.norm2.bias grad: 2.9331346013350412e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.6816043828148395e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.1857819117722102e-05
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.1133095085824607e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -6.911458854119701e-07
sam_encoder.blocks.4.norm1.weight grad: 5.861176077814889e-07
sam_encoder.blocks.4.norm1.bias grad: -3.9904689401737414e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -4.579265350912465e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.1920537872356363e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.472561613511061e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.9829667508020066e-06
sam_encoder.blocks.4.norm2.weight grad: -4.088096829946153e-05
sam_encoder.blocks.4.norm2.bias grad: -2.6371400963398628e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.6101668229093775e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.1774804079323076e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.8693724491167814e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.6670395527617075e-06
sam_encoder.blocks.5.norm1.weight grad: -1.0716785254771821e-06
sam_encoder.blocks.5.norm1.bias grad: -2.1053729142295197e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -5.845955456607044e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.1688045964983758e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -4.145072125538718e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.1923887086595641e-06
sam_encoder.blocks.5.norm2.weight grad: -1.367787172057433e-05
sam_encoder.blocks.5.norm2.bias grad: -5.123983100929763e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.088527642423287e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.3814444577728864e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 7.026525963738095e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.1581748822209192e-06
sam_encoder.blocks.6.norm1.weight grad: 2.2860062927065883e-06
sam_encoder.blocks.6.norm1.bias grad: -5.996058007440297e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.6882298723430722e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 5.588930207522935e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.544455128372647e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.546241833239037e-06
sam_encoder.blocks.6.norm2.weight grad: -1.5869561593717663e-06
sam_encoder.blocks.6.norm2.bias grad: -2.480273906257935e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.2735076729295542e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.1371228083589813e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.7556678812979953e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.755052608132246e-06
sam_encoder.blocks.7.norm1.weight grad: 4.053607426612871e-06
sam_encoder.blocks.7.norm1.bias grad: 4.27751683673705e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.5466630429727957e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.8331678575123078e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.92669335269602e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 6.315542577794986e-07
sam_encoder.blocks.7.norm2.weight grad: 3.96357745557907e-06
sam_encoder.blocks.7.norm2.bias grad: -2.240378307760693e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.598854618758196e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 5.021904598834226e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.0616565759846708e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.4618870497761236e-07
sam_encoder.blocks.8.norm1.weight grad: -2.6038924261229113e-06
sam_encoder.blocks.8.norm1.bias grad: -8.867161227499309e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -5.513938958756626e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.629952632560162e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.196064485815441e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.4879659576981794e-06
sam_encoder.blocks.8.norm2.weight grad: 1.0057199233415304e-06
sam_encoder.blocks.8.norm2.bias grad: 1.021630623654346e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.4482584447250701e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -9.029769216795103e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -6.185420602378144e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.9985631044837646e-07
sam_encoder.blocks.9.norm1.weight grad: -5.751683602284174e-06
sam_encoder.blocks.9.norm1.bias grad: 6.793925422243774e-09
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -6.088581358199008e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.1189034694325528e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.8318881984669133e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.348204119101865e-07
sam_encoder.blocks.9.norm2.weight grad: -2.8548361115099397e-06
sam_encoder.blocks.9.norm2.bias grad: -9.785037491383264e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.326455382397398e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.9498700112308143e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.2866323686466785e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.9527996048273053e-07
sam_encoder.blocks.10.norm1.weight grad: -5.299936219671508e-06
sam_encoder.blocks.10.norm1.bias grad: -2.3174120542535093e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.1981322788633406e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -5.1576158455191035e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -3.4990574704352184e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.174395940026443e-07
sam_encoder.blocks.10.norm2.weight grad: -8.733875802136026e-06
sam_encoder.blocks.10.norm2.bias grad: -1.418728061253205e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -6.018101885274518e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.2739162634243257e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.2229896785574965e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.749446808702487e-07
sam_encoder.blocks.11.norm1.weight grad: -8.605488801549654e-06
sam_encoder.blocks.11.norm1.bias grad: -1.251785761269275e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.2499884835269768e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -6.932981477802969e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -3.367038914348086e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.456364427416702e-07
sam_encoder.blocks.11.norm2.weight grad: -1.2490365406847559e-05
sam_encoder.blocks.11.norm2.bias grad: -2.6064924441016046e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -4.808774065168109e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.587593482734519e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -3.0946218885219423e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.024248717840237e-06
sam_encoder.neck.conv1.trainable_scale grad: -1.0072872100863606e-06
sam_encoder.neck.conv1.trainable_shift grad: -3.285886850790121e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.1569372873054817e-06
sam_encoder.neck.conv2.trainable_shift grad: 4.506252662395127e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00018352980259805918
mask_decoder.transformer.layers.0.norm1.bias grad: -2.2335516405291855e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.00360874249599874
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0001086146803572774
mask_decoder.transformer.layers.0.norm3.weight grad: 7.666932651773095e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.7678866899805143e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0001221072016051039
mask_decoder.transformer.layers.0.norm4.bias grad: 6.842692528152838e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.033442044397816e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -4.855523002333939e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -2.3521268303738907e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 5.99937338847667e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.8434707170818e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 9.23921907087788e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 9.42806072998792e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 1.3772601960226893e-05
mask_decoder.transformer.norm_final_attn.weight grad: 2.822909300448373e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.9912737116101198e-05
Text_Embedding_Affine.0.weight grad: 2.1683653136927994e-12
Text_Embedding_Affine.0.bias grad: -7.551237413139233e-12
Text_Embedding_Affine.2.weight grad: -3.799533951354128e-11
Text_Embedding_Affine.2.bias grad: -3.9134465623646975e-07
Epoch 1 finished with average loss: -68.3149
Epoch 2/39
----------
Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s, loss=-65.4]Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.03it/s, loss=-65.4]Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.03it/s, loss=-67.8]Epoch 2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-67.8]Epoch 2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.62it/s, loss=-68]  Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.27it/s, loss=-68]/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
                                                                
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0785592794418335

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0785592794418335

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07549285888671875

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3569665551185608

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07858419418334961

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07549285888671875

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 45.283905029296875
Max value: 92.34758758544922
Mean value: 65.3807373046875

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0785592794418335

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0785592794418335

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0785592794418335

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3569665551185608

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 45.283905029296875
Max value: 92.34758758544922
Mean value: 65.3807373046875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.380859375
Max value: -65.380859375
Mean value: -65.380859375
sam_encoder.pos_embed grad: -3.31715488410822e-10
sam_encoder.blocks.0.norm1.weight grad: 5.274148406897439e-06
sam_encoder.blocks.0.norm1.bias grad: 7.058074515953194e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -5.920243779655721e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.266765252694313e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.6674230209900998e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 5.31634611888876e-07
sam_encoder.blocks.0.norm2.weight grad: 1.1070847904193215e-05
sam_encoder.blocks.0.norm2.bias grad: 8.046412403928116e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.2694233595975675e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -6.771508509473279e-08
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -3.3190203794219997e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 7.503578558498702e-07
sam_encoder.blocks.1.norm1.weight grad: -1.4600454960600473e-06
sam_encoder.blocks.1.norm1.bias grad: -3.637610916484846e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.065398348349845e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 9.2977666099614e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.212929757661186e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.3315788010004326e-06
sam_encoder.blocks.1.norm2.weight grad: 7.663623364351224e-06
sam_encoder.blocks.1.norm2.bias grad: 6.37410266790539e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.553738224582048e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.656359919863462e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 4.2263018258381635e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 8.70424116783397e-07
sam_encoder.blocks.2.norm1.weight grad: 2.2990532215771964e-06
sam_encoder.blocks.2.norm1.bias grad: -1.6248609426838811e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.326019850646844e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 6.23901428298268e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 7.044732228678185e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.8610659796868276e-07
sam_encoder.blocks.2.norm2.weight grad: -4.720454398920992e-06
sam_encoder.blocks.2.norm2.bias grad: 3.972402737417724e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.674847110029077e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.393806542182574e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.003460849664407e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.3879823654860957e-06
sam_encoder.blocks.3.norm1.weight grad: -7.221869054774288e-06
sam_encoder.blocks.3.norm1.bias grad: -1.2199068351037567e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.9049203931208467e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.5247074947619694e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.169541064882651e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.664301834125581e-07
sam_encoder.blocks.3.norm2.weight grad: 2.157094286303618e-06
sam_encoder.blocks.3.norm2.bias grad: 5.831672751810402e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.172667564082076e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.0142564355628565e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.762866131433839e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -5.612311042568763e-07
sam_encoder.blocks.4.norm1.weight grad: -7.753951649647206e-06
sam_encoder.blocks.4.norm1.bias grad: 3.28079750033794e-08
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.809225290751783e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.1246706890233327e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.9512826788268285e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 4.1165480979543645e-07
sam_encoder.blocks.4.norm2.weight grad: -3.7836350657016737e-06
sam_encoder.blocks.4.norm2.bias grad: -7.168242746047326e-07
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.612905518617481e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -7.707155873504234e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -5.902245447941823e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -8.439478733635042e-07
sam_encoder.blocks.5.norm1.weight grad: -8.417902790824883e-06
sam_encoder.blocks.5.norm1.bias grad: -1.1459209190434194e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.220642949803732e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.3100643627694808e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -9.368515634378127e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -7.397487706839456e-07
sam_encoder.blocks.5.norm2.weight grad: -3.844992079393705e-06
sam_encoder.blocks.5.norm2.bias grad: 3.942414537050354e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.8357256976742065e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -6.150461331344559e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -4.3893828660657164e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.37356413587986e-07
sam_encoder.blocks.6.norm1.weight grad: -1.580330462047641e-07
sam_encoder.blocks.6.norm1.bias grad: 1.4779652701690793e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -5.905013722440344e-08
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.320050841968623e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.925713821852696e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.5864273450461042e-07
sam_encoder.blocks.6.norm2.weight grad: -1.2460018297133502e-06
sam_encoder.blocks.6.norm2.bias grad: -5.183632083571865e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -8.236647772719152e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.0266330125195964e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.1309612091281451e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.394983577071798e-08
sam_encoder.blocks.7.norm1.weight grad: -4.893875029665651e-07
sam_encoder.blocks.7.norm1.bias grad: 1.3312990176927997e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.2085342859791126e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 4.2232736063851917e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 6.885356356178818e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -6.955363005545223e-07
sam_encoder.blocks.7.norm2.weight grad: 1.3743796216658666e-06
sam_encoder.blocks.7.norm2.bias grad: 3.809585109593172e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.0228639979459331e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.9227348363747296e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.533710983243509e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.909609288006322e-07
sam_encoder.blocks.8.norm1.weight grad: -2.9626105515490053e-06
sam_encoder.blocks.8.norm1.bias grad: 1.3182716429582797e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -3.6781293601961806e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.67775738191267e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.9882363605793216e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.9018349917132582e-07
sam_encoder.blocks.8.norm2.weight grad: -7.793166219016712e-07
sam_encoder.blocks.8.norm2.bias grad: -9.002462775242748e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.349950242816703e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -4.85752934764605e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -4.01569195673801e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.5877355963311857e-07
sam_encoder.blocks.9.norm1.weight grad: -4.381277847187448e-07
sam_encoder.blocks.9.norm1.bias grad: -1.5142843778903625e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.1746607242457685e-08
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.321688097912556e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 3.712698344315868e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -6.370984806380875e-07
sam_encoder.blocks.9.norm2.weight grad: -5.295298706187168e-07
sam_encoder.blocks.9.norm2.bias grad: -1.3629959312311257e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.0036213161110936e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.4603672222365276e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -5.64618744647305e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.988321506971261e-07
sam_encoder.blocks.10.norm1.weight grad: 2.1469086277647875e-06
sam_encoder.blocks.10.norm1.bias grad: -7.075504981912673e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.1425680643005762e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 7.778575081829331e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 7.88024181019864e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.6261141051218146e-07
sam_encoder.blocks.10.norm2.weight grad: -1.6997067859847448e-06
sam_encoder.blocks.10.norm2.bias grad: -1.7739979512043647e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.886061736262491e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.893439490340825e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.0286873930454021e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.8704718008375494e-07
sam_encoder.blocks.11.norm1.weight grad: 3.031118239960051e-06
sam_encoder.blocks.11.norm1.bias grad: -3.425495833653258e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.2184274207102135e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.798231750171908e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 7.211110641947016e-08
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 8.270787787978406e-08
sam_encoder.blocks.11.norm2.weight grad: 3.591094923649507e-07
sam_encoder.blocks.11.norm2.bias grad: -9.329600629826018e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.7041051023625187e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.2800775784380676e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -7.371407946266118e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.1165047314752883e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.399093889631331e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.8773767806123942e-05
sam_encoder.neck.conv2.trainable_scale grad: -4.04721504310146e-07
sam_encoder.neck.conv2.trainable_shift grad: 3.0173323466442525e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00015386675659101456
mask_decoder.transformer.layers.0.norm1.bias grad: -1.3571116141974926e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0021473870147019625
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00015734453336335719
mask_decoder.transformer.layers.0.norm3.weight grad: 4.940161306876689e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.087436925852671e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 4.428857209859416e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.0148742148885503e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 6.472082168329507e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -3.586566890589893e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 7.301812729565427e-06
mask_decoder.transformer.layers.1.norm2.bias grad: 8.164397877408192e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.4751246857922524e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.535082502523437e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -8.41102246340597e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -6.840362038929015e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.0869589459616691e-05
mask_decoder.transformer.norm_final_attn.bias grad: 7.689315680181608e-06
Text_Embedding_Affine.0.weight grad: 5.9589178209862315e-12
Text_Embedding_Affine.0.bias grad: 1.7719563316642706e-10
Text_Embedding_Affine.2.weight grad: 1.642544711355498e-10
Text_Embedding_Affine.2.bias grad: -2.636905264807865e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09117071330547333

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09117071330547333

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09454774856567383

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4457928538322449

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0911111831665039

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09454774856567383

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 57.559532165527344
Max value: 82.0401840209961
Mean value: 69.80891418457031

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0904378741979599

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0904378741979599

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0904378741979599

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4353832006454468

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.51746666431427
Max value: 9.999995231628418
Mean value: 1.0139825344085693

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 57.559532165527344
Max value: 82.0401840209961
Mean value: 69.80891418457031

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -70.15339660644531
Max value: -70.15339660644531
Mean value: -70.15339660644531
sam_encoder.pos_embed grad: -1.2087222778234263e-08
sam_encoder.blocks.0.norm1.weight grad: 2.686202060431242e-05
sam_encoder.blocks.0.norm1.bias grad: 2.623440741444938e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.821713451339747e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.118948027098668e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 5.013650024920935e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 5.121063395563397e-07
sam_encoder.blocks.0.norm2.weight grad: 3.341531191836111e-05
sam_encoder.blocks.0.norm2.bias grad: 3.902594471583143e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.4529954341924167e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.5298729673959315e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.5937815987854265e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.641689884010702e-06
sam_encoder.blocks.1.norm1.weight grad: -5.525744199985638e-06
sam_encoder.blocks.1.norm1.bias grad: 1.8915429222943203e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 9.064632422450813e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.5448731005562877e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.481502967086271e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.073724196336116e-07
sam_encoder.blocks.1.norm2.weight grad: 6.172555004013702e-06
sam_encoder.blocks.1.norm2.bias grad: -2.3354432414635085e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.3501937701221323e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.0050118817162002e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -6.886306437081657e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.426919991194154e-06
sam_encoder.blocks.2.norm1.weight grad: 3.484398803266231e-06
sam_encoder.blocks.2.norm1.bias grad: -6.556502739840653e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.188743110309588e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.392885107838083e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.336743930049124e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.8569833173387451e-06
sam_encoder.blocks.2.norm2.weight grad: -5.729563781642355e-06
sam_encoder.blocks.2.norm2.bias grad: -7.72940711613046e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.587088369589765e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.2332176285999594e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.028993422864005e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -4.601224645739421e-07
sam_encoder.blocks.3.norm1.weight grad: 4.043526132591069e-06
sam_encoder.blocks.3.norm1.bias grad: -5.824783784191823e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.4585791581775993e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.108343034658901e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.2604886023837025e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.709966165388323e-07
sam_encoder.blocks.3.norm2.weight grad: -9.586696023689e-07
sam_encoder.blocks.3.norm2.bias grad: -8.086291018116754e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -6.272966857068241e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.99490943436831e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 4.7221401473507285e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.713402574907377e-07
sam_encoder.blocks.4.norm1.weight grad: 2.3052049073157832e-05
sam_encoder.blocks.4.norm1.bias grad: -3.869477041007485e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.1585876563913189e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.7055245936935535e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 6.0053002925997134e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 4.7701360017526895e-06
sam_encoder.blocks.4.norm2.weight grad: -3.966336225857958e-05
sam_encoder.blocks.4.norm2.bias grad: -2.7347332434146665e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.7381116524338722e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.0098561688209884e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 5.851199489370629e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -3.544526805399073e-07
sam_encoder.blocks.5.norm1.weight grad: 1.1386807273083832e-05
sam_encoder.blocks.5.norm1.bias grad: -6.148611646494828e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.0842407947347965e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.392657959011558e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.716009814525023e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.823810402536765e-06
sam_encoder.blocks.5.norm2.weight grad: -1.609624086995609e-05
sam_encoder.blocks.5.norm2.bias grad: -1.4951258890505414e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -6.762936664017616e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.027848950092448e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.398514761305705e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.685670316779579e-07
sam_encoder.blocks.6.norm1.weight grad: 4.095521035196725e-06
sam_encoder.blocks.6.norm1.bias grad: 5.230168881098507e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.948714725585887e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.482829811218835e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.4656850453320658e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 3.789187701386254e-07
sam_encoder.blocks.6.norm2.weight grad: -1.2837102076446172e-05
sam_encoder.blocks.6.norm2.bias grad: -3.893317625625059e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -9.991485057980753e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.869992153544445e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.2253635759407189e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.2390710253384896e-06
sam_encoder.blocks.7.norm1.weight grad: 5.8185682973999064e-06
sam_encoder.blocks.7.norm1.bias grad: 1.2476872370825731e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.3785568120947573e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.5445179997186642e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.9484461972751888e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -6.14644051211144e-08
sam_encoder.blocks.7.norm2.weight grad: 4.021272616228089e-06
sam_encoder.blocks.7.norm2.bias grad: 2.29255033445952e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.4769541343848687e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.1269548849668354e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.561192205685074e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.6695549826836213e-07
sam_encoder.blocks.8.norm1.weight grad: 8.35117680253461e-06
sam_encoder.blocks.8.norm1.bias grad: -2.9589562018372817e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 6.977689736231696e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.446465941829956e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.945277967432048e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 3.329801984364167e-06
sam_encoder.blocks.8.norm2.weight grad: 1.1682257081702119e-06
sam_encoder.blocks.8.norm2.bias grad: 6.12045710113307e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.4828023015288636e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -6.481336356500833e-08
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -6.626559070355142e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.824087677159696e-07
sam_encoder.blocks.9.norm1.weight grad: 2.0044542452524183e-06
sam_encoder.blocks.9.norm1.bias grad: 8.564906011088169e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.0915458688032231e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 6.802087000323809e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 6.454537810895999e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.291914202283806e-07
sam_encoder.blocks.9.norm2.weight grad: 4.804584023077041e-06
sam_encoder.blocks.9.norm2.bias grad: 7.970290312186989e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.3077062653319445e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.107259208765754e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 5.570051371250884e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.2729964282698347e-07
sam_encoder.blocks.10.norm1.weight grad: 7.4246163421776146e-06
sam_encoder.blocks.10.norm1.bias grad: 9.449526032767608e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 4.059969796799123e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.6415026493632467e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.86007525826426e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.0070148164231796e-06
sam_encoder.blocks.10.norm2.weight grad: 7.353713954216801e-06
sam_encoder.blocks.10.norm2.bias grad: 1.1419820111768786e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.7419025577255525e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.4249711739466875e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 5.797994617751101e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.0045360099297795e-08
sam_encoder.blocks.11.norm1.weight grad: 1.8944811017718166e-05
sam_encoder.blocks.11.norm1.bias grad: -4.6789546104264446e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.731740098875889e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.058200827079418e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.338272224733373e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.2390117944960366e-06
sam_encoder.blocks.11.norm2.weight grad: 1.100990175473271e-05
sam_encoder.blocks.11.norm2.bias grad: 1.457863618270494e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.850551926618209e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.2303348739806097e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.832371243741363e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 9.042278037441065e-08
sam_encoder.neck.conv1.trainable_scale grad: 1.0467090305610327e-07
sam_encoder.neck.conv1.trainable_shift grad: 9.288711225963198e-06
sam_encoder.neck.conv2.trainable_scale grad: -7.323887984966859e-08
sam_encoder.neck.conv2.trainable_shift grad: 1.6007685189833865e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -7.168215961428359e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -9.946998034138232e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004796575289219618
mask_decoder.transformer.layers.0.norm2.bias grad: -1.2637261534109712e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -8.868079021340236e-06
mask_decoder.transformer.layers.0.norm3.bias grad: 9.471074008615687e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 5.886155122425407e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 3.689470759127289e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 8.204874575312715e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 1.9244848772359546e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00011957078822888434
mask_decoder.transformer.layers.1.norm2.bias grad: 8.816041372483596e-07
mask_decoder.transformer.layers.1.norm3.weight grad: -4.7251960495486856e-06
mask_decoder.transformer.layers.1.norm3.bias grad: -3.6217352317180485e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -6.025206675985828e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00015229545533657074
mask_decoder.transformer.norm_final_attn.weight grad: 5.969056473986711e-06
mask_decoder.transformer.norm_final_attn.bias grad: 4.788842488778755e-06
Text_Embedding_Affine.0.weight grad: -9.306521699115056e-12
Text_Embedding_Affine.0.bias grad: -3.2259628302000465e-10
Text_Embedding_Affine.2.weight grad: -7.889924130699555e-11
Text_Embedding_Affine.2.bias grad: 5.325784513843246e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08501673489809036

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08501673489809036

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07813549041748047

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.41774576902389526

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08504486083984375

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07813549041748047

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 57.39651870727539
Max value: 82.33651733398438
Mean value: 68.18545532226562

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08457314968109131

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08457314968109131

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08457314968109131

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3997213840484619

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.4957585036754608
Max value: 7.999996185302734
Mean value: 1.0283398628234863

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 57.39651870727539
Max value: 82.33651733398438
Mean value: 68.18545532226562

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.5831069946289
Max value: -68.5831069946289
Mean value: -68.5831069946289
sam_encoder.pos_embed grad: -2.2528350296369126e-09
sam_encoder.blocks.0.norm1.weight grad: 6.413785013137385e-05
sam_encoder.blocks.0.norm1.bias grad: 8.873235492501408e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 7.155368621170055e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.3140358987584477e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.2106862413929775e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -4.141298632021062e-06
sam_encoder.blocks.0.norm2.weight grad: 5.4189218644751236e-05
sam_encoder.blocks.0.norm2.bias grad: 2.3093525669537485e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.7469117665314116e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.372034487052588e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -3.0292319934233092e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.2336075744533446e-06
sam_encoder.blocks.1.norm1.weight grad: -2.8727326935040765e-05
sam_encoder.blocks.1.norm1.bias grad: 1.0272603503835853e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.019040377694182e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.6344114303356037e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -4.842408998229075e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.09988388128113e-06
sam_encoder.blocks.1.norm2.weight grad: 3.224651300115511e-05
sam_encoder.blocks.1.norm2.bias grad: 3.053952923437464e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.4393719538929872e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.3551957585586933e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.0524387107579969e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.5413480620482005e-06
sam_encoder.blocks.2.norm1.weight grad: 6.27664985586307e-06
sam_encoder.blocks.2.norm1.bias grad: -1.7888707589008845e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.6102180211419181e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.4961583850190436e-08
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -9.929985026246868e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.7270992834237404e-06
sam_encoder.blocks.2.norm2.weight grad: -1.0926058166660368e-05
sam_encoder.blocks.2.norm2.bias grad: -9.205960850522388e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.4895514292875305e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.2678050299873576e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.969174243451562e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.254823008726817e-06
sam_encoder.blocks.3.norm1.weight grad: 3.627283876994625e-05
sam_encoder.blocks.3.norm1.bias grad: -3.3284013625234365e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 2.5566364456608426e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.3911111409470323e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.3274598030839115e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 3.205433074526809e-07
sam_encoder.blocks.3.norm2.weight grad: 1.0247083082504105e-05
sam_encoder.blocks.3.norm2.bias grad: -3.648486381280236e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.522000158933224e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.82376959148678e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.6879507610574365e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.6736643121694215e-07
sam_encoder.blocks.4.norm1.weight grad: 8.433546099695377e-06
sam_encoder.blocks.4.norm1.bias grad: -1.3112682609062176e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 4.683226052293321e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 4.976041054760572e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 5.756538485002238e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 6.933099029993173e-06
sam_encoder.blocks.4.norm2.weight grad: -8.683089981786907e-05
sam_encoder.blocks.4.norm2.bias grad: -5.423647235147655e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.184881592867896e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.702902591205202e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.3759008652414195e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.0418407327961177e-06
sam_encoder.blocks.5.norm1.weight grad: -3.5194516385672614e-06
sam_encoder.blocks.5.norm1.bias grad: -1.753062679199502e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -7.324570105993189e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -4.674511728808284e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.3698889890511055e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.583014520496363e-06
sam_encoder.blocks.5.norm2.weight grad: -3.6691468267235905e-05
sam_encoder.blocks.5.norm2.bias grad: -2.0673571270890534e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.2529002560768276e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.6648357308877166e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -2.4275279884022893e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.410639568661281e-07
sam_encoder.blocks.6.norm1.weight grad: 1.522293587186141e-05
sam_encoder.blocks.6.norm1.bias grad: 6.037958428350976e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 6.710708021273604e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.067479828037904e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 4.210847237118287e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.291449269861914e-07
sam_encoder.blocks.6.norm2.weight grad: -2.8174530598334968e-05
sam_encoder.blocks.6.norm2.bias grad: -5.492866876011249e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.6117281120386906e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -6.662296982540283e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -3.733426183316624e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.162531473004492e-06
sam_encoder.blocks.7.norm1.weight grad: 2.982073738166946e-06
sam_encoder.blocks.7.norm1.bias grad: 3.43316605722066e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -6.003419912303798e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -4.84321560634271e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.3059791115210828e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.185309535387205e-06
sam_encoder.blocks.7.norm2.weight grad: 4.492548214329872e-06
sam_encoder.blocks.7.norm2.bias grad: 6.4313735492760316e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 4.962247658113483e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 9.077130016521551e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.204543877975084e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.192379717300355e-07
sam_encoder.blocks.8.norm1.weight grad: 7.145837571442826e-06
sam_encoder.blocks.8.norm1.bias grad: -2.8133304112998303e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.59824093215866e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -8.83280790731078e-08
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.155750164296478e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 4.071731382282451e-06
sam_encoder.blocks.8.norm2.weight grad: -9.65382241702173e-07
sam_encoder.blocks.8.norm2.bias grad: -3.5569723877415527e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.1519911064824555e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -7.866995019867318e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.8190615921630524e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.7061865946743637e-06
sam_encoder.blocks.9.norm1.weight grad: -6.008655873301905e-06
sam_encoder.blocks.9.norm1.bias grad: -3.8425682191700616e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -5.687584689439973e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.8020308516497607e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.256088446818467e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.34485742112156e-06
sam_encoder.blocks.9.norm2.weight grad: -1.9204767340852413e-06
sam_encoder.blocks.9.norm2.bias grad: 1.358327608613763e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.098228146176552e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.1155407264595851e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.7570771433383925e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.655122900956485e-06
sam_encoder.blocks.10.norm1.weight grad: 9.223325832863338e-06
sam_encoder.blocks.10.norm1.bias grad: -1.5738372667328804e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 5.6305666475964244e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.9389171939110383e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.801667960738996e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.1989573067694437e-06
sam_encoder.blocks.10.norm2.weight grad: -3.528456545609515e-06
sam_encoder.blocks.10.norm2.bias grad: -1.4760360045329435e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.191515816070023e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.314289304194972e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -9.744674116518581e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.1285048913123319e-06
sam_encoder.blocks.11.norm1.weight grad: 9.532878721074667e-06
sam_encoder.blocks.11.norm1.bias grad: -2.516602251034783e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.591900051309494e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.0398415472300258e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.157698984068702e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -4.652285383599519e-07
sam_encoder.blocks.11.norm2.weight grad: 7.6153819463797845e-06
sam_encoder.blocks.11.norm2.bias grad: -1.2482886404541205e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.5788847324292874e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -7.126322998374235e-08
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.353176685370272e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.7793828394351294e-07
sam_encoder.neck.conv1.trainable_scale grad: 2.781580406008288e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.7076499463873915e-05
sam_encoder.neck.conv2.trainable_scale grad: -4.931443982059136e-07
sam_encoder.neck.conv2.trainable_shift grad: -4.354854900157079e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -8.437156793661416e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -6.496484274975955e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.00480488408356905
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0002918731770478189
mask_decoder.transformer.layers.0.norm3.weight grad: 5.556378164328635e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 8.229998638853431e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 9.617336036171764e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.0916934115812182e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 4.9342917918693274e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -7.326982085942291e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0002010784373851493
mask_decoder.transformer.layers.1.norm2.bias grad: -7.385933713521808e-07
mask_decoder.transformer.layers.1.norm3.weight grad: 5.53302961634472e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.664920900017023e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00022552424343302846
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00013053658767603338
mask_decoder.transformer.norm_final_attn.weight grad: 3.170937270624563e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.535199407953769e-05
Text_Embedding_Affine.0.weight grad: -1.4623600941288117e-11
Text_Embedding_Affine.0.bias grad: -2.2129599541731437e-10
Text_Embedding_Affine.2.weight grad: 4.312745993662048e-11
Text_Embedding_Affine.2.bias grad: -3.503186599118635e-05
Epoch 2 finished with average loss: -68.0391
Epoch 3/39
----------
Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s, loss=-67.3]Epoch 3:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.02it/s, loss=-67.3]Epoch 3:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.02it/s, loss=-66.1]Epoch 3:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.61it/s, loss=-66.1]Epoch 3:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.61it/s, loss=-67.3]Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.25it/s, loss=-67.3]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08624158799648285

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08624158799648285

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08084821701049805

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3802414536476135

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0862894058227539

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08084821701049805

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 58.44343948364258
Max value: 79.42400360107422
Mean value: 67.33775329589844

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08624158799648285

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08624158799648285

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08624158799648285

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3802414536476135

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 58.44343948364258
Max value: 79.42400360107422
Mean value: 67.33775329589844

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -67.33789825439453
Max value: -67.33789825439453
Mean value: -67.33789825439453
sam_encoder.pos_embed grad: 9.694713920538334e-10
sam_encoder.blocks.0.norm1.weight grad: -6.191369720909279e-06
sam_encoder.blocks.0.norm1.bias grad: 1.3312560440681409e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.6971871446003206e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.598890430112078e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -6.712328968205838e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.4423333516997445e-08
sam_encoder.blocks.0.norm2.weight grad: 4.833633283851668e-06
sam_encoder.blocks.0.norm2.bias grad: 5.118930403114064e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.7566230730590178e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -3.6187280727517646e-08
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -4.864469701715279e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -8.867635870046797e-07
sam_encoder.blocks.1.norm1.weight grad: -2.1550415567617165e-06
sam_encoder.blocks.1.norm1.bias grad: -5.584417408499576e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.5846790120122023e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 5.357720738174976e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.023534761974588e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.3183229157220921e-06
sam_encoder.blocks.1.norm2.weight grad: 9.191243179884623e-07
sam_encoder.blocks.1.norm2.bias grad: 4.030477498417895e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.7059531955965213e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 7.942310276121134e-08
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 2.2754002202418633e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.6007796805060934e-07
sam_encoder.blocks.2.norm1.weight grad: 3.746237780433148e-06
sam_encoder.blocks.2.norm1.bias grad: -2.012576715060277e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.2553741675656056e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 9.747144531502272e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.4645111150457524e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.8080883990023722e-07
sam_encoder.blocks.2.norm2.weight grad: 2.48598098551156e-06
sam_encoder.blocks.2.norm2.bias grad: -5.347453679860337e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 2.4044547899393365e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.0858660693411366e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.3330750334716868e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -4.2962113866451546e-07
sam_encoder.blocks.3.norm1.weight grad: -4.35397305409424e-06
sam_encoder.blocks.3.norm1.bias grad: -9.226878319168463e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.4032297031008056e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.108768282800156e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.867952156928368e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.5995223040808924e-07
sam_encoder.blocks.3.norm2.weight grad: 5.811653863929678e-06
sam_encoder.blocks.3.norm2.bias grad: 5.260055331746116e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.386105501907878e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.4358595308294753e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -5.961843498880626e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -7.307706795245394e-08
sam_encoder.blocks.4.norm1.weight grad: -6.04590695729712e-06
sam_encoder.blocks.4.norm1.bias grad: -4.7442148343179724e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -4.078582605870906e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -9.384543773194309e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.1137578894704347e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.666580141725717e-07
sam_encoder.blocks.4.norm2.weight grad: -5.375950422603637e-07
sam_encoder.blocks.4.norm2.bias grad: 1.5068253560457379e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.593129230874183e-07
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 9.501569309122715e-08
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.8835329974062915e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.59562090277177e-07
sam_encoder.blocks.5.norm1.weight grad: -7.683696821914054e-06
sam_encoder.blocks.5.norm1.bias grad: -6.688657094855444e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.893165169050917e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.1420559076213976e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.1293575375457294e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -9.950667845259886e-07
sam_encoder.blocks.5.norm2.weight grad: -1.3186157721278846e-09
sam_encoder.blocks.5.norm2.bias grad: 1.1925307035198784e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.1256543075433001e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.563589867638939e-09
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.2843013319496777e-09
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.345409140820266e-07
sam_encoder.blocks.6.norm1.weight grad: -1.7883857594824804e-07
sam_encoder.blocks.6.norm1.bias grad: 7.169239211179956e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -8.451997359770758e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -4.6263147623903933e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.764162373608997e-08
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.716334736556746e-07
sam_encoder.blocks.6.norm2.weight grad: 1.047210389515385e-06
sam_encoder.blocks.6.norm2.bias grad: 6.938762453501113e-08
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.4715387806063518e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 6.41910219201236e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.078244160155009e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.0349750684545143e-07
sam_encoder.blocks.7.norm1.weight grad: 4.5938585913063434e-07
sam_encoder.blocks.7.norm1.bias grad: 9.339511848338589e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 6.171694622025825e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 6.350659873533004e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 6.367372407112271e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.6296260102753877e-07
sam_encoder.blocks.7.norm2.weight grad: 1.5110808817553334e-06
sam_encoder.blocks.7.norm2.bias grad: -1.1167401225975482e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.2757312478915992e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 4.1576035414436774e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.4095540968337446e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.94418372909422e-07
sam_encoder.blocks.8.norm1.weight grad: 6.495201887446456e-07
sam_encoder.blocks.8.norm1.bias grad: 8.546869025849446e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -4.233470463077538e-09
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.054190974514313e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 8.398893669436802e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 9.505586007207967e-08
sam_encoder.blocks.8.norm2.weight grad: 8.641594604341662e-07
sam_encoder.blocks.8.norm2.bias grad: -3.681665816657187e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 5.187771421333309e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.171887783537386e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 7.83866980214043e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -9.79140963863756e-08
sam_encoder.blocks.9.norm1.weight grad: -1.067855691871955e-06
sam_encoder.blocks.9.norm1.bias grad: 1.4673103976292623e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -6.356275434882264e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.964727260883592e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 8.892197911336552e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.5854966401748243e-07
sam_encoder.blocks.9.norm2.weight grad: 7.878023779994692e-07
sam_encoder.blocks.9.norm2.bias grad: -7.317410108953482e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 8.624168685855693e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.2389486414576822e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.765287601709133e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.3818969313870184e-07
sam_encoder.blocks.10.norm1.weight grad: 7.86042335221282e-07
sam_encoder.blocks.10.norm1.bias grad: -2.781576426968968e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.0947105693048798e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.850525101574021e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 5.25810264662141e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.6069729958398966e-07
sam_encoder.blocks.10.norm2.weight grad: -1.4055708561500069e-06
sam_encoder.blocks.10.norm2.bias grad: -1.3469743862515315e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.208709446449575e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.434251306724036e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -8.027735702853533e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.731470030743367e-07
sam_encoder.blocks.11.norm1.weight grad: -7.3405169587204e-07
sam_encoder.blocks.11.norm1.bias grad: -2.9549255486926995e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.883975523422123e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.0175383847772537e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 7.793788370236143e-08
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.116076806643832e-08
sam_encoder.blocks.11.norm2.weight grad: -2.899800790601148e-07
sam_encoder.blocks.11.norm2.bias grad: -9.796945050766226e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.0745807230705395e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.6671384034671064e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -7.26684902474517e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.3043229785125732e-07
sam_encoder.neck.conv1.trainable_scale grad: -2.36429968936136e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.0339294021832757e-05
sam_encoder.neck.conv2.trainable_scale grad: -7.576727512059733e-08
sam_encoder.neck.conv2.trainable_shift grad: 2.8634200134547427e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00013378399307839572
mask_decoder.transformer.layers.0.norm1.bias grad: -5.043784767622128e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0023658957798033953
mask_decoder.transformer.layers.0.norm2.bias grad: -7.3475384851917624e-06
mask_decoder.transformer.layers.0.norm3.weight grad: 4.372090188553557e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.1673229639418423e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 4.2812287574633956e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -6.009868229739368e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 5.6563942052889615e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.308946022822056e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 1.8095704945153557e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 6.318695523077622e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.1255302019417286e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.614673864329234e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 7.563725830550538e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -4.975328192813322e-05
mask_decoder.transformer.norm_final_attn.weight grad: 9.059151125256903e-06
mask_decoder.transformer.norm_final_attn.bias grad: 5.7671195463626646e-06
Text_Embedding_Affine.0.weight grad: -7.857371871200503e-12
Text_Embedding_Affine.0.bias grad: -1.6511693401444205e-10
Text_Embedding_Affine.2.weight grad: 1.7238095673111076e-10
Text_Embedding_Affine.2.bias grad: -1.255521783605218e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08136419951915741

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08136419951915741

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08610868453979492

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.37434232234954834

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08127689361572266

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08610868453979492

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 29.030187606811523
Max value: 92.05338287353516
Mean value: 64.60457611083984

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08095654845237732

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08095654845237732

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08095654845237732

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.36504292488098145

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.6720532178878784
Max value: 4.999995231628418
Mean value: 1.012028455734253

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 29.030187606811523
Max value: 92.05338287353516
Mean value: 64.60457611083984

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.92931365966797
Max value: -64.92931365966797
Mean value: -64.92931365966797
sam_encoder.pos_embed grad: -1.1244931208409525e-08
sam_encoder.blocks.0.norm1.weight grad: 3.197579280822538e-05
sam_encoder.blocks.0.norm1.bias grad: 3.19335340464022e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.8022077483692556e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.481510901792717e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.278930821830727e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 4.77319872516091e-08
sam_encoder.blocks.0.norm2.weight grad: 4.012527642771602e-05
sam_encoder.blocks.0.norm2.bias grad: -1.3249180028651608e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.1959009498241358e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.6706234166340437e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.882531250885222e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.760908723255852e-06
sam_encoder.blocks.1.norm1.weight grad: -1.7915499483933672e-05
sam_encoder.blocks.1.norm1.bias grad: -6.302721430984093e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.687752385099884e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 3.950408427044749e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 9.650519672277369e-08
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.896037105098003e-07
sam_encoder.blocks.1.norm2.weight grad: 3.592375605876441e-06
sam_encoder.blocks.1.norm2.bias grad: 2.684032097022282e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.1112979336758144e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 9.185814064949227e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.129520104674157e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.056186076515587e-06
sam_encoder.blocks.2.norm1.weight grad: 7.78436333348509e-06
sam_encoder.blocks.2.norm1.bias grad: -8.881705070962198e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.824890766030876e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.0607009244267829e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.7698483791027684e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.6250099861281342e-06
sam_encoder.blocks.2.norm2.weight grad: 5.157740815775469e-06
sam_encoder.blocks.2.norm2.bias grad: -5.60157513973536e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 2.1246730739221675e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -9.462473258281534e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.1753826356653008e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.810068278653489e-07
sam_encoder.blocks.3.norm1.weight grad: -2.2519695619394042e-07
sam_encoder.blocks.3.norm1.bias grad: -3.6835417631664313e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.505831839196617e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -6.915263384144055e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.917561348818708e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.653921680779604e-07
sam_encoder.blocks.3.norm2.weight grad: 6.175887392600998e-06
sam_encoder.blocks.3.norm2.bias grad: -9.037556992552709e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.305392733134795e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.1720294423867017e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.3094099762820406e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.2138441358474665e-07
sam_encoder.blocks.4.norm1.weight grad: 1.6764299289206974e-05
sam_encoder.blocks.4.norm1.bias grad: -5.726209110434866e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 7.866080522944685e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.7518017330075963e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 5.08929315401474e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 4.151589564571623e-06
sam_encoder.blocks.4.norm2.weight grad: -3.811535862041637e-05
sam_encoder.blocks.4.norm2.bias grad: -3.0758834327571094e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.5806275516515598e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -8.785984391579404e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 6.175691851240117e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -4.599655767378863e-08
sam_encoder.blocks.5.norm1.weight grad: 5.681577022187412e-06
sam_encoder.blocks.5.norm1.bias grad: -4.3874038055946585e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.411578267607183e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.3343955274081054e-08
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.671151600632584e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.6909119696938433e-06
sam_encoder.blocks.5.norm2.weight grad: -1.8564842321211472e-05
sam_encoder.blocks.5.norm2.bias grad: -1.4060919056646526e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -7.0394489739555866e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.197413323301589e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -3.647796233963163e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.190673277866154e-07
sam_encoder.blocks.6.norm1.weight grad: 2.95714698950178e-06
sam_encoder.blocks.6.norm1.bias grad: 7.987365279404912e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.887203152113216e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.042100734593987e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.8391554021945922e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.128221687300538e-07
sam_encoder.blocks.6.norm2.weight grad: -1.494189928052947e-05
sam_encoder.blocks.6.norm2.bias grad: -5.209214123169659e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -9.250702532881405e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.294915925129317e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.1050577743153553e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.4693562206957722e-06
sam_encoder.blocks.7.norm1.weight grad: 3.590155301935738e-06
sam_encoder.blocks.7.norm1.bias grad: 2.418582880636677e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.4689171621284913e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 7.830324193491833e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.5266512036760105e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -8.679182315063372e-07
sam_encoder.blocks.7.norm2.weight grad: 4.799119778908789e-06
sam_encoder.blocks.7.norm2.bias grad: 1.9323597371112555e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 4.548416200123029e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 8.406802294302906e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.982757210811542e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.3453846387819794e-07
sam_encoder.blocks.8.norm1.weight grad: 1.4733043371961685e-06
sam_encoder.blocks.8.norm1.bias grad: -1.918294401548337e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.3680686379302642e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -7.044247354315303e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.7001258331438294e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.1628889044222888e-06
sam_encoder.blocks.8.norm2.weight grad: 2.9799457479384728e-06
sam_encoder.blocks.8.norm2.bias grad: -6.509441163871088e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.36185019275581e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.0139905270989402e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.3596286407846492e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.7286465587603743e-07
sam_encoder.blocks.9.norm1.weight grad: 2.533202518861799e-07
sam_encoder.blocks.9.norm1.bias grad: 1.5766739807077101e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -7.341647574321541e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 8.59056854096707e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 6.978848432481755e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.1353252915569101e-07
sam_encoder.blocks.9.norm2.weight grad: 5.876450359210139e-06
sam_encoder.blocks.9.norm2.bias grad: 4.6499644668074325e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.430714398040436e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.147287432308076e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 5.154283257979841e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.090578957198886e-07
sam_encoder.blocks.10.norm1.weight grad: 8.2761725934688e-06
sam_encoder.blocks.10.norm1.bias grad: 1.2601262824318837e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 4.636207449948415e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.983307583941496e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.2950021048018243e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.413162635799381e-06
sam_encoder.blocks.10.norm2.weight grad: 7.927300430310424e-06
sam_encoder.blocks.10.norm2.bias grad: 1.19543119581067e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 5.079819857201073e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.726171831251122e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 5.365200195228681e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.2008905514448998e-07
sam_encoder.blocks.11.norm1.weight grad: 1.300376152357785e-05
sam_encoder.blocks.11.norm1.bias grad: 2.9211605578893796e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.093704097205773e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.3577576396528457e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.2421935480233515e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.758087695539871e-07
sam_encoder.blocks.11.norm2.weight grad: 1.1925915714527946e-05
sam_encoder.blocks.11.norm2.bias grad: 5.907529043724935e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 7.286510935955448e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.29376621771371e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.360754471439577e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.8823229197550972e-07
sam_encoder.neck.conv1.trainable_scale grad: 2.9585953598143533e-07
sam_encoder.neck.conv1.trainable_shift grad: 4.320338121033274e-06
sam_encoder.neck.conv2.trainable_scale grad: -1.8457376427249983e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.4880811249895487e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00011324538354529068
mask_decoder.transformer.layers.0.norm1.bias grad: -5.009351298213005e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00421863840892911
mask_decoder.transformer.layers.0.norm2.bias grad: -3.0324998078867793e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -3.0201670597307384e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.3382807082962245e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 7.249055488500744e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.9400740711716935e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.5689245376270264e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 9.298846634919755e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -9.925604535965249e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 1.5116040231077932e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 1.689451528363861e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.6310455976054072e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -4.532575076154899e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0001522159727755934
mask_decoder.transformer.norm_final_attn.weight grad: 1.2640034583455417e-05
mask_decoder.transformer.norm_final_attn.bias grad: 9.235147444996983e-06
Text_Embedding_Affine.0.weight grad: -7.456996825583317e-12
Text_Embedding_Affine.0.bias grad: -2.196485354710731e-10
Text_Embedding_Affine.2.weight grad: 8.990355335192213e-12
Text_Embedding_Affine.2.bias grad: -3.4905888242064975e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0910688266158104

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0910688266158104

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08556747436523438

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3389984965324402

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09107494354248047

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08556747436523438

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 64.0465087890625
Max value: 82.59117126464844
Mean value: 69.061767578125

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.090489961206913

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.090489961206913

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.090489961206913

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3161514401435852

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.6123117208480835
Max value: 11.80859088897705
Mean value: 1.0388587713241577

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 64.0465087890625
Max value: 82.59117126464844
Mean value: 69.061767578125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -69.5157241821289
Max value: -69.5157241821289
Mean value: -69.5157241821289
sam_encoder.pos_embed grad: 2.1832586849512836e-09
sam_encoder.blocks.0.norm1.weight grad: 4.031878779642284e-05
sam_encoder.blocks.0.norm1.bias grad: 3.205002212780528e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -9.697364475869108e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.5959161575883627e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.382273800729308e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.579060830816161e-06
sam_encoder.blocks.0.norm2.weight grad: 1.081343179976102e-05
sam_encoder.blocks.0.norm2.bias grad: 4.1673218220239505e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -6.586389645235613e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.937981323862914e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.1007556167896837e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.9944874313514447e-06
sam_encoder.blocks.1.norm1.weight grad: -2.8705129807349294e-05
sam_encoder.blocks.1.norm1.bias grad: 9.802424756344408e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.0091963304148521e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -4.0823788367561065e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.798184924467932e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.096691438666312e-06
sam_encoder.blocks.1.norm2.weight grad: 1.7660273442743346e-05
sam_encoder.blocks.1.norm2.bias grad: -1.0620908142300323e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 6.120090802141931e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.1707651285396423e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.4868411401257617e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.338907734156237e-06
sam_encoder.blocks.2.norm1.weight grad: 1.4632521924795583e-05
sam_encoder.blocks.2.norm1.bias grad: -2.454925152051146e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.742592864204198e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.7725734526029555e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.053176780871581e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.585055881354492e-06
sam_encoder.blocks.2.norm2.weight grad: 3.768113629121217e-06
sam_encoder.blocks.2.norm2.bias grad: 1.694197180768242e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 3.712447096404503e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 7.08569530161185e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.535954071296146e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.199789261998376e-06
sam_encoder.blocks.3.norm1.weight grad: 2.1600499167107046e-05
sam_encoder.blocks.3.norm1.bias grad: -1.3713061889575329e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 3.3935807550733443e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.5415261600537633e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.437098484937451e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 4.967131417288329e-07
sam_encoder.blocks.3.norm2.weight grad: 1.7490412574261427e-05
sam_encoder.blocks.3.norm2.bias grad: 1.8619355159898987e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.0442185157444328e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.7638428744248813e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.276177156090853e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -9.792388482310344e-07
sam_encoder.blocks.4.norm1.weight grad: 5.547721229959279e-06
sam_encoder.blocks.4.norm1.bias grad: -7.760821972624399e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.470444087521173e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.1104797269799747e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -9.65767299021536e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.2593935682380106e-06
sam_encoder.blocks.4.norm2.weight grad: -3.3745309337973595e-05
sam_encoder.blocks.4.norm2.bias grad: -2.2547894332092255e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.3081593099050224e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -7.806500434526242e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.451648015266983e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.4593446167054935e-06
sam_encoder.blocks.5.norm1.weight grad: -5.263962520984933e-06
sam_encoder.blocks.5.norm1.bias grad: -2.1702802769141272e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -7.758580068184528e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.0739606700080913e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.283630581383477e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.0720227692218032e-06
sam_encoder.blocks.5.norm2.weight grad: -1.4201110388967209e-05
sam_encoder.blocks.5.norm2.bias grad: -1.1213239304197486e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.466115453600651e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.9310855350340717e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -9.067420023711747e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 4.876689558841463e-07
sam_encoder.blocks.6.norm1.weight grad: -1.0243507858831435e-05
sam_encoder.blocks.6.norm1.bias grad: -4.447884748515207e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -6.966872206248809e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -3.502858362480765e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.017355084011797e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.5775950689421734e-06
sam_encoder.blocks.6.norm2.weight grad: -9.491821401752532e-06
sam_encoder.blocks.6.norm2.bias grad: -3.6550718505168334e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -5.8399164117872715e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.871179049179773e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -4.119301593163982e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 9.298263989876432e-07
sam_encoder.blocks.7.norm1.weight grad: -9.119412425206974e-06
sam_encoder.blocks.7.norm1.bias grad: -9.923905963660218e-08
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -7.760221706121229e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.784043090287014e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.26634153680061e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.4529304027964827e-06
sam_encoder.blocks.7.norm2.weight grad: 3.002410267072264e-06
sam_encoder.blocks.7.norm2.bias grad: -1.152933108983234e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.3469605164573295e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.0360737923729175e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 3.527796366142866e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 8.785026466284762e-07
sam_encoder.blocks.8.norm1.weight grad: -1.1303966118703102e-07
sam_encoder.blocks.8.norm1.bias grad: -1.6514813978574239e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -8.660639423396788e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -5.535130185307935e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -6.742902769474313e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.0409735295979772e-06
sam_encoder.blocks.8.norm2.weight grad: -5.358964699553326e-06
sam_encoder.blocks.8.norm2.bias grad: -1.8165692381444387e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -7.0754208536527585e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.9471310628869105e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.762238071023603e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.906439130536455e-07
sam_encoder.blocks.9.norm1.weight grad: -4.449550942808855e-06
sam_encoder.blocks.9.norm1.bias grad: 1.3117487185354548e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -5.678159141098149e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.7048463380197063e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.4388655245056725e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.9233655166317476e-06
sam_encoder.blocks.9.norm2.weight grad: -8.117521247186232e-06
sam_encoder.blocks.9.norm2.bias grad: -1.93994401342934e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -8.103302207018714e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.613556827986031e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.6309471650165506e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.6145584140758729e-06
sam_encoder.blocks.10.norm1.weight grad: -7.641162369509402e-07
sam_encoder.blocks.10.norm1.bias grad: -2.6866291591431946e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -6.724583272443851e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -5.4982473329801e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.744943318726655e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.752686327767151e-07
sam_encoder.blocks.10.norm2.weight grad: -1.0277122783008963e-05
sam_encoder.blocks.10.norm2.bias grad: -4.304230060370173e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.199189217819367e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.952296199509874e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -9.385673251927074e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.344956429733429e-07
sam_encoder.blocks.11.norm1.weight grad: -6.702689461235423e-06
sam_encoder.blocks.11.norm1.bias grad: 1.5488658391404897e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.8703543673836975e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.9464779888476187e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 9.972712859962485e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.775078371541895e-07
sam_encoder.blocks.11.norm2.weight grad: -7.724030183453579e-06
sam_encoder.blocks.11.norm2.bias grad: -4.6629297685285565e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.1900985959509853e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.8256125713378424e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.0350080259513561e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.161085260217078e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.1292786439298652e-06
sam_encoder.neck.conv1.trainable_shift grad: -2.3284537746803835e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.5142177289817482e-06
sam_encoder.neck.conv2.trainable_shift grad: -3.2210115023190156e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -2.584879803180229e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 2.9035218176431954e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005185631103813648
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00017744512297213078
mask_decoder.transformer.layers.0.norm3.weight grad: 6.888144707772881e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 6.448759813793004e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 2.6880856239586137e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 3.2131720217876136e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 1.4494912647933234e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -4.5643810153706e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00019948833505623043
mask_decoder.transformer.layers.1.norm2.bias grad: -4.3524400098249316e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.185386908124201e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.8906426198082045e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00023869232973083854
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00011922480189241469
mask_decoder.transformer.norm_final_attn.weight grad: 1.6892250641831197e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.3961906006443314e-05
Text_Embedding_Affine.0.weight grad: 7.792897403768873e-12
Text_Embedding_Affine.0.bias grad: 3.8068315166839284e-10
Text_Embedding_Affine.2.weight grad: 3.2842964459156576e-11
Text_Embedding_Affine.2.bias grad: -4.76749437439139e-06
Epoch 3 finished with average loss: -67.2610
Epoch 4/39
----------
Epoch 4:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 4:   0%|          | 0/3 [00:00<?, ?it/s, loss=-75.1]Epoch 4:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.09it/s, loss=-75.1]Epoch 4:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.09it/s, loss=-68.9]Epoch 4:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-68.9]Epoch 4:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-68.7]Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.32it/s, loss=-68.7]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09852415323257446

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09852415323257446

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09526634216308594

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3333193063735962

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09861278533935547

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09526634216308594

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 62.74843978881836
Max value: 93.75611114501953
Mean value: 75.05642700195312

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09852415323257446

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09852415323257446

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09852415323257446

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3333193063735962

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 62.74843978881836
Max value: 93.75611114501953
Mean value: 75.05642700195312

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -75.05661010742188
Max value: -75.05661010742188
Mean value: -75.05661010742188
sam_encoder.pos_embed grad: -1.2953711436836102e-09
sam_encoder.blocks.0.norm1.weight grad: 7.261450264195446e-06
sam_encoder.blocks.0.norm1.bias grad: 1.199417602038011e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.2015589163638651e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.6678561109984003e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.686049924705003e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.0276536244191448e-07
sam_encoder.blocks.0.norm2.weight grad: 3.620617235355894e-06
sam_encoder.blocks.0.norm2.bias grad: 1.3515676073438954e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -4.881456789007643e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.9506055082274543e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -7.62764011597028e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -8.124164878609008e-07
sam_encoder.blocks.1.norm1.weight grad: -3.2867578738660086e-06
sam_encoder.blocks.1.norm1.bias grad: -1.1240231287956703e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.695345190455555e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 6.87240969909908e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.7594832115719328e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.119131297855347e-06
sam_encoder.blocks.1.norm2.weight grad: 5.142026111570885e-06
sam_encoder.blocks.1.norm2.bias grad: 1.2286213291190506e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.7034576507721795e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 6.211786853782542e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.1661475127766607e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.5108911100014666e-07
sam_encoder.blocks.2.norm1.weight grad: 5.145987415744457e-06
sam_encoder.blocks.2.norm1.bias grad: -4.4076068661524914e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.657082515928778e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.3111197176840506e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 5.957913344900589e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.808838021588599e-07
sam_encoder.blocks.2.norm2.weight grad: -9.387701993546216e-07
sam_encoder.blocks.2.norm2.bias grad: -9.080272320716176e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 3.0684972784911224e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.4034712825814495e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -8.868360055203084e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.486561344194342e-07
sam_encoder.blocks.3.norm1.weight grad: -1.4452716641244479e-06
sam_encoder.blocks.3.norm1.bias grad: -2.1198575268499553e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.83909740675881e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.5603936276420427e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.8241118482364982e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 4.900347221337142e-07
sam_encoder.blocks.3.norm2.weight grad: 2.2345816432789434e-06
sam_encoder.blocks.3.norm2.bias grad: 6.247612873266917e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.2320250536722597e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 8.537937787878036e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 9.678025207904284e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.230795021456288e-07
sam_encoder.blocks.4.norm1.weight grad: -2.863790541596245e-06
sam_encoder.blocks.4.norm1.bias grad: 1.7522136204206618e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.9295609945402248e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.969968591060024e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.241776257960737e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.9901170250923315e-07
sam_encoder.blocks.4.norm2.weight grad: -7.036279839667259e-06
sam_encoder.blocks.4.norm2.bias grad: -1.974195356524433e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.7234902922355104e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.3285625755088404e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.5297919137301506e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.050364961789455e-07
sam_encoder.blocks.5.norm1.weight grad: -6.5207714214921e-06
sam_encoder.blocks.5.norm1.bias grad: 2.7046971240451967e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.666057066060603e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.4251345419324934e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -4.075415631632495e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.792709316665423e-07
sam_encoder.blocks.5.norm2.weight grad: -5.916430382058024e-06
sam_encoder.blocks.5.norm2.bias grad: -7.899470801930875e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.8705180739052594e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -9.073698379324924e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -9.074076388060348e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.661295740035712e-07
sam_encoder.blocks.6.norm1.weight grad: 3.053946784348227e-07
sam_encoder.blocks.6.norm1.bias grad: 1.5878366639299202e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -5.506018965206749e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.160105042203213e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 4.132146784741053e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.2361551777503337e-07
sam_encoder.blocks.6.norm2.weight grad: -9.912113227983355e-07
sam_encoder.blocks.6.norm2.bias grad: 8.985704198494204e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 3.788986759900581e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.601036269174074e-08
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.6640733235817606e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -7.621283515391042e-08
sam_encoder.blocks.7.norm1.weight grad: -7.863643531891285e-07
sam_encoder.blocks.7.norm1.bias grad: 9.024390692502493e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.146228664263617e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.5628117466803815e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 4.837895062337338e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.2166518672529492e-06
sam_encoder.blocks.7.norm2.weight grad: 2.0981899524485925e-06
sam_encoder.blocks.7.norm2.bias grad: 1.0771249208119116e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.03279660379485e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 4.784676548297284e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.125107331745312e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.2940732808128814e-07
sam_encoder.blocks.8.norm1.weight grad: -8.842566785460804e-07
sam_encoder.blocks.8.norm1.bias grad: 9.302308967562567e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.834920567489462e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -9.293932521359238e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.0722378647187725e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 3.5970623457615147e-07
sam_encoder.blocks.8.norm2.weight grad: 1.1760874940591748e-06
sam_encoder.blocks.8.norm2.bias grad: -2.7167570237907057e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 9.69858888311137e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.936621280648978e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 3.1204461947709206e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.0604761270278686e-08
sam_encoder.blocks.9.norm1.weight grad: -1.378906745230779e-06
sam_encoder.blocks.9.norm1.bias grad: 3.1443573789147194e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -8.632069921077345e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.139353796337673e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 5.773370048700599e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.858166893332964e-07
sam_encoder.blocks.9.norm2.weight grad: 1.7426020804123254e-06
sam_encoder.blocks.9.norm2.bias grad: -6.852936849099933e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.932887244038284e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 5.825604034725984e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.6279955161735415e-09
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.869261888667097e-07
sam_encoder.blocks.10.norm1.weight grad: 1.8192838524555555e-06
sam_encoder.blocks.10.norm1.bias grad: 4.8798369789437857e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.8540170003689127e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 8.398191653213871e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 8.264946700364817e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.130956080596661e-07
sam_encoder.blocks.10.norm2.weight grad: 2.7093196308669576e-07
sam_encoder.blocks.10.norm2.bias grad: -1.573062718307483e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.4036438642506255e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -9.525278699129558e-08
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -7.355906745942775e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.9601286516699474e-07
sam_encoder.blocks.11.norm1.weight grad: 2.536539795983117e-06
sam_encoder.blocks.11.norm1.bias grad: 1.756395704433089e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.8372264182507934e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.1297054192691576e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 5.351394065655768e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.625965495577475e-07
sam_encoder.blocks.11.norm2.weight grad: 2.7645380669127917e-06
sam_encoder.blocks.11.norm2.bias grad: -5.490531975738122e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.2502790670841932e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.6932602875385783e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.027903284826607e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.4723957519890973e-07
sam_encoder.neck.conv1.trainable_scale grad: -2.482393028913066e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.1603561688389163e-05
sam_encoder.neck.conv2.trainable_scale grad: -4.5090928324498236e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.8144572095479816e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00016370590310543776
mask_decoder.transformer.layers.0.norm1.bias grad: -1.3827266229782254e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00266430270858109
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00017344747902825475
mask_decoder.transformer.layers.0.norm3.weight grad: 4.431928391568363e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.116201721946709e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.247973240329884e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 9.22693288885057e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 5.346846592146903e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.5580635590595193e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 2.2920226911082864e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 6.758476956747472e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.9963935958221555e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.099081317894161e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.4347260730573907e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00010104594548465684
mask_decoder.transformer.norm_final_attn.weight grad: 9.19546073419042e-06
mask_decoder.transformer.norm_final_attn.bias grad: 7.039069714664947e-06
Text_Embedding_Affine.0.weight grad: 4.467075580966151e-12
Text_Embedding_Affine.0.bias grad: 1.2988378428335778e-10
Text_Embedding_Affine.2.weight grad: 6.309222588818386e-11
Text_Embedding_Affine.2.bias grad: -4.070749128004536e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06564168632030487

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06564168632030487

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06572341918945312

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.30736976861953735

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06558513641357422

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06572341918945312

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 42.76279830932617
Max value: 69.84174346923828
Mean value: 62.447364807128906

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06509687006473541

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06509687006473541

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06509687006473541

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2985239326953888

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.6662272810935974
Max value: 4.999995231628418
Mean value: 1.0116572380065918

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 42.76279830932617
Max value: 69.84174346923828
Mean value: 62.447364807128906

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.73002243041992
Max value: -62.73002243041992
Mean value: -62.73002243041992
sam_encoder.pos_embed grad: -6.889111503483036e-09
sam_encoder.blocks.0.norm1.weight grad: -1.9919772967114113e-05
sam_encoder.blocks.0.norm1.bias grad: 1.7158281480078585e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.199179784336593e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.1044733128073858e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.2547154710773611e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.9608106615341967e-06
sam_encoder.blocks.0.norm2.weight grad: 1.0771742381621152e-05
sam_encoder.blocks.0.norm2.bias grad: 1.1978025213466026e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.8118271327693947e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -3.16079126605473e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.4935329090803862e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.957371179945767e-06
sam_encoder.blocks.1.norm1.weight grad: -1.8818279841070762e-06
sam_encoder.blocks.1.norm1.bias grad: 3.2367810831601673e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.2277890820987523e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.1508753889065702e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.067695703544814e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.1494857687921467e-07
sam_encoder.blocks.1.norm2.weight grad: 7.031394034129335e-06
sam_encoder.blocks.1.norm2.bias grad: -3.3329204143228708e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.9999443995620823e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 6.264053808990866e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 6.781289698665205e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -6.478402383436332e-07
sam_encoder.blocks.2.norm1.weight grad: 3.2486466352565913e-06
sam_encoder.blocks.2.norm1.bias grad: -1.0982271305692848e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.984569391628611e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.1497477316879667e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.1186070878466126e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -7.20148761956807e-07
sam_encoder.blocks.2.norm2.weight grad: 7.485317610189668e-07
sam_encoder.blocks.2.norm2.bias grad: -3.6573946999851614e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.468509592290502e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.593945285094378e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.779158083081711e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -8.014246759557864e-07
sam_encoder.blocks.3.norm1.weight grad: 2.3728227915853495e-07
sam_encoder.blocks.3.norm1.bias grad: -7.651823580090422e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.0314793144061696e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 7.376327175734332e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -7.036597935439204e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.6285366655210964e-07
sam_encoder.blocks.3.norm2.weight grad: 7.709957571933046e-06
sam_encoder.blocks.3.norm2.bias grad: 1.6835668930070824e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.412099315231899e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 7.095445653249044e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 9.80551931206719e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.927083073700487e-07
sam_encoder.blocks.4.norm1.weight grad: 5.540423444472253e-06
sam_encoder.blocks.4.norm1.bias grad: -6.434540409827605e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 3.56451960215054e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.263581452803919e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.4849472285714e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 4.042227374156937e-06
sam_encoder.blocks.4.norm2.weight grad: -2.6390389393782243e-05
sam_encoder.blocks.4.norm2.bias grad: -1.4252917026169598e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.7283569832216017e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.522233888972551e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 8.46466832626902e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -4.5447768570738845e-07
sam_encoder.blocks.5.norm1.weight grad: 2.624866965561523e-06
sam_encoder.blocks.5.norm1.bias grad: -5.3933795243210625e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.2157405510370154e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.0596870652079815e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.6815930596058024e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.3915014278609306e-06
sam_encoder.blocks.5.norm2.weight grad: -9.471705197938718e-06
sam_encoder.blocks.5.norm2.bias grad: -6.162462341308128e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.368820100353332e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.5914469031486078e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.903836389123171e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.2949728279163537e-07
sam_encoder.blocks.6.norm1.weight grad: 4.108999746677e-06
sam_encoder.blocks.6.norm1.bias grad: 4.133312813792145e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.8999227197346045e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 9.600355497241253e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.8175600189351826e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 7.22505546946195e-07
sam_encoder.blocks.6.norm2.weight grad: -7.745066795905586e-06
sam_encoder.blocks.6.norm2.bias grad: -3.3032144983735634e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -5.801791758131003e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.522549038985744e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -4.534051001314765e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.4495300244307145e-07
sam_encoder.blocks.7.norm1.weight grad: 2.9011553124291822e-06
sam_encoder.blocks.7.norm1.bias grad: 2.4382786705245962e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.7266409031435614e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.2491349252741202e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.0483093976508826e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 6.763486339878e-07
sam_encoder.blocks.7.norm2.weight grad: 1.5102717725312687e-06
sam_encoder.blocks.7.norm2.bias grad: 2.7156724513588415e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 5.975763883725449e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.3083233163513341e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.46414026353159e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.7184422530554e-07
sam_encoder.blocks.8.norm1.weight grad: 5.991905254632002e-06
sam_encoder.blocks.8.norm1.bias grad: -1.1322557469384265e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.50491006631637e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.64893879173178e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.3771837024687557e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.4278060664073564e-06
sam_encoder.blocks.8.norm2.weight grad: 2.0850748114753515e-06
sam_encoder.blocks.8.norm2.bias grad: -2.749939085333608e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.099011569749564e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 7.273674782481976e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 8.14894860923232e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 9.785104992943161e-08
sam_encoder.blocks.9.norm1.weight grad: 1.3831313481205143e-06
sam_encoder.blocks.9.norm1.bias grad: 5.571943120230571e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 6.422627620850108e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 6.265438514674315e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 7.205619567685062e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.1355454887507221e-07
sam_encoder.blocks.9.norm2.weight grad: 3.4139820854761638e-06
sam_encoder.blocks.9.norm2.bias grad: 1.3917039609623316e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.1027067305112723e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 8.427757620665943e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.3792215131379635e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.046520475891157e-07
sam_encoder.blocks.10.norm1.weight grad: 4.7589774112566374e-06
sam_encoder.blocks.10.norm1.bias grad: -1.7411154829005682e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.038920795006561e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.1030335826944793e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.312031827183091e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 7.965140866872389e-07
sam_encoder.blocks.10.norm2.weight grad: 5.360245268093422e-06
sam_encoder.blocks.10.norm2.bias grad: 6.324831929305219e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.125285729765892e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 8.190904168259294e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.5856629665431683e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.251147973060142e-07
sam_encoder.blocks.11.norm1.weight grad: 1.6024767319322564e-05
sam_encoder.blocks.11.norm1.bias grad: -5.164102958588046e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.1092054137407104e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.335977562026528e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.4947039517210214e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.67807376228302e-07
sam_encoder.blocks.11.norm2.weight grad: 1.0598118933557998e-05
sam_encoder.blocks.11.norm2.bias grad: 6.354915740303113e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 5.606352715403773e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.4805750652158167e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 6.388338533724891e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.557106538210064e-07
sam_encoder.neck.conv1.trainable_scale grad: 6.13911197433481e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.0575216694851406e-06
sam_encoder.neck.conv2.trainable_scale grad: 4.3641693991958164e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.1702401025104336e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -4.1860039345920086e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 7.448434189427644e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004989247303456068
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0002339846978429705
mask_decoder.transformer.layers.0.norm3.weight grad: -7.566592103103176e-06
mask_decoder.transformer.layers.0.norm3.bias grad: 2.9490583983715624e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 4.685066596721299e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.4218585420167074e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 4.5478773245122284e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -8.987617547973059e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 3.056645073229447e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 7.2615293902345e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.8421825845725834e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.012349381810054e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.528284676373005e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -8.985923341242597e-05
mask_decoder.transformer.norm_final_attn.weight grad: 9.317134754383005e-06
mask_decoder.transformer.norm_final_attn.bias grad: 8.509611689078156e-06
Text_Embedding_Affine.0.weight grad: -6.487328035875706e-12
Text_Embedding_Affine.0.bias grad: -1.8170075166690225e-10
Text_Embedding_Affine.2.weight grad: 4.002445944117916e-11
Text_Embedding_Affine.2.bias grad: -1.3872937415726483e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09815804660320282

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09815804660320282

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09744930267333984

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.4224590063095093

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09830951690673828

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09744930267333984

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 60.23073196411133
Max value: 79.07083129882812
Mean value: 67.93037414550781

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09748150408267975

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09748150408267975

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09748150408267975

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.40066879987716675

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.6346039772033691
Max value: 7.999996185302734
Mean value: 1.034557580947876

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 60.23073196411133
Max value: 79.07083129882812
Mean value: 67.93037414550781

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.40691375732422
Max value: -68.40691375732422
Mean value: -68.40691375732422
sam_encoder.pos_embed grad: -2.371215224172829e-08
sam_encoder.blocks.0.norm1.weight grad: 2.3684209736529738e-05
sam_encoder.blocks.0.norm1.bias grad: 6.785217556171119e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 6.253571882552933e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.7401579270881484e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.1213747711735778e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.7656702766544186e-07
sam_encoder.blocks.0.norm2.weight grad: 0.00011857948265969753
sam_encoder.blocks.0.norm2.bias grad: 1.1432446171966149e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -7.10587255525752e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.26562606258085e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.966778892092407e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.841923949541524e-05
sam_encoder.blocks.1.norm1.weight grad: -6.502682663267478e-05
sam_encoder.blocks.1.norm1.bias grad: -2.902006144722691e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.9740416721324436e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -9.380150913784746e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.2402786271413788e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.4933120837667957e-05
sam_encoder.blocks.1.norm2.weight grad: 2.3186069029179635e-06
sam_encoder.blocks.1.norm2.bias grad: 7.741720764897764e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.457023806025973e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.3600882741448004e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.7749618059024215e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.3196406143833883e-05
sam_encoder.blocks.2.norm1.weight grad: 3.673381434055045e-05
sam_encoder.blocks.2.norm1.bias grad: -1.65728124557063e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 8.581325346312951e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.8979684455189272e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.0420939361210912e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -7.825810826034285e-06
sam_encoder.blocks.2.norm2.weight grad: -3.391653763173963e-06
sam_encoder.blocks.2.norm2.bias grad: -3.099387322436087e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -9.305629646405578e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -9.639370546210557e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.8574868590803817e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.084091976139462e-06
sam_encoder.blocks.3.norm1.weight grad: 2.3826443793950602e-05
sam_encoder.blocks.3.norm1.bias grad: -2.2355892724590376e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.40062720674905e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.996907253167592e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.3575480807048734e-05
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.525312760961242e-06
sam_encoder.blocks.3.norm2.weight grad: -1.0217877388640773e-05
sam_encoder.blocks.3.norm2.bias grad: -6.74729235470295e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -2.529714947741013e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.642520368885016e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.003275302646216e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.316742554990924e-06
sam_encoder.blocks.4.norm1.weight grad: 6.850925274193287e-05
sam_encoder.blocks.4.norm1.bias grad: -1.3560609659180045e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 3.3101758162956685e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.0101748557644896e-05
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.395280833094148e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 9.099117960431613e-06
sam_encoder.blocks.4.norm2.weight grad: -0.0001461962383473292
sam_encoder.blocks.4.norm2.bias grad: -0.00011081247066613287
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -0.00010058940824819729
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.619028575485572e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.5964882322805352e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.944777523021912e-06
sam_encoder.blocks.5.norm1.weight grad: 5.2619703637901694e-05
sam_encoder.blocks.5.norm1.bias grad: -2.5932531571015716e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 7.135642135835951e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.651657607406378e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.3071813555143308e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 8.719948709767777e-06
sam_encoder.blocks.5.norm2.weight grad: -7.484821253456175e-05
sam_encoder.blocks.5.norm2.bias grad: -5.374993634177372e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.6660985895432532e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.536756129411515e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -8.701469482730317e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.034172948446212e-07
sam_encoder.blocks.6.norm1.weight grad: 2.2819105652160943e-05
sam_encoder.blocks.6.norm1.bias grad: 2.17024062294513e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.018213076051325e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -3.4851279906433774e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.695022991858423e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.155964239136665e-06
sam_encoder.blocks.6.norm2.weight grad: -5.4637930588796735e-05
sam_encoder.blocks.6.norm2.bias grad: -2.7273094019619748e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.855800241581164e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.7988566469284706e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -9.065740414371248e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.2994986365083605e-06
sam_encoder.blocks.7.norm1.weight grad: 9.064446203410625e-06
sam_encoder.blocks.7.norm1.bias grad: 7.274183644767618e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.7059126093954546e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 5.587637019743852e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.9278412512212526e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.6593887671187986e-06
sam_encoder.blocks.7.norm2.weight grad: 1.4855343579256441e-05
sam_encoder.blocks.7.norm2.bias grad: 4.565538802125957e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.4197952623362653e-05
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 9.197344184030953e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.663795152737293e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.3015676358918427e-06
sam_encoder.blocks.8.norm1.weight grad: 1.4667791219835635e-05
sam_encoder.blocks.8.norm1.bias grad: -1.0767740604933351e-05
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.1692908376280684e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -5.126292990098591e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 5.200065061217174e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 5.2378927648533136e-06
sam_encoder.blocks.8.norm2.weight grad: 2.3760037493048003e-06
sam_encoder.blocks.8.norm2.bias grad: -2.3922257241792977e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -9.822019819694106e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.9141605750737654e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.4257578843389638e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.189353608628153e-06
sam_encoder.blocks.9.norm1.weight grad: -2.3720622266409919e-07
sam_encoder.blocks.9.norm1.bias grad: 4.353103577159345e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.8626632229133975e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.0612303330835857e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.0664471119525842e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.2471658692447818e-06
sam_encoder.blocks.9.norm2.weight grad: 5.6689932534936816e-06
sam_encoder.blocks.9.norm2.bias grad: 2.0755214791279286e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.1958426259516273e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.006769136642106e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.7610895497455203e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -9.245130740964669e-07
sam_encoder.blocks.10.norm1.weight grad: 2.1883233785047196e-05
sam_encoder.blocks.10.norm1.bias grad: 5.3672847570851445e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.1447019460320007e-05
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 4.85717009723885e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.582147307199193e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.622079702836345e-06
sam_encoder.blocks.10.norm2.weight grad: 1.243701990460977e-05
sam_encoder.blocks.10.norm2.bias grad: 9.281772008762346e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 8.775894457357936e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.7694800362733076e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.0441719950904371e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.819057827873621e-07
sam_encoder.blocks.11.norm1.weight grad: 4.477462425711565e-05
sam_encoder.blocks.11.norm1.bias grad: 3.039169087060145e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.075680408277549e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.3689096906309715e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 6.719034900015686e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.441752030790667e-06
sam_encoder.blocks.11.norm2.weight grad: 2.303193286934402e-05
sam_encoder.blocks.11.norm2.bias grad: 3.9894410974739003e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.3740724170929752e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.417730229353765e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.8087055195792345e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.2639612495822803e-07
sam_encoder.neck.conv1.trainable_scale grad: 8.247516234405339e-07
sam_encoder.neck.conv1.trainable_shift grad: -7.016187737463042e-06
sam_encoder.neck.conv2.trainable_scale grad: -9.202267392538488e-07
sam_encoder.neck.conv2.trainable_shift grad: -6.621048669330776e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -3.285069396952167e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -9.844370651990175e-08
mask_decoder.transformer.layers.0.norm2.weight grad: 0.002608384471386671
mask_decoder.transformer.layers.0.norm2.bias grad: -9.373336797580123e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 0.0002573892707005143
mask_decoder.transformer.layers.0.norm3.bias grad: 4.298564454074949e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00013410836982075125
mask_decoder.transformer.layers.0.norm4.bias grad: -5.436391802504659e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -6.1270779951883014e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 1.61560092237778e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -6.231461884453893e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -5.0409897085046396e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.1927537343581207e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -4.546514537651092e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.0002123831945937127
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00013968063285574317
mask_decoder.transformer.norm_final_attn.weight grad: 3.25237269862555e-05
mask_decoder.transformer.norm_final_attn.bias grad: 2.4544959160266444e-05
Text_Embedding_Affine.0.weight grad: 2.08789548150623e-11
Text_Embedding_Affine.0.bias grad: 9.903686759571428e-10
Text_Embedding_Affine.2.weight grad: 3.1778264047988e-11
Text_Embedding_Affine.2.bias grad: 2.3708389562671073e-06
Epoch 4 finished with average loss: -68.7312
Epoch 5/39
----------
Epoch 5:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 5:   0%|          | 0/3 [00:00<?, ?it/s, loss=-66]Epoch 5:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.07it/s, loss=-66]Epoch 5:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.07it/s, loss=-65.6]Epoch 5:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-65.6]Epoch 5:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-66.3]Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.29it/s, loss=-66.3]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09021461009979248

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09021461009979248

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09315967559814453

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.33668601512908936

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09018993377685547

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09315967559814453

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 37.75712966918945
Max value: 89.90220642089844
Mean value: 65.9754638671875

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09021461009979248

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09021461009979248

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09021461009979248

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.33668601512908936

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 37.75712966918945
Max value: 89.90220642089844
Mean value: 65.9754638671875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.97569274902344
Max value: -65.97569274902344
Mean value: -65.97569274902344
sam_encoder.pos_embed grad: -3.1740305939109703e-09
sam_encoder.blocks.0.norm1.weight grad: -4.834555511479266e-07
sam_encoder.blocks.0.norm1.bias grad: 2.325868990737945e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.6409763854171615e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.7663656965160044e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.2462500080800964e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.0448496229619195e-07
sam_encoder.blocks.0.norm2.weight grad: 7.106116299837595e-06
sam_encoder.blocks.0.norm2.bias grad: 2.0601652067853138e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -2.5873214326566085e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.8776830756905838e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.0329438737244345e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.884273271774873e-06
sam_encoder.blocks.1.norm1.weight grad: -7.493726116081234e-06
sam_encoder.blocks.1.norm1.bias grad: -1.7691791072138585e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.3707877971901326e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.143197550845798e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.500484242773382e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.452686547054327e-06
sam_encoder.blocks.1.norm2.weight grad: 1.0244318218610715e-05
sam_encoder.blocks.1.norm2.bias grad: -1.510869878984522e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 6.036572358425474e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.3199085060477955e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 4.568567419482861e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.6780833195516607e-07
sam_encoder.blocks.2.norm1.weight grad: 4.651352355722338e-06
sam_encoder.blocks.2.norm1.bias grad: -4.2139895413129125e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.0538006942369975e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.6733151824155357e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 6.923231694599963e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 6.844656752491574e-08
sam_encoder.blocks.2.norm2.weight grad: 3.0715486332155706e-07
sam_encoder.blocks.2.norm2.bias grad: -3.5563039091357496e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.4745364751433954e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.551694595036679e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.245742052764399e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 2.6436018174536e-07
sam_encoder.blocks.3.norm1.weight grad: -2.051154751825379e-06
sam_encoder.blocks.3.norm1.bias grad: -4.239999270794215e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -6.532188479013712e-08
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 7.713339300607913e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 7.436428859364241e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 9.239550990969292e-07
sam_encoder.blocks.3.norm2.weight grad: 7.352087777690031e-06
sam_encoder.blocks.3.norm2.bias grad: 1.5234926422635908e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.8457362683839165e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.0697393665614072e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.9250712739449227e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 7.284002094820607e-07
sam_encoder.blocks.4.norm1.weight grad: -1.437757759958913e-06
sam_encoder.blocks.4.norm1.bias grad: 4.412380292251328e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.651491174925468e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.4236843526305165e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.243603037437424e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.8753726180875674e-06
sam_encoder.blocks.4.norm2.weight grad: -5.468393283081241e-06
sam_encoder.blocks.4.norm2.bias grad: -5.634824447042774e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.62619903171435e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.224203288074932e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 6.375857424245623e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.559452003784827e-08
sam_encoder.blocks.5.norm1.weight grad: -4.36278605775442e-06
sam_encoder.blocks.5.norm1.bias grad: -1.2371124284982216e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.321086180425482e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.614805796634755e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 7.658506433472212e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.0774075437657302e-07
sam_encoder.blocks.5.norm2.weight grad: -2.654186346262577e-06
sam_encoder.blocks.5.norm2.bias grad: -3.186539288435597e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.420202006054751e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 3.7081690607010387e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.0167586879106238e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.753208137728507e-07
sam_encoder.blocks.6.norm1.weight grad: 1.4419815670407843e-06
sam_encoder.blocks.6.norm1.bias grad: 2.8027552616549656e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 9.135510481428355e-08
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -6.688696316814458e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 7.189429993559315e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.9257524286331318e-07
sam_encoder.blocks.6.norm2.weight grad: -1.7438119357393589e-06
sam_encoder.blocks.6.norm2.bias grad: -8.827660167298745e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.901357080669186e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.762263591193914e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.2250709460204234e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.3284461526127416e-07
sam_encoder.blocks.7.norm1.weight grad: -3.304452889096865e-07
sam_encoder.blocks.7.norm1.bias grad: 1.0488954558240948e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.943667590850964e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 6.39335382857098e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 9.676730314822635e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.443753205876419e-07
sam_encoder.blocks.7.norm2.weight grad: 3.4737181522359606e-06
sam_encoder.blocks.7.norm2.bias grad: -1.1407004052443881e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.8043357360729715e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 9.769179314389476e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.528395839362929e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.3855342823917454e-07
sam_encoder.blocks.8.norm1.weight grad: -1.3898155657443567e-06
sam_encoder.blocks.8.norm1.bias grad: -1.3326932446489081e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.1790269784105476e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -9.110216296903673e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.5191083093668567e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.347960051134578e-06
sam_encoder.blocks.8.norm2.weight grad: 2.819736891979119e-06
sam_encoder.blocks.8.norm2.bias grad: 2.520209818612784e-09
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.495912440281245e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.4349100183608243e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 4.426318298555998e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.664703278147499e-08
sam_encoder.blocks.9.norm1.weight grad: -2.3673803752899403e-06
sam_encoder.blocks.9.norm1.bias grad: 4.396693782382499e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.800403310880938e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.5226478922159004e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.8131839141233286e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -9.165308938463568e-07
sam_encoder.blocks.9.norm2.weight grad: 3.336644795126631e-06
sam_encoder.blocks.9.norm2.bias grad: -5.041806616645772e-08
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.9662774068128783e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.2574892025440931e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -9.117927390889236e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.5329489378455037e-07
sam_encoder.blocks.10.norm1.weight grad: 1.7309789654973429e-06
sam_encoder.blocks.10.norm1.bias grad: 2.685156346160511e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.7385561932314886e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 8.12654093351739e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 8.267691100627417e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.866240826435387e-07
sam_encoder.blocks.10.norm2.weight grad: 3.119995199085679e-06
sam_encoder.blocks.10.norm2.bias grad: -5.444929342957039e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.9567090678028762e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 7.255995342347887e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.7830690757800767e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.0853778437412984e-07
sam_encoder.blocks.11.norm1.weight grad: 8.879319466359448e-06
sam_encoder.blocks.11.norm1.bias grad: -2.2762174012314063e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.073489611120749e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.752596799382445e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 8.201042192013119e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.397513523850648e-07
sam_encoder.blocks.11.norm2.weight grad: 5.395267180574592e-06
sam_encoder.blocks.11.norm2.bias grad: 1.2290615813981276e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.5818200103676645e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 6.988002496655099e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.686589368749992e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 5.2568907449312974e-08
sam_encoder.neck.conv1.trainable_scale grad: -3.0630417313659564e-07
sam_encoder.neck.conv1.trainable_shift grad: -4.457499471755e-06
sam_encoder.neck.conv2.trainable_scale grad: -5.470874384627678e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.867563696578145e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00012798630632460117
mask_decoder.transformer.layers.0.norm1.bias grad: -8.497117960359901e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0034698559902608395
mask_decoder.transformer.layers.0.norm2.bias grad: 7.08404986653477e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -1.0493160516489297e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.079496334772557e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.202453030506149e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 2.496926754247397e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 4.6090426621958613e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.564033926930279e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 5.670573955285363e-06
mask_decoder.transformer.layers.1.norm2.bias grad: 4.7497811465291306e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.898833918152377e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.1140283428831026e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -7.600501703564078e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00010465968807693571
mask_decoder.transformer.norm_final_attn.weight grad: 8.496708687744103e-06
mask_decoder.transformer.norm_final_attn.bias grad: 6.808817943237955e-06
Text_Embedding_Affine.0.weight grad: -2.6408575846958993e-12
Text_Embedding_Affine.0.bias grad: -5.150807211307118e-11
Text_Embedding_Affine.2.weight grad: 5.246502537969988e-11
Text_Embedding_Affine.2.bias grad: -4.629471732187085e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07749801874160767

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07749801874160767

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0821847915649414

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.34109362959861755

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07748746871948242

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0821847915649414

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 47.82929229736328
Max value: 77.89336395263672
Mean value: 64.88024139404297

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07734241336584091

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07734241336584091

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07734241336584091

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3312406539916992

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.704276978969574
Max value: 5.265829086303711
Mean value: 1.0132979154586792

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 47.82929229736328
Max value: 77.89336395263672
Mean value: 64.88024139404297

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.19187927246094
Max value: -65.19187927246094
Mean value: -65.19187927246094
sam_encoder.pos_embed grad: 6.0197336004819135e-09
sam_encoder.blocks.0.norm1.weight grad: 1.308527089349809e-06
sam_encoder.blocks.0.norm1.bias grad: 5.285680799715919e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.0926153208856704e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -8.526398431740745e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.109777597070206e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.693721060291864e-06
sam_encoder.blocks.0.norm2.weight grad: -2.7519388368091313e-06
sam_encoder.blocks.0.norm2.bias grad: -2.2673120838589966e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 5.4625243137707e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.311282282287721e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.952626335987588e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.0282080893375678e-06
sam_encoder.blocks.1.norm1.weight grad: -1.2262508789717685e-05
sam_encoder.blocks.1.norm1.bias grad: -4.409183020470664e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -5.252462869975716e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.2631057870748919e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.755550667643547e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.9021065327251563e-06
sam_encoder.blocks.1.norm2.weight grad: -2.8508156901807524e-06
sam_encoder.blocks.1.norm2.bias grad: -1.259291025235143e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.5293087421450764e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.2127098898417898e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.1306713026424404e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.326453896894236e-07
sam_encoder.blocks.2.norm1.weight grad: 2.1374055449996376e-06
sam_encoder.blocks.2.norm1.bias grad: 2.924507498391904e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.014051171452593e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 4.964517756889109e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.7058523477971903e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -7.815888238837942e-07
sam_encoder.blocks.2.norm2.weight grad: 1.0409572496428154e-05
sam_encoder.blocks.2.norm2.bias grad: -6.429870609281352e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 7.275451025634538e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.4341711650777142e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.087598194426391e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.0462063073646277e-06
sam_encoder.blocks.3.norm1.weight grad: -1.057538884197129e-05
sam_encoder.blocks.3.norm1.bias grad: -1.0531157386139967e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -6.194493380462518e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.3647544367122464e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.0648520805698354e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.5017297982922173e-06
sam_encoder.blocks.3.norm2.weight grad: 9.249746653949842e-06
sam_encoder.blocks.3.norm2.bias grad: 8.66793641307595e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.419860826805234e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.224188847321784e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.931329501938308e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.2399107163219014e-06
sam_encoder.blocks.4.norm1.weight grad: -1.1286812878097408e-05
sam_encoder.blocks.4.norm1.bias grad: -3.886792001139838e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -6.679549187538214e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -9.545917691866634e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.088204266532557e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.2481604017011705e-06
sam_encoder.blocks.4.norm2.weight grad: 1.5748495343359536e-06
sam_encoder.blocks.4.norm2.bias grad: 3.0224464353523217e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.905583696450776e-07
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 6.954063564990065e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.580890966579318e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -8.735539154258731e-07
sam_encoder.blocks.5.norm1.weight grad: -1.3552315067499876e-05
sam_encoder.blocks.5.norm1.bias grad: -4.8363799578510225e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -9.03649015526753e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.6162119866057765e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.0791205795612768e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.5551879641861888e-06
sam_encoder.blocks.5.norm2.weight grad: 3.821433836037613e-07
sam_encoder.blocks.5.norm2.bias grad: 2.998551963173668e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.1077426051997463e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.4879668103494623e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -5.458161922433646e-09
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.977641137633327e-08
sam_encoder.blocks.6.norm1.weight grad: -5.546573447645642e-06
sam_encoder.blocks.6.norm1.bias grad: -1.237369133377797e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -3.7533152408286696e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.5941359379212372e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -6.108463139753439e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.4115162722846435e-07
sam_encoder.blocks.6.norm2.weight grad: 2.357360926907859e-06
sam_encoder.blocks.6.norm2.bias grad: 1.2961177162651438e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.0637298803194426e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.834253507444373e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 6.232583018572768e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.949494100652373e-07
sam_encoder.blocks.7.norm1.weight grad: -5.012205747334519e-06
sam_encoder.blocks.7.norm1.bias grad: 1.0426294920762302e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.841273610305507e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.4459081967288512e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -7.267598789439944e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -9.836620620262693e-07
sam_encoder.blocks.7.norm2.weight grad: 2.099099674524041e-06
sam_encoder.blocks.7.norm2.bias grad: -3.397667569515761e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 5.348558147488802e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.3361269541055663e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.3686641270614928e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.9037730680793175e-07
sam_encoder.blocks.8.norm1.weight grad: 5.390404567151563e-07
sam_encoder.blocks.8.norm1.bias grad: 1.7677128880677628e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 9.943763501496505e-08
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -3.309906730919465e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.733995927428623e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.115345185098704e-07
sam_encoder.blocks.8.norm2.weight grad: -1.719498868624214e-06
sam_encoder.blocks.8.norm2.bias grad: -3.820072720372991e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.2747760795027716e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.0662747627065983e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -6.133867600510712e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.854842193755758e-07
sam_encoder.blocks.9.norm1.weight grad: -3.3517717383801937e-06
sam_encoder.blocks.9.norm1.bias grad: -1.5662783425796079e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.5467506929999217e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -7.906316454864282e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.008035148217459e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.7539668912577326e-07
sam_encoder.blocks.9.norm2.weight grad: -3.638775524450466e-06
sam_encoder.blocks.9.norm2.bias grad: -1.5207455135168857e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.8120516617491376e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.504151668996201e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.1031141866624239e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -8.393659527428099e-07
sam_encoder.blocks.10.norm1.weight grad: -1.9928597794205416e-06
sam_encoder.blocks.10.norm1.bias grad: -1.086709062292357e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.8584663052934047e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.3897931694373256e-09
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.346896697095872e-08
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.0653286014749028e-07
sam_encoder.blocks.10.norm2.weight grad: -9.377862625115085e-06
sam_encoder.blocks.10.norm2.bias grad: -2.832749942172086e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.873199941357598e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.7747828426072374e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.327330548723694e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.065684728018823e-06
sam_encoder.blocks.11.norm1.weight grad: -6.829019184806384e-06
sam_encoder.blocks.11.norm1.bias grad: 6.19981790350721e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.1443611331051216e-08
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.711540988935667e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.0942943024238048e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.7670576824002637e-07
sam_encoder.blocks.11.norm2.weight grad: -8.677011464897078e-06
sam_encoder.blocks.11.norm2.bias grad: -2.3393502033286495e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.5718326216738205e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.765206206982839e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.7536335690238047e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.119051138535724e-07
sam_encoder.neck.conv1.trainable_scale grad: -6.393120202119462e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.039164974121377e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.9744129531318322e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.9223291019443423e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00012276426423341036
mask_decoder.transformer.layers.0.norm1.bias grad: 9.86878148978576e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0015597736928611994
mask_decoder.transformer.layers.0.norm2.bias grad: 5.972097278572619e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -1.8758764781523496e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.9319009627215564e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 3.3160024031531066e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -4.83263374917442e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 7.529393769800663e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -4.8528454499319196e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00013327876513358206
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00011610502406256273
mask_decoder.transformer.layers.1.norm3.weight grad: 6.59567303955555e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 9.065297490451485e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 6.48809946142137e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -8.324531336256769e-06
mask_decoder.transformer.norm_final_attn.weight grad: 1.082845756172901e-05
mask_decoder.transformer.norm_final_attn.bias grad: 8.347081347892527e-06
Text_Embedding_Affine.0.weight grad: 8.379234806010771e-14
Text_Embedding_Affine.0.bias grad: -4.2799472299570596e-11
Text_Embedding_Affine.2.weight grad: 6.094452720262211e-11
Text_Embedding_Affine.2.bias grad: -1.3440065231407061e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07368500530719757

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07368500530719757

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06858634948730469

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.25897929072380066

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07372379302978516

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06858634948730469

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 62.800750732421875
Max value: 78.89051055908203
Mean value: 67.43740844726562

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07343501597642899

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07343501597642899

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07343501597642899

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.24127702414989471

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.5422961711883545
Max value: 19.34709930419922
Mean value: 1.0319355726242065

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 62.800750732421875
Max value: 78.89051055908203
Mean value: 67.43740844726562

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -67.76447296142578
Max value: -67.76447296142578
Mean value: -67.76447296142578
sam_encoder.pos_embed grad: 1.4113414437133542e-08
sam_encoder.blocks.0.norm1.weight grad: -3.40579790645279e-05
sam_encoder.blocks.0.norm1.bias grad: -1.1181975423824042e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.282739496375143e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.1793021548764955e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.0262226624035975e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.111907282502216e-07
sam_encoder.blocks.0.norm2.weight grad: -3.2218973501585424e-05
sam_encoder.blocks.0.norm2.bias grad: -3.1603092793375254e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 7.488570190616883e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 8.35138689581072e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.9220438844058663e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 7.821075087122153e-06
sam_encoder.blocks.1.norm1.weight grad: -1.3402450349531136e-06
sam_encoder.blocks.1.norm1.bias grad: 1.185567612083105e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.419916876940988e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -5.674685326084727e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.4460426882578759e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.2504224287113175e-06
sam_encoder.blocks.1.norm2.weight grad: -8.749656444706488e-06
sam_encoder.blocks.1.norm2.bias grad: 2.968991566376644e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.129102646606043e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.509997436092817e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.6922271015573642e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.2739147880201926e-06
sam_encoder.blocks.2.norm1.weight grad: -6.476468115579337e-06
sam_encoder.blocks.2.norm1.bias grad: -6.768522780475905e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.3244350611785194e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 7.114871891644725e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 7.523531166953035e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.971229259354004e-07
sam_encoder.blocks.2.norm2.weight grad: 6.347017006191891e-06
sam_encoder.blocks.2.norm2.bias grad: 1.190587045130087e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 8.901592082111165e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.3415678899473278e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.808538740988297e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 7.317057679756545e-07
sam_encoder.blocks.3.norm1.weight grad: -5.236046035861364e-06
sam_encoder.blocks.3.norm1.bias grad: 3.6928577173966914e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 8.899318117983057e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.1669878808315843e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -9.376002481076284e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.297975806366594e-07
sam_encoder.blocks.3.norm2.weight grad: 1.2756585419992916e-05
sam_encoder.blocks.3.norm2.bias grad: 1.0845741599041503e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.095749656902626e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.5113074570981553e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -5.531383976631332e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.1952261047554202e-07
sam_encoder.blocks.4.norm1.weight grad: -3.33646748913452e-05
sam_encoder.blocks.4.norm1.bias grad: -3.745716412595357e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.0555327864713036e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.034109562984668e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.0141638085769955e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -5.662438525178004e-06
sam_encoder.blocks.4.norm2.weight grad: 3.507734800223261e-05
sam_encoder.blocks.4.norm2.bias grad: 2.586284972494468e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 2.268441312480718e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 7.5240727710479405e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.7586929718381725e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 6.268662104957912e-07
sam_encoder.blocks.5.norm1.weight grad: -3.7215471820672974e-05
sam_encoder.blocks.5.norm1.bias grad: -6.844885774626164e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.561189467087388e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -5.641740244755056e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -9.068754479812924e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -7.514945082220947e-06
sam_encoder.blocks.5.norm2.weight grad: 1.6496302123414353e-05
sam_encoder.blocks.5.norm2.bias grad: 8.185775186575484e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 5.7029783420148306e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.5915400126687018e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.3840955936927912e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 8.745820991862274e-07
sam_encoder.blocks.6.norm1.weight grad: -1.8975697457790375e-07
sam_encoder.blocks.6.norm1.bias grad: -5.034352398070041e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.6552526176383253e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.404482857964467e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.0842206847883062e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.2770749435730977e-06
sam_encoder.blocks.6.norm2.weight grad: 8.225531928474084e-06
sam_encoder.blocks.6.norm2.bias grad: -6.434847819036804e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 7.062660642986884e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.2985853977152146e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.0851363185793161e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 8.296644296024169e-07
sam_encoder.blocks.7.norm1.weight grad: -5.880687240278348e-06
sam_encoder.blocks.7.norm1.bias grad: 1.6531855351331615e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -4.16965576732764e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.364275587751763e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.3041872080066241e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 7.156504011618381e-07
sam_encoder.blocks.7.norm2.weight grad: -4.0486461330146994e-06
sam_encoder.blocks.7.norm2.bias grad: -3.0663486541016027e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -4.333893230068497e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.2724803961391444e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.382593901818836e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 4.3757734147220617e-07
sam_encoder.blocks.8.norm1.weight grad: -5.200704890739871e-06
sam_encoder.blocks.8.norm1.bias grad: 2.0644683900172822e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.9466714295267593e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.5140079173979757e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.051519342989195e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.832469820328697e-06
sam_encoder.blocks.8.norm2.weight grad: -2.84300676867133e-06
sam_encoder.blocks.8.norm2.bias grad: -4.4796661313739605e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.956724301839131e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.3197585531088407e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.0106959962286055e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.0312548915389925e-07
sam_encoder.blocks.9.norm1.weight grad: -6.851244506833609e-06
sam_encoder.blocks.9.norm1.bias grad: 4.968774192093406e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.918714239465771e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.7685258626443101e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.1463646387710469e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -7.00085820426466e-08
sam_encoder.blocks.9.norm2.weight grad: -1.128608528233599e-05
sam_encoder.blocks.9.norm2.bias grad: -3.271663899795385e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -8.196378985303454e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.489314051170368e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.850865257641999e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.096679499023594e-07
sam_encoder.blocks.10.norm1.weight grad: -8.497360795445275e-06
sam_encoder.blocks.10.norm1.bias grad: -1.8591899788589217e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.602492481353693e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.0435545593500137e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.5630615735062747e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -9.68517383626022e-07
sam_encoder.blocks.10.norm2.weight grad: -1.3526107068173587e-05
sam_encoder.blocks.10.norm2.bias grad: -5.215386408963241e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -6.844582003395772e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.138090844207909e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.2459116735262796e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.931553465008619e-07
sam_encoder.blocks.11.norm1.weight grad: -1.0571287930360995e-05
sam_encoder.blocks.11.norm1.bias grad: 7.707984650551225e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.058902959513944e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.1418661642892403e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.420514647383243e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.4676907085231505e-06
sam_encoder.blocks.11.norm2.weight grad: -1.5022229490568861e-05
sam_encoder.blocks.11.norm2.bias grad: -4.343125965533545e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -6.92897810949944e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.398709057160886e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.0658801531681092e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -6.005194563840632e-07
sam_encoder.neck.conv1.trainable_scale grad: -3.705845301738009e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.355773929390125e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.8278296920470893e-07
sam_encoder.neck.conv2.trainable_shift grad: 3.401832145755179e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 4.5514858356909826e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 2.0317565940786153e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004841011017560959
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00021924194879829884
mask_decoder.transformer.layers.0.norm3.weight grad: 6.56758711556904e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.290707172709517e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -2.424706326564774e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -4.942839950672351e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.280138819012791e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -7.748063580947928e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0002273963764309883
mask_decoder.transformer.layers.1.norm2.bias grad: 8.463462290819734e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.764728848589584e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.9469533880474046e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00013921056233812124
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00016906698874663562
mask_decoder.transformer.norm_final_attn.weight grad: 6.836997272330336e-06
mask_decoder.transformer.norm_final_attn.bias grad: 3.4013994536508108e-06
Text_Embedding_Affine.0.weight grad: 4.258555313940704e-12
Text_Embedding_Affine.0.bias grad: 9.420585145303306e-11
Text_Embedding_Affine.2.weight grad: -4.658823327119421e-11
Text_Embedding_Affine.2.bias grad: -3.9658130845054984e-05
Epoch 5 finished with average loss: -66.3107
Epoch 6/39
----------
Epoch 6:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 6:   0%|          | 0/3 [00:00<?, ?it/s, loss=-65.4]Epoch 6:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.15it/s, loss=-65.4]Epoch 6:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.15it/s, loss=-67.1]Epoch 6:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.74it/s, loss=-67.1]Epoch 6:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.74it/s, loss=-67.4]Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.39it/s, loss=-67.4]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08812081813812256

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08812081813812256

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09002256393432617

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2652907371520996

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08796215057373047

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09002256393432617

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 47.88814926147461
Max value: 85.28234100341797
Mean value: 65.36831665039062

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08812081813812256

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08812081813812256

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08812081813812256

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2652907371520996

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 47.88814926147461
Max value: 85.28234100341797
Mean value: 65.36831665039062

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.36858367919922
Max value: -65.36858367919922
Mean value: -65.36858367919922
sam_encoder.pos_embed grad: -2.3273525329159384e-09
sam_encoder.blocks.0.norm1.weight grad: 8.400769729632884e-06
sam_encoder.blocks.0.norm1.bias grad: 2.5682253181003034e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.041488637085422e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.2132932997465105e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.6904157007502363e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.621885985514382e-07
sam_encoder.blocks.0.norm2.weight grad: 1.1155072570545599e-05
sam_encoder.blocks.0.norm2.bias grad: -4.18284980696626e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -7.449559120686899e-07
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.6353226328646997e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.941228093637619e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.7233581957043498e-06
sam_encoder.blocks.1.norm1.weight grad: 1.756601193392271e-07
sam_encoder.blocks.1.norm1.bias grad: -3.4459662856534123e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.0593287192459684e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 9.911083225233597e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 3.054222815990215e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.6718838651286205e-06
sam_encoder.blocks.1.norm2.weight grad: 5.81857011638931e-06
sam_encoder.blocks.1.norm2.bias grad: 6.655750439676922e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.331473524463945e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.967466343761771e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 2.2899985197000206e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 3.0085436719673453e-07
sam_encoder.blocks.2.norm1.weight grad: 1.6392385759900208e-06
sam_encoder.blocks.2.norm1.bias grad: -1.278378363167576e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.757961283350596e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 7.39054371479142e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 4.0624735220262664e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.0747732776271732e-07
sam_encoder.blocks.2.norm2.weight grad: -2.0479149043239886e-06
sam_encoder.blocks.2.norm2.bias grad: -2.583409695944283e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.0197936717304401e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -7.393981604764122e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.1165393232204224e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -4.266175608336198e-07
sam_encoder.blocks.3.norm1.weight grad: -3.6724504752783105e-06
sam_encoder.blocks.3.norm1.bias grad: -3.211916464351816e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.689145503609325e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.4487092648305406e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.9654523220633564e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.6366162469694245e-07
sam_encoder.blocks.3.norm2.weight grad: 2.81943493973813e-06
sam_encoder.blocks.3.norm2.bias grad: 4.5960650822962634e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.5844051378953736e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.1831641586468322e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 7.519018936363864e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -3.813685722775517e-08
sam_encoder.blocks.4.norm1.weight grad: -2.1787782316096127e-06
sam_encoder.blocks.4.norm1.bias grad: 7.280065688064496e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.5126734069781378e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -4.4558913714354276e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 6.880217711113801e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.434404109408206e-07
sam_encoder.blocks.4.norm2.weight grad: -7.476583959942218e-06
sam_encoder.blocks.4.norm2.bias grad: -5.61452316105715e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.814204658032395e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.7488061985204695e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.9364454096357804e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -4.429381874615501e-07
sam_encoder.blocks.5.norm1.weight grad: -4.259344677848276e-06
sam_encoder.blocks.5.norm1.bias grad: -2.3638203572318162e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.346623659832403e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.2234046380399377e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.9630397218861617e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.571301358031633e-07
sam_encoder.blocks.5.norm2.weight grad: -4.10613711210317e-06
sam_encoder.blocks.5.norm2.bias grad: -4.0287513911607675e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.1109131037301267e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -4.782519908985705e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 6.80211087455973e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.17592445955961e-07
sam_encoder.blocks.6.norm1.weight grad: -1.6628785033390159e-06
sam_encoder.blocks.6.norm1.bias grad: 9.94266201814753e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.3634617062052712e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -8.173551009349467e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.9187993416380777e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.4239601493245573e-07
sam_encoder.blocks.6.norm2.weight grad: -1.1311144589853939e-06
sam_encoder.blocks.6.norm2.bias grad: -1.7282054614042863e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -5.147596766619245e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.446153075652546e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.89681519613805e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.229436747962609e-07
sam_encoder.blocks.7.norm1.weight grad: 8.219405458476103e-07
sam_encoder.blocks.7.norm1.bias grad: 1.0859835128940176e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 8.00959696789505e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 7.718474535067799e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 6.484776235993195e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -6.96921233611647e-07
sam_encoder.blocks.7.norm2.weight grad: 2.414028585917549e-06
sam_encoder.blocks.7.norm2.bias grad: -2.150673452661067e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.9802723727480043e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 6.229273594726692e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -8.720834188125082e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.624024091346655e-07
sam_encoder.blocks.8.norm1.weight grad: 3.683441889279493e-07
sam_encoder.blocks.8.norm1.bias grad: -1.0160806596104521e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -7.880853445385583e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -3.9775795812602155e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 7.264706596288306e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 6.46511466584343e-08
sam_encoder.blocks.8.norm2.weight grad: -4.680741483298334e-07
sam_encoder.blocks.8.norm2.bias grad: -1.134284275394748e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.217149734448867e-08
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.434163886595343e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -4.1830338659565314e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.391514837858267e-07
sam_encoder.blocks.9.norm1.weight grad: -2.4116063741530525e-06
sam_encoder.blocks.9.norm1.bias grad: 4.884501549895504e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.7662284790276317e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.6860121831996366e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.9870367395924404e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.827363444652292e-07
sam_encoder.blocks.9.norm2.weight grad: 9.392417723574908e-07
sam_encoder.blocks.9.norm2.bias grad: -1.4176098375173751e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.5003282669567852e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.636140041227918e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.7292867937612755e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.3185267511726124e-07
sam_encoder.blocks.10.norm1.weight grad: 1.989400288948673e-06
sam_encoder.blocks.10.norm1.bias grad: 2.152370086605515e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.5945005316098104e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.313279072855948e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 9.69154825725127e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.193301373969007e-07
sam_encoder.blocks.10.norm2.weight grad: 7.886915227572899e-07
sam_encoder.blocks.10.norm2.bias grad: -1.7981701603275724e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.5859795894357376e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.921353445932255e-08
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -8.214647095883265e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.2216925660577544e-07
sam_encoder.blocks.11.norm1.weight grad: 5.84014651394682e-06
sam_encoder.blocks.11.norm1.bias grad: -1.4314659324554668e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.5887152926552517e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.260682847004091e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 8.290668347399333e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.3074223299299774e-07
sam_encoder.blocks.11.norm2.weight grad: 1.5551222531939857e-06
sam_encoder.blocks.11.norm2.bias grad: -9.260612614525598e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.5402700885024387e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -5.278868542291093e-08
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.922878472119919e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.860514882740972e-07
sam_encoder.neck.conv1.trainable_scale grad: -5.968695404590108e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.2333557606325485e-05
sam_encoder.neck.conv2.trainable_scale grad: -8.393326424993575e-07
sam_encoder.neck.conv2.trainable_shift grad: 4.037292819702998e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00017409764404874295
mask_decoder.transformer.layers.0.norm1.bias grad: -1.2588898243848234e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.002224552445113659
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0003589881816878915
mask_decoder.transformer.layers.0.norm3.weight grad: -1.2434138625394553e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 9.120540198637173e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 5.069126927992329e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.624453034310136e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.5466324334265664e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.2460941434255801e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 2.2982061636867e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 3.841024590656161e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.3548691135365516e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.912774991476908e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -9.218869308824651e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00010049356205854565
mask_decoder.transformer.norm_final_attn.weight grad: 6.786881385778543e-06
mask_decoder.transformer.norm_final_attn.bias grad: 6.51093250780832e-06
Text_Embedding_Affine.0.weight grad: 5.524454591704364e-12
Text_Embedding_Affine.0.bias grad: 3.051530417241821e-10
Text_Embedding_Affine.2.weight grad: 1.469968452516568e-10
Text_Embedding_Affine.2.bias grad: 1.1375050235074013e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0805966854095459

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0805966854095459

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07910299301147461

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2670794129371643

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0806131362915039

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07910299301147461

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 59.990543365478516
Max value: 91.16741943359375
Mean value: 68.50354766845703

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0801764726638794

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0801764726638794

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0801764726638794

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.25793176889419556

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.7087928056716919
Max value: 4.0
Mean value: 1.0117824077606201

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 59.990543365478516
Max value: 91.16741943359375
Mean value: 68.50354766845703

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.84049224853516
Max value: -68.84049224853516
Mean value: -68.84049224853516
sam_encoder.pos_embed grad: -1.171348990025578e-10
sam_encoder.blocks.0.norm1.weight grad: -2.4742554160184227e-05
sam_encoder.blocks.0.norm1.bias grad: 1.1998493391729426e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.5723281282807875e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.4228567124519031e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.9118252768967068e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -9.81414473244513e-07
sam_encoder.blocks.0.norm2.weight grad: -2.787389803415863e-06
sam_encoder.blocks.0.norm2.bias grad: -4.5658697445105645e-07
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.088909124926431e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.0975455754523864e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.1438678484410048e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.5115281207254156e-06
sam_encoder.blocks.1.norm1.weight grad: -3.7082827475387603e-06
sam_encoder.blocks.1.norm1.bias grad: -2.9869852369301952e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.5631908303912496e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.5601293625877588e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 3.1321123969973996e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.0662459999366547e-06
sam_encoder.blocks.1.norm2.weight grad: -8.77588172443211e-06
sam_encoder.blocks.1.norm2.bias grad: -2.2897378926245437e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.910007762897294e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.967681317997631e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -9.791282309379312e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -6.99539384640957e-07
sam_encoder.blocks.2.norm1.weight grad: -4.7379453462781385e-06
sam_encoder.blocks.2.norm1.bias grad: -7.351620297413319e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.172877546196105e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 3.207980512343056e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.568410764069995e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.949106594016484e-07
sam_encoder.blocks.2.norm2.weight grad: 9.63638399298361e-07
sam_encoder.blocks.2.norm2.bias grad: -4.489779257710325e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.7255191551157623e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -5.297187044561724e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.750982957877568e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -9.040161330631236e-07
sam_encoder.blocks.3.norm1.weight grad: -3.0600101581512718e-06
sam_encoder.blocks.3.norm1.bias grad: -6.401092832675204e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.54609312833054e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.090034906312212e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.2144057513505686e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.779936719183752e-07
sam_encoder.blocks.3.norm2.weight grad: 1.9179092305421364e-06
sam_encoder.blocks.3.norm2.bias grad: 2.4422693059023004e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.603729272886994e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.5729237879422726e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.3924948183994275e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.5567118225590093e-06
sam_encoder.blocks.4.norm1.weight grad: -5.352878361009061e-06
sam_encoder.blocks.4.norm1.bias grad: 4.897571557194169e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -5.354169843485579e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.1546981113497168e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -7.657669129912392e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.403999133093748e-07
sam_encoder.blocks.4.norm2.weight grad: -4.395136784296483e-06
sam_encoder.blocks.4.norm2.bias grad: -7.640889634785708e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.9245128391485196e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.3915232557337731e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -8.951435574999778e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -8.564845188629988e-07
sam_encoder.blocks.5.norm1.weight grad: -4.08718233302352e-06
sam_encoder.blocks.5.norm1.bias grad: -5.455423433886608e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.5713071611098712e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -9.633356512495084e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 5.329089844963164e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.2215568290230294e-07
sam_encoder.blocks.5.norm2.weight grad: -1.7705983736959752e-06
sam_encoder.blocks.5.norm2.bias grad: -6.712156391586177e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.060125896401587e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.700932182937322e-08
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.8656310203368776e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.078133659073501e-08
sam_encoder.blocks.6.norm1.weight grad: 7.209549579556551e-08
sam_encoder.blocks.6.norm1.bias grad: -4.616943982682642e-08
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -6.625001560678356e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -4.393237418298668e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.7190235957496043e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.213363962752737e-08
sam_encoder.blocks.6.norm2.weight grad: -1.1115835150121711e-06
sam_encoder.blocks.6.norm2.bias grad: -1.2157165656390134e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.3989723584018066e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.1022821051228675e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.002534066989028e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.0628536390177032e-07
sam_encoder.blocks.7.norm1.weight grad: 1.5363624470410286e-06
sam_encoder.blocks.7.norm1.bias grad: 8.74780766935146e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.5141174571908778e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 8.668186524118937e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.2530232424978749e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -5.533902367460541e-07
sam_encoder.blocks.7.norm2.weight grad: 6.921171006979421e-06
sam_encoder.blocks.7.norm2.bias grad: -4.500737702528568e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.0837118174531497e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.047926500381436e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.1115890547207528e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.748332796429168e-07
sam_encoder.blocks.8.norm1.weight grad: 1.0875766065510106e-06
sam_encoder.blocks.8.norm1.bias grad: -7.260687198140658e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.15020291863766e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.029337906606088e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.2783642634749413e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.5810724107723217e-06
sam_encoder.blocks.8.norm2.weight grad: 1.019341198116308e-06
sam_encoder.blocks.8.norm2.bias grad: -2.0498518438216706e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -7.238198804770946e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.6142445247169235e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -9.959468343367917e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.503157123916026e-07
sam_encoder.blocks.9.norm1.weight grad: -2.1013026980654104e-06
sam_encoder.blocks.9.norm1.bias grad: 3.7387042084446875e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.126249344451935e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.3130166937335161e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.6946614778134972e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -7.249217333082925e-07
sam_encoder.blocks.9.norm2.weight grad: -6.748093142050493e-07
sam_encoder.blocks.9.norm2.bias grad: -1.7494461417300045e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.4933497141100815e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.3005333130422514e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.7911031591211213e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -9.371486839881982e-07
sam_encoder.blocks.10.norm1.weight grad: 1.0529511200729758e-06
sam_encoder.blocks.10.norm1.bias grad: -2.2765487273090912e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.3586413842858747e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.334022373266635e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.071662609319901e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.467107027674501e-07
sam_encoder.blocks.10.norm2.weight grad: -3.2977773116726894e-06
sam_encoder.blocks.10.norm2.bias grad: -3.0221679025999038e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -9.235106404048565e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.4977792943682289e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.4861830095469486e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.0072081825856e-07
sam_encoder.blocks.11.norm1.weight grad: 3.5761120216193376e-06
sam_encoder.blocks.11.norm1.bias grad: 2.0125025912420824e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.516833319532452e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.725147112414561e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.590209421920008e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 8.617302569291496e-07
sam_encoder.blocks.11.norm2.weight grad: -2.124490720234462e-06
sam_encoder.blocks.11.norm2.bias grad: -2.6932352739095222e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.981595000368543e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -9.835553100856487e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.1732349776139017e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.2261713183979737e-07
sam_encoder.neck.conv1.trainable_scale grad: -6.271445727179525e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.938358400366269e-05
sam_encoder.neck.conv2.trainable_scale grad: -5.316478564054705e-07
sam_encoder.neck.conv2.trainable_shift grad: 6.267426942940801e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0001715578546281904
mask_decoder.transformer.layers.0.norm1.bias grad: 6.198424671310931e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.00028115720488131046
mask_decoder.transformer.layers.0.norm2.bias grad: -6.570585537701845e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 2.9702474421355873e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.380706246185582e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 3.415733954170719e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -2.6791349228005856e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 5.1746195822488517e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -3.994155122200027e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00012591689301189035
mask_decoder.transformer.layers.1.norm2.bias grad: 6.464334728661925e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.0827635277528316e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.031432712916285e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 7.501245272578672e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -6.280331581365317e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.4209799701347947e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.378518390993122e-05
Text_Embedding_Affine.0.weight grad: 8.367809917197988e-12
Text_Embedding_Affine.0.bias grad: 4.3770240210072586e-10
Text_Embedding_Affine.2.weight grad: 1.3257213382633637e-10
Text_Embedding_Affine.2.bias grad: -7.95862615632359e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08721351623535156

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08721351623535156

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08072471618652344

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.34516072273254395

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08722782135009766

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08072471618652344

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 61.87260055541992
Max value: 77.49674987792969
Mean value: 67.59742736816406

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0865400955080986

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0865400955080986

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0865400955080986

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.3198699653148651

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.6283472180366516
Max value: 16.0
Mean value: 1.0451998710632324

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 61.87260055541992
Max value: 77.49674987792969
Mean value: 67.59742736816406

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.06082916259766
Max value: -68.06082916259766
Mean value: -68.06082916259766
sam_encoder.pos_embed grad: 2.773778096099022e-09
sam_encoder.blocks.0.norm1.weight grad: -1.8265238395542838e-05
sam_encoder.blocks.0.norm1.bias grad: -2.4147819203790277e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.1213638774497667e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.5369096217909828e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -6.221876446943497e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.5978679332183674e-06
sam_encoder.blocks.0.norm2.weight grad: -5.931332907493925e-06
sam_encoder.blocks.0.norm2.bias grad: -8.823155076242983e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 7.607348379679024e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -3.5877108075510478e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.6981346309185028e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.8949656300246716e-06
sam_encoder.blocks.1.norm1.weight grad: -2.6727317163022235e-05
sam_encoder.blocks.1.norm1.bias grad: -1.185321161756292e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.413601451844443e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.620897930682986e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.404180683399318e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.6916638893890195e-06
sam_encoder.blocks.1.norm2.weight grad: -2.883170236600563e-05
sam_encoder.blocks.1.norm2.bias grad: 1.3468775250657927e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.1844507500645705e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.2473740247951355e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.8836875571869314e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -6.766611477360129e-06
sam_encoder.blocks.2.norm1.weight grad: 3.969831232097931e-05
sam_encoder.blocks.2.norm1.bias grad: -7.337329407164361e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.7831642253440805e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.5841050046437886e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.6031830227802857e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 3.072622121180757e-06
sam_encoder.blocks.2.norm2.weight grad: -6.367611604218837e-06
sam_encoder.blocks.2.norm2.bias grad: 4.088314199179877e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -9.444103852729313e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.988090611528605e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.3431275874609128e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.4891806990344776e-06
sam_encoder.blocks.3.norm1.weight grad: 1.4202649254002608e-05
sam_encoder.blocks.3.norm1.bias grad: 7.127740445866948e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.083887582353782e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.844834855546651e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -6.948642749193823e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.7695227799995337e-06
sam_encoder.blocks.3.norm2.weight grad: 1.0234247383777983e-05
sam_encoder.blocks.3.norm2.bias grad: -1.3786840099783149e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.891213499533478e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.3115829915477661e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.03352374228416e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.8713875533649116e-06
sam_encoder.blocks.4.norm1.weight grad: 4.14019450545311e-06
sam_encoder.blocks.4.norm1.bias grad: -4.769868610310368e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 5.494075139722554e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.2974381888852804e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.224037077918183e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -8.757540115311713e-08
sam_encoder.blocks.4.norm2.weight grad: -6.765520811313763e-05
sam_encoder.blocks.4.norm2.bias grad: -4.2054754885612056e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.239484769641422e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.3396476788329892e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 6.662712621618994e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.2117085361751379e-06
sam_encoder.blocks.5.norm1.weight grad: 2.4435144950984977e-05
sam_encoder.blocks.5.norm1.bias grad: 1.285513280890882e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 9.746883733896539e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.9036389150860487e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.247673026227858e-05
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 8.699231329956092e-06
sam_encoder.blocks.5.norm2.weight grad: -3.3449370675953105e-05
sam_encoder.blocks.5.norm2.bias grad: -1.3157058674551081e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.713980600470677e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -5.785080702480627e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.1605925465119071e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.103437170968391e-06
sam_encoder.blocks.6.norm1.weight grad: 8.903960406314582e-06
sam_encoder.blocks.6.norm1.bias grad: 2.0527710148599e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.760061983688502e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -4.183478665709117e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 4.171813998254947e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.836748879213701e-06
sam_encoder.blocks.6.norm2.weight grad: -2.8496539016487077e-05
sam_encoder.blocks.6.norm2.bias grad: -1.1183855349372607e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.7129201296484098e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -8.121252903947607e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -8.477331903122831e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.818040906684473e-06
sam_encoder.blocks.7.norm1.weight grad: -4.326489943196066e-06
sam_encoder.blocks.7.norm1.bias grad: 7.780033229209948e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -4.9679306357575115e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -4.025498128612526e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.413806216987723e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.0118154705196503e-06
sam_encoder.blocks.7.norm2.weight grad: 5.656651410390623e-06
sam_encoder.blocks.7.norm2.bias grad: 2.3676589080423582e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 9.236728146788664e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.6266658349195495e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.4033612387720495e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.332936095532204e-07
sam_encoder.blocks.8.norm1.weight grad: -2.675067207746906e-06
sam_encoder.blocks.8.norm1.bias grad: -1.3971269936519093e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -9.07540561456699e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -8.328657713718712e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 9.454828386878944e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.0541552910581231e-06
sam_encoder.blocks.8.norm2.weight grad: 2.0612192201951984e-06
sam_encoder.blocks.8.norm2.bias grad: -2.102271082549123e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 5.262639319880691e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.3045347436200245e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 7.109133548510727e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.1892295976044807e-08
sam_encoder.blocks.9.norm1.weight grad: -6.5756212279666215e-06
sam_encoder.blocks.9.norm1.bias grad: 3.5825996747007594e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -6.500569270428969e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.3865300136094447e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.5155428627622314e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.4958912945294287e-06
sam_encoder.blocks.9.norm2.weight grad: -6.196508365974296e-06
sam_encoder.blocks.9.norm2.bias grad: -4.6641671360703185e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.8127667519584065e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.0422908164619002e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.2157901210230193e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.6755128626755322e-06
sam_encoder.blocks.10.norm1.weight grad: 2.205733380833408e-06
sam_encoder.blocks.10.norm1.bias grad: -2.240954927401617e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.3053456768830074e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.249351780392317e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.3281845642486587e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.9225363934747293e-07
sam_encoder.blocks.10.norm2.weight grad: -2.3052641608956037e-06
sam_encoder.blocks.10.norm2.bias grad: -3.2668358471710235e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.8808350432664156e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.7533136542624561e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 8.300596618937561e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.701093522882729e-07
sam_encoder.blocks.11.norm1.weight grad: -2.017599399550818e-06
sam_encoder.blocks.11.norm1.bias grad: 4.400523607728246e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -6.6246502683497965e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.5519584596622735e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.0048037185915746e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.7519710127089638e-06
sam_encoder.blocks.11.norm2.weight grad: 3.054380499634135e-07
sam_encoder.blocks.11.norm2.bias grad: -4.404471383168129e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.822333842937951e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.776826815737877e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.4644845123257255e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.134059340936801e-07
sam_encoder.neck.conv1.trainable_scale grad: 3.5254161048214883e-06
sam_encoder.neck.conv1.trainable_shift grad: -3.966987787862308e-05
sam_encoder.neck.conv2.trainable_scale grad: 3.1619638320989907e-06
sam_encoder.neck.conv2.trainable_shift grad: -3.3491753129055724e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0001748822396621108
mask_decoder.transformer.layers.0.norm1.bias grad: 2.160973963327706e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0013448875397443771
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0003127343952655792
mask_decoder.transformer.layers.0.norm3.weight grad: 9.454022801946849e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.9102167647797614e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 7.16159847797826e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -9.972889529308304e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 5.46362207387574e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -3.5452130759949796e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00014100845146458596
mask_decoder.transformer.layers.1.norm2.bias grad: 4.8426882131025195e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 6.386451423168182e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 8.296180021716282e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00018688960699364543
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0001854998990893364
mask_decoder.transformer.norm_final_attn.weight grad: 1.7787713659345172e-05
mask_decoder.transformer.norm_final_attn.bias grad: 6.688205303362338e-06
Text_Embedding_Affine.0.weight grad: 1.0708999659270191e-11
Text_Embedding_Affine.0.bias grad: 5.148511617036888e-10
Text_Embedding_Affine.2.weight grad: -2.0792055577256718e-10
Text_Embedding_Affine.2.bias grad: -3.813956936937757e-07
Epoch 6 finished with average loss: -67.4233
Epoch 7/39
----------
Epoch 7:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 7:   0%|          | 0/3 [00:00<?, ?it/s, loss=-65.8]Epoch 7:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.05it/s, loss=-65.8]Epoch 7:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.05it/s, loss=-64.1]Epoch 7:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.64it/s, loss=-64.1]Epoch 7:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.64it/s, loss=-63.4]Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.29it/s, loss=-63.4]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08072340488433838

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08072340488433838

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0850062370300293

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.28375908732414246

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08025026321411133

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0850062370300293

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 44.972347259521484
Max value: 84.22184753417969
Mean value: 65.78982543945312

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08072340488433838

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08072340488433838

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08072340488433838

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.28375908732414246

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 44.972347259521484
Max value: 84.22184753417969
Mean value: 65.78982543945312

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.79010772705078
Max value: -65.79010772705078
Mean value: -65.79010772705078
sam_encoder.pos_embed grad: -2.419069611292457e-09
sam_encoder.blocks.0.norm1.weight grad: 9.047914318216499e-06
sam_encoder.blocks.0.norm1.bias grad: 2.7594300263444893e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.1987726793449838e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.6253533630106176e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 7.989062282831583e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.0541930350882467e-07
sam_encoder.blocks.0.norm2.weight grad: 1.2974916899111122e-05
sam_encoder.blocks.0.norm2.bias grad: 1.909293814605917e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.8815717339748517e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.000464635581011e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -9.48060187511146e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.910495257106959e-06
sam_encoder.blocks.1.norm1.weight grad: -1.9956971755163977e-06
sam_encoder.blocks.1.norm1.bias grad: -1.6547963923585485e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.147916802641703e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 8.444680474894994e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.9537401385605335e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.0991312819896848e-06
sam_encoder.blocks.1.norm2.weight grad: 5.548494300455786e-06
sam_encoder.blocks.1.norm2.bias grad: 4.7439456807296665e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.200977284403052e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 9.57217821451195e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.5404820032927091e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.927724267465237e-07
sam_encoder.blocks.2.norm1.weight grad: 6.396034223143943e-06
sam_encoder.blocks.2.norm1.bias grad: -3.845890660159057e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.468409770197468e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.0471727591720992e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 9.75780835688056e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 5.058183774053759e-07
sam_encoder.blocks.2.norm2.weight grad: 4.079241477938922e-07
sam_encoder.blocks.2.norm2.bias grad: -1.3895909205530188e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 5.365993160921789e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -5.739418611483416e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 8.155804493981123e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 2.797235083562555e-07
sam_encoder.blocks.3.norm1.weight grad: -5.351243999029975e-06
sam_encoder.blocks.3.norm1.bias grad: -2.1363343876146246e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.48363926402817e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.6028775462473277e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -6.359848612191854e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 6.04371791723679e-07
sam_encoder.blocks.3.norm2.weight grad: 4.632027412299067e-06
sam_encoder.blocks.3.norm2.bias grad: 4.074357093486469e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.239685040374752e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.4282611573435133e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 8.342585715581663e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.2707370084826834e-07
sam_encoder.blocks.4.norm1.weight grad: -3.1824197321839165e-06
sam_encoder.blocks.4.norm1.bias grad: 1.960306235559983e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.9606982277764473e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.95184144963423e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 8.491107905683748e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.0202636531175813e-06
sam_encoder.blocks.4.norm2.weight grad: -8.288960088975728e-06
sam_encoder.blocks.4.norm2.bias grad: -6.110645244916668e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.73799479752779e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.2563935999642126e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -6.708589808113175e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.376517601187516e-07
sam_encoder.blocks.5.norm1.weight grad: -3.620547431637533e-06
sam_encoder.blocks.5.norm1.bias grad: 1.1877143606398022e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.77967819783953e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.1037451486117789e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.1821969110314967e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.533096790102718e-07
sam_encoder.blocks.5.norm2.weight grad: -4.665246706281323e-06
sam_encoder.blocks.5.norm2.bias grad: -4.188796992821153e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.292913111683447e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -4.1723615140654147e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -3.493648250696424e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.610045263892971e-07
sam_encoder.blocks.6.norm1.weight grad: 9.911302356613305e-08
sam_encoder.blocks.6.norm1.bias grad: 3.627180376497563e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -6.483186325567658e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.491647693314007e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 4.041190493353497e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.6149931525433203e-07
sam_encoder.blocks.6.norm2.weight grad: -9.029976695273945e-07
sam_encoder.blocks.6.norm2.bias grad: -2.0327138372522313e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.2533651389267106e-08
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.196640108171778e-08
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.04505568035529e-09
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.468126656500317e-08
sam_encoder.blocks.7.norm1.weight grad: 6.038422952769906e-07
sam_encoder.blocks.7.norm1.bias grad: 9.373346756547107e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 8.931016850510787e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 7.84515805207775e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.1000179256370757e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.007021405210253e-07
sam_encoder.blocks.7.norm2.weight grad: 3.1211318400892196e-06
sam_encoder.blocks.7.norm2.bias grad: -9.331014183544539e-08
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.2713575162924826e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.0006870070355944e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.2639972030447097e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.203953380965686e-07
sam_encoder.blocks.8.norm1.weight grad: -3.735287918971153e-07
sam_encoder.blocks.8.norm1.bias grad: 1.743789468378054e-08
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.7516167645226233e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -8.475296340293426e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.0737026059359778e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 9.364040920445404e-07
sam_encoder.blocks.8.norm2.weight grad: 1.7803657783588278e-06
sam_encoder.blocks.8.norm2.bias grad: -3.905466883225017e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.7799575289245695e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 8.407393465859059e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 3.5782250051852316e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.4132901899065473e-07
sam_encoder.blocks.9.norm1.weight grad: -1.9361978047527373e-06
sam_encoder.blocks.9.norm1.bias grad: 4.444185321972327e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.6449091617687372e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.4246727175759588e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.266334188851033e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -7.369436616500025e-07
sam_encoder.blocks.9.norm2.weight grad: 2.965937710541766e-06
sam_encoder.blocks.9.norm2.bias grad: -5.481222729031288e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.542191850807285e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.0682124411687255e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.663201428276807e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.984461957566964e-07
sam_encoder.blocks.10.norm1.weight grad: 2.0161612610536395e-06
sam_encoder.blocks.10.norm1.bias grad: 4.9404633273297804e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.7861250398709672e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 8.518128993273422e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.0268349797115661e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.746313374605961e-07
sam_encoder.blocks.10.norm2.weight grad: 2.9993370844749734e-06
sam_encoder.blocks.10.norm2.bias grad: -7.807857400621288e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.34907929552719e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 5.940153755545907e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.5690135291588376e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.9431284670190507e-07
sam_encoder.blocks.11.norm1.weight grad: 5.647763373417547e-06
sam_encoder.blocks.11.norm1.bias grad: -8.895382848095323e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -6.243259349503205e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.1445214909144852e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 7.32782041268365e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.4145008953601064e-07
sam_encoder.blocks.11.norm2.weight grad: 3.534188635967439e-06
sam_encoder.blocks.11.norm2.bias grad: -4.6451631874333543e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.277107680332847e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 4.914218152407557e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -3.951131475332659e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.958886646808878e-08
sam_encoder.neck.conv1.trainable_scale grad: -3.688801371026784e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.6733805498224683e-06
sam_encoder.neck.conv2.trainable_scale grad: -4.100784281035885e-07
sam_encoder.neck.conv2.trainable_shift grad: 3.157186074531637e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00015144067583605647
mask_decoder.transformer.layers.0.norm1.bias grad: -8.353745215572417e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.002563650254160166
mask_decoder.transformer.layers.0.norm2.bias grad: 9.648286504670978e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -2.6274243282387033e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.2427339243004099e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 4.312977762310766e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -6.754899004590698e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 3.240955265937373e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.137405888584908e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 2.8635691705858335e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 3.867034683935344e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.078595909755677e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.85081184504088e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.8678651031223126e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -9.782479173736647e-05
mask_decoder.transformer.norm_final_attn.weight grad: 5.357121153792832e-06
mask_decoder.transformer.norm_final_attn.bias grad: 5.7463444136374164e-06
Text_Embedding_Affine.0.weight grad: 2.4767096359901153e-11
Text_Embedding_Affine.0.bias grad: 8.24693757728312e-10
Text_Embedding_Affine.2.weight grad: -8.72042021926589e-13
Text_Embedding_Affine.2.bias grad: 9.740670066094026e-07

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07805292308330536

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07805292308330536

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08536720275878906

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2781713604927063

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07793617248535156

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08536720275878906

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 36.15520095825195
Max value: 85.08322143554688
Mean value: 62.00950241088867

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0769277960062027

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0769277960062027

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0769277960062027

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2691114544868469

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.7497435212135315
Max value: 4.143560886383057
Mean value: 1.011720895767212

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 36.15520095825195
Max value: 85.08322143554688
Mean value: 62.00950241088867

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.324432373046875
Max value: -62.324432373046875
Mean value: -62.324432373046875
sam_encoder.pos_embed grad: -1.0843716147235227e-08
sam_encoder.blocks.0.norm1.weight grad: 7.99230929260375e-06
sam_encoder.blocks.0.norm1.bias grad: 2.9751015972578898e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.0153788682364393e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -9.602748463066746e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.8079674595792312e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.8296066173206782e-06
sam_encoder.blocks.0.norm2.weight grad: 2.5767552870092914e-05
sam_encoder.blocks.0.norm2.bias grad: -2.2983036615187302e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.6533933780447114e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.372730764614971e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.5331652321037836e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -7.314978574868292e-06
sam_encoder.blocks.1.norm1.weight grad: -7.891790119174402e-06
sam_encoder.blocks.1.norm1.bias grad: -9.632591172703542e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.5474803300749045e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.462463274037873e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 3.4507397685956676e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.8566165636002552e-06
sam_encoder.blocks.1.norm2.weight grad: 1.743033317325171e-05
sam_encoder.blocks.1.norm2.bias grad: 5.435174443846336e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.599953172146343e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.7419843061361462e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 4.517830802797107e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.183419499284355e-06
sam_encoder.blocks.2.norm1.weight grad: 5.0616431508387905e-06
sam_encoder.blocks.2.norm1.bias grad: -6.991951067902846e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 5.574228453042451e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 5.705985586246243e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.4871575331198983e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -9.87318799161585e-07
sam_encoder.blocks.2.norm2.weight grad: -2.0618081180145964e-06
sam_encoder.blocks.2.norm2.bias grad: 1.064758521351905e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -8.103563686745474e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.1807424016296864e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.7988030524284113e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.423956916823954e-07
sam_encoder.blocks.3.norm1.weight grad: -2.41876387008233e-06
sam_encoder.blocks.3.norm1.bias grad: -4.772320153278997e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.158644621085841e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.1578803170996252e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.562272473165649e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -9.379825769428862e-07
sam_encoder.blocks.3.norm2.weight grad: 6.917043265275424e-06
sam_encoder.blocks.3.norm2.bias grad: -5.662999228661647e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.895474830846069e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.4824274785496527e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.469307780003874e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 5.051701919001061e-07
sam_encoder.blocks.4.norm1.weight grad: 1.6138325008796528e-05
sam_encoder.blocks.4.norm1.bias grad: -3.0850558232486947e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 6.466267223004252e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.1951019587286282e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 4.0118811739375815e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.5665502764459234e-06
sam_encoder.blocks.4.norm2.weight grad: -3.716431092470884e-05
sam_encoder.blocks.4.norm2.bias grad: -3.090218888246454e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.5367267880938016e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -9.60011311690323e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.4681190805276856e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 6.183427103678696e-09
sam_encoder.blocks.5.norm1.weight grad: 3.123383066849783e-06
sam_encoder.blocks.5.norm1.bias grad: -6.866373496450251e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -9.444665920455009e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.1084891816135496e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.6944654817052651e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.1778214431833476e-06
sam_encoder.blocks.5.norm2.weight grad: -1.4745439329999499e-05
sam_encoder.blocks.5.norm2.bias grad: -1.9425080608925782e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -6.386202130670426e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.9506292119331192e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 7.218419568744139e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -8.587842330598505e-07
sam_encoder.blocks.6.norm1.weight grad: 4.3737336454796605e-06
sam_encoder.blocks.6.norm1.bias grad: 6.4017344811873045e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.0671889160439605e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.913502766295096e-08
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.9282974790257867e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 8.604638424003497e-07
sam_encoder.blocks.6.norm2.weight grad: -1.6514071830897592e-05
sam_encoder.blocks.6.norm2.bias grad: -4.4398375393939205e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.2274380424059927e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.526045242731925e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.577859961798822e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.7771833427104866e-06
sam_encoder.blocks.7.norm1.weight grad: 9.414387022843584e-06
sam_encoder.blocks.7.norm1.bias grad: 1.3708131518797018e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 6.632568329223432e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.5202325559803285e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.19888340527541e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.494531822274439e-07
sam_encoder.blocks.7.norm2.weight grad: 4.540041118161753e-06
sam_encoder.blocks.7.norm2.bias grad: 2.3979332581802737e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 5.574180249823257e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 9.883082157102763e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.138043542909145e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.693859972983773e-07
sam_encoder.blocks.8.norm1.weight grad: 7.309394277399406e-06
sam_encoder.blocks.8.norm1.bias grad: -3.2196821848629043e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.9108187997480854e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 8.776730169302027e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 4.7175299187074415e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 4.082240593561437e-06
sam_encoder.blocks.8.norm2.weight grad: -6.747702627762919e-07
sam_encoder.blocks.8.norm2.bias grad: -9.184552141050517e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 7.075111052579075e-10
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.512424768814526e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.740825837259763e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.6190928135983995e-06
sam_encoder.blocks.9.norm1.weight grad: 1.6371748188248603e-06
sam_encoder.blocks.9.norm1.bias grad: 5.079356810711033e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.2459363460948225e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.3661677940035588e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 9.94157971945242e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 6.230416147445794e-07
sam_encoder.blocks.9.norm2.weight grad: 2.7762835088651627e-06
sam_encoder.blocks.9.norm2.bias grad: -1.0389957196821342e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.6069823181605898e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.3157672356101102e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 4.917966975881427e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.514000349648995e-07
sam_encoder.blocks.10.norm1.weight grad: 8.082765816652682e-06
sam_encoder.blocks.10.norm1.bias grad: 1.0110987886946532e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 4.893490768154152e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.103576662193518e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.5301239929831354e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.2636032806767616e-06
sam_encoder.blocks.10.norm2.weight grad: 7.120407644833904e-06
sam_encoder.blocks.10.norm2.bias grad: -2.3260479053988092e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 5.025488462706562e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.062837893390679e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 8.438644272246165e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.2469654936685401e-07
sam_encoder.blocks.11.norm1.weight grad: 1.1537089449120685e-05
sam_encoder.blocks.11.norm1.bias grad: 7.205123324638407e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.0982467958674533e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -4.2651626586120983e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.181476702389773e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 8.611167459093849e-07
sam_encoder.blocks.11.norm2.weight grad: 9.16967292141635e-06
sam_encoder.blocks.11.norm2.bias grad: 2.9430219683490577e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.2804692788631655e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.3046141020822688e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.270625251796446e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.3055559239537615e-08
sam_encoder.neck.conv1.trainable_scale grad: 1.1228621588088572e-08
sam_encoder.neck.conv1.trainable_shift grad: -9.51611036725808e-06
sam_encoder.neck.conv2.trainable_scale grad: -6.745431164745241e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.765828528732527e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00010798568109748885
mask_decoder.transformer.layers.0.norm1.bias grad: -2.480390321579762e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003535858355462551
mask_decoder.transformer.layers.0.norm2.bias grad: 8.772156434133649e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -0.0001021777861751616
mask_decoder.transformer.layers.0.norm3.bias grad: -2.6504178094910458e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00011527385504450649
mask_decoder.transformer.layers.0.norm4.bias grad: -2.1671166905434802e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -1.6868216334842145e-07
mask_decoder.transformer.layers.1.norm1.bias grad: 6.244476026040502e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00020448537543416023
mask_decoder.transformer.layers.1.norm2.bias grad: -5.6395347201032564e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 1.7881427993415855e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.2010748832835816e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -7.731769073870964e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00016662487178109586
mask_decoder.transformer.norm_final_attn.weight grad: 8.0644613262848e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.2344760762061924e-05
Text_Embedding_Affine.0.weight grad: -3.1424749954989117e-12
Text_Embedding_Affine.0.bias grad: -7.343656932556897e-12
Text_Embedding_Affine.2.weight grad: 9.524681737760332e-11
Text_Embedding_Affine.2.bias grad: 1.8696906408877112e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07017242908477783

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07017242908477783

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07906246185302734

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.266642689704895

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06931114196777344

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07906246185302734

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 32.34724426269531
Max value: 89.62918090820312
Mean value: 61.94395065307617

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06935685127973557

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06935685127973557

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06935685127973557

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.2523568570613861

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.5450608730316162
Max value: 9.365001678466797
Mean value: 1.0243476629257202

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 32.34724426269531
Max value: 89.62918090820312
Mean value: 61.94395065307617

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.21870803833008
Max value: -62.21870803833008
Mean value: -62.21870803833008
sam_encoder.pos_embed grad: -5.215710530137585e-09
sam_encoder.blocks.0.norm1.weight grad: -1.057013651006855e-05
sam_encoder.blocks.0.norm1.bias grad: -1.928969140863046e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.0199904863839038e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 9.37299432735017e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 9.281717211706564e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.0854370177403325e-06
sam_encoder.blocks.0.norm2.weight grad: 3.1820386539038736e-06
sam_encoder.blocks.0.norm2.bias grad: -6.752229819539934e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.071609221980907e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.2073639936716063e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 4.89457761432277e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.3419012248050421e-06
sam_encoder.blocks.1.norm1.weight grad: -1.8889999182647443e-06
sam_encoder.blocks.1.norm1.bias grad: -4.005883056379389e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 7.266278771567158e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -5.348960598894337e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.554409891468822e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.094328349106945e-07
sam_encoder.blocks.1.norm2.weight grad: -1.9675744624692015e-05
sam_encoder.blocks.1.norm2.bias grad: 5.3703170124208555e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.85748842038447e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.0378528259025188e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -4.0230079321190715e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.178153562544139e-08
sam_encoder.blocks.2.norm1.weight grad: -1.7180869690491818e-05
sam_encoder.blocks.2.norm1.bias grad: -3.1638228392694145e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.8632384808370261e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -8.730596618988784e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.43893417873187e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 4.78667516290443e-07
sam_encoder.blocks.2.norm2.weight grad: -9.912117093335837e-06
sam_encoder.blocks.2.norm2.bias grad: 9.004093953990377e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.2186859521534643e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -5.387586838878633e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -5.1809615797537845e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.4258870351113728e-06
sam_encoder.blocks.3.norm1.weight grad: 1.4100248336035293e-05
sam_encoder.blocks.3.norm1.bias grad: -2.665071951923892e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 7.478182851627935e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.117442818416748e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.5212862081170897e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.4294726230777997e-08
sam_encoder.blocks.3.norm2.weight grad: -1.0490206477697939e-05
sam_encoder.blocks.3.norm2.bias grad: -1.6129248251672834e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.0657764505594969e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -6.4632963585609104e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.1655902198981494e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.7446016045141732e-06
sam_encoder.blocks.4.norm1.weight grad: -1.3539505744120106e-05
sam_encoder.blocks.4.norm1.bias grad: -2.8384863981045783e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.3515832506527659e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.0358924050233327e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.1958253480770509e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.084209083681344e-06
sam_encoder.blocks.4.norm2.weight grad: -6.6396382862876635e-06
sam_encoder.blocks.4.norm2.bias grad: 2.823691602316103e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.422401851414179e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.0685501905527417e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.0479944851103937e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.6894490499907988e-06
sam_encoder.blocks.5.norm1.weight grad: -8.681687177158892e-06
sam_encoder.blocks.5.norm1.bias grad: -2.5401790480827913e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.29595365858404e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 5.475795660458971e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.9433001600409625e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.724281671362405e-07
sam_encoder.blocks.5.norm2.weight grad: 1.3151415600987093e-07
sam_encoder.blocks.5.norm2.bias grad: -1.55645830091089e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.1732311072119046e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 3.0462319955404382e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.1821515474584885e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.7787826891435543e-06
sam_encoder.blocks.6.norm1.weight grad: 1.0984414075210225e-05
sam_encoder.blocks.6.norm1.bias grad: 6.895960723340977e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 6.960779046494281e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.6975682228803635e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.4284929622808704e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.630414999453933e-06
sam_encoder.blocks.6.norm2.weight grad: -2.4412860511802137e-05
sam_encoder.blocks.6.norm2.bias grad: -1.1712577361322474e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.4465707863564603e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.489786078920588e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -3.370543254277436e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.512782657504431e-06
sam_encoder.blocks.7.norm1.weight grad: 1.2079057341907173e-05
sam_encoder.blocks.7.norm1.bias grad: 1.0517444479773985e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 8.234273082052823e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 3.983735041401815e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.3218618682440137e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.264104407207924e-06
sam_encoder.blocks.7.norm2.weight grad: 3.107970314886188e-06
sam_encoder.blocks.7.norm2.bias grad: -1.3378837593336357e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.1033857845177408e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.192643362126546e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 7.122623060240585e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.7317772694223095e-07
sam_encoder.blocks.8.norm1.weight grad: 1.0278386980644427e-05
sam_encoder.blocks.8.norm1.bias grad: -7.387712230411125e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.1171785445185378e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.6987129280751105e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 4.232549144944642e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 5.39890334039228e-06
sam_encoder.blocks.8.norm2.weight grad: 4.916118996334262e-06
sam_encoder.blocks.8.norm2.bias grad: -1.9412407255003927e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.419664840796031e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.0537622756601195e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 4.0906672893470386e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.4221711808204418e-07
sam_encoder.blocks.9.norm1.weight grad: -4.468153292691568e-06
sam_encoder.blocks.9.norm1.bias grad: 5.892105718885432e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.4242166293552145e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -3.1357180318991595e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -6.63416017232521e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.4063180060475133e-06
sam_encoder.blocks.9.norm2.weight grad: 1.483688492953661e-06
sam_encoder.blocks.9.norm2.bias grad: -1.4355625808093464e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.0500747293917811e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.91619005818211e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -6.139031825114216e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -9.061373020813335e-07
sam_encoder.blocks.10.norm1.weight grad: 6.037996172381099e-06
sam_encoder.blocks.10.norm1.bias grad: 6.870297397654213e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.0076749933650717e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 3.406123028071306e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.9019337287318194e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.6591756093475851e-06
sam_encoder.blocks.10.norm2.weight grad: 1.1780647582781967e-05
sam_encoder.blocks.10.norm2.bias grad: 1.236547859662096e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.959774287272012e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 8.953394399213721e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.4860921712388517e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 3.453541808084992e-07
sam_encoder.blocks.11.norm1.weight grad: 4.003251433459809e-06
sam_encoder.blocks.11.norm1.bias grad: 8.035098062464385e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -7.940219802549109e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.4479246601695195e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.4944665949201408e-08
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.0942009112113738e-06
sam_encoder.blocks.11.norm2.weight grad: 6.338674211292528e-06
sam_encoder.blocks.11.norm2.bias grad: -6.214980203367304e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 5.916441295994446e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 7.686575713705679e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 9.376084335599444e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 7.012098421910196e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.330017767031677e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.4819273928878829e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.0451185517013073e-06
sam_encoder.neck.conv2.trainable_shift grad: -5.6029544794000685e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -4.666107633966021e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 4.999878001399338e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0016678718384355307
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0005057693924754858
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00016120003419928253
mask_decoder.transformer.layers.0.norm3.bias grad: -6.484086043201387e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -1.1759742847061716e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 6.105660759203602e-07
mask_decoder.transformer.layers.1.norm1.weight grad: -5.3514311730396e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.1648808140307665e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00013501729699783027
mask_decoder.transformer.layers.1.norm2.bias grad: -8.489680476486683e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 6.761288386769593e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.7109794498537667e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 0.00014109647599980235
mask_decoder.transformer.layers.1.norm4.bias grad: 5.794195749331266e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.1027640539396089e-05
mask_decoder.transformer.norm_final_attn.bias grad: 2.2602212993660942e-05
Text_Embedding_Affine.0.weight grad: -1.7279414010751282e-11
Text_Embedding_Affine.0.bias grad: -1.259009119181087e-09
Text_Embedding_Affine.2.weight grad: 5.031829813928468e-11
Text_Embedding_Affine.2.bias grad: -4.9106347432825714e-05
Epoch 7 finished with average loss: -63.4444
Epoch 8/39
----------
Epoch 8:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 8:   0%|          | 0/3 [00:00<?, ?it/s, loss=-68.9]Epoch 8:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.15it/s, loss=-68.9]Epoch 8:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.15it/s, loss=-67]  Epoch 8:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.73it/s, loss=-67]Epoch 8:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.73it/s, loss=-67.1]Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.39it/s, loss=-67.1]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07557214051485062

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07557214051485062

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07977676391601562

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.21752645075321198

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07576179504394531

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07977676391601562

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 57.23752975463867
Max value: 83.68571472167969
Mean value: 68.94578552246094

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07557214051485062

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07557214051485062

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07557214051485062

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.21752645075321198

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 57.23752975463867
Max value: 83.68571472167969
Mean value: 68.94578552246094

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.94606018066406
Max value: -68.94606018066406
Mean value: -68.94606018066406
sam_encoder.pos_embed grad: -2.9644011689811123e-09
sam_encoder.blocks.0.norm1.weight grad: 1.0737966476881411e-05
sam_encoder.blocks.0.norm1.bias grad: 2.686656080186367e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.547538886370603e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.5374861561667785e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.31066667563573e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.435702637943905e-07
sam_encoder.blocks.0.norm2.weight grad: 1.2643322406802326e-05
sam_encoder.blocks.0.norm2.bias grad: 1.5870995412115008e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -5.350131687009707e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.5922814782243222e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.0254101653117687e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.233809820812894e-06
sam_encoder.blocks.1.norm1.weight grad: -3.1296719953388674e-06
sam_encoder.blocks.1.norm1.bias grad: -3.76554521608341e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.724568498204462e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.6852138742251555e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.606869879353326e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.7878547825821443e-06
sam_encoder.blocks.1.norm2.weight grad: 4.231863840686856e-06
sam_encoder.blocks.1.norm2.bias grad: 9.629828809920582e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.961811105706147e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.612249426827475e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 3.9867077248345595e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.052567739634469e-07
sam_encoder.blocks.2.norm1.weight grad: 6.222477168194018e-06
sam_encoder.blocks.2.norm1.bias grad: -1.1543837672434165e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.945253749610856e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.3526135944630369e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.4785090317891445e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 7.680361591155815e-07
sam_encoder.blocks.2.norm2.weight grad: 4.2192218074887933e-07
sam_encoder.blocks.2.norm2.bias grad: -4.677727702073753e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.61095192652283e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.488045029418572e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.0165938419959275e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.030359145370312e-08
sam_encoder.blocks.3.norm1.weight grad: -4.989960871171206e-07
sam_encoder.blocks.3.norm1.bias grad: -1.5112152595975203e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.34399236534955e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 5.670218428122098e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 5.906251203668944e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.0054063750430942e-06
sam_encoder.blocks.3.norm2.weight grad: 4.898310635326197e-06
sam_encoder.blocks.3.norm2.bias grad: 2.5643075787229463e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 3.2750717764429282e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.0328890311939176e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.591897433987469e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.3764497452939395e-07
sam_encoder.blocks.4.norm1.weight grad: 2.7979156129731564e-06
sam_encoder.blocks.4.norm1.bias grad: 3.0206974770408124e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 8.843616683407163e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.7187155044193787e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.3455810403684154e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.3447349829220911e-06
sam_encoder.blocks.4.norm2.weight grad: -8.643452019896358e-06
sam_encoder.blocks.4.norm2.bias grad: -8.241670911957044e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.801222869195044e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.368446303080418e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -5.706099273083964e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.449896889331285e-07
sam_encoder.blocks.5.norm1.weight grad: -4.602982698997948e-06
sam_encoder.blocks.5.norm1.bias grad: -1.065004425981897e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.5712032513401937e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.8742183556241798e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.3937476473511197e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -4.3522582870991755e-08
sam_encoder.blocks.5.norm2.weight grad: -4.00104090658715e-06
sam_encoder.blocks.5.norm2.bias grad: -5.146417151991045e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.3918624972575344e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -4.911465794066316e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -3.342516947668628e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -8.182020678759727e-07
sam_encoder.blocks.6.norm1.weight grad: -5.699723715224536e-07
sam_encoder.blocks.6.norm1.bias grad: 1.8492572735340218e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -9.03852196643129e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -9.200518888974329e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 4.921217851006077e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 7.625328635185724e-08
sam_encoder.blocks.6.norm2.weight grad: -2.0701227185782045e-06
sam_encoder.blocks.6.norm2.bias grad: -2.04312911478155e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.0565333923295839e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -7.994643738129525e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.3528870940481283e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.597887368618103e-07
sam_encoder.blocks.7.norm1.weight grad: 1.6629767287668074e-06
sam_encoder.blocks.7.norm1.bias grad: 7.067549177008914e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.4386046132131014e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 5.421783839665295e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 9.767602477950277e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -8.952173402576591e-07
sam_encoder.blocks.7.norm2.weight grad: 3.636429028119892e-06
sam_encoder.blocks.7.norm2.bias grad: 1.4455315522354795e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.1007618872536113e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 7.574917617603205e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.889691354037495e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.06701632932527e-07
sam_encoder.blocks.8.norm1.weight grad: 1.9037743186345324e-06
sam_encoder.blocks.8.norm1.bias grad: -2.3580939512157784e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.222415448864922e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.7198155433106876e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.0671720903919777e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.2540466514110449e-06
sam_encoder.blocks.8.norm2.weight grad: 1.6227422747761011e-06
sam_encoder.blocks.8.norm2.bias grad: -8.14501817103519e-08
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.4570281337000779e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 7.01796921021014e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -4.32545533612938e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.270956080494216e-07
sam_encoder.blocks.9.norm1.weight grad: -1.6323635918524815e-06
sam_encoder.blocks.9.norm1.bias grad: 5.098737574371626e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -9.6045346253959e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.422280829250667e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.3945485477506736e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.4999120518696145e-07
sam_encoder.blocks.9.norm2.weight grad: 2.6348761821282096e-06
sam_encoder.blocks.9.norm2.bias grad: -5.399731435318245e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.5096783247136045e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.0132329180123634e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.672034386501764e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.8387034944898915e-07
sam_encoder.blocks.10.norm1.weight grad: 2.4566777483414626e-06
sam_encoder.blocks.10.norm1.bias grad: 3.034378721622488e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.0809682155231712e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 9.274478429688315e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.177151261799736e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 7.667680392842158e-07
sam_encoder.blocks.10.norm2.weight grad: 1.3052989515927038e-06
sam_encoder.blocks.10.norm2.bias grad: -1.2756138403346995e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.9609537957876455e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.8888378860992816e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -4.3434664576125215e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.643492109655199e-07
sam_encoder.blocks.11.norm1.weight grad: 8.563352821511216e-06
sam_encoder.blocks.11.norm1.bias grad: -1.4013039617566392e-09
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.1809960293903714e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.6297349247906823e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.410425625181233e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 7.648143309779698e-07
sam_encoder.blocks.11.norm2.weight grad: 2.629132495712838e-06
sam_encoder.blocks.11.norm2.bias grad: -4.994280402570439e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.9485181585187092e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.4807064019350946e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -4.2677888245634676e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.285147880978002e-08
sam_encoder.neck.conv1.trainable_scale grad: -5.06544438394485e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.4261953512905166e-06
sam_encoder.neck.conv2.trainable_scale grad: -5.389974830904976e-07
sam_encoder.neck.conv2.trainable_shift grad: 3.3018211979651824e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00016637874068692327
mask_decoder.transformer.layers.0.norm1.bias grad: -1.4149372873362154e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0013367647770792246
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0002659327583387494
mask_decoder.transformer.layers.0.norm3.weight grad: -2.3731830879114568e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.2709845072531607e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 5.676306682289578e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.8361788534093648e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 2.6184050511801615e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -7.835587894078344e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 1.0804942576214671e-06
mask_decoder.transformer.layers.1.norm2.bias grad: 2.0563893485814333e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.674874667718541e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.108121745754033e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.5735242413938977e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00010335366823710501
mask_decoder.transformer.norm_final_attn.weight grad: 6.29795431450475e-06
mask_decoder.transformer.norm_final_attn.bias grad: 7.1114927777671255e-06
Text_Embedding_Affine.0.weight grad: -1.0813713639812317e-11
Text_Embedding_Affine.0.bias grad: -3.6529312907873646e-10
Text_Embedding_Affine.2.weight grad: -7.113979544337568e-13
Text_Embedding_Affine.2.bias grad: 9.915951522998512e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07705828547477722

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07705828547477722

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0852055549621582

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.24336273968219757

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07625579833984375

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0852055549621582

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 42.182891845703125
Max value: 93.65483856201172
Mean value: 64.79158020019531

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07677073776721954

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07677073776721954

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07677073776721954

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.235109344124794

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.794603168964386
Max value: 5.005037784576416
Mean value: 1.0106815099716187

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 42.182891845703125
Max value: 93.65483856201172
Mean value: 64.79158020019531

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.09017944335938
Max value: -65.09017944335938
Mean value: -65.09017944335938
sam_encoder.pos_embed grad: -2.5319673024881695e-09
sam_encoder.blocks.0.norm1.weight grad: 3.3054336654458893e-06
sam_encoder.blocks.0.norm1.bias grad: 3.355161607032642e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.00902308683726e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.5846110080228755e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.1303500286885537e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.5959442357125226e-07
sam_encoder.blocks.0.norm2.weight grad: 2.2835793060949072e-05
sam_encoder.blocks.0.norm2.bias grad: 3.248080611228943e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.4698707673233002e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.2496775525505655e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.1302274288027547e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.2757629974657902e-06
sam_encoder.blocks.1.norm1.weight grad: -9.875786417978816e-06
sam_encoder.blocks.1.norm1.bias grad: -5.121573394717416e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.0382808543217834e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 4.792576078216371e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.952685124706477e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.0959438441204838e-06
sam_encoder.blocks.1.norm2.weight grad: 1.2329829587542918e-05
sam_encoder.blocks.1.norm2.bias grad: -2.2424540020438144e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.813198185933288e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.3527127293855301e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 5.7987617765320465e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 4.441736791704898e-07
sam_encoder.blocks.2.norm1.weight grad: -1.4995866877143271e-06
sam_encoder.blocks.2.norm1.bias grad: -2.0530274014163297e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.9741653431992745e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 3.842710611934308e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.6594339058428886e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 5.9843427990813325e-09
sam_encoder.blocks.2.norm2.weight grad: 1.997947720155935e-06
sam_encoder.blocks.2.norm2.bias grad: -1.8119440028385725e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 2.8001718419545796e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.2034760743517836e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 9.146757520284154e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.3930988390929997e-07
sam_encoder.blocks.3.norm1.weight grad: -3.4363201848464087e-06
sam_encoder.blocks.3.norm1.bias grad: -3.301033530078712e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.6814191187440883e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.256461068052886e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -7.164838962125941e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 7.877392249611148e-07
sam_encoder.blocks.3.norm2.weight grad: 7.976106644491665e-06
sam_encoder.blocks.3.norm2.bias grad: 3.62966693501221e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.0145845307270065e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.3497823374564177e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 8.429643685303745e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -4.702183105109725e-07
sam_encoder.blocks.4.norm1.weight grad: 3.819171467966953e-07
sam_encoder.blocks.4.norm1.bias grad: 3.689610537094268e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.3636806051617896e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 6.921028727902012e-08
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.2539675253719906e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.991678573176614e-06
sam_encoder.blocks.4.norm2.weight grad: -8.415328920818865e-06
sam_encoder.blocks.4.norm2.bias grad: -1.1730267942766659e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -6.816875156800961e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.6910736323770834e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.616198682721006e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.670433094768669e-07
sam_encoder.blocks.5.norm1.weight grad: -6.882975867483765e-06
sam_encoder.blocks.5.norm1.bias grad: -7.052635737636592e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -6.2218114180723205e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.596408876343048e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -7.538817214935989e-08
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -8.39471681501891e-07
sam_encoder.blocks.5.norm2.weight grad: -1.6040975197029184e-06
sam_encoder.blocks.5.norm2.bias grad: -7.078143426042516e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 2.3373729618469952e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.460487908389041e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.865453438971599e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -6.662465921181138e-07
sam_encoder.blocks.6.norm1.weight grad: -2.8715703592752106e-06
sam_encoder.blocks.6.norm1.bias grad: 4.3892504208997707e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.4314456368301762e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.1803465440607397e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.263361752990022e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.3550627992772206e-07
sam_encoder.blocks.6.norm2.weight grad: -1.5000730400061002e-06
sam_encoder.blocks.6.norm2.bias grad: -2.659970732565853e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.3169853900762973e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -8.642272177894483e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.0368739462337544e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -3.4431030826453934e-07
sam_encoder.blocks.7.norm1.weight grad: -1.0183898666582536e-06
sam_encoder.blocks.7.norm1.bias grad: 8.3720885868388e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -4.148087953126378e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.920189956512331e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 5.205959041632013e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.0881287835218245e-06
sam_encoder.blocks.7.norm2.weight grad: 5.376939952839166e-06
sam_encoder.blocks.7.norm2.bias grad: -2.302189585634551e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.4254633192176698e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.0452810101924115e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.775027946379851e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.384192149904266e-07
sam_encoder.blocks.8.norm1.weight grad: 1.1184786217199871e-06
sam_encoder.blocks.8.norm1.bias grad: -6.496620699181221e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.192182530005084e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -6.88076113419811e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.877673184935702e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.3233938034318271e-06
sam_encoder.blocks.8.norm2.weight grad: -9.514909606878064e-07
sam_encoder.blocks.8.norm2.bias grad: -9.140444490185473e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.2884619309261325e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -6.891455086588394e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.5019638794910861e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -8.513130751452991e-07
sam_encoder.blocks.9.norm1.weight grad: -3.629159436968621e-06
sam_encoder.blocks.9.norm1.bias grad: 5.670630116583197e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.0704109121870715e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -6.696715217913152e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.197342491352174e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.490881100442493e-07
sam_encoder.blocks.9.norm2.weight grad: 6.805015573263518e-07
sam_encoder.blocks.9.norm2.bias grad: -1.3050151892457507e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 5.375964633458352e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.1273839578839215e-08
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -9.091766060009832e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -8.245505114246043e-07
sam_encoder.blocks.10.norm1.weight grad: 1.7807694803195773e-06
sam_encoder.blocks.10.norm1.bias grad: 2.7848273020936176e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.4037913160791504e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.338495381896792e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.106899844671716e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.573524504143279e-07
sam_encoder.blocks.10.norm2.weight grad: -1.6554694184378604e-06
sam_encoder.blocks.10.norm2.bias grad: -2.6967279609380057e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.334849623115588e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.575013458132162e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.6784936178737553e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -8.713459465070628e-07
sam_encoder.blocks.11.norm1.weight grad: 7.811858267814387e-06
sam_encoder.blocks.11.norm1.bias grad: 3.3639770435911487e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.768254543956573e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.892182979190693e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.9138601601298433e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.042774556481163e-06
sam_encoder.blocks.11.norm2.weight grad: -4.86778787944786e-07
sam_encoder.blocks.11.norm2.bias grad: -2.1624425698973937e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.5603886822646018e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.508509962557582e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.2846238632846507e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.182152792964189e-07
sam_encoder.neck.conv1.trainable_scale grad: -6.387544999597594e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.8885904864873737e-05
sam_encoder.neck.conv2.trainable_scale grad: -9.085260899155401e-07
sam_encoder.neck.conv2.trainable_shift grad: 3.4378856071271e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00014264816127251834
mask_decoder.transformer.layers.0.norm1.bias grad: 4.397334123495966e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0023491366300731897
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00021564261987805367
mask_decoder.transformer.layers.0.norm3.weight grad: -4.347252252046019e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 6.700702215312049e-07
mask_decoder.transformer.layers.0.norm4.weight grad: 8.062603592406958e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -4.521564278547885e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.0026345232035965e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.2582859199028462e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 7.230651681311429e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 6.492149259429425e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.566662730416283e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.933095624437556e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 1.894848173833452e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00013453770952764899
mask_decoder.transformer.norm_final_attn.weight grad: 8.195974260161165e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.2104603229090571e-05
Text_Embedding_Affine.0.weight grad: -1.466934386462615e-11
Text_Embedding_Affine.0.bias grad: -4.0933090250661053e-10
Text_Embedding_Affine.2.weight grad: 4.731319502848663e-13
Text_Embedding_Affine.2.bias grad: 1.1751038073271047e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.051607665760154e-39
Max value: 1.0
Mean value: 0.08388454467058182

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.051607665760154e-39
Max value: 1.0
Mean value: 0.08388454467058182

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08897018432617188

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.21787846088409424

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08325004577636719

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08897018432617188

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 61.59609603881836
Max value: 80.97766876220703
Mean value: 66.78585815429688

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.552325492992453e-34
Max value: 1.0
Mean value: 0.08224278688430786

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.552325492992453e-34
Max value: 1.0
Mean value: 0.08224278688430786

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.552325492992453e-34
Max value: 1.0
Mean value: 0.08224278688430786

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1994306445121765

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.7661799192428589
Max value: 19.123268127441406
Mean value: 1.0339667797088623

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 61.59609603881836
Max value: 80.97766876220703
Mean value: 66.78585815429688

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -67.1427001953125
Max value: -67.1427001953125
Mean value: -67.1427001953125
sam_encoder.pos_embed grad: -4.586819812857357e-09
sam_encoder.blocks.0.norm1.weight grad: 4.57907808595337e-05
sam_encoder.blocks.0.norm1.bias grad: 2.717602728807833e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.7424724774173228e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 8.223329928114254e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.7987039768740942e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.846950681283488e-06
sam_encoder.blocks.0.norm2.weight grad: -2.9413144147838466e-05
sam_encoder.blocks.0.norm2.bias grad: 4.086088210897287e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.4077289961278439e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -7.677413123019505e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 5.989384135318687e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.359399443070288e-06
sam_encoder.blocks.1.norm1.weight grad: -1.70902148965979e-06
sam_encoder.blocks.1.norm1.bias grad: 1.0050211130874231e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.018398380547296e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.1132676667766646e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.315174348652363e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.405109171377262e-06
sam_encoder.blocks.1.norm2.weight grad: 9.063024663191754e-06
sam_encoder.blocks.1.norm2.bias grad: -5.299636541167274e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.878696472587762e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.859365793028701e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 4.426718987815548e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -5.666752258548513e-07
sam_encoder.blocks.2.norm1.weight grad: -4.368739610072225e-06
sam_encoder.blocks.2.norm1.bias grad: -2.6149932637054008e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.128279215365183e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -8.337544841197086e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.175537469564006e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.511831320996862e-06
sam_encoder.blocks.2.norm2.weight grad: -5.2324699026939925e-06
sam_encoder.blocks.2.norm2.bias grad: -5.2523682825267315e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 4.917907858725812e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.317670808020921e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 8.433162292931229e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -4.88545026655629e-07
sam_encoder.blocks.3.norm1.weight grad: -4.909938979835715e-06
sam_encoder.blocks.3.norm1.bias grad: -6.6517986851977184e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.5961011235485785e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.7248061112695723e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.2047928521496942e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 4.84228053210245e-07
sam_encoder.blocks.3.norm2.weight grad: 3.6350663776829606e-06
sam_encoder.blocks.3.norm2.bias grad: -1.0411640687379986e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.7131523009084049e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -5.090015520181623e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.94786649546586e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.8985396081916406e-06
sam_encoder.blocks.4.norm1.weight grad: 7.147607448132476e-06
sam_encoder.blocks.4.norm1.bias grad: -8.539214832126163e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 4.922504786009085e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 6.803556971135549e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 8.710325687388831e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.8152165637275175e-07
sam_encoder.blocks.4.norm2.weight grad: -1.625834556762129e-05
sam_encoder.blocks.4.norm2.bias grad: -1.0157720680581406e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.0687071153370198e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.894351721100975e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.977177584602032e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.1651197837636573e-06
sam_encoder.blocks.5.norm1.weight grad: 1.0586193639028352e-05
sam_encoder.blocks.5.norm1.bias grad: -9.112470252148341e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.909963303769473e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.7530704781165696e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.8472355804988183e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.814901679608738e-06
sam_encoder.blocks.5.norm2.weight grad: -1.1897489002876682e-06
sam_encoder.blocks.5.norm2.bias grad: -2.41417774304864e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.29772911350301e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -6.458275834120286e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.0955064883310115e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 8.455296551801439e-07
sam_encoder.blocks.6.norm1.weight grad: 6.128771019575652e-06
sam_encoder.blocks.6.norm1.bias grad: 4.7294059868363547e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.16870670960634e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.604096041774028e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.120323642884614e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.0290933662181487e-06
sam_encoder.blocks.6.norm2.weight grad: 7.208082024590112e-07
sam_encoder.blocks.6.norm2.bias grad: -1.2095631518604932e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 5.74733121538884e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.448708755764528e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.859812866518041e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.0931387350865407e-06
sam_encoder.blocks.7.norm1.weight grad: 2.582555453045643e-06
sam_encoder.blocks.7.norm1.bias grad: 6.000553867124836e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 9.075924936041702e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 3.8173959637788357e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.7938373275683261e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.8678750848266645e-06
sam_encoder.blocks.7.norm2.weight grad: -5.890288775844965e-06
sam_encoder.blocks.7.norm2.bias grad: 7.754244393254339e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.412721298445831e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.2515437194670085e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.662430903110362e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 5.341301445582758e-08
sam_encoder.blocks.8.norm1.weight grad: -8.701289857526717e-07
sam_encoder.blocks.8.norm1.bias grad: -6.58504404782434e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.991847168232198e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -5.078210278952611e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.285406480950769e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -9.665659490565304e-07
sam_encoder.blocks.8.norm2.weight grad: -3.302298637208878e-06
sam_encoder.blocks.8.norm2.bias grad: -1.2117764072172577e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.4484096431697253e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.9619442355178762e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -8.11582481219375e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.0780156496111886e-07
sam_encoder.blocks.9.norm1.weight grad: 2.0006198155897437e-06
sam_encoder.blocks.9.norm1.bias grad: 1.1671167143845196e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 8.425989790339372e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.0515334376323153e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 3.2280649975291453e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.0678644457584596e-06
sam_encoder.blocks.9.norm2.weight grad: 3.9226841863637674e-07
sam_encoder.blocks.9.norm2.bias grad: 2.355962124056532e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.1817792255897075e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 9.062491699296515e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 8.181126531781047e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 3.72694834993581e-08
sam_encoder.blocks.10.norm1.weight grad: 2.8698973437712993e-06
sam_encoder.blocks.10.norm1.bias grad: 8.24347694106109e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.3508242773241363e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.9396312584140105e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.4838652734615607e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.2748481260114204e-08
sam_encoder.blocks.10.norm2.weight grad: 3.813195689872373e-06
sam_encoder.blocks.10.norm2.bias grad: 4.043884018756216e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.6003377822926268e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 8.333164487339673e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 3.0278869189714896e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.5706199008036492e-07
sam_encoder.blocks.11.norm1.weight grad: 1.422836612618994e-05
sam_encoder.blocks.11.norm1.bias grad: 2.949456757050939e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.226075139333261e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.529430376962409e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 5.959699365121196e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -5.652585173265834e-07
sam_encoder.blocks.11.norm2.weight grad: 1.6832782421261072e-06
sam_encoder.blocks.11.norm2.bias grad: 1.7967188341572182e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.0284186373610282e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 8.245396543316019e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 4.191982441170694e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.515541185881375e-07
sam_encoder.neck.conv1.trainable_scale grad: 9.833988769969437e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.5845853340579197e-06
sam_encoder.neck.conv2.trainable_scale grad: 7.229027687571943e-08
sam_encoder.neck.conv2.trainable_shift grad: -9.60845427471213e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 9.397219400852919e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 5.278270691633224e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0008680382743477821
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0006221102084964514
mask_decoder.transformer.layers.0.norm3.weight grad: -5.788836278952658e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.30299228860531e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 1.6560919902985916e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 3.4361764846835285e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -2.789884092635475e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 6.389754162228201e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00015729584265500307
mask_decoder.transformer.layers.1.norm2.bias grad: -8.533312939107418e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.2540393981907982e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -4.207875826978125e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.5845898815314285e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -5.427124779089354e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.5009375147201354e-06
mask_decoder.transformer.norm_final_attn.bias grad: 6.12540998190525e-06
Text_Embedding_Affine.0.weight grad: 7.31053238778312e-13
Text_Embedding_Affine.0.bias grad: 7.881419128441536e-11
Text_Embedding_Affine.2.weight grad: -7.656504596997848e-11
Text_Embedding_Affine.2.bias grad: -2.1038575141574256e-05
Epoch 8 finished with average loss: -67.0596
Epoch 9/39
----------
Epoch 9:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 9:   0%|          | 0/3 [00:00<?, ?it/s, loss=-64.1]Epoch 9:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.07it/s, loss=-64.1]Epoch 9:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.07it/s, loss=-66.9]Epoch 9:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-66.9]Epoch 9:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-64.1]Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.30it/s, loss=-64.1]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
                                                                  
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07155443727970123

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07155443727970123

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07647466659545898

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1658235639333725

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07037687301635742

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07647466659545898

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 56.62107467651367
Max value: 76.88262176513672
Mean value: 64.09884643554688

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07155443727970123

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07155443727970123

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07155443727970123

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1658235639333725

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 56.62107467651367
Max value: 76.88262176513672
Mean value: 64.09884643554688

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.0992660522461
Max value: -64.0992660522461
Mean value: -64.0992660522461
sam_encoder.pos_embed grad: -3.5246781049380616e-09
sam_encoder.blocks.0.norm1.weight grad: 1.6182451872737147e-05
sam_encoder.blocks.0.norm1.bias grad: 1.2468137356336229e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.8079451820085524e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.852429676318934e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.929564056510571e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.5638306649634615e-08
sam_encoder.blocks.0.norm2.weight grad: 2.3419465833285358e-06
sam_encoder.blocks.0.norm2.bias grad: 1.8055019609164447e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -8.910514225135557e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.3974484975042287e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -9.935692105500493e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.867919531330699e-06
sam_encoder.blocks.1.norm1.weight grad: -2.4436340027023107e-06
sam_encoder.blocks.1.norm1.bias grad: -6.356531230267137e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 5.086245437269099e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.0287948245822918e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 5.482648248289479e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.1115255296754185e-06
sam_encoder.blocks.1.norm2.weight grad: 8.106785571726505e-06
sam_encoder.blocks.1.norm2.bias grad: 3.239275201849523e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.13078884978313e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 9.754938901096466e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 5.842111931997351e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 4.6923568675083516e-07
sam_encoder.blocks.2.norm1.weight grad: 5.894198238820536e-06
sam_encoder.blocks.2.norm1.bias grad: -1.7847610251919832e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 5.651828814734472e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.6692446251909132e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 3.1038414363138145e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.6182582385226851e-06
sam_encoder.blocks.2.norm2.weight grad: -1.6621246459180838e-06
sam_encoder.blocks.2.norm2.bias grad: 2.805951908158022e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.9426693143032026e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.3755798628808407e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.8818020635080757e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 2.4410380206063564e-07
sam_encoder.blocks.3.norm1.weight grad: -4.468050065042917e-06
sam_encoder.blocks.3.norm1.bias grad: -3.582728822948411e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.042325478323619e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.489755956958106e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.0601966096146498e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.5153431149883545e-06
sam_encoder.blocks.3.norm2.weight grad: 5.6846620282158256e-06
sam_encoder.blocks.3.norm2.bias grad: 5.1983242883579805e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.897647158941254e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.5173767451415188e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.834431714087259e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.7440884764473594e-07
sam_encoder.blocks.4.norm1.weight grad: 2.491491613909602e-06
sam_encoder.blocks.4.norm1.bias grad: 3.1881652375886915e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 3.7262358887346636e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.4742888626860804e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.4626446045440389e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.8756003328235238e-06
sam_encoder.blocks.4.norm2.weight grad: -4.526521024672547e-06
sam_encoder.blocks.4.norm2.bias grad: -5.71868076804094e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.908509941335069e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.49619597777928e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.896677469583665e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.541156618462992e-07
sam_encoder.blocks.5.norm1.weight grad: -2.8038971322530415e-06
sam_encoder.blocks.5.norm1.bias grad: 3.7148220144445077e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.3927868824102916e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.5075673900355469e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.8395160117943306e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -6.861679224812178e-08
sam_encoder.blocks.5.norm2.weight grad: -1.4781902564209304e-06
sam_encoder.blocks.5.norm2.bias grad: -4.154107955400832e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.5686824756121496e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.052003142376634e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -2.79612208942126e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -8.748215236664691e-07
sam_encoder.blocks.6.norm1.weight grad: 4.997029350306548e-07
sam_encoder.blocks.6.norm1.bias grad: 1.977802185137989e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.974161361635197e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.527552484503758e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 7.415837899316102e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.7723582358448766e-08
sam_encoder.blocks.6.norm2.weight grad: 5.984256858937442e-07
sam_encoder.blocks.6.norm2.bias grad: 9.20914970947706e-08
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 7.298023518842456e-08
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.4710845991648966e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.7440041233385273e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.7262723278909107e-07
sam_encoder.blocks.7.norm1.weight grad: 2.597166485429625e-06
sam_encoder.blocks.7.norm1.bias grad: 5.710348887077998e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.417597443127306e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.10042287815304e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.3286120292832493e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -5.275409193927771e-07
sam_encoder.blocks.7.norm2.weight grad: 5.323646291799378e-06
sam_encoder.blocks.7.norm2.bias grad: -2.74208105111029e-08
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.83527321901056e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.531198336124362e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.243711207938759e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.6218036686695996e-07
sam_encoder.blocks.8.norm1.weight grad: 1.850317744356289e-06
sam_encoder.blocks.8.norm1.bias grad: -3.7677426689697313e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.3514949159798562e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -4.085387672603247e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.588921688584378e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.6108027693917393e-06
sam_encoder.blocks.8.norm2.weight grad: 2.2903545868757647e-06
sam_encoder.blocks.8.norm2.bias grad: 2.779506758088246e-08
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.7968286556424573e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.2210343811602797e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.402987545086944e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.390338853634603e-07
sam_encoder.blocks.9.norm1.weight grad: -8.863512448442634e-07
sam_encoder.blocks.9.norm1.bias grad: 7.398247703349625e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.7935178675543284e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 6.85020211221854e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.6042479817078856e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -5.707488526240923e-07
sam_encoder.blocks.9.norm2.weight grad: 3.1285635486710817e-06
sam_encoder.blocks.9.norm2.bias grad: -8.620995686214883e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.942056880783639e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.1742956758098444e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.973834961674584e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.692622835340444e-07
sam_encoder.blocks.10.norm1.weight grad: 2.2637620986643014e-06
sam_encoder.blocks.10.norm1.bias grad: 5.408471679402282e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.158564939236385e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.0302150030838675e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.1234042176511139e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.641936352025368e-07
sam_encoder.blocks.10.norm2.weight grad: 3.853464477288071e-06
sam_encoder.blocks.10.norm2.bias grad: -7.045707093311648e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.140419494229718e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 9.448498303754604e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -6.613719847337052e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.552898704128893e-07
sam_encoder.blocks.11.norm1.weight grad: 1.2580490874825045e-05
sam_encoder.blocks.11.norm1.bias grad: -3.97281809227934e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.3211526947998209e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 5.321469416230684e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.744071596476715e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 9.471768862567842e-07
sam_encoder.blocks.11.norm2.weight grad: 4.457131126400782e-06
sam_encoder.blocks.11.norm2.bias grad: -2.1069801903195184e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.476202209640178e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 6.540708454849664e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.421490527623973e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.728140285375048e-08
sam_encoder.neck.conv1.trainable_scale grad: -3.926461431547068e-07
sam_encoder.neck.conv1.trainable_shift grad: -9.059107469511218e-06
sam_encoder.neck.conv2.trainable_scale grad: -4.409394023241475e-07
sam_encoder.neck.conv2.trainable_shift grad: 5.29856224602554e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0001605704746907577
mask_decoder.transformer.layers.0.norm1.bias grad: -9.938376024365425e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0019153633620589972
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00026853533927351236
mask_decoder.transformer.layers.0.norm3.weight grad: -2.6679772417992353e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 9.241944098903332e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 6.157983443699777e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.479488673794549e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.758225855359342e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -4.804896889254451e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -1.871183849289082e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 1.5744793927296996e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.464532710495405e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.236949851270765e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.5938687283778563e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0001107369753299281
mask_decoder.transformer.norm_final_attn.weight grad: 5.788173439214006e-06
mask_decoder.transformer.norm_final_attn.bias grad: 8.646885362395551e-06
Text_Embedding_Affine.0.weight grad: 9.486985849682661e-14
Text_Embedding_Affine.0.bias grad: 3.159875139324697e-11
Text_Embedding_Affine.2.weight grad: -5.691431700927119e-12
Text_Embedding_Affine.2.bias grad: 1.7102282072301023e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08713029325008392

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08713029325008392

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09493207931518555

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.20926588773727417

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0867147445678711

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09493207931518555

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 43.38823699951172
Max value: 89.54428100585938
Mean value: 69.33503723144531

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08678518235683441

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08678518235683441

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08678518235683441

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.201780766248703

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.8693743944168091
Max value: 3.9843673706054688
Mean value: 1.0097606182098389

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 43.38823699951172
Max value: 89.54428100585938
Mean value: 69.33503723144531

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -69.64142608642578
Max value: -69.64142608642578
Mean value: -69.64142608642578
sam_encoder.pos_embed grad: 8.43614678114335e-10
sam_encoder.blocks.0.norm1.weight grad: 4.391187030705623e-05
sam_encoder.blocks.0.norm1.bias grad: 3.533556082402356e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.2777129541063914e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.100088494216834e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -5.255805717752082e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.1264357908657985e-06
sam_encoder.blocks.0.norm2.weight grad: 5.524109838006552e-06
sam_encoder.blocks.0.norm2.bias grad: 2.2985890609561466e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -8.080146471911576e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.0437929631734733e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.7980336199107114e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -6.370061669258575e-07
sam_encoder.blocks.1.norm1.weight grad: -5.146489911567187e-06
sam_encoder.blocks.1.norm1.bias grad: -2.367974730077549e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.047294623887865e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.2655026182528673e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 8.83005554896954e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 7.122509941837052e-07
sam_encoder.blocks.1.norm2.weight grad: -3.610231829043187e-07
sam_encoder.blocks.1.norm2.bias grad: 1.0992189345415682e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.0451666412336635e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.8931350470884354e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.2740614465656108e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.0407286481495248e-06
sam_encoder.blocks.2.norm1.weight grad: -1.5535440525127342e-06
sam_encoder.blocks.2.norm1.bias grad: -3.53137033926032e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.5027252402433078e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 8.265823225883651e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 3.5251207464170875e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.0616416545872198e-07
sam_encoder.blocks.2.norm2.weight grad: 8.291343647215399e-07
sam_encoder.blocks.2.norm2.bias grad: 5.227070687396917e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.5920672922220547e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.390416338788782e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.1204112979612546e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.127847314019164e-07
sam_encoder.blocks.3.norm1.weight grad: -4.59445254819002e-06
sam_encoder.blocks.3.norm1.bias grad: -6.151913112262264e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.5260233087465167e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -8.959680144471349e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.3257974842417752e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.327619969515581e-07
sam_encoder.blocks.3.norm2.weight grad: 2.279550699313404e-06
sam_encoder.blocks.3.norm2.bias grad: -1.208572484756587e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.0955898233078187e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.4459149610956956e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.1332189135137014e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.5175555745372549e-06
sam_encoder.blocks.4.norm1.weight grad: -4.163632638665149e-06
sam_encoder.blocks.4.norm1.bias grad: -7.746034498268273e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -4.8143183448701166e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -8.844501167004637e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -5.870130621588032e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 5.271301120046701e-07
sam_encoder.blocks.4.norm2.weight grad: -3.289482037871494e-06
sam_encoder.blocks.4.norm2.bias grad: -8.958561011240818e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.7371000871644355e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.6557405615458265e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.205560403785057e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -8.538922884326894e-07
sam_encoder.blocks.5.norm1.weight grad: -8.012504622456618e-06
sam_encoder.blocks.5.norm1.bias grad: -8.627270290162414e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -5.5167274695122615e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.6528535979887238e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 5.779704110864259e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.248772936283785e-07
sam_encoder.blocks.5.norm2.weight grad: -3.7795325624756515e-06
sam_encoder.blocks.5.norm2.bias grad: -4.560772595141316e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.1120291674160399e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -8.969512066414609e-08
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.96576024791284e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -6.330203063953377e-07
sam_encoder.blocks.6.norm1.weight grad: -8.534777293789375e-07
sam_encoder.blocks.6.norm1.bias grad: 9.818791113502812e-08
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -9.126229087996762e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.058540631987853e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.311322972076596e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 8.200676120395656e-07
sam_encoder.blocks.6.norm2.weight grad: -3.0882383725838736e-06
sam_encoder.blocks.6.norm2.bias grad: -1.2846664958487963e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.4971799373597605e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -9.968985068553593e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -5.5449696390041936e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.7343755587262422e-07
sam_encoder.blocks.7.norm1.weight grad: 1.277805239396912e-07
sam_encoder.blocks.7.norm1.bias grad: 9.226125143868558e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.626390588986396e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.9853609956044238e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.4749852539353014e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -6.842386710559367e-07
sam_encoder.blocks.7.norm2.weight grad: 2.9938419174868613e-06
sam_encoder.blocks.7.norm2.bias grad: -3.7941043729006196e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.5566843103442807e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 8.272513696283568e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.0084331734105945e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.30514364274859e-07
sam_encoder.blocks.8.norm1.weight grad: 1.0067058155982522e-06
sam_encoder.blocks.8.norm1.bias grad: -7.562206292277551e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.5774104983611323e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -6.476192311311024e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.251009052793961e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.1465550642242306e-06
sam_encoder.blocks.8.norm2.weight grad: -2.6130469450436067e-06
sam_encoder.blocks.8.norm2.bias grad: -1.5352051150330226e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.8707352157653077e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.439548100279353e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.0424859030754305e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.1062662679250934e-06
sam_encoder.blocks.9.norm1.weight grad: -3.951800408685813e-06
sam_encoder.blocks.9.norm1.bias grad: 3.38063841809344e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.995467866639956e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -6.853981631138595e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.31301265532602e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.9334688633753103e-07
sam_encoder.blocks.9.norm2.weight grad: -2.6959219212585595e-06
sam_encoder.blocks.9.norm2.bias grad: -1.8254177120979875e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.4912641290720785e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.1267516129009891e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -9.934287845680956e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -8.270621378869691e-07
sam_encoder.blocks.10.norm1.weight grad: 1.4468955669144634e-06
sam_encoder.blocks.10.norm1.bias grad: -3.3101900953624863e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.2012350225631963e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 3.983927570061496e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.1092879503848962e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 7.738661906842026e-07
sam_encoder.blocks.10.norm2.weight grad: -4.373043339001015e-06
sam_encoder.blocks.10.norm2.bias grad: -2.462040811224142e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.1574934433156159e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.3629123714054003e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.2035293366352562e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.069199341458443e-07
sam_encoder.blocks.11.norm1.weight grad: 4.252823600836564e-06
sam_encoder.blocks.11.norm1.bias grad: 5.20230969414115e-10
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.1363247267581755e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.1747466405486193e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.076672217299347e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.2655289083340904e-06
sam_encoder.blocks.11.norm2.weight grad: -2.6201446416962426e-06
sam_encoder.blocks.11.norm2.bias grad: -1.6271791309918626e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -9.20194196396551e-08
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -6.834868031546648e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.6008368675102247e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.15691397140472e-07
sam_encoder.neck.conv1.trainable_scale grad: -5.494084689416923e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.1917809388251044e-05
sam_encoder.neck.conv2.trainable_scale grad: -4.780358722200617e-07
sam_encoder.neck.conv2.trainable_shift grad: 3.360768096172251e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0001435384328942746
mask_decoder.transformer.layers.0.norm1.bias grad: 2.8847716748714447e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0017594578675925732
mask_decoder.transformer.layers.0.norm2.bias grad: 9.950518142431974e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -2.6566878659650683e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 5.946695637248922e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 7.14199777576141e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.983321908483049e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.329405080876313e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.6087778931250796e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 6.259029760258272e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 4.5387081627268344e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.529701957129873e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.485978570301086e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.772355921682902e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -8.472718764096498e-05
mask_decoder.transformer.norm_final_attn.weight grad: 7.762429959257133e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.2016108485113364e-05
Text_Embedding_Affine.0.weight grad: -4.227561009595426e-12
Text_Embedding_Affine.0.bias grad: -1.8854987016148073e-10
Text_Embedding_Affine.2.weight grad: 9.549141859188648e-12
Text_Embedding_Affine.2.bias grad: 7.804828783264384e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06715065985918045

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06715065985918045

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07606983184814453

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.23517721891403198

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06553268432617188

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07606983184814453

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 42.589210510253906
Max value: 70.08968353271484
Mean value: 58.390193939208984

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06751580536365509

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06751580536365509

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06751580536365509

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.21857604384422302

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.7318297028541565
Max value: 22.672286987304688
Mean value: 1.0289145708084106

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 42.589210510253906
Max value: 70.08968353271484
Mean value: 58.390193939208984

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.69606018066406
Max value: -58.69606018066406
Mean value: -58.69606018066406
sam_encoder.pos_embed grad: 3.702641304670351e-09
sam_encoder.blocks.0.norm1.weight grad: 4.284891110728495e-05
sam_encoder.blocks.0.norm1.bias grad: 8.088632057479117e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.089856232283637e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 6.989447456362541e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 4.4796743168262765e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -4.1393030869585345e-07
sam_encoder.blocks.0.norm2.weight grad: 1.7658796423347667e-05
sam_encoder.blocks.0.norm2.bias grad: -4.3645424739224836e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.9174074623151682e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.756402177008567e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 8.746901585254818e-07
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 5.734627393394476e-06
sam_encoder.blocks.1.norm1.weight grad: -8.390110451728106e-06
sam_encoder.blocks.1.norm1.bias grad: 2.43222484641592e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.3535114703699946e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.967948941863142e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.1949574400205165e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -7.237023055495229e-06
sam_encoder.blocks.1.norm2.weight grad: 2.675901100701594e-07
sam_encoder.blocks.1.norm2.bias grad: 6.274852694332367e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -3.4220645375171443e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -8.565447018327177e-08
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.9334283933858387e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.1723739084554836e-06
sam_encoder.blocks.2.norm1.weight grad: -7.627184459124692e-06
sam_encoder.blocks.2.norm1.bias grad: 5.906925707677146e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -9.351957487524487e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.2263611754169688e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.077558166201925e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.4796830732375383e-06
sam_encoder.blocks.2.norm2.weight grad: 7.309460556825798e-07
sam_encoder.blocks.2.norm2.bias grad: -3.65733239959809e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.1309102774248458e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 4.4943163857169566e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.0287887562299147e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.1673629362339852e-06
sam_encoder.blocks.3.norm1.weight grad: -2.2165193058754085e-06
sam_encoder.blocks.3.norm1.bias grad: -2.622849933686666e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.868870852689724e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.859441795204475e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -6.6934335336554796e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.045555670018075e-06
sam_encoder.blocks.3.norm2.weight grad: -8.005894414964132e-06
sam_encoder.blocks.3.norm2.bias grad: -1.7165541066788137e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -7.1068984652811196e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.4758737708907574e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.7973233045486268e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -9.769300959305838e-07
sam_encoder.blocks.4.norm1.weight grad: 1.7249280972464476e-06
sam_encoder.blocks.4.norm1.bias grad: -2.9252296371851116e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -8.948948106990429e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.1007994632782356e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.5445980302029056e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.0230173706513597e-06
sam_encoder.blocks.4.norm2.weight grad: -1.4902400835126173e-05
sam_encoder.blocks.4.norm2.bias grad: -7.821138751751278e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.1715796063072048e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.4382796911813784e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -8.318839945786749e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.854862479282019e-07
sam_encoder.blocks.5.norm1.weight grad: -7.255756599988672e-07
sam_encoder.blocks.5.norm1.bias grad: -1.307915044890251e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.897952984108997e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.2742832211642963e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.554985141818179e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.5800658275111346e-06
sam_encoder.blocks.5.norm2.weight grad: -3.930910679628141e-06
sam_encoder.blocks.5.norm2.bias grad: -1.8084468820234179e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.9507558540208265e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.1597384173001046e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 9.853208666754654e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.495616051121033e-07
sam_encoder.blocks.6.norm1.weight grad: -2.123195372405462e-06
sam_encoder.blocks.6.norm1.bias grad: -4.869846634392161e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -4.783144618158985e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.878084615076659e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.2305690688663162e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.31055389829271e-06
sam_encoder.blocks.6.norm2.weight grad: -3.222706027372624e-06
sam_encoder.blocks.6.norm2.bias grad: 2.740950321822311e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.1578438210999593e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.5011701179901138e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.516605152573902e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.4544505922440294e-08
sam_encoder.blocks.7.norm1.weight grad: -2.485597178747412e-06
sam_encoder.blocks.7.norm1.bias grad: -9.658351700636558e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -4.237224857206456e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.3504512682848144e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.9033130886091385e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.443526454953826e-06
sam_encoder.blocks.7.norm2.weight grad: 5.1944880397059023e-08
sam_encoder.blocks.7.norm2.bias grad: 2.495326725693303e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.4549002571584424e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.1210233878955478e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.342186178339034e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 3.824028453891515e-07
sam_encoder.blocks.8.norm1.weight grad: 7.295203886314994e-06
sam_encoder.blocks.8.norm1.bias grad: -8.813014460429258e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.217057827801909e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.0388380309886998e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.5272570383094717e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.8642901977727888e-06
sam_encoder.blocks.8.norm2.weight grad: -4.391298716655001e-06
sam_encoder.blocks.8.norm2.bias grad: -2.7898749976884574e-09
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.752794095315039e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.8986719371459913e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.6550037546257954e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.580622541856428e-07
sam_encoder.blocks.9.norm1.weight grad: -1.5642366406609653e-06
sam_encoder.blocks.9.norm1.bias grad: -2.2735246574256962e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.306018359377049e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.3229469004727434e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.628643056203146e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -3.9991931544136605e-07
sam_encoder.blocks.9.norm2.weight grad: -3.4701338336162735e-06
sam_encoder.blocks.9.norm2.bias grad: 1.4431454928853782e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.4688075579178985e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.9501903807395138e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 8.923909433633526e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.497305899851199e-07
sam_encoder.blocks.10.norm1.weight grad: -2.8705303520837333e-06
sam_encoder.blocks.10.norm1.bias grad: -2.95830062668756e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.050310740742134e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -5.613460416498128e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -9.055758596332453e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -4.936593356319463e-08
sam_encoder.blocks.10.norm2.weight grad: -1.0001464033848606e-05
sam_encoder.blocks.10.norm2.bias grad: -3.412094429222634e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -7.21161040928564e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.5492357710609213e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.114841211347084e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -6.389326472344692e-07
sam_encoder.blocks.11.norm1.weight grad: -8.360766514670104e-06
sam_encoder.blocks.11.norm1.bias grad: 1.4282504707807675e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.2041968489029387e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 4.605159915627155e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.3477188076649327e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -6.82636482451926e-07
sam_encoder.blocks.11.norm2.weight grad: -1.1954774890909903e-05
sam_encoder.blocks.11.norm2.bias grad: -2.245952373414184e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -5.704770501324674e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.6833977244677953e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -4.294270183891058e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.854902388411574e-07
sam_encoder.neck.conv1.trainable_scale grad: -7.854641808080487e-07
sam_encoder.neck.conv1.trainable_shift grad: -4.510586222750135e-06
sam_encoder.neck.conv2.trainable_scale grad: -3.937275323551148e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.8701750377658755e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 2.6029649234260432e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 1.2061937013641e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005447741597890854
mask_decoder.transformer.layers.0.norm2.bias grad: 5.47918607480824e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 9.247187699656934e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.3651442208793014e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -6.068376387702301e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.5023379091871902e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 5.410515313997166e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -4.666307631850941e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00022836003336124122
mask_decoder.transformer.layers.1.norm2.bias grad: 7.563222607132047e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 1.4325261872727424e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.8829032342182472e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 8.344111120095477e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 2.1637684767483734e-05
mask_decoder.transformer.norm_final_attn.weight grad: 4.825268206332112e-06
mask_decoder.transformer.norm_final_attn.bias grad: 3.421390374569455e-06
Text_Embedding_Affine.0.weight grad: -2.9692841067852083e-12
Text_Embedding_Affine.0.bias grad: -1.957602135949088e-10
Text_Embedding_Affine.2.weight grad: 5.2017556928518616e-12
Text_Embedding_Affine.2.bias grad: -3.256726995459758e-05
Epoch 9 finished with average loss: -64.1456
Epoch 10/39
----------
Epoch 10:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 10:   0%|          | 0/3 [00:01<?, ?it/s, loss=-61.2]Epoch 10:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.01s/it, loss=-61.2]Epoch 10:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.01s/it, loss=-63.4]Epoch 10:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.58it/s, loss=-63.4]Epoch 10:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.58it/s, loss=-62.6]Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.22it/s, loss=-62.6]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.154840583741374e-36
Max value: 1.0
Mean value: 0.06534002721309662

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.154840583741374e-36
Max value: 1.0
Mean value: 0.06534002721309662

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0687413215637207

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.17283892631530762

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06453895568847656

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0687413215637207

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 51.059906005859375
Max value: 66.81366729736328
Mean value: 61.24110412597656

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.154840583741374e-36
Max value: 1.0
Mean value: 0.06534002721309662

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.154840583741374e-36
Max value: 1.0
Mean value: 0.06534002721309662

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.154840583741374e-36
Max value: 1.0
Mean value: 0.06534002721309662

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.17283892631530762

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 51.059906005859375
Max value: 66.81366729736328
Mean value: 61.24110412597656

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.24144744873047
Max value: -61.24144744873047
Mean value: -61.24144744873047
sam_encoder.pos_embed grad: -4.6197787262336476e-10
sam_encoder.blocks.0.norm1.weight grad: 7.068292688927613e-06
sam_encoder.blocks.0.norm1.bias grad: 2.643886546138674e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.9609516332129715e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.1526454929698957e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.0980867247999413e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.71968332299366e-07
sam_encoder.blocks.0.norm2.weight grad: 4.8918254833552055e-06
sam_encoder.blocks.0.norm2.bias grad: 1.975612758542411e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -5.021052402298665e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 6.635435738644446e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -5.344417786545819e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.342449417687021e-06
sam_encoder.blocks.1.norm1.weight grad: -1.998113475565333e-06
sam_encoder.blocks.1.norm1.bias grad: -5.216864792600973e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 5.028708528698189e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.0442496406758437e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 5.697560482076369e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.2672478482709266e-06
sam_encoder.blocks.1.norm2.weight grad: 3.3378169064235408e-06
sam_encoder.blocks.1.norm2.bias grad: 1.580710886628367e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.073909167345846e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.682405574385484e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 5.963068815617589e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.60414196873171e-07
sam_encoder.blocks.2.norm1.weight grad: 9.25263884710148e-06
sam_encoder.blocks.2.norm1.bias grad: -9.562976401866763e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 6.618279257963877e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.0945071810274385e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 4.035242454847321e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.6096258832476451e-06
sam_encoder.blocks.2.norm2.weight grad: 4.871666305916733e-07
sam_encoder.blocks.2.norm2.bias grad: -1.3210283213993534e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.1588934967221576e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.3168236989713478e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.734617626425461e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.6353952503322944e-07
sam_encoder.blocks.3.norm1.weight grad: -1.1284821539447876e-06
sam_encoder.blocks.3.norm1.bias grad: -3.46991146216169e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.0308328910468845e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 3.940368458188459e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.1403833468648372e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.7183854197355686e-06
sam_encoder.blocks.3.norm2.weight grad: 5.531700480787549e-06
sam_encoder.blocks.3.norm2.bias grad: 4.200370312901214e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.677807737607509e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.3796146731692716e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -7.163134796428494e-08
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -3.188007440257934e-07
sam_encoder.blocks.4.norm1.weight grad: -1.4440074664889835e-06
sam_encoder.blocks.4.norm1.bias grad: 5.05658999827574e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.4771916312383837e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.023973581482096e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.2393173537693656e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 8.705492291483097e-07
sam_encoder.blocks.4.norm2.weight grad: 1.1255920071562286e-06
sam_encoder.blocks.4.norm2.bias grad: -4.5438391680363566e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 6.08660229772795e-07
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.426768842018646e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -6.70382974021777e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.788831683479657e-07
sam_encoder.blocks.5.norm1.weight grad: -6.961811777728144e-06
sam_encoder.blocks.5.norm1.bias grad: 2.220913302153349e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -5.503628926817328e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.4318946998391766e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.904726213477261e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.1482995887490688e-06
sam_encoder.blocks.5.norm2.weight grad: -1.8575956346467137e-06
sam_encoder.blocks.5.norm2.bias grad: -4.085168257006444e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.2296362089946342e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.6644929107533244e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -5.354746690500178e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.052898369380273e-06
sam_encoder.blocks.6.norm1.weight grad: -2.0420432065293426e-06
sam_encoder.blocks.6.norm1.bias grad: 1.4085012480791193e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -9.626445489629987e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -6.143854989204556e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.7270814939583943e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.877169069075535e-07
sam_encoder.blocks.6.norm2.weight grad: 2.4437340471195057e-06
sam_encoder.blocks.6.norm2.bias grad: -1.1052960502411224e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.0971417598047992e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 6.011191544530448e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.589844249698217e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.4271920178998698e-07
sam_encoder.blocks.7.norm1.weight grad: 6.966629371163435e-07
sam_encoder.blocks.7.norm1.bias grad: 5.720875719816831e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.1379992201909772e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 4.1219988133889274e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 6.405028898370801e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.6716874635421846e-07
sam_encoder.blocks.7.norm2.weight grad: 5.655128461512504e-06
sam_encoder.blocks.7.norm2.bias grad: -8.269930162896344e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 4.289847311156336e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.8774957197820186e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.224312313752307e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.507919300067442e-07
sam_encoder.blocks.8.norm1.weight grad: 2.301479526067851e-06
sam_encoder.blocks.8.norm1.bias grad: -2.2917174646863714e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.9976341718574986e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.721088978001717e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.30475188800483e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.3868664154870203e-06
sam_encoder.blocks.8.norm2.weight grad: 1.929549398482777e-06
sam_encoder.blocks.8.norm2.bias grad: 6.215877874637954e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.46198340189585e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.2612599675776437e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -8.409961083089001e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.49840523894818e-07
sam_encoder.blocks.9.norm1.weight grad: -2.104297436744673e-06
sam_encoder.blocks.9.norm1.bias grad: 4.6374680096050724e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.2910439863844658e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.331353670115277e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.1660178955708034e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.035846690290782e-07
sam_encoder.blocks.9.norm2.weight grad: 2.0474562916206196e-06
sam_encoder.blocks.9.norm2.bias grad: -5.2327300181787e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.0908751139359083e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 9.263656011171406e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -6.69839835154562e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.648402066071867e-07
sam_encoder.blocks.10.norm1.weight grad: 1.2629291177290725e-06
sam_encoder.blocks.10.norm1.bias grad: 7.071889740473125e-09
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.57126055455592e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 7.283978789018875e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 8.967796816250484e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.634256012854166e-07
sam_encoder.blocks.10.norm2.weight grad: 7.916163440313539e-07
sam_encoder.blocks.10.norm2.bias grad: -9.80267714112415e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.551264176669065e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.07812795135942e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -7.636598411409068e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.3151673051179387e-07
sam_encoder.blocks.11.norm1.weight grad: 1.2452829651010688e-05
sam_encoder.blocks.11.norm1.bias grad: -1.1573027904887567e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.0653806132031605e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.485131163775804e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.7181872635774198e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.085726466953929e-06
sam_encoder.blocks.11.norm2.weight grad: 1.4198328699421836e-06
sam_encoder.blocks.11.norm2.bias grad: -1.518272654266184e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.9965279989264673e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 8.177477184290183e-08
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -6.86421742557286e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.425672545631642e-08
sam_encoder.neck.conv1.trainable_scale grad: -6.678355930489488e-07
sam_encoder.neck.conv1.trainable_shift grad: -8.653190889162943e-06
sam_encoder.neck.conv2.trainable_scale grad: -5.565161700360477e-07
sam_encoder.neck.conv2.trainable_shift grad: 6.356756784953177e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00016558979405090213
mask_decoder.transformer.layers.0.norm1.bias grad: -1.2380769476294518e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0010623177513480186
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0002544268500059843
mask_decoder.transformer.layers.0.norm3.weight grad: -9.287683496950194e-06
mask_decoder.transformer.layers.0.norm3.bias grad: 1.2148572750447784e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.1667753723450005e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -9.128257261181716e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 2.6671017621993087e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.1040401659556665e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 7.79943002271466e-06
mask_decoder.transformer.layers.1.norm2.bias grad: 2.0494164346018806e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.300411481177434e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.413398371776566e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -4.181234544375911e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -8.642378088552505e-05
mask_decoder.transformer.norm_final_attn.weight grad: 5.20719368068967e-06
mask_decoder.transformer.norm_final_attn.bias grad: 7.52558071326348e-06
Text_Embedding_Affine.0.weight grad: -6.250609405067387e-12
Text_Embedding_Affine.0.bias grad: -1.7054660461646165e-10
Text_Embedding_Affine.2.weight grad: 7.630630155519569e-11
Text_Embedding_Affine.2.bias grad: 1.3621091056847945e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08609605580568314

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08609605580568314

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09928655624389648

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.20306631922721863

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08499002456665039

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09928655624389648

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 28.33624839782715
Max value: 80.0062255859375
Mean value: 65.19908905029297

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08513659983873367

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08513659983873367

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08513659983873367

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.19633308053016663

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.8337379097938538
Max value: 4.945779323577881
Mean value: 1.0088908672332764

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 28.33624839782715
Max value: 80.0062255859375
Mean value: 65.19908905029297

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.46117401123047
Max value: -65.46117401123047
Mean value: -65.46117401123047
sam_encoder.pos_embed grad: -7.419590275503651e-09
sam_encoder.blocks.0.norm1.weight grad: -1.4820068827248178e-05
sam_encoder.blocks.0.norm1.bias grad: 2.1967634893371724e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 7.846091989449633e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 7.027864512565429e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.6156844822035055e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.183711984571346e-07
sam_encoder.blocks.0.norm2.weight grad: 1.241197060153354e-05
sam_encoder.blocks.0.norm2.bias grad: 1.6914866137085482e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -7.011305115156574e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.483213160710875e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.8874998204410076e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -5.6759745348244905e-06
sam_encoder.blocks.1.norm1.weight grad: -8.780109055805951e-06
sam_encoder.blocks.1.norm1.bias grad: -5.284414328343701e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.5105072129226755e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.611192257973016e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.5838216970441863e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.2256309673830401e-06
sam_encoder.blocks.1.norm2.weight grad: 1.7725371435517445e-05
sam_encoder.blocks.1.norm2.bias grad: 9.71972667684895e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 7.140207799238851e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.8742156271400745e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 6.708650744258193e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 8.916330074271173e-08
sam_encoder.blocks.2.norm1.weight grad: -2.75525212600769e-06
sam_encoder.blocks.2.norm1.bias grad: -7.04265676176874e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.375741360083339e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.8968070725786674e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.2412390333338408e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.4210882000043057e-06
sam_encoder.blocks.2.norm2.weight grad: -5.77751052333042e-06
sam_encoder.blocks.2.norm2.bias grad: 3.605635356507264e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.688603444767068e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.1977700725983595e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.2231107575644273e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.140997695387341e-07
sam_encoder.blocks.3.norm1.weight grad: -5.992226306261728e-07
sam_encoder.blocks.3.norm1.bias grad: -6.49769708616077e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.699365495573147e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -8.733837830732227e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 7.897301657067146e-08
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.1610813999141101e-07
sam_encoder.blocks.3.norm2.weight grad: 2.323013859495404e-06
sam_encoder.blocks.3.norm2.bias grad: -1.979108674277086e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.6499592447871692e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.1958723550596915e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 4.011693818029016e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.1355594864426166e-07
sam_encoder.blocks.4.norm1.weight grad: 8.320830602315255e-06
sam_encoder.blocks.4.norm1.bias grad: -2.9042871574347373e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 3.0804039852228016e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 4.531043984457028e-08
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.874869435094297e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.984900558862137e-06
sam_encoder.blocks.4.norm2.weight grad: -2.4684681193321012e-05
sam_encoder.blocks.4.norm2.bias grad: -2.1569536329479888e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.5219256965792738e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.616176167677622e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.4362813089974225e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 6.006466435337643e-08
sam_encoder.blocks.5.norm1.weight grad: -2.720548764045816e-06
sam_encoder.blocks.5.norm1.bias grad: -8.265467840828933e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.3879960028571077e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.4990905533049954e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 9.713824056234444e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.4212928363122046e-06
sam_encoder.blocks.5.norm2.weight grad: -8.322514077008236e-06
sam_encoder.blocks.5.norm2.bias grad: -1.3385551937972195e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.9752861792076146e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.118832172636758e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 6.852880574115261e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.561637302278541e-07
sam_encoder.blocks.6.norm1.weight grad: 2.6138127395824995e-06
sam_encoder.blocks.6.norm1.bias grad: 3.0473488550342154e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.3967055565444753e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.97589366482498e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.2403970686136745e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.541136829378956e-07
sam_encoder.blocks.6.norm2.weight grad: -1.2611496458703186e-05
sam_encoder.blocks.6.norm2.bias grad: -4.6047043724684045e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -9.032378329720814e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.065194843860809e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.8778277421915845e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -9.633944273446104e-07
sam_encoder.blocks.7.norm1.weight grad: 6.208865670487285e-06
sam_encoder.blocks.7.norm1.bias grad: 5.832559324403519e-08
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.16123748436803e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.515324467822211e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.54808105637494e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.0756732393701895e-07
sam_encoder.blocks.7.norm2.weight grad: 1.4468441804638132e-06
sam_encoder.blocks.7.norm2.bias grad: 1.980673914658837e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.9452118067420088e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.018541150368037e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.3787857824354433e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -8.637524615551229e-07
sam_encoder.blocks.8.norm1.weight grad: 4.777259164256975e-06
sam_encoder.blocks.8.norm1.bias grad: -1.5520839724558755e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.6755309338332154e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.1062830935770762e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.3453659398219315e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.449352450639708e-06
sam_encoder.blocks.8.norm2.weight grad: -3.2265313620882807e-06
sam_encoder.blocks.8.norm2.bias grad: -1.0819560429808917e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.5481776901870035e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.6177444877030212e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.657656866882462e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.369371489090554e-06
sam_encoder.blocks.9.norm1.weight grad: 9.199599162457162e-07
sam_encoder.blocks.9.norm1.bias grad: 2.305794666312977e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 6.972535970817262e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 3.597404543143057e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 7.815731351001887e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.7135325808558264e-07
sam_encoder.blocks.9.norm2.weight grad: -1.4770466805202886e-07
sam_encoder.blocks.9.norm2.bias grad: -1.149094600805256e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 5.555268103307753e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.560075469977164e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -5.882717459826381e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -8.804107665127958e-07
sam_encoder.blocks.10.norm1.weight grad: 7.2245347837451845e-06
sam_encoder.blocks.10.norm1.bias grad: 2.3336050958278065e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.85413613912533e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.31545937165356e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.086748509100289e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.1580027603486087e-06
sam_encoder.blocks.10.norm2.weight grad: 2.401738356638816e-06
sam_encoder.blocks.10.norm2.bias grad: -1.1722918316081632e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.3537816105090315e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 6.588390419892676e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.3257734937942587e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.302542144316249e-07
sam_encoder.blocks.11.norm1.weight grad: 1.037981201079674e-05
sam_encoder.blocks.11.norm1.bias grad: 1.3628348369820742e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 8.674971354594163e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.017583682345503e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.1142387797444826e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.4537857850882574e-06
sam_encoder.blocks.11.norm2.weight grad: 6.637124442931963e-06
sam_encoder.blocks.11.norm2.bias grad: -4.810895006812643e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.259848537913058e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 9.597418966222904e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.5062479974403686e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.3143964849859913e-07
sam_encoder.neck.conv1.trainable_scale grad: -2.0504921849351376e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.1733794053725433e-05
sam_encoder.neck.conv2.trainable_scale grad: -2.257766027469188e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.539508593850769e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -4.61879390059039e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 3.515524440445006e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005030086729675531
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00011876109056174755
mask_decoder.transformer.layers.0.norm3.weight grad: -7.688057667110115e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.032630411325954e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 9.297183714807034e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -7.099298272805754e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.051283015840454e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 6.277819920796901e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -2.97229562420398e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 2.8576323529705405e-07
mask_decoder.transformer.layers.1.norm3.weight grad: 4.256388274370693e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.3013504940317944e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -7.201164407888427e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00014692942204419523
mask_decoder.transformer.norm_final_attn.weight grad: 4.816322871192824e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.4380138964042999e-05
Text_Embedding_Affine.0.weight grad: -1.3414675620326832e-11
Text_Embedding_Affine.0.bias grad: -3.6405001235806367e-10
Text_Embedding_Affine.2.weight grad: -1.4636072909191e-10
Text_Embedding_Affine.2.bias grad: 1.80302704393398e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0458937476554287e-31
Max value: 1.0
Mean value: 0.06659738719463348

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0458937476554287e-31
Max value: 1.0
Mean value: 0.06659738719463348

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0827178955078125

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.17894220352172852

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06386375427246094

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0827178955078125

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 44.559574127197266
Max value: 90.71417236328125
Mean value: 61.00087356567383

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.385121786359003e-27
Max value: 1.0
Mean value: 0.06581337749958038

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.385121786359003e-27
Max value: 1.0
Mean value: 0.06581337749958038

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.385121786359003e-27
Max value: 1.0
Mean value: 0.06581337749958038

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.16829752922058105

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.6588020920753479
Max value: 22.337480545043945
Mean value: 1.020682454109192

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 44.559574127197266
Max value: 90.71417236328125
Mean value: 61.00087356567383

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.157981872558594
Max value: -61.157981872558594
Mean value: -61.157981872558594
sam_encoder.pos_embed grad: -6.084679426976436e-09
sam_encoder.blocks.0.norm1.weight grad: -6.809835031162947e-05
sam_encoder.blocks.0.norm1.bias grad: 6.09091648584581e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.4514836240996374e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 7.717684411545633e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 8.39540189190302e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.90241985112516e-07
sam_encoder.blocks.0.norm2.weight grad: 2.092526756314328e-06
sam_encoder.blocks.0.norm2.bias grad: -9.711987331684213e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -9.869103223536513e-07
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -6.927263711986598e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.3784959921613336e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -6.8212316364224534e-06
sam_encoder.blocks.1.norm1.weight grad: -4.920581886835862e-06
sam_encoder.blocks.1.norm1.bias grad: 7.099482900230214e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.633776370610576e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.2395438463718165e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -6.4869072957662866e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.59260081697721e-06
sam_encoder.blocks.1.norm2.weight grad: -6.081480023567565e-06
sam_encoder.blocks.1.norm2.bias grad: -5.4184565669856966e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.628395345207537e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.879589934920659e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.403909845976159e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.2478145587665495e-06
sam_encoder.blocks.2.norm1.weight grad: 1.374030716760899e-06
sam_encoder.blocks.2.norm1.bias grad: 5.754009180236608e-08
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.607456503435969e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.157228209398454e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -8.226221325458027e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.413819053501356e-06
sam_encoder.blocks.2.norm2.weight grad: -8.407131645071786e-06
sam_encoder.blocks.2.norm2.bias grad: -1.2966949725523591e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.23021639714716e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.8701497285510413e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.8911002775421366e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.0406832845765166e-06
sam_encoder.blocks.3.norm1.weight grad: 5.747807790612569e-06
sam_encoder.blocks.3.norm1.bias grad: -2.8975471195735736e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.7600239061721368e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -6.581103662028909e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.0696322735602735e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.8446538661009981e-06
sam_encoder.blocks.3.norm2.weight grad: -1.1333191650919616e-05
sam_encoder.blocks.3.norm2.bias grad: -1.4550721971318126e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -8.000693924259394e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.5084958653897047e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 8.22265246824827e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.3399946965364506e-06
sam_encoder.blocks.4.norm1.weight grad: 3.085910793743096e-05
sam_encoder.blocks.4.norm1.bias grad: -2.1922758151049493e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.5847279428271577e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.4154136301367544e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 7.181394721555989e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.9620708776055835e-06
sam_encoder.blocks.4.norm2.weight grad: -3.384644878678955e-05
sam_encoder.blocks.4.norm2.bias grad: -2.153760942746885e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.2883363271830603e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -7.60267266741721e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.63193680641416e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 5.723145477531943e-07
sam_encoder.blocks.5.norm1.weight grad: 2.999135722348001e-05
sam_encoder.blocks.5.norm1.bias grad: 8.938720270634803e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.9937229808419943e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.91526134283049e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 6.490454325103201e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 5.387996679928619e-06
sam_encoder.blocks.5.norm2.weight grad: -1.3991767445986625e-05
sam_encoder.blocks.5.norm2.bias grad: -1.1026420907001011e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -7.495650606870186e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.867488092306303e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.9300449568836484e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 6.307669764282764e-07
sam_encoder.blocks.6.norm1.weight grad: 8.484650606987998e-06
sam_encoder.blocks.6.norm1.bias grad: 4.79999243907514e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.856159987160936e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.631755251059076e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.6911521925067063e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.4709760282348725e-07
sam_encoder.blocks.6.norm2.weight grad: -1.0884940820687916e-05
sam_encoder.blocks.6.norm2.bias grad: -5.187861461308785e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -9.826381756283808e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.427743533597095e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.1518394532904495e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.9130993678118102e-07
sam_encoder.blocks.7.norm1.weight grad: 7.2998591349460185e-06
sam_encoder.blocks.7.norm1.bias grad: 1.3034045309723297e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.3688232835847884e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.558437699917704e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.2340551620582119e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.33697540150024e-07
sam_encoder.blocks.7.norm2.weight grad: -5.941065865044948e-06
sam_encoder.blocks.7.norm2.bias grad: -4.332844980581285e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.2933140826353338e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.7862224694908946e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.80575067740574e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 3.8747703001718037e-07
sam_encoder.blocks.8.norm1.weight grad: 9.944043995346874e-06
sam_encoder.blocks.8.norm1.bias grad: -1.4832064607617212e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 9.458028216613457e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.5177330321166664e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.313518621122057e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -7.287003427336458e-07
sam_encoder.blocks.8.norm2.weight grad: -3.4957065508933738e-06
sam_encoder.blocks.8.norm2.bias grad: -5.597255992029204e-08
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.2810770587966545e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -4.3008759575968725e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 5.621532750410552e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.3028238754486665e-07
sam_encoder.blocks.9.norm1.weight grad: 6.86317207510001e-06
sam_encoder.blocks.9.norm1.bias grad: -6.30297904535837e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 5.3346934691944625e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 5.612605491478462e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 5.326553491613595e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 6.89356397742813e-07
sam_encoder.blocks.9.norm2.weight grad: -5.650014713864948e-07
sam_encoder.blocks.9.norm2.bias grad: 8.07055585028138e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.049097932082077e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.651108050282346e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 8.878122912392428e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 8.335481282983892e-08
sam_encoder.blocks.10.norm1.weight grad: 7.631704647792503e-06
sam_encoder.blocks.10.norm1.bias grad: 2.5956246645364445e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.4376025723759085e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.057976987794973e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 7.985422598721925e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.794759847636669e-08
sam_encoder.blocks.10.norm2.weight grad: 2.32735669669637e-06
sam_encoder.blocks.10.norm2.bias grad: 2.018352461163886e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 7.810419333509344e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.170202608591353e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.313837742600299e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.098233255447667e-07
sam_encoder.blocks.11.norm1.weight grad: 5.39989832759602e-06
sam_encoder.blocks.11.norm1.bias grad: 4.4000162233714946e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.2406354673876194e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 4.6083340521363425e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.1180054571013898e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.7105325866850762e-07
sam_encoder.blocks.11.norm2.weight grad: 5.091531420475803e-06
sam_encoder.blocks.11.norm2.bias grad: 2.594269403743965e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.7159480850968976e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.0906169336521998e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.919502892633318e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.1546608646995082e-07
sam_encoder.neck.conv1.trainable_scale grad: 6.084892447688617e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.3742501323577017e-06
sam_encoder.neck.conv2.trainable_scale grad: -1.753323886077851e-07
sam_encoder.neck.conv2.trainable_shift grad: -8.531921776011586e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00010222253331448883
mask_decoder.transformer.layers.0.norm1.bias grad: -2.700617187656462e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0023025991395115852
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0001993419718928635
mask_decoder.transformer.layers.0.norm3.weight grad: 3.48617322742939e-06
mask_decoder.transformer.layers.0.norm3.bias grad: -1.3089309504721314e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 9.215382306138054e-06
mask_decoder.transformer.layers.0.norm4.bias grad: 2.3103139028535224e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -4.5971326471772045e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 9.341454642708413e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00013679750554729253
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00010924517118837684
mask_decoder.transformer.layers.1.norm3.weight grad: -1.0105801266035996e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -5.519877595361322e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 1.0860581824090332e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -3.777978417929262e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.8509562096369336e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.1255291610723361e-05
Text_Embedding_Affine.0.weight grad: 9.181782070766253e-12
Text_Embedding_Affine.0.bias grad: 6.074388769761185e-10
Text_Embedding_Affine.2.weight grad: -5.4193045884165514e-11
Text_Embedding_Affine.2.bias grad: -1.2683431123150513e-05
Epoch 10 finished with average loss: -62.6202
Epoch 11/39
----------
Epoch 11:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 11:   0%|          | 0/3 [00:00<?, ?it/s, loss=-68.9]Epoch 11:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.02it/s, loss=-68.9]Epoch 11:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.02it/s, loss=-61.8]Epoch 11:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.60it/s, loss=-61.8]Epoch 11:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.60it/s, loss=-61.6]Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.25it/s, loss=-61.6]/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.48414438857082e-34
Max value: 1.0
Mean value: 0.09091344475746155

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.48414438857082e-34
Max value: 1.0
Mean value: 0.09091344475746155

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10187911987304688

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.18588197231292725

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08994483947753906

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10187911987304688

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 51.350833892822266
Max value: 90.32415008544922
Mean value: 68.85293579101562

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.48414438857082e-34
Max value: 1.0
Mean value: 0.09091344475746155

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.48414438857082e-34
Max value: 1.0
Mean value: 0.09091344475746155

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.48414438857082e-34
Max value: 1.0
Mean value: 0.09091344475746155

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.18588197231292725

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 51.350833892822266
Max value: 90.32415008544922
Mean value: 68.85293579101562

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.85346221923828
Max value: -68.85346221923828
Mean value: -68.85346221923828
sam_encoder.pos_embed grad: -3.1146742962562257e-09
sam_encoder.blocks.0.norm1.weight grad: -1.0129645033885026e-06
sam_encoder.blocks.0.norm1.bias grad: 7.464439022442093e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.3636962371019763e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -9.160213920722526e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -9.52904088080686e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.5277978465965134e-07
sam_encoder.blocks.0.norm2.weight grad: -3.331875632284209e-06
sam_encoder.blocks.0.norm2.bias grad: 1.7317137462669052e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -5.259126737655606e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.315312713108142e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.4318477042252198e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.831596470467048e-06
sam_encoder.blocks.1.norm1.weight grad: -7.592712336190743e-06
sam_encoder.blocks.1.norm1.bias grad: -2.1365863176470157e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.2175025808101054e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 9.151783046945638e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 3.366581950103864e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.8151763470086735e-06
sam_encoder.blocks.1.norm2.weight grad: 7.730852303211577e-06
sam_encoder.blocks.1.norm2.bias grad: -1.258715656149434e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.650722414429765e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.0052492598333629e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 5.8192090364173055e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 3.884823343014432e-07
sam_encoder.blocks.2.norm1.weight grad: 6.067051344871288e-06
sam_encoder.blocks.2.norm1.bias grad: -2.440538310111151e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.711426299763843e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 9.955986115528503e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.4678624868101906e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 7.880706789364922e-07
sam_encoder.blocks.2.norm2.weight grad: 3.631391109593096e-06
sam_encoder.blocks.2.norm2.bias grad: -1.5096806009751162e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 3.540907300703111e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 8.210399471408891e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.0466907244554022e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 2.0357178698304779e-07
sam_encoder.blocks.3.norm1.weight grad: -8.473801926811575e-07
sam_encoder.blocks.3.norm1.bias grad: -1.8461248600942781e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.410709501215024e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.4993443048515473e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 4.6922568230911565e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 7.317280505958479e-07
sam_encoder.blocks.3.norm2.weight grad: 6.992565886321245e-06
sam_encoder.blocks.3.norm2.bias grad: 1.6101209894259227e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 6.259058864088729e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.2464153062173864e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.6041908565966878e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.79698747110524e-07
sam_encoder.blocks.4.norm1.weight grad: -7.744246204310912e-07
sam_encoder.blocks.4.norm1.bias grad: 2.2929123133508256e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 3.0072033041506074e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.0617856932858558e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.8440471194480779e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.4463111028817366e-06
sam_encoder.blocks.4.norm2.weight grad: -1.0132744137081318e-05
sam_encoder.blocks.4.norm2.bias grad: -9.495328413322568e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.996018560632365e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.726534492263454e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.878494680975564e-08
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.5821484566913568e-07
sam_encoder.blocks.5.norm1.weight grad: -6.961339295230573e-06
sam_encoder.blocks.5.norm1.bias grad: 6.626473805226851e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -6.745412974851206e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.6626420296670403e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.779922164743766e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.4923072910733026e-07
sam_encoder.blocks.5.norm2.weight grad: -5.121684807818383e-06
sam_encoder.blocks.5.norm2.bias grad: -6.192527507664636e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.2865816643170547e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.1952004658487567e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -7.504324912588345e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.565779588323494e-07
sam_encoder.blocks.6.norm1.weight grad: -1.6996199292407255e-06
sam_encoder.blocks.6.norm1.bias grad: 2.4225751076301094e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.7674459513727925e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.2539103408926167e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.824128474936515e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -8.969641385192517e-08
sam_encoder.blocks.6.norm2.weight grad: -2.386524101893883e-06
sam_encoder.blocks.6.norm2.bias grad: -1.3025646694586612e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.0685155302780913e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.261653086563456e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 6.028481038811151e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.9405027273933229e-07
sam_encoder.blocks.7.norm1.weight grad: 1.3878875506634358e-06
sam_encoder.blocks.7.norm1.bias grad: 5.470368336091269e-08
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.3735188986174762e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.1434958651079796e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.2231214441271732e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -7.997985562724352e-08
sam_encoder.blocks.7.norm2.weight grad: 3.0406399673665874e-06
sam_encoder.blocks.7.norm2.bias grad: 1.2277148471184773e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.2586887098441366e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 6.810116133237898e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.580875388957793e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.988915401962004e-07
sam_encoder.blocks.8.norm1.weight grad: -8.846085961522476e-07
sam_encoder.blocks.8.norm1.bias grad: -4.80127880564396e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.606608632049756e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.1844966820717673e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.334864464297425e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 6.556749667652184e-07
sam_encoder.blocks.8.norm2.weight grad: 1.5063501450640615e-06
sam_encoder.blocks.8.norm2.bias grad: -1.9501567294355482e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.5463491536138463e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 8.710014185453474e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.9033504372600873e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.398449391374015e-07
sam_encoder.blocks.9.norm1.weight grad: -2.0649970338126877e-06
sam_encoder.blocks.9.norm1.bias grad: 3.9422366171493195e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.5694110970798647e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.2470212002190237e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.242858369669534e-10
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -9.137095275946194e-07
sam_encoder.blocks.9.norm2.weight grad: 3.3800286018959014e-06
sam_encoder.blocks.9.norm2.bias grad: -5.12451265421987e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.004946847795509e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.2385835361783393e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.8064428053985466e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.2879234506945068e-07
sam_encoder.blocks.10.norm1.weight grad: 1.7383470094500808e-06
sam_encoder.blocks.10.norm1.bias grad: 4.649767788578174e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.5826642538740998e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 7.729983053650358e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.1316502650515758e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.540757340189884e-07
sam_encoder.blocks.10.norm2.weight grad: 2.3993450213311007e-06
sam_encoder.blocks.10.norm2.bias grad: -1.1225141633985913e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.2232970877666958e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 5.598288908004179e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -4.0330786532649654e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.291404138712096e-07
sam_encoder.blocks.11.norm1.weight grad: 4.04760521632852e-06
sam_encoder.blocks.11.norm1.bias grad: 1.0194041522026964e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.5226575555971067e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.6909041278267978e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.8476279137757956e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.0464558499734267e-06
sam_encoder.blocks.11.norm2.weight grad: 3.2861380532267503e-06
sam_encoder.blocks.11.norm2.bias grad: -1.704353280729265e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.5245473100076197e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 5.008520815863449e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.6786409534906852e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 4.930364383426422e-08
sam_encoder.neck.conv1.trainable_scale grad: -7.300568540813401e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.8628001018660143e-06
sam_encoder.neck.conv2.trainable_scale grad: -7.738462954876013e-07
sam_encoder.neck.conv2.trainable_shift grad: 7.227288278954802e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0001436118909623474
mask_decoder.transformer.layers.0.norm1.bias grad: -6.049085641279817e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0021560273598879576
mask_decoder.transformer.layers.0.norm2.bias grad: 4.177534719929099e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -1.397761661792174e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.1990691746177617e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 6.983538332860917e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -3.863727215502877e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.275653216405772e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.0902371034026146e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 5.7419794757151976e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 3.4581888030515984e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.807081131730229e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.901858508470468e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -5.965115633443929e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00011725357035174966
mask_decoder.transformer.norm_final_attn.weight grad: 4.582546353049111e-06
mask_decoder.transformer.norm_final_attn.bias grad: 8.520995834260248e-06
Text_Embedding_Affine.0.weight grad: -5.061022781416291e-12
Text_Embedding_Affine.0.bias grad: -1.4956159921641898e-10
Text_Embedding_Affine.2.weight grad: 1.2523594661306703e-10
Text_Embedding_Affine.2.bias grad: 1.1889598681591451e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.035773293815231e-38
Max value: 0.9999998807907104
Mean value: 0.0630522072315216

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.035773293815231e-38
Max value: 0.9999998807907104
Mean value: 0.0630522072315216

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0741724967956543

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1751686930656433

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.061337947845458984

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0741724967956543

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 27.504426956176758
Max value: 73.4681396484375
Mean value: 54.497432708740234

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.8132112645994917e-35
Max value: 0.9999998807907104
Mean value: 0.06344671547412872

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.8132112645994917e-35
Max value: 0.9999998807907104
Mean value: 0.06344671547412872

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.8132112645994917e-35
Max value: 0.9999998807907104
Mean value: 0.06344671547412872

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.16948851943016052

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.8332515954971313
Max value: 3.9012858867645264
Mean value: 1.0073449611663818

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 27.504426956176758
Max value: 73.4681396484375
Mean value: 54.497432708740234

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -54.677093505859375
Max value: -54.677093505859375
Mean value: -54.677093505859375
sam_encoder.pos_embed grad: 1.2714531649749006e-09
sam_encoder.blocks.0.norm1.weight grad: 4.7406698286067694e-05
sam_encoder.blocks.0.norm1.bias grad: 3.751540498342365e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.8942924877337646e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.0227253142147674e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -7.2652087510505226e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.004173322551651e-06
sam_encoder.blocks.0.norm2.weight grad: 7.972099410835654e-06
sam_encoder.blocks.0.norm2.bias grad: 8.407423592871055e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.1237807484576479e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -3.0137512112560216e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.223111576109659e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.6157829274307005e-06
sam_encoder.blocks.1.norm1.weight grad: 3.633488177001709e-08
sam_encoder.blocks.1.norm1.bias grad: 8.778212759352755e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.438023102513398e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -7.507045438615023e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.7364070572511991e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.6337185115844477e-07
sam_encoder.blocks.1.norm2.weight grad: 7.198026651167311e-06
sam_encoder.blocks.1.norm2.bias grad: -5.156337465450633e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -3.5929688237956725e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.4290001217887038e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -6.781715455872472e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.144374775525648e-06
sam_encoder.blocks.2.norm1.weight grad: -1.2299584341235459e-05
sam_encoder.blocks.2.norm1.bias grad: -8.536308087059297e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.4308294491202105e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -5.315898761182325e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.638231868942967e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.018300387542695e-06
sam_encoder.blocks.2.norm2.weight grad: -8.402292223763652e-06
sam_encoder.blocks.2.norm2.bias grad: -4.0608301787870005e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.75226635596482e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.3992765818547923e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.58024237054633e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.6572233764454722e-06
sam_encoder.blocks.3.norm1.weight grad: -4.767337031807983e-06
sam_encoder.blocks.3.norm1.bias grad: -6.534319254569709e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.3709102353896014e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 5.755865117862413e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.5890561775886454e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.6347992186638294e-06
sam_encoder.blocks.3.norm2.weight grad: 9.055981536221225e-06
sam_encoder.blocks.3.norm2.bias grad: -6.90090644184238e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.159544343769085e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.5158927908487385e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -5.227648216532543e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.838131081261963e-07
sam_encoder.blocks.4.norm1.weight grad: -4.519760295806918e-06
sam_encoder.blocks.4.norm1.bias grad: -3.261958681832766e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -4.674972842622083e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.362397142656846e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.738065004199598e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.2292102837818675e-06
sam_encoder.blocks.4.norm2.weight grad: -1.247061572939856e-05
sam_encoder.blocks.4.norm2.bias grad: -9.971628969651647e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -9.765334652911406e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.8094538012956036e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.284025074710371e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.103306090044498e-06
sam_encoder.blocks.5.norm1.weight grad: -5.674042768077925e-06
sam_encoder.blocks.5.norm1.bias grad: -1.0345504961151164e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -6.737759576935787e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.515924850536976e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -8.203011248042458e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -9.786908776732162e-07
sam_encoder.blocks.5.norm2.weight grad: -1.2293606232560705e-05
sam_encoder.blocks.5.norm2.bias grad: -5.076632987766061e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.5874652389320545e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.8027465102932183e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.4280651612352813e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.0776818726299098e-06
sam_encoder.blocks.6.norm1.weight grad: 1.6602150481048739e-06
sam_encoder.blocks.6.norm1.bias grad: 2.247842303404468e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -6.058315875634435e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.0286387350788573e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.050578799156938e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.186533075767329e-08
sam_encoder.blocks.6.norm2.weight grad: -3.2741152153903386e-06
sam_encoder.blocks.6.norm2.bias grad: -5.656563075717713e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.7336847071856027e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.8400623957859352e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -8.28894997084717e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.004702299833298e-07
sam_encoder.blocks.7.norm1.weight grad: 1.2618637583727832e-06
sam_encoder.blocks.7.norm1.bias grad: 3.21741254083463e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 6.205244176271663e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.562908605341363e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 6.269450523177511e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -5.88163175052614e-07
sam_encoder.blocks.7.norm2.weight grad: -5.592802949649922e-07
sam_encoder.blocks.7.norm2.bias grad: 9.410782695340458e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -8.211517865674978e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -9.155741054200917e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.4286649729911005e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -9.283880899602082e-07
sam_encoder.blocks.8.norm1.weight grad: 3.116478183073923e-06
sam_encoder.blocks.8.norm1.bias grad: -2.182094249292277e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.7536314064491307e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.8692951186949358e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.569115738675464e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 8.804368007986341e-07
sam_encoder.blocks.8.norm2.weight grad: -1.0727565040724585e-06
sam_encoder.blocks.8.norm2.bias grad: -6.150522722236929e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -7.009792852841201e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.0698853947797033e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 5.776583833494442e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.850335244555026e-08
sam_encoder.blocks.9.norm1.weight grad: -3.592306711652782e-06
sam_encoder.blocks.9.norm1.bias grad: 3.1769388897373574e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.2301817352854414e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -3.165835096297087e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.260480975266546e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -7.516534878959646e-07
sam_encoder.blocks.9.norm2.weight grad: -2.1068060505058384e-06
sam_encoder.blocks.9.norm2.bias grad: -1.4953445770515827e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.8907453522842843e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.071309839062451e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.2066199057444464e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.2785950427060015e-07
sam_encoder.blocks.10.norm1.weight grad: 1.4289685168478172e-06
sam_encoder.blocks.10.norm1.bias grad: -7.144807341319392e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.459250938751211e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 3.006258850746235e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.843031314929249e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.165383415966062e-07
sam_encoder.blocks.10.norm2.weight grad: -5.14069461132749e-06
sam_encoder.blocks.10.norm2.bias grad: -3.029161689482862e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.714861238928279e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.033712462434778e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.447085651307134e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -8.494203029840719e-07
sam_encoder.blocks.11.norm1.weight grad: 1.0723970262915827e-05
sam_encoder.blocks.11.norm1.bias grad: 5.502860034312107e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.0394412583991652e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.900099159181991e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.7540427279527648e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.1008772200257226e-07
sam_encoder.blocks.11.norm2.weight grad: -7.132217433536425e-06
sam_encoder.blocks.11.norm2.bias grad: -4.095054919162067e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -8.698815463503706e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.4946533610782353e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.3829649105900899e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -9.105880138804423e-08
sam_encoder.neck.conv1.trainable_scale grad: -3.5863922676071525e-07
sam_encoder.neck.conv1.trainable_shift grad: -9.281106940761674e-06
sam_encoder.neck.conv2.trainable_scale grad: -4.920357241644524e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.1890398784307763e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00021526103955693543
mask_decoder.transformer.layers.0.norm1.bias grad: 5.307520041242242e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0005966790486127138
mask_decoder.transformer.layers.0.norm2.bias grad: 1.2239674106240273e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -5.9987647546222433e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.547350620967336e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 6.44449537503533e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -4.084358806721866e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.968173794215545e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -8.344977686647326e-08
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00010567408753558993
mask_decoder.transformer.layers.1.norm2.bias grad: 2.8755679522873834e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.5613683798583224e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.730905493488535e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.056507193832658e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00011272104893578216
mask_decoder.transformer.norm_final_attn.weight grad: 1.1504002031870186e-05
mask_decoder.transformer.norm_final_attn.bias grad: 1.6388001313316636e-05
Text_Embedding_Affine.0.weight grad: 8.729943851149002e-13
Text_Embedding_Affine.0.bias grad: -4.606565129350315e-12
Text_Embedding_Affine.2.weight grad: 8.011402652385868e-11
Text_Embedding_Affine.2.bias grad: 6.602549547096714e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0105746537536504e-26
Max value: 0.9999996423721313
Mean value: 0.06530892848968506

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0105746537536504e-26
Max value: 0.9999996423721313
Mean value: 0.06530892848968506

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0671072006225586

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12976858019828796

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06183624267578125

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0671072006225586

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 54.077877044677734
Max value: 71.72880554199219
Mean value: 60.97863006591797

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 6.137903929205058e-23
Max value: 0.9999985694885254
Mean value: 0.06673477590084076

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.137903929205058e-23
Max value: 0.9999985694885254
Mean value: 0.06673477590084076

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.137903929205058e-23
Max value: 0.9999985694885254
Mean value: 0.06673477590084076

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12244220077991486

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.7909722924232483
Max value: 32.115211486816406
Mean value: 1.0133929252624512

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 54.077877044677734
Max value: 71.72880554199219
Mean value: 60.97863006591797

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.12108612060547
Max value: -61.12108612060547
Mean value: -61.12108612060547
sam_encoder.pos_embed grad: 9.612462825714374e-09
sam_encoder.blocks.0.norm1.weight grad: 1.555574817757588e-05
sam_encoder.blocks.0.norm1.bias grad: -3.057538560824469e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.69943097414216e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.0686846962926211e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.7859323381562717e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.8694433379096154e-07
sam_encoder.blocks.0.norm2.weight grad: 2.623163709358778e-05
sam_encoder.blocks.0.norm2.bias grad: -3.0322884413180873e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.6105190297821537e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 8.555500244256109e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.2999416614766233e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.0232761269435287e-05
sam_encoder.blocks.1.norm1.weight grad: 1.3069668511889176e-06
sam_encoder.blocks.1.norm1.bias grad: 2.021124146267539e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.784905857173726e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.557989321554487e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.2941270546871237e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.9609819901234005e-06
sam_encoder.blocks.1.norm2.weight grad: -1.7491369362687692e-05
sam_encoder.blocks.1.norm2.bias grad: -6.288531722020707e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -6.1754940361424815e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.2671796412178082e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.1138510672026314e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 3.9596976364464354e-08
sam_encoder.blocks.2.norm1.weight grad: -1.2367509043542668e-05
sam_encoder.blocks.2.norm1.bias grad: 1.54630356519192e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -6.4825935623957776e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.2475411494961008e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.1733280846092384e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.333634701150004e-07
sam_encoder.blocks.2.norm2.weight grad: -2.421050794509938e-06
sam_encoder.blocks.2.norm2.bias grad: 2.638230398588348e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.0453171600820497e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.3631686215376249e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.641940778237768e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.615233827578777e-06
sam_encoder.blocks.3.norm1.weight grad: -6.849370493000606e-07
sam_encoder.blocks.3.norm1.bias grad: 4.966642791259801e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.9085775875282707e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.8997465076608933e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.4393046917102765e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.306955477455631e-06
sam_encoder.blocks.3.norm2.weight grad: -7.4141184995824005e-06
sam_encoder.blocks.3.norm2.bias grad: -1.3319047411641805e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -8.470478860544972e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.769195589280571e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -6.077319085306954e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -8.177333938874654e-07
sam_encoder.blocks.4.norm1.weight grad: -1.0338735592085868e-05
sam_encoder.blocks.4.norm1.bias grad: -4.521832124737557e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -4.8146630433620885e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.6188445215448155e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.7888966037135106e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.567823457866325e-06
sam_encoder.blocks.4.norm2.weight grad: 1.7794680388760753e-05
sam_encoder.blocks.4.norm2.bias grad: 1.9724851881619543e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.032118234434165e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 4.481490577745717e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.220585431838117e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.953525779503252e-07
sam_encoder.blocks.5.norm1.weight grad: -1.5412057109642774e-05
sam_encoder.blocks.5.norm1.bias grad: -7.272351922438247e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -6.82000381857506e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.069183781510219e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -6.061878139007604e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.6305615417877561e-06
sam_encoder.blocks.5.norm2.weight grad: 1.6020367183955386e-05
sam_encoder.blocks.5.norm2.bias grad: 1.053135929396376e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 6.361842679325491e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.4275382202176843e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.474011469326797e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.4994457160355523e-06
sam_encoder.blocks.6.norm1.weight grad: -5.570878329308471e-06
sam_encoder.blocks.6.norm1.bias grad: -6.764374120393768e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.2261390313360607e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.573241033587692e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.8513477471060469e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -5.451519200505572e-07
sam_encoder.blocks.6.norm2.weight grad: 2.32009801948152e-06
sam_encoder.blocks.6.norm2.bias grad: 2.1547496089624474e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.978697693833965e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 9.599916666047648e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -9.247219168173615e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.324282028595917e-07
sam_encoder.blocks.7.norm1.weight grad: -9.004392268252559e-06
sam_encoder.blocks.7.norm1.bias grad: -7.564960355921357e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -6.384415883076144e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.844680693669943e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.725544391068979e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.940720034734113e-07
sam_encoder.blocks.7.norm2.weight grad: -1.945700205396861e-06
sam_encoder.blocks.7.norm2.bias grad: -1.3664770222021616e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.1463411030708812e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -8.940600650930719e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.6012089076866687e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 6.040808671059494e-07
sam_encoder.blocks.8.norm1.weight grad: -2.9635725695698056e-06
sam_encoder.blocks.8.norm1.bias grad: 2.3652726213185815e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -5.822686262035859e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 6.953102911211317e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.58207171302638e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.4530100947449682e-06
sam_encoder.blocks.8.norm2.weight grad: -2.300449978065444e-06
sam_encoder.blocks.8.norm2.bias grad: 1.0478795502422145e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.980263843710418e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.9597534901549807e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.9518051885825116e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 8.426090403190756e-07
sam_encoder.blocks.9.norm1.weight grad: -4.114463990845252e-06
sam_encoder.blocks.9.norm1.bias grad: -2.893638679779542e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.926006684196182e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.9174390217813198e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.4269362509367056e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.6569772393922904e-07
sam_encoder.blocks.9.norm2.weight grad: -6.1707796703558415e-06
sam_encoder.blocks.9.norm2.bias grad: 7.129848995646171e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -7.0505516305274796e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.822300984917092e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -7.807686301930516e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.5581191443488933e-07
sam_encoder.blocks.10.norm1.weight grad: -8.588694981881417e-06
sam_encoder.blocks.10.norm1.bias grad: -1.4142012787488056e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -5.465019967232365e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.0583115656336304e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.231362032034667e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -8.593555662628205e-07
sam_encoder.blocks.10.norm2.weight grad: -1.3911245332565159e-05
sam_encoder.blocks.10.norm2.bias grad: -1.9806329873972572e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.459506716462784e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.125925443076994e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.1488274367366103e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.9908369469922036e-07
sam_encoder.blocks.11.norm1.weight grad: -3.3586082281544805e-05
sam_encoder.blocks.11.norm1.bias grad: -2.5555073079885915e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.9408614662097534e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -8.313238026858016e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.9467978492903057e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -9.98401446850039e-07
sam_encoder.blocks.11.norm2.weight grad: -1.1600619473028928e-05
sam_encoder.blocks.11.norm2.bias grad: -8.446438073406171e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -7.37362279323861e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.3212312498799292e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.74555087951012e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.707274570137088e-08
sam_encoder.neck.conv1.trainable_scale grad: 3.5917037166655064e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.0787569408421405e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.076074795491877e-06
sam_encoder.neck.conv2.trainable_shift grad: 1.4865937373542693e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 4.753893517772667e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 3.0487863114103675e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004674453288316727
mask_decoder.transformer.layers.0.norm2.bias grad: 5.014805356040597e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 3.973117418354377e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.6712568796938285e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -9.133135608863086e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 5.875529041077243e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.0830880455614533e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.6313274399144575e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0002997884002979845
mask_decoder.transformer.layers.1.norm2.bias grad: 9.211653377860785e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.5363750208052807e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.750166484271176e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 5.172751843929291e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00018228363478556275
mask_decoder.transformer.norm_final_attn.weight grad: -2.108541821144172e-07
mask_decoder.transformer.norm_final_attn.bias grad: -5.2370637604326475e-06
Text_Embedding_Affine.0.weight grad: 1.3830017860094745e-13
Text_Embedding_Affine.0.bias grad: -2.0104695686029572e-11
Text_Embedding_Affine.2.weight grad: 1.3335302306849428e-10
Text_Embedding_Affine.2.bias grad: -2.5062847271328792e-05
Epoch 11 finished with average loss: -61.5505
Epoch 12/39
----------
Epoch 12:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 12:   0%|          | 0/3 [00:00<?, ?it/s, loss=-58.4]Epoch 12:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.06it/s, loss=-58.4]Epoch 12:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.06it/s, loss=-59.3]Epoch 12:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-59.3]Epoch 12:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-62.4]Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.28it/s, loss=-62.4]/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.641281910397285e-26
Max value: 0.9999996423721313
Mean value: 0.08065822720527649

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.641281910397285e-26
Max value: 0.9999996423721313
Mean value: 0.08065822720527649

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0751194953918457

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13171543180942535

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07219743728637695

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0751194953918457

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 39.58944320678711
Max value: 85.67781829833984
Mean value: 58.356666564941406

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.641281910397285e-26
Max value: 0.9999996423721313
Mean value: 0.08065822720527649

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.641281910397285e-26
Max value: 0.9999996423721313
Mean value: 0.08065822720527649

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.641281910397285e-26
Max value: 0.9999996423721313
Mean value: 0.08065822720527649

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13171543180942535

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 39.58944320678711
Max value: 85.67781829833984
Mean value: 58.356666564941406

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.357486724853516
Max value: -58.357486724853516
Mean value: -58.357486724853516
sam_encoder.pos_embed grad: -6.846379019265214e-10
sam_encoder.blocks.0.norm1.weight grad: 9.315814168076031e-06
sam_encoder.blocks.0.norm1.bias grad: 2.827434400387574e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.3365038284973707e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.159016041034192e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -3.3955216167669278e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.145778583122592e-08
sam_encoder.blocks.0.norm2.weight grad: -9.546981345920358e-06
sam_encoder.blocks.0.norm2.bias grad: -4.412570888234768e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.2531337978980446e-07
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.708601644168084e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.1387232916604262e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -9.672320402387413e-07
sam_encoder.blocks.1.norm1.weight grad: -7.65266747748683e-07
sam_encoder.blocks.1.norm1.bias grad: 1.445657971999026e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.2607408734766068e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 7.924586498120334e-08
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -9.803123930396396e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.351202172372723e-08
sam_encoder.blocks.1.norm2.weight grad: 8.796878319117241e-07
sam_encoder.blocks.1.norm2.bias grad: 9.877464890450938e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.772593350324314e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.768531536887167e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -4.501357011577056e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 9.791068578124396e-08
sam_encoder.blocks.2.norm1.weight grad: -1.1025092305771977e-07
sam_encoder.blocks.2.norm1.bias grad: -2.8533468139357865e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 5.053710765423602e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 7.621929398737848e-08
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 5.356390602173633e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.1834453061965178e-06
sam_encoder.blocks.2.norm2.weight grad: 4.62292337033432e-06
sam_encoder.blocks.2.norm2.bias grad: -3.9261994970729575e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 2.3960474209161475e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.550981434978894e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.4185047209357435e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.0609885947587827e-07
sam_encoder.blocks.3.norm1.weight grad: -5.866002084076172e-06
sam_encoder.blocks.3.norm1.bias grad: -2.035973693637061e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.8810750336560886e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.368710276343336e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.738926122627163e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.0329542255458364e-07
sam_encoder.blocks.3.norm2.weight grad: 3.280155851825839e-06
sam_encoder.blocks.3.norm2.bias grad: 3.125257080682786e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.9508328225347213e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.4606048353016376e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.204170414188411e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -4.3009160322071693e-07
sam_encoder.blocks.4.norm1.weight grad: -1.8634436855791137e-06
sam_encoder.blocks.4.norm1.bias grad: -3.5322429425832524e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.0009405286837136e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.6400567065820724e-08
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 7.277157010321389e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.5570066125292215e-07
sam_encoder.blocks.4.norm2.weight grad: -1.1046495274058543e-06
sam_encoder.blocks.4.norm2.bias grad: -2.7961868909187615e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.0240858589204436e-07
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.215088887984166e-09
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.4676686532766325e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -3.672043291658156e-08
sam_encoder.blocks.5.norm1.weight grad: -9.399749615113251e-06
sam_encoder.blocks.5.norm1.bias grad: 1.0500011740077753e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -6.881233275635168e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.719793656069669e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 6.99202473697369e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.0736720241766307e-06
sam_encoder.blocks.5.norm2.weight grad: -6.342484539345605e-06
sam_encoder.blocks.5.norm2.bias grad: -3.4684107959037647e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.1247298011294333e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -8.719450192984368e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -2.307609747731476e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.605321575785638e-07
sam_encoder.blocks.6.norm1.weight grad: -4.8357028390455525e-06
sam_encoder.blocks.6.norm1.bias grad: 1.3024898635194404e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.9871648621337954e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.0865630883927224e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -5.030176453146851e-08
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.7751050879487593e-07
sam_encoder.blocks.6.norm2.weight grad: 2.1679279598174617e-06
sam_encoder.blocks.6.norm2.bias grad: 1.5448976000698167e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.0650522856158204e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 7.785071147736744e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.3103250391141046e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.1607293792792461e-08
sam_encoder.blocks.7.norm1.weight grad: -7.311523404496256e-07
sam_encoder.blocks.7.norm1.bias grad: 2.555405842485925e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.176606237000669e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 9.194006445056857e-09
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.9056670907957596e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -5.225042514211964e-07
sam_encoder.blocks.7.norm2.weight grad: 2.9380071282503195e-06
sam_encoder.blocks.7.norm2.bias grad: 2.1082402668071154e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.4176242732210085e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.134212766373821e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.7020209241991324e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.059951154682494e-07
sam_encoder.blocks.8.norm1.weight grad: -1.2763820222971844e-06
sam_encoder.blocks.8.norm1.bias grad: 6.712525646435097e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -2.6936129415844334e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.1962854387093103e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.2874209548717772e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -9.900141861862721e-08
sam_encoder.blocks.8.norm2.weight grad: 1.940844867931446e-06
sam_encoder.blocks.8.norm2.bias grad: -5.7406435161055924e-08
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.0369536741782213e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.2758409866364673e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -8.938749118669875e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.1238403153110994e-07
sam_encoder.blocks.9.norm1.weight grad: -1.6201861399167683e-06
sam_encoder.blocks.9.norm1.bias grad: 7.050131785035774e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.7605242419449496e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 9.545109236341887e-08
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.8200730639582616e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.060924254645215e-07
sam_encoder.blocks.9.norm2.weight grad: 1.4740558071935084e-06
sam_encoder.blocks.9.norm2.bias grad: -1.928644906001864e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.535421006337856e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 6.308411570898897e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.1196287630355073e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.4503692113976285e-07
sam_encoder.blocks.10.norm1.weight grad: 1.9466665435174946e-06
sam_encoder.blocks.10.norm1.bias grad: 2.2115725073490466e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.3288070022099419e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.6477878135629e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 9.936043170455378e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.056993010541191e-07
sam_encoder.blocks.10.norm2.weight grad: -5.493967591974069e-07
sam_encoder.blocks.10.norm2.bias grad: -7.198977982625365e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.1005031309614424e-08
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.8901720245121396e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -9.388136277266312e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.947946763422806e-07
sam_encoder.blocks.11.norm1.weight grad: 3.830718924291432e-06
sam_encoder.blocks.11.norm1.bias grad: -8.358063041669084e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.1414083189720259e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.45190562964126e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.3201192814449314e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 7.952056648719008e-07
sam_encoder.blocks.11.norm2.weight grad: -7.567916213702119e-07
sam_encoder.blocks.11.norm2.bias grad: -1.0304349871148588e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.0568438710834016e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.516801203000796e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -8.598049134889152e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.5201098335637653e-07
sam_encoder.neck.conv1.trainable_scale grad: -9.62470039667096e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.0013794710393995e-06
sam_encoder.neck.conv2.trainable_scale grad: -9.609200333215995e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.1338603144395165e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00016847440565470606
mask_decoder.transformer.layers.0.norm1.bias grad: -5.47363015357405e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 3.97504772990942e-05
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0003461339510977268
mask_decoder.transformer.layers.0.norm3.weight grad: -1.890057319542393e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -9.086998034035787e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 4.53973698313348e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.3955223039374687e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.9662340491777286e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.7329839465674013e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 4.6717526856809855e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 1.2012762454105541e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.7342786779627204e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.744480843830388e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.640241629909724e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -7.542056846432388e-05
mask_decoder.transformer.norm_final_attn.weight grad: 5.441424491436919e-06
mask_decoder.transformer.norm_final_attn.bias grad: 7.540756996604614e-06
Text_Embedding_Affine.0.weight grad: 2.9641254728485222e-12
Text_Embedding_Affine.0.bias grad: -6.034882316097168e-11
Text_Embedding_Affine.2.weight grad: 1.8978260803159674e-12
Text_Embedding_Affine.2.bias grad: 1.679037814028561e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.1282170337335128e-25
Max value: 0.9999998807907104
Mean value: 0.07003895938396454

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1282170337335128e-25
Max value: 0.9999998807907104
Mean value: 0.07003895938396454

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.078948974609375

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.16496066749095917

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06790971755981445

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.078948974609375

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 52.382843017578125
Max value: 79.4161605834961
Mean value: 60.15706253051758

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.854563394162796e-24
Max value: 0.9999996423721313
Mean value: 0.06946614384651184

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.854563394162796e-24
Max value: 0.9999996423721313
Mean value: 0.06946614384651184

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.854563394162796e-24
Max value: 0.9999996423721313
Mean value: 0.06946614384651184

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.16047324240207672

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.8652469515800476
Max value: 4.316761016845703
Mean value: 1.0058752298355103

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 52.382843017578125
Max value: 79.4161605834961
Mean value: 60.15706253051758

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.32199478149414
Max value: -60.32199478149414
Mean value: -60.32199478149414
sam_encoder.pos_embed grad: -6.8710646061731495e-09
sam_encoder.blocks.0.norm1.weight grad: 4.8553421947872266e-05
sam_encoder.blocks.0.norm1.bias grad: 1.9387858628761023e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.1197697606112342e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.879637233694666e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.9056764105916955e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.5600425058437395e-06
sam_encoder.blocks.0.norm2.weight grad: -1.2124713975936174e-05
sam_encoder.blocks.0.norm2.bias grad: 4.535528933047317e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -8.883156624506228e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -6.158613359730225e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.568171865073964e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -9.266535016649868e-06
sam_encoder.blocks.1.norm1.weight grad: -1.241274549101945e-05
sam_encoder.blocks.1.norm1.bias grad: -1.1516887752804905e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.757973900064826e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 4.429221007740125e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 3.344920969539089e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.062680434595677e-06
sam_encoder.blocks.1.norm2.weight grad: 3.325014404254034e-05
sam_encoder.blocks.1.norm2.bias grad: 4.628963324648794e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 7.1568370003660675e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.423451749360538e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.5618357792845927e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.6979083738988265e-07
sam_encoder.blocks.2.norm1.weight grad: 1.0860216207220219e-05
sam_encoder.blocks.2.norm1.bias grad: -6.464444595621899e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 7.196380011009751e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 9.842158306128113e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.3544075702375267e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 2.926869626662665e-07
sam_encoder.blocks.2.norm2.weight grad: 2.161602424166631e-05
sam_encoder.blocks.2.norm2.bias grad: -3.655702130345162e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.2464503925002646e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.965746261907043e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 7.15105670678895e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 2.3785560188116506e-07
sam_encoder.blocks.3.norm1.weight grad: 2.0274987946322653e-06
sam_encoder.blocks.3.norm1.bias grad: -1.2001679351669736e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.1616294816340087e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.934964519838104e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 5.204321951168822e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.1056976038380526e-06
sam_encoder.blocks.3.norm2.weight grad: 1.308905666519422e-05
sam_encoder.blocks.3.norm2.bias grad: -7.43751570553286e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.099498967960244e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 4.133715265197679e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.882051482331008e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.414917273403262e-07
sam_encoder.blocks.4.norm1.weight grad: 1.9593937395256944e-05
sam_encoder.blocks.4.norm1.bias grad: -2.9864836506021675e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.0552830644883215e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.194701548636658e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 5.400103873398621e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 5.479450919665396e-06
sam_encoder.blocks.4.norm2.weight grad: -2.6233034077449702e-05
sam_encoder.blocks.4.norm2.bias grad: -3.3936397812794894e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.5799083485035226e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.252874300116673e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.3454640540876426e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -3.661342304894788e-07
sam_encoder.blocks.5.norm1.weight grad: 8.288970093417447e-06
sam_encoder.blocks.5.norm1.bias grad: -1.0842183655768167e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 5.201172825763933e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.7056553335569333e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.847584594041109e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 6.942493655515136e-07
sam_encoder.blocks.5.norm2.weight grad: -7.095911769283703e-06
sam_encoder.blocks.5.norm2.bias grad: -1.3282717191032134e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.8141865609777597e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.1451512449411894e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.893562395911431e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.438258377424063e-07
sam_encoder.blocks.6.norm1.weight grad: -3.788015192185412e-06
sam_encoder.blocks.6.norm1.bias grad: 2.479948761902051e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -3.6063102015759796e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.5485866242670454e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -5.253596100374125e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.954771384291234e-07
sam_encoder.blocks.6.norm2.weight grad: -4.714152055385057e-06
sam_encoder.blocks.6.norm2.bias grad: -2.4289147404488176e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -4.87486340716714e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.96389555640053e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.8889098782892688e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -3.906287417976273e-07
sam_encoder.blocks.7.norm1.weight grad: 4.930243449052796e-06
sam_encoder.blocks.7.norm1.bias grad: 1.4802731129748281e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.4564965315221343e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.4036434095032746e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 6.950526199034357e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.7659452800653526e-07
sam_encoder.blocks.7.norm2.weight grad: 5.530142516363412e-06
sam_encoder.blocks.7.norm2.bias grad: 1.2364787380647613e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 5.465491994982585e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.9698588857863797e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 6.78363562656159e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.0227747537783216e-07
sam_encoder.blocks.8.norm1.weight grad: 6.018704425514443e-06
sam_encoder.blocks.8.norm1.bias grad: -3.325745410620584e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.4764912015816662e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.71174656063522e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.7343216970621143e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.3868622065492673e-06
sam_encoder.blocks.8.norm2.weight grad: -2.500263690308202e-06
sam_encoder.blocks.8.norm2.bias grad: 4.80922608403489e-08
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.6954920738498913e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.4538365412117855e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.5478830164283863e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.3115343335812213e-06
sam_encoder.blocks.9.norm1.weight grad: -1.6656372281431686e-06
sam_encoder.blocks.9.norm1.bias grad: 1.0786795883177547e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.1211259334231727e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -8.70503953365187e-08
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.0558607616294466e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -5.916282930229499e-07
sam_encoder.blocks.9.norm2.weight grad: 2.344330596315558e-06
sam_encoder.blocks.9.norm2.bias grad: -1.055471656741247e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.8373323200648883e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.287011173189967e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.8451450500833744e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.52098185835348e-07
sam_encoder.blocks.10.norm1.weight grad: 3.8135447084641783e-06
sam_encoder.blocks.10.norm1.bias grad: 1.760571876729955e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.616001438582316e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.301417228205537e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.5651664853066904e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.452831715047068e-07
sam_encoder.blocks.10.norm2.weight grad: 4.1331900320074055e-06
sam_encoder.blocks.10.norm2.bias grad: 1.4965144146117382e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.64011396211572e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.4241217058952316e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.0290273994305608e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.608977803854941e-07
sam_encoder.blocks.11.norm1.weight grad: 1.972810241568368e-05
sam_encoder.blocks.11.norm1.bias grad: 3.183383228133607e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.1189832700183615e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.1057607025577454e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.56401960743824e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.2846101071772864e-06
sam_encoder.blocks.11.norm2.weight grad: 5.12468432134483e-06
sam_encoder.blocks.11.norm2.bias grad: 1.8665484446955816e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.983220267400611e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.0741221103671705e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.572174366832769e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -7.456601736066659e-08
sam_encoder.neck.conv1.trainable_scale grad: -3.1717536330688745e-07
sam_encoder.neck.conv1.trainable_shift grad: -9.074166882783175e-06
sam_encoder.neck.conv2.trainable_scale grad: -7.947173799038865e-07
sam_encoder.neck.conv2.trainable_shift grad: 8.442319085588679e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00010397541336715221
mask_decoder.transformer.layers.0.norm1.bias grad: -9.077884897124022e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003083333605900407
mask_decoder.transformer.layers.0.norm2.bias grad: -1.3440381735563278e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -6.302435940597206e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.5770536265335977e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0001408818206982687
mask_decoder.transformer.layers.0.norm4.bias grad: -4.830495072383201e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 7.512069714721292e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 3.848048891086364e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00026266672648489475
mask_decoder.transformer.layers.1.norm2.bias grad: -8.659502054797485e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.993572656530887e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.247757028177148e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 3.0681476346217096e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00016236206283792853
mask_decoder.transformer.norm_final_attn.weight grad: 1.0772879249998368e-05
mask_decoder.transformer.norm_final_attn.bias grad: 2.1146912331460044e-05
Text_Embedding_Affine.0.weight grad: -3.7467667857171705e-12
Text_Embedding_Affine.0.bias grad: -1.854716380478294e-10
Text_Embedding_Affine.2.weight grad: -4.0044838972574937e-11
Text_Embedding_Affine.2.bias grad: 1.7052980183507316e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.959992997357642e-25
Max value: 0.9999943971633911
Mean value: 0.11173498630523682

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.959992997357642e-25
Max value: 0.9999943971633911
Mean value: 0.11173498630523682

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11077117919921875

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.18101805448532104

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.1108245849609375

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.11077117919921875

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 55.387149810791016
Max value: 76.18597412109375
Mean value: 68.42927551269531

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.797169774647189e-21
Max value: 0.9999680519104004
Mean value: 0.11123155057430267

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.797169774647189e-21
Max value: 0.9999680519104004
Mean value: 0.11123155057430267

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.797169774647189e-21
Max value: 0.9999680519104004
Mean value: 0.11123155057430267

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.16842883825302124

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8463180065155029
Max value: 20.449134826660156
Mean value: 1.0248322486877441

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 55.387149810791016
Max value: 76.18597412109375
Mean value: 68.42927551269531

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.63912963867188
Max value: -68.63912963867188
Mean value: -68.63912963867188
sam_encoder.pos_embed grad: 4.005355158653856e-09
sam_encoder.blocks.0.norm1.weight grad: 2.1849700715392828e-05
sam_encoder.blocks.0.norm1.bias grad: -1.8051721781375818e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.8333802220004145e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.089051230948826e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.241014271930908e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.998770014528418e-07
sam_encoder.blocks.0.norm2.weight grad: 5.383665666158777e-06
sam_encoder.blocks.0.norm2.bias grad: -7.4452559601922985e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.1915860341105144e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.932996489515062e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.4593207854195498e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.1595878277148586e-05
sam_encoder.blocks.1.norm1.weight grad: 4.95679796586046e-06
sam_encoder.blocks.1.norm1.bias grad: 1.2749324923788663e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.655293302377686e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.1140399439900648e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.232266852952307e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.85445900974446e-06
sam_encoder.blocks.1.norm2.weight grad: -1.6337493434548378e-05
sam_encoder.blocks.1.norm2.bias grad: -1.0053612413685187e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -6.911714081070386e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.170116092907847e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -9.633942681830376e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -9.111234788861111e-08
sam_encoder.blocks.2.norm1.weight grad: -1.0456605195940938e-05
sam_encoder.blocks.2.norm1.bias grad: -1.0456640211486956e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -7.673001164221205e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.6255069112958154e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.880966571363388e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.741727030297625e-06
sam_encoder.blocks.2.norm2.weight grad: -4.6912273319321685e-06
sam_encoder.blocks.2.norm2.bias grad: 2.3233155843627173e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.21919003201765e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.6047599160629034e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -8.020960194699e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.684895096332184e-06
sam_encoder.blocks.3.norm1.weight grad: 6.061829481041059e-06
sam_encoder.blocks.3.norm1.bias grad: 9.30316105041129e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 2.408566160738701e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.427433400953305e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.7682993984635687e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.8068751614919165e-06
sam_encoder.blocks.3.norm2.weight grad: -1.2233400411787443e-05
sam_encoder.blocks.3.norm2.bias grad: -4.64424829260679e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.0803083569044247e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -4.285753675503656e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -7.576871212222613e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -8.238565669671516e-07
sam_encoder.blocks.4.norm1.weight grad: -9.998169844038785e-06
sam_encoder.blocks.4.norm1.bias grad: -9.191145181830507e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -7.178066880442202e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.3727621990256011e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.5973183659953065e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.157638047923683e-06
sam_encoder.blocks.4.norm2.weight grad: 1.5105003512871917e-05
sam_encoder.blocks.4.norm2.bias grad: 1.782505387382116e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 7.239530077640666e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.904439952544635e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.72620400210144e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -4.503955324253184e-07
sam_encoder.blocks.5.norm1.weight grad: 1.184402890430647e-06
sam_encoder.blocks.5.norm1.bias grad: -1.3549892173614353e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 3.11834401145461e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 5.843450708198361e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.4639662140325527e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.7459153411891748e-07
sam_encoder.blocks.5.norm2.weight grad: 8.052846169448458e-06
sam_encoder.blocks.5.norm2.bias grad: 9.394125299877487e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 2.0218737972754752e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 9.302981993641879e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.5445812096004374e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.107268066240067e-07
sam_encoder.blocks.6.norm1.weight grad: -2.896009334563132e-07
sam_encoder.blocks.6.norm1.bias grad: -5.181309461477213e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.54900907445699e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.2806540325982496e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -4.779052460435196e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.892787733799196e-07
sam_encoder.blocks.6.norm2.weight grad: -4.5724937081104144e-07
sam_encoder.blocks.6.norm2.bias grad: 5.896167749597225e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.1637418992904713e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.1810323030658765e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.4775918089071638e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.254608600400388e-07
sam_encoder.blocks.7.norm1.weight grad: -3.00501415040344e-06
sam_encoder.blocks.7.norm1.bias grad: -1.5807692932412465e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -2.046197550953366e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -8.836500455799978e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.5103630630619591e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 9.016739568323828e-07
sam_encoder.blocks.7.norm2.weight grad: -1.7125406657214626e-06
sam_encoder.blocks.7.norm2.bias grad: -6.381787329701183e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.2972491226246348e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.69676830714161e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.5012801668490283e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.1458707831479842e-06
sam_encoder.blocks.8.norm1.weight grad: -2.16579041989462e-06
sam_encoder.blocks.8.norm1.bias grad: -2.5416724724891537e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.0710381199460244e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.3008884707232937e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.7877089248941047e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -8.12390680948738e-07
sam_encoder.blocks.8.norm2.weight grad: -2.4874721020751167e-06
sam_encoder.blocks.8.norm2.bias grad: 8.696284794496023e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.3005997011059662e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.5032107967272168e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -8.679799066158012e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 4.3777504288300406e-07
sam_encoder.blocks.9.norm1.weight grad: -9.329389172307856e-07
sam_encoder.blocks.9.norm1.bias grad: 1.657372195040807e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.7517958212920348e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -9.795406867851852e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.385739427765657e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.1059137250413187e-06
sam_encoder.blocks.9.norm2.weight grad: -5.34683476871578e-06
sam_encoder.blocks.9.norm2.bias grad: 8.538604561181273e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.762175533163827e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.4491141630278435e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.6216130234170123e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.3201278648011794e-07
sam_encoder.blocks.10.norm1.weight grad: -4.685907697421499e-06
sam_encoder.blocks.10.norm1.bias grad: -1.2590342066687299e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.700632987602148e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.5870418792474084e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.6863126575117349e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -8.365732355741784e-07
sam_encoder.blocks.10.norm2.weight grad: -4.473799890547525e-06
sam_encoder.blocks.10.norm2.bias grad: 1.5184746189333964e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.050110874231905e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.2581375585796195e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 8.782490112935193e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.747131185922626e-07
sam_encoder.blocks.11.norm1.weight grad: -1.2074591722921468e-05
sam_encoder.blocks.11.norm1.bias grad: -7.016110430413391e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.389389232528629e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.284790755562426e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -3.2258085411740467e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.7185839169542305e-06
sam_encoder.blocks.11.norm2.weight grad: -9.15462169359671e-06
sam_encoder.blocks.11.norm2.bias grad: 1.2768389012762782e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -5.413254257291555e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.529659925836313e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -9.814763188842335e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.1518887649563112e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.176262230728753e-06
sam_encoder.neck.conv1.trainable_shift grad: 4.6409004426095635e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.0612748155836016e-06
sam_encoder.neck.conv2.trainable_shift grad: -1.1729598554666154e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00016631625476293266
mask_decoder.transformer.layers.0.norm1.bias grad: 2.2232670744415373e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0015927569475024939
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00034573464654386044
mask_decoder.transformer.layers.0.norm3.weight grad: 1.3340990335564129e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.2254389730514959e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00010239001858280972
mask_decoder.transformer.layers.0.norm4.bias grad: 4.7966832426027395e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -1.9892879208782688e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.5629542506067082e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -1.43635697895661e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 4.612360498867929e-06
mask_decoder.transformer.layers.1.norm3.weight grad: -5.088502439321019e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -2.98305822070688e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.013293280673679e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00018208597612101585
mask_decoder.transformer.norm_final_attn.weight grad: -2.0327183847257402e-07
mask_decoder.transformer.norm_final_attn.bias grad: -8.01871283329092e-06
Text_Embedding_Affine.0.weight grad: -1.157011552538334e-12
Text_Embedding_Affine.0.bias grad: 2.3486823597096418e-11
Text_Embedding_Affine.2.weight grad: -4.896546709765026e-11
Text_Embedding_Affine.2.bias grad: -2.541568028391339e-05
Epoch 12 finished with average loss: -62.4395
Epoch 13/39
----------
Epoch 13:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 13:   0%|          | 0/3 [00:00<?, ?it/s, loss=-64.6]Epoch 13:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.13it/s, loss=-64.6]Epoch 13:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.13it/s, loss=-61.2]Epoch 13:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.71it/s, loss=-61.2]Epoch 13:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.71it/s, loss=-58.7]Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.35it/s, loss=-58.7]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.6034862593218665e-22
Max value: 0.999997615814209
Mean value: 0.07420514523983002

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.6034862593218665e-22
Max value: 0.999997615814209
Mean value: 0.07420514523983002

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08456802368164062

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1275067925453186

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07237815856933594

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08456802368164062

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 45.144046783447266
Max value: 92.56324768066406
Mean value: 64.60137939453125

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.6034862593218665e-22
Max value: 0.999997615814209
Mean value: 0.07420514523983002

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.6034862593218665e-22
Max value: 0.999997615814209
Mean value: 0.07420514523983002

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.6034862593218665e-22
Max value: 0.999997615814209
Mean value: 0.07420514523983002

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1275067925453186

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 45.144046783447266
Max value: 92.56324768066406
Mean value: 64.60137939453125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -64.60200500488281
Max value: -64.60200500488281
Mean value: -64.60200500488281
sam_encoder.pos_embed grad: -3.629825329198866e-09
sam_encoder.blocks.0.norm1.weight grad: 1.6679334294167347e-05
sam_encoder.blocks.0.norm1.bias grad: 2.3349548428086564e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 9.662057891546283e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.8714250415996503e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.7914575778377184e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.0545288198215985e-08
sam_encoder.blocks.0.norm2.weight grad: -3.6422461562324315e-06
sam_encoder.blocks.0.norm2.bias grad: 1.3848165508534294e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -9.990222679334693e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.944417469232576e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.5943114703986794e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -6.119032150309067e-06
sam_encoder.blocks.1.norm1.weight grad: 3.45773685239692e-07
sam_encoder.blocks.1.norm1.bias grad: -5.4462934713228606e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 5.710274763259804e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.5437769889103947e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 5.2442496780713554e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.309798103146022e-06
sam_encoder.blocks.1.norm2.weight grad: 1.1539112165337428e-05
sam_encoder.blocks.1.norm2.bias grad: 2.7258129193796776e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.126217274664668e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.916208465350792e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 8.509258805133868e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 6.806861847508117e-07
sam_encoder.blocks.2.norm1.weight grad: 7.610818101966288e-06
sam_encoder.blocks.2.norm1.bias grad: -2.7621879326034104e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 5.400902409746777e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.2538604323708569e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 3.3340127174597e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.359761881758459e-06
sam_encoder.blocks.2.norm2.weight grad: 2.6213808723696275e-06
sam_encoder.blocks.2.norm2.bias grad: -3.4572028653201414e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 3.5117127481498756e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -6.61207977259437e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 4.523249117482919e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 6.717227734043263e-07
sam_encoder.blocks.3.norm1.weight grad: -4.07467041441123e-07
sam_encoder.blocks.3.norm1.bias grad: -2.4090654733299743e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.878257525182562e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.3945347632215999e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.1784227353928145e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.1944391644647112e-06
sam_encoder.blocks.3.norm2.weight grad: 7.375241693807766e-06
sam_encoder.blocks.3.norm2.bias grad: 3.853505404549651e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.473328201333061e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.5080258890520781e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.2813020425237482e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 6.578218290087534e-07
sam_encoder.blocks.4.norm1.weight grad: 2.7633791432890575e-06
sam_encoder.blocks.4.norm1.bias grad: 4.9258305807597935e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.0739607887444436e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.2038417196436058e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.3099082682165317e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.6921874248509994e-06
sam_encoder.blocks.4.norm2.weight grad: -1.4995070159784518e-05
sam_encoder.blocks.4.norm2.bias grad: -1.4318127796286717e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -8.316917956108227e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.43291458193562e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -4.713695034297416e-08
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.547217369894497e-07
sam_encoder.blocks.5.norm1.weight grad: -3.150167231069645e-06
sam_encoder.blocks.5.norm1.bias grad: 2.1113328330102377e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.325748821225716e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.552481873863144e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 8.499759474034363e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -7.428750450344523e-07
sam_encoder.blocks.5.norm2.weight grad: -8.437742508249357e-06
sam_encoder.blocks.5.norm2.bias grad: -7.548439953097841e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.383562898306991e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.1272179563093232e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.8430084480769438e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -6.147977273940342e-07
sam_encoder.blocks.6.norm1.weight grad: 2.239203467979678e-06
sam_encoder.blocks.6.norm1.bias grad: 3.663469215098303e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 7.694306418670749e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -3.5004876508537563e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.1728213848982705e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.938489948675851e-07
sam_encoder.blocks.6.norm2.weight grad: -3.1759782359586097e-06
sam_encoder.blocks.6.norm2.bias grad: -1.3653519772560685e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.5156008430494694e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -7.457353490281093e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 6.725272214680444e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.1940529393305042e-07
sam_encoder.blocks.7.norm1.weight grad: 3.7257584608596517e-06
sam_encoder.blocks.7.norm1.bias grad: 9.648723562349915e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.4299797587445937e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.3094144151182263e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.5627463199052727e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -8.546999197278637e-07
sam_encoder.blocks.7.norm2.weight grad: 1.8840058828573092e-06
sam_encoder.blocks.7.norm2.bias grad: 2.5602241748856613e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.546692940086359e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 7.859911193008884e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.515622720191459e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -7.903663004071859e-07
sam_encoder.blocks.8.norm1.weight grad: 3.666973952931585e-06
sam_encoder.blocks.8.norm1.bias grad: -1.3326807675184682e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.0677325665019453e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.6839426204314805e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.5579261091479566e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.3171064665584709e-06
sam_encoder.blocks.8.norm2.weight grad: -2.217987429276036e-07
sam_encoder.blocks.8.norm2.bias grad: -8.084369937932934e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.1616134543146472e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.925440748593246e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.8639215088333003e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -8.153821227097069e-07
sam_encoder.blocks.9.norm1.weight grad: -7.379773592219863e-07
sam_encoder.blocks.9.norm1.bias grad: 4.5360158651419624e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.8760140935446543e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 4.860842182097258e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 9.239075637879068e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -7.651357236682088e-07
sam_encoder.blocks.9.norm2.weight grad: 1.8536214838604792e-06
sam_encoder.blocks.9.norm2.bias grad: -1.4676405726277153e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.6327629711886402e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 9.369432518724352e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.6954574511582905e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.445032004696259e-07
sam_encoder.blocks.10.norm1.weight grad: 4.5106635297997855e-06
sam_encoder.blocks.10.norm1.bias grad: 5.878382580704056e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.0246737878769636e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.2333887298154877e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.7497189901405363e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.0031865258497419e-06
sam_encoder.blocks.10.norm2.weight grad: 2.415103153907694e-06
sam_encoder.blocks.10.norm2.bias grad: -1.6659786297168466e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.254949777125148e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 6.64121671434259e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.37252998861004e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.553971848508809e-07
sam_encoder.blocks.11.norm1.weight grad: 1.0862209819606505e-05
sam_encoder.blocks.11.norm1.bias grad: 1.3395728615250846e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.1523857210704591e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.7559215115834377e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.131619794454309e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 8.351802875949943e-07
sam_encoder.blocks.11.norm2.weight grad: 2.02077580979676e-06
sam_encoder.blocks.11.norm2.bias grad: -1.4524342759614228e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.9674399684154196e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 3.273794391134288e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.511305403160804e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.4356376115974854e-07
sam_encoder.neck.conv1.trainable_scale grad: -4.80426024296321e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.3709090126212686e-05
sam_encoder.neck.conv2.trainable_scale grad: -8.174156391760334e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.0489193047978915e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00017039672820828855
mask_decoder.transformer.layers.0.norm1.bias grad: -1.340231392532587e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.002396786818280816
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0002675396390259266
mask_decoder.transformer.layers.0.norm3.weight grad: -4.989763692719862e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -4.7373841880471446e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 9.838798723649234e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -3.6530000215861946e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.3311595466802828e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.467969013901893e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -1.9637107470771298e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 3.5295452107675374e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 4.386631917441264e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.484206561348401e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.577884490368888e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00016825551574584097
mask_decoder.transformer.norm_final_attn.weight grad: 4.094168161827838e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.1480472494440619e-05
Text_Embedding_Affine.0.weight grad: -1.982576602888031e-11
Text_Embedding_Affine.0.bias grad: -5.615079512466536e-10
Text_Embedding_Affine.2.weight grad: 7.055784428944278e-11
Text_Embedding_Affine.2.bias grad: 3.0046296160435304e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.2042765725233346e-22
Max value: 0.9999991655349731
Mean value: 0.08493171632289886

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.2042765725233346e-22
Max value: 0.9999991655349731
Mean value: 0.08493171632289886

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08831787109375

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.15394175052642822

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08049583435058594

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08831787109375

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 46.749629974365234
Max value: 69.26127624511719
Mean value: 57.761444091796875

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.1141867761426145e-21
Max value: 0.9999983310699463
Mean value: 0.08553110063076019

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.1141867761426145e-21
Max value: 0.9999983310699463
Mean value: 0.08553110063076019

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.1141867761426145e-21
Max value: 0.9999983310699463
Mean value: 0.08553110063076019

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1510574221611023

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.8995441198348999
Max value: 4.070988178253174
Mean value: 1.003713846206665

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 46.749629974365234
Max value: 69.26127624511719
Mean value: 57.761444091796875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.878787994384766
Max value: -57.878787994384766
Mean value: -57.878787994384766
sam_encoder.pos_embed grad: 9.879771667442583e-09
sam_encoder.blocks.0.norm1.weight grad: 3.690152516355738e-05
sam_encoder.blocks.0.norm1.bias grad: -5.521590537682641e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 9.28098688746104e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.1727399257542857e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.999088565047714e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 4.7612851972189674e-07
sam_encoder.blocks.0.norm2.weight grad: 1.417425573890796e-05
sam_encoder.blocks.0.norm2.bias grad: 3.3045089367078617e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.2927537682116963e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 8.009429620869923e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 7.111880222510081e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 5.515068096428877e-06
sam_encoder.blocks.1.norm1.weight grad: 3.155556214551325e-06
sam_encoder.blocks.1.norm1.bias grad: -2.798995183184161e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.557147126935888e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.3944861620984739e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.008731371461181e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.3617941969387175e-07
sam_encoder.blocks.1.norm2.weight grad: 3.056952436963911e-06
sam_encoder.blocks.1.norm2.bias grad: 5.270290330372518e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -2.7856819997396087e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.718322088592686e-08
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.1218492545594927e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.6328892797901062e-06
sam_encoder.blocks.2.norm1.weight grad: -2.248534292448312e-05
sam_encoder.blocks.2.norm1.bias grad: 1.7182768488055444e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -9.484651855018456e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.2381637993239565e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.006907147413585e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.813638618841651e-06
sam_encoder.blocks.2.norm2.weight grad: 1.9402987163630314e-06
sam_encoder.blocks.2.norm2.bias grad: -1.0254530025122222e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -8.918538583202462e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 5.214192242419813e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.261269042326603e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.787437551887706e-06
sam_encoder.blocks.3.norm1.weight grad: -5.848113687534351e-06
sam_encoder.blocks.3.norm1.bias grad: -3.201248318873695e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -8.571313628635835e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.937940164178144e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.357400368666276e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.503414857026655e-06
sam_encoder.blocks.3.norm2.weight grad: -1.951168769664946e-06
sam_encoder.blocks.3.norm2.bias grad: 9.129043974098749e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -2.942654646176379e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 9.032229399963398e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.838657332584262e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.934230678874883e-06
sam_encoder.blocks.4.norm1.weight grad: 1.2932412118971115e-06
sam_encoder.blocks.4.norm1.bias grad: -2.1647495032084407e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -4.100222099623352e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.987616767313739e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.3061152205627877e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.232455583201954e-07
sam_encoder.blocks.4.norm2.weight grad: -4.099186753592221e-06
sam_encoder.blocks.4.norm2.bias grad: 5.295932623994304e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.562987669487484e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.726376516828168e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.633251026258222e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.689956206973875e-06
sam_encoder.blocks.5.norm1.weight grad: -1.4090112017584033e-05
sam_encoder.blocks.5.norm1.bias grad: -1.7002577806124464e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -6.9765119405929e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -4.435260962054599e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.2237677512748633e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.8698332243948244e-07
sam_encoder.blocks.5.norm2.weight grad: -9.51574111240916e-06
sam_encoder.blocks.5.norm2.bias grad: 2.1935343283985276e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -6.719322755088797e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.3893958314147312e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.708617046209838e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.547207825249643e-07
sam_encoder.blocks.6.norm1.weight grad: -7.217164238682017e-06
sam_encoder.blocks.6.norm1.bias grad: -6.6929528657055926e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -3.983533133578021e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.671532102904166e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.6741457784519298e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.0575879514362896e-06
sam_encoder.blocks.6.norm2.weight grad: -5.3221410780679435e-06
sam_encoder.blocks.6.norm2.bias grad: 4.492448624660028e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.7212762435956392e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.9607964532042388e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -5.174252919459832e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.4251483548832766e-07
sam_encoder.blocks.7.norm1.weight grad: -1.4667051573269418e-06
sam_encoder.blocks.7.norm1.bias grad: -9.70838982539135e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.7643536693867645e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -9.679334880274837e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.2320054995361716e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.6481375243747607e-06
sam_encoder.blocks.7.norm2.weight grad: -2.099297262248001e-06
sam_encoder.blocks.7.norm2.bias grad: 1.4953836569020496e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.9120350316370605e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.977704399309005e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -5.240768246039806e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 3.018772076757159e-07
sam_encoder.blocks.8.norm1.weight grad: 4.0712839108891785e-06
sam_encoder.blocks.8.norm1.bias grad: -5.059047794020444e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.502589829120552e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 6.770169136416371e-08
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.3776600553683238e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.280308765672089e-06
sam_encoder.blocks.8.norm2.weight grad: -1.1519611689436715e-05
sam_encoder.blocks.8.norm2.bias grad: 7.345321932916704e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.1486161383800209e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -5.772952135885134e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -4.755031113745645e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.9685255665535806e-06
sam_encoder.blocks.9.norm1.weight grad: -8.202548997360282e-06
sam_encoder.blocks.9.norm1.bias grad: -7.265154522428929e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -7.318144980672514e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -3.2918912893364904e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.6229845389025286e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.4766901585971937e-06
sam_encoder.blocks.9.norm2.weight grad: -1.1350831300660502e-05
sam_encoder.blocks.9.norm2.bias grad: -1.9344820429978427e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -8.971709576144349e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.912322310701711e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.4320910395326791e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.533686706054141e-07
sam_encoder.blocks.10.norm1.weight grad: -2.898728780564852e-06
sam_encoder.blocks.10.norm1.bias grad: -1.5072158703333116e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.0136708371865097e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -9.708689958642935e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -4.952379413225572e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.9530175165982655e-07
sam_encoder.blocks.10.norm2.weight grad: -2.060052429442294e-05
sam_encoder.blocks.10.norm2.bias grad: -3.964607003581477e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.1323775652272161e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.208582933846628e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.1123919395904522e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -9.950015282811364e-07
sam_encoder.blocks.11.norm1.weight grad: -2.2508829715661705e-05
sam_encoder.blocks.11.norm1.bias grad: 4.7307079853453615e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.0349134527132264e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.892043759558874e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -5.056993472862814e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.7329832619216177e-07
sam_encoder.blocks.11.norm2.weight grad: -1.4169879250403028e-05
sam_encoder.blocks.11.norm2.bias grad: -1.1135729209854617e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -7.501480922655901e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.871050810426823e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.0429298527014907e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -6.676443149444822e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.0890526027651504e-06
sam_encoder.neck.conv1.trainable_shift grad: -2.54097358265426e-05
sam_encoder.neck.conv2.trainable_scale grad: -3.7841073208255693e-07
sam_encoder.neck.conv2.trainable_shift grad: 5.28777418367099e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -9.74324211711064e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 1.6729391063563526e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0036921855062246323
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0005775928148068488
mask_decoder.transformer.layers.0.norm3.weight grad: 5.567706830333918e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.3005613911664113e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 3.302993718534708e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 5.395622793002985e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.2775009458418936e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.806434728583554e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00017280312022194266
mask_decoder.transformer.layers.1.norm2.bias grad: 7.464654481736943e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.600043368758634e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.358515434432775e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 9.485885675530881e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 3.420250868657604e-05
mask_decoder.transformer.norm_final_attn.weight grad: 8.802191587164998e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.206875458592549e-05
Text_Embedding_Affine.0.weight grad: 5.024969589734196e-12
Text_Embedding_Affine.0.bias grad: 3.584140206847053e-10
Text_Embedding_Affine.2.weight grad: 2.0574909831427846e-11
Text_Embedding_Affine.2.bias grad: -1.7169975762953982e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.6709273932368303e-15
Max value: 0.9999974966049194
Mean value: 0.06635551899671555

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.6709273932368303e-15
Max value: 0.9999974966049194
Mean value: 0.06635551899671555

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07336044311523438

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1364414542913437

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06044292449951172

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07336044311523438

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 44.39608383178711
Max value: 61.147274017333984
Mean value: 53.655914306640625

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 7.290476273895397e-14
Max value: 0.9999926090240479
Mean value: 0.06743276119232178

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.290476273895397e-14
Max value: 0.9999926090240479
Mean value: 0.06743276119232178

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.290476273895397e-14
Max value: 0.9999926090240479
Mean value: 0.06743276119232178

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13296742737293243

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.7402892708778381
Max value: 6.0917439460754395
Mean value: 1.0054223537445068

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 44.39608383178711
Max value: 61.147274017333984
Mean value: 53.655914306640625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.708675384521484
Max value: -53.708675384521484
Mean value: -53.708675384521484
sam_encoder.pos_embed grad: -3.7051783863262244e-10
sam_encoder.blocks.0.norm1.weight grad: -1.702933877822943e-05
sam_encoder.blocks.0.norm1.bias grad: -5.1126144171576016e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.3021294711943483e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 6.258486564547638e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.4146611394826323e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.4951759769464843e-08
sam_encoder.blocks.0.norm2.weight grad: 7.5779680628329515e-06
sam_encoder.blocks.0.norm2.bias grad: 5.432679017758346e-07
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 7.189925668171782e-07
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.0882230273855384e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -9.417564797331579e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.8296453845323413e-06
sam_encoder.blocks.1.norm1.weight grad: -1.0140100130229257e-05
sam_encoder.blocks.1.norm1.bias grad: 7.159154847613536e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -5.797285666631069e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.9382342745520873e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.390898422774626e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.4186048196716e-06
sam_encoder.blocks.1.norm2.weight grad: -8.522848702341435e-07
sam_encoder.blocks.1.norm2.bias grad: -5.123293703945819e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.680390702560544e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.9812869090383174e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -8.446700121567119e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.4443315851385705e-06
sam_encoder.blocks.2.norm1.weight grad: -1.2033502571284771e-05
sam_encoder.blocks.2.norm1.bias grad: -3.4609092836035416e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -8.437906217295676e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.4671118100959575e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.326792456296971e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.836743755731732e-06
sam_encoder.blocks.2.norm2.weight grad: -4.573664227791596e-06
sam_encoder.blocks.2.norm2.bias grad: -6.1973314586794e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.918283255188726e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.104804823626182e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.749378720385721e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.7656338968663476e-06
sam_encoder.blocks.3.norm1.weight grad: 1.923420086313854e-06
sam_encoder.blocks.3.norm1.bias grad: -2.8574590942298528e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.007621555501828e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.2391335530992365e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.6617594812705647e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.1381794087792514e-06
sam_encoder.blocks.3.norm2.weight grad: -6.596377261303132e-06
sam_encoder.blocks.3.norm2.bias grad: -1.2441417311492842e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -6.633081284235232e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.2300423552223947e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.147817773831775e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 8.552682402296341e-07
sam_encoder.blocks.4.norm1.weight grad: 1.1760916095227003e-05
sam_encoder.blocks.4.norm1.bias grad: -7.2480702328903135e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 6.6722054725687485e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.0365967000325327e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.5496874513919465e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 7.158895414249855e-07
sam_encoder.blocks.4.norm2.weight grad: -1.1770925993914716e-05
sam_encoder.blocks.4.norm2.bias grad: -9.593361028237268e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -8.699228601471987e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.3542565941170324e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 5.357641384762246e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.95017810256104e-06
sam_encoder.blocks.5.norm1.weight grad: 1.9572222299757414e-05
sam_encoder.blocks.5.norm1.bias grad: 1.3246266235000803e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.3339470569917466e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.385109605209436e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.6769444048113655e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.6077718757733237e-06
sam_encoder.blocks.5.norm2.weight grad: -1.5171239056144259e-06
sam_encoder.blocks.5.norm2.bias grad: -4.3221334067311545e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.564750505167467e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.868314936677052e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.9118646125425585e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.315044073635363e-06
sam_encoder.blocks.6.norm1.weight grad: 2.302536813658662e-06
sam_encoder.blocks.6.norm1.bias grad: -5.677544550053426e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.2300184835112304e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 7.495704608118103e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.2079996736247267e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -5.443692998596816e-07
sam_encoder.blocks.6.norm2.weight grad: -3.6881679079669993e-06
sam_encoder.blocks.6.norm2.bias grad: -9.823943400988355e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.6529486351355445e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.4105871741776355e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.6194260297197616e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.823927616191213e-07
sam_encoder.blocks.7.norm1.weight grad: 5.789065085082257e-07
sam_encoder.blocks.7.norm1.bias grad: 2.1498203750525136e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.329284714302048e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.1225022805992921e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.5165741160672042e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.1812883258244256e-06
sam_encoder.blocks.7.norm2.weight grad: -6.45867930870736e-06
sam_encoder.blocks.7.norm2.bias grad: 1.3102234106554533e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -5.3337680583354086e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.9301363611011766e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 3.3901335427799495e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 8.140675618051318e-07
sam_encoder.blocks.8.norm1.weight grad: 6.167219453345751e-06
sam_encoder.blocks.8.norm1.bias grad: 6.782726131859818e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.872397312283283e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.6102710510022007e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.0781852728978265e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.101465608779108e-06
sam_encoder.blocks.8.norm2.weight grad: -2.8658864721364807e-06
sam_encoder.blocks.8.norm2.bias grad: -4.911489099868049e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.260379116909462e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.2640255135920597e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.0675034900486935e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 8.470188959108782e-07
sam_encoder.blocks.9.norm1.weight grad: 3.376691438461421e-06
sam_encoder.blocks.9.norm1.bias grad: -3.1977796766113897e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.6382878129661549e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.9078800050920108e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.093385944590409e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 5.727207508243737e-07
sam_encoder.blocks.9.norm2.weight grad: -4.399789759190753e-07
sam_encoder.blocks.9.norm2.bias grad: 3.3184139738295926e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.9640668799402192e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -9.849619431179235e-08
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.3634478364110691e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 7.903751679805282e-07
sam_encoder.blocks.10.norm1.weight grad: 1.572396627125272e-06
sam_encoder.blocks.10.norm1.bias grad: 6.776376721973065e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.409748157740978e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.3789238195727194e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -8.504797506247996e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -5.603731096925912e-07
sam_encoder.blocks.10.norm2.weight grad: -3.6414028272702126e-06
sam_encoder.blocks.10.norm2.bias grad: 1.9058692259932286e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.155889655521605e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.0107601156050805e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 4.7010820480863913e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 7.189790096617799e-08
sam_encoder.blocks.11.norm1.weight grad: -1.2121056897740345e-05
sam_encoder.blocks.11.norm1.bias grad: 4.347910362412222e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.7339938267468824e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -7.361870757449651e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.0254930202791002e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -6.193768626872043e-07
sam_encoder.blocks.11.norm2.weight grad: -2.5119334168266505e-06
sam_encoder.blocks.11.norm2.bias grad: 3.498045657579496e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.61458762906841e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -6.639949106101994e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 8.654652674522367e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.6830533411393844e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.0131066119356547e-06
sam_encoder.neck.conv1.trainable_shift grad: -1.4212282621883787e-06
sam_encoder.neck.conv2.trainable_scale grad: 7.065536919981241e-07
sam_encoder.neck.conv2.trainable_shift grad: -9.606080857338384e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.0001338819129159674
mask_decoder.transformer.layers.0.norm1.bias grad: -1.222259015776217e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0015255843754857779
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0004418363096192479
mask_decoder.transformer.layers.0.norm3.weight grad: 6.121581100160256e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.5612400349928066e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -5.070554107078351e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 7.146940333768725e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -2.378285898885224e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.6727790352888405e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -3.793520590988919e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -5.1966242608614266e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -3.605526944738813e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.99782948079519e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -5.913684617553372e-07
mask_decoder.transformer.layers.1.norm4.bias grad: 1.7330808987026103e-05
mask_decoder.transformer.norm_final_attn.weight grad: 7.545426115029841e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.4787893860557233e-06
Text_Embedding_Affine.0.weight grad: -2.719277494150907e-12
Text_Embedding_Affine.0.bias grad: -3.199747411475329e-11
Text_Embedding_Affine.2.weight grad: -7.567650672779536e-11
Text_Embedding_Affine.2.bias grad: -2.2482774511445314e-05
Epoch 13 finished with average loss: -58.7298
Epoch 14/39
----------
Epoch 14:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 14:   0%|          | 0/3 [00:01<?, ?it/s, loss=-54.8]Epoch 14:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.01s/it, loss=-54.8]Epoch 14:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.01s/it, loss=-55.6]Epoch 14:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-55.6]Epoch 14:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.57it/s, loss=-59.8]Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.14it/s, loss=-59.8]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.3603178740073303e-16
Max value: 0.999967098236084
Mean value: 0.0729346051812172

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.3603178740073303e-16
Max value: 0.999967098236084
Mean value: 0.0729346051812172

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07131767272949219

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11898262798786163

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06223869323730469

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07131767272949219

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 34.90873718261719
Max value: 74.64155578613281
Mean value: 54.7718505859375

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.3603178740073303e-16
Max value: 0.999967098236084
Mean value: 0.0729346051812172

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.3603178740073303e-16
Max value: 0.999967098236084
Mean value: 0.0729346051812172

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.3603178740073303e-16
Max value: 0.999967098236084
Mean value: 0.0729346051812172

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11898262798786163

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 34.90873718261719
Max value: 74.64155578613281
Mean value: 54.7718505859375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -54.77286148071289
Max value: -54.77286148071289
Mean value: -54.77286148071289
sam_encoder.pos_embed grad: 1.0577727582727903e-09
sam_encoder.blocks.0.norm1.weight grad: 9.552408300805837e-06
sam_encoder.blocks.0.norm1.bias grad: 2.70098535111174e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.4145643945084885e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.132696153012148e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -3.879230462189298e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 5.953227741883893e-07
sam_encoder.blocks.0.norm2.weight grad: -2.6799766601470765e-06
sam_encoder.blocks.0.norm2.bias grad: 1.6992980818031356e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.089107809093548e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.225015805379371e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.2865199096268043e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.6575202153035207e-06
sam_encoder.blocks.1.norm1.weight grad: -2.323724856978515e-06
sam_encoder.blocks.1.norm1.bias grad: -1.0854167840079754e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.505838321871124e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.1776364772231318e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 3.011145508935442e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.1839418877789285e-06
sam_encoder.blocks.1.norm2.weight grad: 4.921281515635201e-07
sam_encoder.blocks.1.norm2.bias grad: -2.292472345288843e-08
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.7360200672555948e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.709530341846403e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 3.388082404853776e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -8.231056369822909e-08
sam_encoder.blocks.2.norm1.weight grad: 2.7084895464213332e-06
sam_encoder.blocks.2.norm1.bias grad: -6.784418360439304e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.1855577162787085e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 8.668648092680087e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.420614237053087e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.265663399863115e-06
sam_encoder.blocks.2.norm2.weight grad: 3.396287638679496e-06
sam_encoder.blocks.2.norm2.bias grad: -8.215683919843286e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 2.393182512605563e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.775439883999752e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.8536405832492164e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -9.29122847992403e-07
sam_encoder.blocks.3.norm1.weight grad: -2.0731595213874243e-06
sam_encoder.blocks.3.norm1.bias grad: -1.4454999472945929e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.633160875120666e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -7.223220563901123e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.0152062297238444e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.6419691917235468e-07
sam_encoder.blocks.3.norm2.weight grad: 5.142660938872723e-06
sam_encoder.blocks.3.norm2.bias grad: 2.8313286293268902e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 3.194963028363418e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.2895847021354712e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -5.970313168290886e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -9.161655043499195e-07
sam_encoder.blocks.4.norm1.weight grad: -2.2359622562362347e-06
sam_encoder.blocks.4.norm1.bias grad: 1.8054049633065006e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.9741319192689843e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.242178531261743e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.0821123314362922e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -9.844804793601725e-08
sam_encoder.blocks.4.norm2.weight grad: -4.13367979490431e-06
sam_encoder.blocks.4.norm2.bias grad: -3.044430741283577e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.2985233247018186e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -8.147654853019048e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.3876846171333455e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.4567325479220017e-06
sam_encoder.blocks.5.norm1.weight grad: -7.619380085088778e-06
sam_encoder.blocks.5.norm1.bias grad: -6.3450233938056044e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.7119486933079315e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.756064989422157e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -6.178417493174493e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -4.620105755748227e-07
sam_encoder.blocks.5.norm2.weight grad: -4.587935109157115e-06
sam_encoder.blocks.5.norm2.bias grad: -3.5612326882983325e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.7928033432544908e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -8.524695545020222e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 6.484940513473703e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.1922893956325424e-07
sam_encoder.blocks.6.norm1.weight grad: 1.7840555983639206e-06
sam_encoder.blocks.6.norm1.bias grad: -2.3705060812062584e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 6.25959273747867e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.3841945190051774e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.197541324581834e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -5.937306468695169e-08
sam_encoder.blocks.6.norm2.weight grad: 1.2661718074014061e-06
sam_encoder.blocks.6.norm2.bias grad: 1.3970309282740345e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 9.101067917072214e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.5656613072678738e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.1614189361353056e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.50300382478963e-07
sam_encoder.blocks.7.norm1.weight grad: -1.9945398435083916e-06
sam_encoder.blocks.7.norm1.bias grad: 7.020846055638685e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.3687298405784531e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.080212766486511e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -4.937998028253787e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.8703278783505084e-06
sam_encoder.blocks.7.norm2.weight grad: 2.1334924440452596e-06
sam_encoder.blocks.7.norm2.bias grad: -1.4271985264713294e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.030099039984634e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.0692069685755996e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.5275026044037077e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.8801909479625465e-07
sam_encoder.blocks.8.norm1.weight grad: 1.5661546513001667e-06
sam_encoder.blocks.8.norm1.bias grad: -4.399494173412677e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.906748927169247e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.6567181521386374e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 4.357298166723922e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 5.170121397668481e-08
sam_encoder.blocks.8.norm2.weight grad: -2.715369191719219e-06
sam_encoder.blocks.8.norm2.bias grad: -3.5611873272500816e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.5762044515431626e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.1984354841843015e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.266425897483714e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -9.107060350288521e-07
sam_encoder.blocks.9.norm1.weight grad: -4.004957645520335e-06
sam_encoder.blocks.9.norm1.bias grad: 5.465439016916207e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.5300270155858016e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -7.560360018032952e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -8.897033012544853e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.750452025196864e-07
sam_encoder.blocks.9.norm2.weight grad: -2.0398833839863073e-06
sam_encoder.blocks.9.norm2.bias grad: -1.824339392442198e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.07772427782038e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -8.378004849873832e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.709029527954044e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.3934566090465523e-07
sam_encoder.blocks.10.norm1.weight grad: 7.308931344596203e-07
sam_encoder.blocks.10.norm1.bias grad: -2.8514438099591644e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.9301605763976113e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.6897953375737416e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 7.194484510364418e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.6950500493258e-07
sam_encoder.blocks.10.norm2.weight grad: -5.5253140089917e-06
sam_encoder.blocks.10.norm2.bias grad: -3.2668644962541293e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.373307324887719e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.5712689673819114e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.4050259551368072e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -6.388304427673575e-07
sam_encoder.blocks.11.norm1.weight grad: -1.6132403288793284e-06
sam_encoder.blocks.11.norm1.bias grad: -5.436885430754046e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.73312722956598e-08
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.2485960709796018e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.209102606480883e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 8.168305498656991e-07
sam_encoder.blocks.11.norm2.weight grad: -4.158408046350814e-06
sam_encoder.blocks.11.norm2.bias grad: -2.5083327273023315e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -9.532267881695589e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.0990657983711571e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.3165017662686296e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.4594052067404846e-07
sam_encoder.neck.conv1.trainable_scale grad: -5.419606168288738e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.575052010593936e-05
sam_encoder.neck.conv2.trainable_scale grad: -5.576930561801419e-07
sam_encoder.neck.conv2.trainable_shift grad: 4.1184117435477674e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00017423249664716423
mask_decoder.transformer.layers.0.norm1.bias grad: 1.964228431461379e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0016209636814892292
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00045546545879915357
mask_decoder.transformer.layers.0.norm3.weight grad: -3.048494181712158e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.4237792129279114e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 8.354446617886424e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -3.6833494050370064e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.7060705431504175e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.4928518794476986e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 8.763954974710941e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 5.904119461774826e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.075359563808888e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.8969090635655448e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -9.070681699085981e-07
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0001093879618565552
mask_decoder.transformer.norm_final_attn.weight grad: 4.05181663154508e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.1884518244187348e-05
Text_Embedding_Affine.0.weight grad: 4.59543427616671e-13
Text_Embedding_Affine.0.bias grad: 1.7703560839521515e-10
Text_Embedding_Affine.2.weight grad: 6.031447563614734e-11
Text_Embedding_Affine.2.bias grad: 2.4407221644651145e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.9817848857940022e-23
Max value: 0.9999890327453613
Mean value: 0.07294702529907227

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.9817848857940022e-23
Max value: 0.9999890327453613
Mean value: 0.07294702529907227

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08775806427001953

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14687439799308777

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06881570816040039

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08775806427001953

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 44.83468246459961
Max value: 70.05006408691406
Mean value: 56.39836883544922

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.914443900297432e-22
Max value: 0.9999817609786987
Mean value: 0.07274660468101501

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.914443900297432e-22
Max value: 0.9999817609786987
Mean value: 0.07274660468101501

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.914443900297432e-22
Max value: 0.9999817609786987
Mean value: 0.07274660468101501

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.144364595413208

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.917062520980835
Max value: 3.2645492553710938
Mean value: 1.003075122833252

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 44.83468246459961
Max value: 70.05006408691406
Mean value: 56.39836883544922

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.513763427734375
Max value: -56.513763427734375
Mean value: -56.513763427734375
sam_encoder.pos_embed grad: -3.3417073552755028e-09
sam_encoder.blocks.0.norm1.weight grad: -1.2396318197716027e-05
sam_encoder.blocks.0.norm1.bias grad: 2.2914809960639104e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.20076605930808e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 9.012804014219e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.270562046964187e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.643924060270365e-07
sam_encoder.blocks.0.norm2.weight grad: -1.5507857824559323e-05
sam_encoder.blocks.0.norm2.bias grad: 2.3366068489849567e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.2912352758576162e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -8.041826731641777e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.307569229742512e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -9.499929547018837e-06
sam_encoder.blocks.1.norm1.weight grad: -9.512170436209999e-06
sam_encoder.blocks.1.norm1.bias grad: 9.96583366941195e-08
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.853769951296272e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.2473705030279234e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.268823886377504e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.496077058822266e-06
sam_encoder.blocks.1.norm2.weight grad: 2.143393430742435e-05
sam_encoder.blocks.1.norm2.bias grad: -6.054315235815011e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.0019763976742979e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.6389120673920843e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.0434372597956099e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.8432321386162585e-08
sam_encoder.blocks.2.norm1.weight grad: 7.824120984878391e-06
sam_encoder.blocks.2.norm1.bias grad: 1.076847865988384e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.992708909412613e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 8.068396937233047e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.0459010582053452e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.3298798648975207e-06
sam_encoder.blocks.2.norm2.weight grad: 1.122857383961673e-06
sam_encoder.blocks.2.norm2.bias grad: -6.155477876745863e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 2.6265468022756977e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -9.780558229977032e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.6931470529234502e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -7.43607415643055e-07
sam_encoder.blocks.3.norm1.weight grad: -3.7054029178307246e-08
sam_encoder.blocks.3.norm1.bias grad: -3.463003622528049e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.284797796572093e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.29023942463391e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 8.069946488831192e-09
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 9.891040235743276e-07
sam_encoder.blocks.3.norm2.weight grad: 3.3716178222675808e-06
sam_encoder.blocks.3.norm2.bias grad: -4.649882157536922e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 3.2277275749947876e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.3711064639210235e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.973120096314233e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 8.264979669547756e-07
sam_encoder.blocks.4.norm1.weight grad: 9.45116062212037e-06
sam_encoder.blocks.4.norm1.bias grad: 3.1700526506028837e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 4.279142558516469e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.2981585939542128e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 4.048595656058751e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.230501079087844e-06
sam_encoder.blocks.4.norm2.weight grad: -3.092921542702243e-05
sam_encoder.blocks.4.norm2.bias grad: -2.990321627294179e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.797122968127951e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.991113878029864e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.8931432350655086e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -3.248374014219735e-07
sam_encoder.blocks.5.norm1.weight grad: -3.77455580746755e-06
sam_encoder.blocks.5.norm1.bias grad: -3.892729182553012e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.801886461791582e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -5.507702553586569e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.496247759609105e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 4.948777814206551e-07
sam_encoder.blocks.5.norm2.weight grad: -1.3270814633870032e-05
sam_encoder.blocks.5.norm2.bias grad: -1.4079030734137632e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.444526323117316e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.1593434667011024e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.623619482415961e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.515001362255134e-07
sam_encoder.blocks.6.norm1.weight grad: 2.42500561853376e-07
sam_encoder.blocks.6.norm1.bias grad: 3.3127669212262845e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -5.576014814323571e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -5.975018666504184e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.019926341745304e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.896878210061459e-08
sam_encoder.blocks.6.norm2.weight grad: -9.50799039856065e-06
sam_encoder.blocks.6.norm2.bias grad: -4.240088856022339e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.48935110802995e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.9997809178894386e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.9878448256349657e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -5.134943421580829e-07
sam_encoder.blocks.7.norm1.weight grad: 9.134316314884927e-06
sam_encoder.blocks.7.norm1.bias grad: -2.393438478520693e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 5.487787348101847e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 3.0832889024168253e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.4123892217176035e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.1984126331299194e-06
sam_encoder.blocks.7.norm2.weight grad: -1.99376700038556e-07
sam_encoder.blocks.7.norm2.bias grad: 9.280382755605388e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.8181215182266897e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.612389605223143e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.1965884141318384e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.3216756542533403e-06
sam_encoder.blocks.8.norm1.weight grad: 1.169528241007356e-05
sam_encoder.blocks.8.norm1.bias grad: -1.948964381881524e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.0287948498444166e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.8983704396523535e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.475329094726476e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.69062309396395e-06
sam_encoder.blocks.8.norm2.weight grad: -5.11100279254606e-06
sam_encoder.blocks.8.norm2.bias grad: -2.584663434390677e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.221621227567084e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.8900277609645855e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.9731587599380873e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.667651645220758e-06
sam_encoder.blocks.9.norm1.weight grad: 6.893255886097904e-07
sam_encoder.blocks.9.norm1.bias grad: 2.808822896493979e-10
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.1740876288968138e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 4.6254962171587977e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 8.051476640957844e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.3465660231304355e-07
sam_encoder.blocks.9.norm2.weight grad: 1.1304177860438358e-06
sam_encoder.blocks.9.norm2.bias grad: -2.9321230954337807e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.650746298764716e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 8.66526534082368e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.900911451637512e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.271909001043241e-07
sam_encoder.blocks.10.norm1.weight grad: 6.616263817704748e-06
sam_encoder.blocks.10.norm1.bias grad: 8.815248975224677e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 4.093511961400509e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.5160917428147513e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.1418811684270622e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.1247406064285315e-06
sam_encoder.blocks.10.norm2.weight grad: 8.103966138151009e-07
sam_encoder.blocks.10.norm2.bias grad: -1.537365733383922e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.619618615222862e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 9.724781193654053e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -8.108440852083731e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -6.587882808162249e-07
sam_encoder.blocks.11.norm1.weight grad: 2.021950058406219e-05
sam_encoder.blocks.11.norm1.bias grad: 2.078071247524349e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 5.4301522141031455e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.5247794635797618e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 4.554951374302618e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.064866293949308e-06
sam_encoder.blocks.11.norm2.weight grad: 6.4215964812319726e-06
sam_encoder.blocks.11.norm2.bias grad: 4.655542795717338e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.565589850040851e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.171361191154574e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.9909973048015672e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.4228125283798363e-08
sam_encoder.neck.conv1.trainable_scale grad: -4.1715975385159254e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.955929838004522e-05
sam_encoder.neck.conv2.trainable_scale grad: -3.726636350620538e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.0889407349168323e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -8.76621634233743e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -3.2168100005947053e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0025686463341116905
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00017587735783308744
mask_decoder.transformer.layers.0.norm3.weight grad: -1.5010202332632616e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.537302134442143e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00013720194692723453
mask_decoder.transformer.layers.0.norm4.bias grad: -5.688418241334148e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.1834924407594372e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 5.0213657232234254e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00013579026563093066
mask_decoder.transformer.layers.1.norm2.bias grad: -1.832476118579507e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.9726669860538095e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.211076207458973e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -4.8176891141338274e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00023393373703584075
mask_decoder.transformer.norm_final_attn.weight grad: 3.8064076761656906e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.5992307453416288e-05
Text_Embedding_Affine.0.weight grad: -1.5527115183877616e-12
Text_Embedding_Affine.0.bias grad: -7.30532162540598e-11
Text_Embedding_Affine.2.weight grad: 3.976938917071848e-11
Text_Embedding_Affine.2.bias grad: 8.876337233232334e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0803348741582255e-14
Max value: 0.9999761581420898
Mean value: 0.09958101809024811

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0803348741582255e-14
Max value: 0.9999761581420898
Mean value: 0.09958101809024811

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10042667388916016

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1361696869134903

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0950918197631836

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10042667388916016

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 52.96604537963867
Max value: 85.15107727050781
Mean value: 68.03482055664062

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.210549230983628e-13
Max value: 0.9999493360519409
Mean value: 0.10092766582965851

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.210549230983628e-13
Max value: 0.9999493360519409
Mean value: 0.10092766582965851

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.210549230983628e-13
Max value: 0.9999493360519409
Mean value: 0.10092766582965851

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13279646635055542

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8422417044639587
Max value: 8.772051811218262
Mean value: 1.0051321983337402

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 52.96604537963867
Max value: 85.15107727050781
Mean value: 68.03482055664062

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -68.13683319091797
Max value: -68.13683319091797
Mean value: -68.13683319091797
sam_encoder.pos_embed grad: 7.216774289275918e-09
sam_encoder.blocks.0.norm1.weight grad: -1.2745513231493533e-05
sam_encoder.blocks.0.norm1.bias grad: -2.811451122397557e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.179438235496491e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.3948018557671276e-09
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.1716542758222204e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.3091403988928505e-07
sam_encoder.blocks.0.norm2.weight grad: 2.9722359613515437e-06
sam_encoder.blocks.0.norm2.bias grad: -3.2515758903173264e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 4.417556738189887e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 5.803294243378332e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.4540522897732444e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 7.60657167120371e-06
sam_encoder.blocks.1.norm1.weight grad: 8.694762982486282e-06
sam_encoder.blocks.1.norm1.bias grad: 9.894848517433275e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.901694071828388e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.762008992045594e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.57487419428071e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.15415582008427e-06
sam_encoder.blocks.1.norm2.weight grad: -3.63127765012905e-06
sam_encoder.blocks.1.norm2.bias grad: -3.0955059173720656e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -7.049854502838571e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.0717393479353632e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -7.380060196737759e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -9.681962183094583e-07
sam_encoder.blocks.2.norm1.weight grad: -9.241506631951779e-06
sam_encoder.blocks.2.norm1.bias grad: 5.787627287645591e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -6.494973604276311e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.2586606317199767e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.954038220399525e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.526534328557318e-06
sam_encoder.blocks.2.norm2.weight grad: -4.703736522060353e-06
sam_encoder.blocks.2.norm2.bias grad: 4.315089881856693e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.5586554076871835e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 5.048494813308935e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -5.521407729247585e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.7406213146387017e-06
sam_encoder.blocks.3.norm1.weight grad: -4.056050329381833e-06
sam_encoder.blocks.3.norm1.bias grad: 1.6367027910746401e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.2000199351168703e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.119188823395234e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.6022232759714825e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.0489345590467565e-06
sam_encoder.blocks.3.norm2.weight grad: -9.456620318815112e-06
sam_encoder.blocks.3.norm2.bias grad: -5.177780167286983e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -8.107928806566633e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.969475644931663e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.7263928384636529e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.3078871436155168e-07
sam_encoder.blocks.4.norm1.weight grad: -5.731067176384386e-08
sam_encoder.blocks.4.norm1.bias grad: -4.502722731558606e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.1601898677326972e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.2020981898785976e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.247239535790868e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.194818534917431e-06
sam_encoder.blocks.4.norm2.weight grad: 1.2413284821377601e-05
sam_encoder.blocks.4.norm2.bias grad: 8.102446372504346e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 5.67021334063611e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.2810477275925223e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 7.995155897333461e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 5.645585474667314e-07
sam_encoder.blocks.5.norm1.weight grad: 5.814306859974749e-06
sam_encoder.blocks.5.norm1.bias grad: -4.775060460815439e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.890510354016442e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.7785322345152963e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.3187860733742127e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.1245985831465077e-07
sam_encoder.blocks.5.norm2.weight grad: 7.367219950538129e-06
sam_encoder.blocks.5.norm2.bias grad: 5.888000941922655e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 2.970853074657498e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 8.676266816110001e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.2354329328445601e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 9.580171536072157e-07
sam_encoder.blocks.6.norm1.weight grad: -9.594263019607752e-07
sam_encoder.blocks.6.norm1.bias grad: -3.962913069699425e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 8.977539067700491e-08
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 9.107657206186559e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -8.940177735894395e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -3.5488545790940407e-07
sam_encoder.blocks.6.norm2.weight grad: 3.1802035209693713e-06
sam_encoder.blocks.6.norm2.bias grad: 2.3645950477657607e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.6306720453940216e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.5899378758585954e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.7910915062202548e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.336434807963087e-07
sam_encoder.blocks.7.norm1.weight grad: -5.441642770165345e-06
sam_encoder.blocks.7.norm1.bias grad: -1.1333759175613523e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -4.336184247222263e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.0435604710655753e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.411058176221559e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.141265463886157e-08
sam_encoder.blocks.7.norm2.weight grad: -2.009967602134566e-06
sam_encoder.blocks.7.norm2.bias grad: -9.465040875511477e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.606596353871282e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.572044652675686e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.854090723758418e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.1135610975543386e-06
sam_encoder.blocks.8.norm1.weight grad: -2.9941354569018586e-06
sam_encoder.blocks.8.norm1.bias grad: 2.208298326422664e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.3867663710698253e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.02674686483806e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.878230018017348e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.9233888199087232e-06
sam_encoder.blocks.8.norm2.weight grad: -1.8171330111727002e-06
sam_encoder.blocks.8.norm2.bias grad: 2.0718138671327324e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.9142684070393443e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.257760004591546e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.0070346806733141e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 7.02651675510424e-07
sam_encoder.blocks.9.norm1.weight grad: 4.3570857144459296e-08
sam_encoder.blocks.9.norm1.bias grad: -8.455317015432229e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.3762141293227614e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.948489049638738e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -8.610265211927981e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.383180858738342e-07
sam_encoder.blocks.9.norm2.weight grad: -5.45073044122546e-06
sam_encoder.blocks.9.norm2.bias grad: 8.992291782305983e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -6.1473124333133455e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.370028369114152e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -7.422808039336815e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.909056320277159e-07
sam_encoder.blocks.10.norm1.weight grad: -3.9488895708927885e-06
sam_encoder.blocks.10.norm1.bias grad: -1.1222743978578364e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.414846676401794e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.2341552064754069e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.5240134416671935e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -8.991551112558227e-07
sam_encoder.blocks.10.norm2.weight grad: -1.1219075531698763e-05
sam_encoder.blocks.10.norm2.bias grad: -7.22115942153323e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -7.96260246715974e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.396001375222113e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.6376443454646505e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.2499264079888235e-07
sam_encoder.blocks.11.norm1.weight grad: -1.376872751279734e-05
sam_encoder.blocks.11.norm1.bias grad: 1.1091664191553718e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.7615579395169334e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.214771714330709e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.5851881016715197e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -9.751718152983813e-07
sam_encoder.blocks.11.norm2.weight grad: -1.3981148185848724e-05
sam_encoder.blocks.11.norm2.bias grad: -1.5061953035910847e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -7.425135663652327e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.5958247533708345e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.2526015780167654e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.5044066609989386e-07
sam_encoder.neck.conv1.trainable_scale grad: 4.6699824451934546e-07
sam_encoder.neck.conv1.trainable_shift grad: 5.061181582277641e-06
sam_encoder.neck.conv2.trainable_scale grad: 7.69209236750612e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.9346045519341715e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 7.014258153503761e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.3973840395919979e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004013890400528908
mask_decoder.transformer.layers.0.norm2.bias grad: -7.691176142543554e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 4.251296923030168e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.2771282854373567e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -8.832126331981272e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 9.860043974185828e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.401333171699662e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -2.988271717185853e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00011897100193891674
mask_decoder.transformer.layers.1.norm2.bias grad: 1.295944457524456e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -3.0982570024207234e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -8.532858373655472e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 4.760398223879747e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00017395245959050953
mask_decoder.transformer.norm_final_attn.weight grad: 5.298915084495093e-07
mask_decoder.transformer.norm_final_attn.bias grad: -5.9439103097247425e-06
Text_Embedding_Affine.0.weight grad: -5.385485460362993e-12
Text_Embedding_Affine.0.bias grad: -2.1486178114482613e-10
Text_Embedding_Affine.2.weight grad: -6.839644128842082e-11
Text_Embedding_Affine.2.bias grad: -2.0668852812377736e-05
Epoch 14 finished with average loss: -59.8078
Epoch 15/39
----------
Epoch 15:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 15:   0%|          | 0/3 [00:00<?, ?it/s, loss=-57.1]Epoch 15:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.14it/s, loss=-57.1]Epoch 15:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.14it/s, loss=-56.8]Epoch 15:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.73it/s, loss=-56.8]Epoch 15:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.73it/s, loss=-58]  Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.38it/s, loss=-58]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                 
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.1650113852303704e-19
Max value: 0.9999959468841553
Mean value: 0.07150281220674515

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1650113852303704e-19
Max value: 0.9999959468841553
Mean value: 0.07150281220674515

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07196187973022461

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12206999212503433

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06478214263916016

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07196187973022461

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 42.58108901977539
Max value: 72.1766128540039
Mean value: 57.0599365234375

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.1650113852303704e-19
Max value: 0.9999959468841553
Mean value: 0.07150281220674515

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1650113852303704e-19
Max value: 0.9999959468841553
Mean value: 0.07150281220674515

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1650113852303704e-19
Max value: 0.9999959468841553
Mean value: 0.07150281220674515

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12206999212503433

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 42.58108901977539
Max value: 72.1766128540039
Mean value: 57.0599365234375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.06075668334961
Max value: -57.06075668334961
Mean value: -57.06075668334961
sam_encoder.pos_embed grad: -1.2075108690723368e-09
sam_encoder.blocks.0.norm1.weight grad: 1.683467962720897e-05
sam_encoder.blocks.0.norm1.bias grad: 3.782966814469546e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.6834527488972526e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 3.891566109359701e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.995161255763378e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 9.846689863479696e-07
sam_encoder.blocks.0.norm2.weight grad: 1.6516816685907543e-05
sam_encoder.blocks.0.norm2.bias grad: -2.3445452370651765e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.7100048189131485e-07
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.4774204828427173e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -9.874211173155345e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.447387830921798e-06
sam_encoder.blocks.1.norm1.weight grad: 3.2127445592777804e-06
sam_encoder.blocks.1.norm1.bias grad: -1.865189346972329e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.598175908336998e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.8821616265540797e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 7.004863959991781e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 6.671540973002266e-07
sam_encoder.blocks.1.norm2.weight grad: 8.598994099884294e-06
sam_encoder.blocks.1.norm2.bias grad: -1.0608112006593728e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.897715027458617e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 8.279016583401244e-08
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.3737912922806572e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.761702606017934e-08
sam_encoder.blocks.2.norm1.weight grad: -2.6531324692768976e-06
sam_encoder.blocks.2.norm1.bias grad: -5.490823241416365e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -8.172045795618033e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -7.592370820930228e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.5136781712499214e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -9.904897524393164e-07
sam_encoder.blocks.2.norm2.weight grad: -5.52926940144971e-06
sam_encoder.blocks.2.norm2.bias grad: -5.517647878150456e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.1864080938248662e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.519122065474221e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.303988690589904e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.487033488156158e-07
sam_encoder.blocks.3.norm1.weight grad: -5.652897925756406e-06
sam_encoder.blocks.3.norm1.bias grad: -5.847896318300627e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.085901764483424e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.261298383629764e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.5258495977832354e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.92015721217831e-07
sam_encoder.blocks.3.norm2.weight grad: 4.4106427594670095e-06
sam_encoder.blocks.3.norm2.bias grad: 5.333698481990723e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 3.105919859081041e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.8477319372323109e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.2229432968524634e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -3.7238201855416264e-08
sam_encoder.blocks.4.norm1.weight grad: -3.796017153945286e-06
sam_encoder.blocks.4.norm1.bias grad: 1.833851001720177e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.043377091671573e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -9.834031970967771e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 4.796540338247723e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.9566873277199193e-07
sam_encoder.blocks.4.norm2.weight grad: -1.2574309039337095e-05
sam_encoder.blocks.4.norm2.bias grad: -8.70540679898113e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -8.178059943020344e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.414050979699823e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.896634330478264e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.469239919060783e-06
sam_encoder.blocks.5.norm1.weight grad: -2.0651314116548747e-06
sam_encoder.blocks.5.norm1.bias grad: -2.301767153767287e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -6.53459665045375e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -4.988088448953931e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 6.288327085712808e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -9.581385711499024e-07
sam_encoder.blocks.5.norm2.weight grad: -6.539863534271717e-06
sam_encoder.blocks.5.norm2.bias grad: -4.7855082812020555e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.29471254190139e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.2944653917656979e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 7.505926760131842e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.566049938148353e-07
sam_encoder.blocks.6.norm1.weight grad: -2.271404355269624e-06
sam_encoder.blocks.6.norm1.bias grad: 2.1996167731686e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.08376343632699e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -4.139612883591326e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 5.31353634869447e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -3.0428464015130885e-07
sam_encoder.blocks.6.norm2.weight grad: 1.6269477782770991e-06
sam_encoder.blocks.6.norm2.bias grad: 3.135614861093927e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 7.482170758521534e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.453876166124246e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.6202905044337967e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.200676807566197e-07
sam_encoder.blocks.7.norm1.weight grad: 9.516245427221293e-07
sam_encoder.blocks.7.norm1.bias grad: 1.0102394298883155e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 9.696602774056373e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 9.196096470986959e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 5.467202868203458e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -9.766174571268493e-07
sam_encoder.blocks.7.norm2.weight grad: 7.186849870777223e-08
sam_encoder.blocks.7.norm2.bias grad: 1.0517720738789649e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 6.03014768785215e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.0058311633874837e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.833950756870763e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.8257000533594692e-07
sam_encoder.blocks.8.norm1.weight grad: 3.126852334389696e-06
sam_encoder.blocks.8.norm1.bias grad: -6.000482244417071e-08
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.5425114270328777e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.878961424812587e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 5.93956883676583e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -6.572721531483694e-07
sam_encoder.blocks.8.norm2.weight grad: -2.023086381086614e-06
sam_encoder.blocks.8.norm2.bias grad: -1.585937752679456e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.425220489181811e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -5.256844133327832e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -8.573119885113556e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.026280286481779e-07
sam_encoder.blocks.9.norm1.weight grad: -8.568455882596027e-07
sam_encoder.blocks.9.norm1.bias grad: 3.6175856621412095e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -8.29882878861099e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -3.7284166864992585e-08
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.395949417812517e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -6.332645625661826e-07
sam_encoder.blocks.9.norm2.weight grad: 5.6937249581778815e-08
sam_encoder.blocks.9.norm2.bias grad: -1.309864614995604e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 5.2815533280181626e-08
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.587751737337385e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.5456718926998292e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.661675347961136e-07
sam_encoder.blocks.10.norm1.weight grad: 3.898179784300737e-06
sam_encoder.blocks.10.norm1.bias grad: -1.7961951925826725e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.2923095457372256e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 9.684224551165244e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.2512640523709706e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.968459042080212e-07
sam_encoder.blocks.10.norm2.weight grad: -6.261466296564322e-07
sam_encoder.blocks.10.norm2.bias grad: -2.019702151301317e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.3097528039907047e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.402520173447556e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -8.119081940094475e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.231426089518209e-07
sam_encoder.blocks.11.norm1.weight grad: 5.128205884830095e-06
sam_encoder.blocks.11.norm1.bias grad: -6.815218398514844e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 6.10645372489671e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.145331106679805e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.559961447128444e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 7.000439268267655e-07
sam_encoder.blocks.11.norm2.weight grad: -3.855942850350402e-06
sam_encoder.blocks.11.norm2.bias grad: -2.0267350464564515e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.749264684913214e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -8.04354556294129e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.2733906942230533e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.2922121679112024e-07
sam_encoder.neck.conv1.trainable_scale grad: -5.585461622104049e-07
sam_encoder.neck.conv1.trainable_shift grad: -3.0159528250806034e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.0719486454036087e-06
sam_encoder.neck.conv2.trainable_shift grad: 3.9328428101725876e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00018028944032266736
mask_decoder.transformer.layers.0.norm1.bias grad: -1.0513031156733632e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.001356199150905013
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00031047267839312553
mask_decoder.transformer.layers.0.norm3.weight grad: -3.1331459467764944e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.0298621418769471e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 6.914182449690998e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.1761762834794354e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.120887009165017e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -4.83818439533934e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 2.0664061594288796e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 2.1305197151377797e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.075733886566013e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.165714588249102e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.7618029232835397e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00011280598846497014
mask_decoder.transformer.norm_final_attn.weight grad: 6.05479181103874e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.2193258044135291e-05
Text_Embedding_Affine.0.weight grad: 4.916598378423842e-12
Text_Embedding_Affine.0.bias grad: 2.5947449744379014e-10
Text_Embedding_Affine.2.weight grad: 8.800529749386499e-12
Text_Embedding_Affine.2.bias grad: 1.874432564363815e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.4246177007704984e-17
Max value: 0.9999569654464722
Mean value: 0.07481297850608826

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.4246177007704984e-17
Max value: 0.9999569654464722
Mean value: 0.07481297850608826

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09508848190307617

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1646774262189865

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07161092758178711

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09508848190307617

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 3.1919784545898438
Max value: 91.93933868408203
Mean value: 56.49374008178711

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.912075979254235e-16
Max value: 0.9999388456344604
Mean value: 0.07489345967769623

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.912075979254235e-16
Max value: 0.9999388456344604
Mean value: 0.07489345967769623

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.912075979254235e-16
Max value: 0.9999388456344604
Mean value: 0.07489345967769623

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1621350646018982

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9232094287872314
Max value: 4.448322296142578
Mean value: 1.0031569004058838

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 3.1919784545898438
Max value: 91.93933868408203
Mean value: 56.49374008178711

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.591949462890625
Max value: -56.591949462890625
Mean value: -56.591949462890625
sam_encoder.pos_embed grad: -4.6494958994003355e-09
sam_encoder.blocks.0.norm1.weight grad: -1.789972884580493e-05
sam_encoder.blocks.0.norm1.bias grad: 2.4488914277753793e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.647067961130233e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.297302389957622e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.0465056422835914e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 4.016729633349314e-07
sam_encoder.blocks.0.norm2.weight grad: -1.9945222447859123e-05
sam_encoder.blocks.0.norm2.bias grad: 1.1103987162641715e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.3415497960522771e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -6.9596148932760116e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.1090067093609832e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.1265011380601209e-05
sam_encoder.blocks.1.norm1.weight grad: -8.323828296852298e-06
sam_encoder.blocks.1.norm1.bias grad: -6.1067867136443965e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 5.001408680982422e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 4.877314268014743e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.778104994329624e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.6027460080513265e-06
sam_encoder.blocks.1.norm2.weight grad: 2.042123924184125e-05
sam_encoder.blocks.1.norm2.bias grad: 1.2787313607987016e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.0367102731834166e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.014147639783914e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.016198621073272e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.2730183129860961e-07
sam_encoder.blocks.2.norm1.weight grad: 7.094555257936008e-06
sam_encoder.blocks.2.norm1.bias grad: -1.0042771236840053e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 6.15493263467215e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.128518306359183e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 2.7606347430264577e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.640647440126486e-07
sam_encoder.blocks.2.norm2.weight grad: 3.903115157299908e-06
sam_encoder.blocks.2.norm2.bias grad: -8.557094588468317e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 6.116897111496655e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 5.235871185504948e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 4.28430394094903e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.0172751646896359e-07
sam_encoder.blocks.3.norm1.weight grad: -1.3864155334886163e-07
sam_encoder.blocks.3.norm1.bias grad: -4.327985607233131e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.637179133875179e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.3112376109347679e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 6.348740271278075e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 6.000241228321102e-07
sam_encoder.blocks.3.norm2.weight grad: 8.087385140242986e-06
sam_encoder.blocks.3.norm2.bias grad: -2.9678376449737698e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.824249456054531e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.6158330709004076e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.485454832727555e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 8.635255426270305e-07
sam_encoder.blocks.4.norm1.weight grad: 8.055675607465673e-06
sam_encoder.blocks.4.norm1.bias grad: 3.940301098737109e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 3.1867421057540923e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.455902574638458e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.7997788240318187e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.326985734020127e-06
sam_encoder.blocks.4.norm2.weight grad: -2.5722009013406932e-05
sam_encoder.blocks.4.norm2.bias grad: -2.726514321693685e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.4750294212717563e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.805475666420534e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.235307642375119e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 7.084322533046361e-07
sam_encoder.blocks.5.norm1.weight grad: 1.347569195786491e-06
sam_encoder.blocks.5.norm1.bias grad: -4.771845851792023e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.4305194326880155e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -4.282131158106495e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 9.601626516086981e-08
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 6.126896323621622e-07
sam_encoder.blocks.5.norm2.weight grad: -7.189204552560113e-06
sam_encoder.blocks.5.norm2.bias grad: -1.2150194379501045e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.9241919037303887e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -9.719013860376435e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.3667648747505154e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -8.142986729353652e-08
sam_encoder.blocks.6.norm1.weight grad: 8.000708362487785e-07
sam_encoder.blocks.6.norm1.bias grad: 4.437296411197167e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.1335582712490577e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.0354712003390887e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.1655093601348199e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -5.077747005088895e-07
sam_encoder.blocks.6.norm2.weight grad: -8.934397556004114e-06
sam_encoder.blocks.6.norm2.bias grad: -2.4494274839526042e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.639319963142043e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.108195414824877e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.199430471388041e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -8.518003369317739e-07
sam_encoder.blocks.7.norm1.weight grad: 1.2303363291721325e-05
sam_encoder.blocks.7.norm1.bias grad: 1.6082344700407702e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 8.127999535645358e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 4.012877070636023e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.43333522323519e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.0336801636867676e-07
sam_encoder.blocks.7.norm2.weight grad: -9.240729923476465e-07
sam_encoder.blocks.7.norm2.bias grad: 9.98064933810383e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.78888126356469e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.7363082583397045e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.0157476708627655e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.34209892621584e-06
sam_encoder.blocks.8.norm1.weight grad: 9.850064998317976e-06
sam_encoder.blocks.8.norm1.bias grad: -1.8870446183427703e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.214023753476795e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.945188387253438e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.7409122342069168e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.167686943721492e-06
sam_encoder.blocks.8.norm2.weight grad: -2.786033974189195e-06
sam_encoder.blocks.8.norm2.bias grad: -6.619902137572353e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.5132118278415874e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -9.106753964260861e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.2753162081935443e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.488344423705712e-06
sam_encoder.blocks.9.norm1.weight grad: 3.2712166557757882e-06
sam_encoder.blocks.9.norm1.bias grad: -2.7993809226245503e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 3.64348670700565e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.4224033293430693e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.1272084066149546e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 5.813077450511628e-07
sam_encoder.blocks.9.norm2.weight grad: 1.8193329651694512e-06
sam_encoder.blocks.9.norm2.bias grad: -2.7779114475379174e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.8826325433328748e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.3975426327306195e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 7.756178774798173e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.52199026060407e-07
sam_encoder.blocks.10.norm1.weight grad: 7.564912266389001e-06
sam_encoder.blocks.10.norm1.bias grad: 1.1345919119776227e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 4.878450909018284e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.803206032491289e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.3140351004258264e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.104206603486091e-06
sam_encoder.blocks.10.norm2.weight grad: 4.232613264321117e-06
sam_encoder.blocks.10.norm2.bias grad: 2.2126794618770873e-08
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.0730313937965548e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.044276925516897e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 6.931966254342115e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.369958332972601e-07
sam_encoder.blocks.11.norm1.weight grad: 1.8864131561713293e-05
sam_encoder.blocks.11.norm1.bias grad: 2.6866989628615556e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.953345185436774e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 9.425720008948701e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.534657025738852e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.362466150567343e-06
sam_encoder.blocks.11.norm2.weight grad: 8.006953066796996e-06
sam_encoder.blocks.11.norm2.bias grad: 1.1098802588094259e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.496010660659522e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.7137148233814514e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 9.382931693835417e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.9779682247644814e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.060616341419518e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.491357761551626e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.010557753033936e-07
sam_encoder.neck.conv2.trainable_shift grad: -2.0049548766110092e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 3.2684711186448112e-06
mask_decoder.transformer.layers.0.norm1.bias grad: -1.6045851225499064e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0053322650492191315
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00048616353888064623
mask_decoder.transformer.layers.0.norm3.weight grad: -5.714994404115714e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -6.293822661973536e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00013376722927205265
mask_decoder.transformer.layers.0.norm4.bias grad: -1.0385432688053697e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 2.8066133381798863e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 7.277747499756515e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00018986854411195964
mask_decoder.transformer.layers.1.norm2.bias grad: -3.675701009342447e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.510242797550745e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.0218385543557815e-07
mask_decoder.transformer.layers.1.norm4.weight grad: -5.346265606931411e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00022204946435522288
mask_decoder.transformer.norm_final_attn.weight grad: 2.493174179107882e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.7100906916311942e-05
Text_Embedding_Affine.0.weight grad: 2.7471254437916315e-13
Text_Embedding_Affine.0.bias grad: -3.148152225018741e-11
Text_Embedding_Affine.2.weight grad: -2.6204122205442104e-11
Text_Embedding_Affine.2.bias grad: 5.5497548601124436e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.1793015565822462e-12
Max value: 0.9995904564857483
Mean value: 0.08104913681745529

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1793015565822462e-12
Max value: 0.9995904564857483
Mean value: 0.08104913681745529

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0847482681274414

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1274990737438202

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07389259338378906

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0847482681274414

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 52.78866958618164
Max value: 77.29740142822266
Mean value: 60.39304733276367

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.9671059919845746e-11
Max value: 0.9993941783905029
Mean value: 0.08498575538396835

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.9671059919845746e-11
Max value: 0.9993941783905029
Mean value: 0.08498575538396835

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.9671059919845746e-11
Max value: 0.9993941783905029
Mean value: 0.08498575538396835

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12754493951797485

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8693152666091919
Max value: 5.541372299194336
Mean value: 1.0013447999954224

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 52.78866958618164
Max value: 77.29740142822266
Mean value: 60.39304733276367

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.29890441894531
Max value: -60.29890441894531
Mean value: -60.29890441894531
sam_encoder.pos_embed grad: 2.200385207373756e-09
sam_encoder.blocks.0.norm1.weight grad: -5.012239489587955e-05
sam_encoder.blocks.0.norm1.bias grad: -3.717343497555703e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.5386171980935615e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.017308704831521e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.370289510305156e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.5937397392917774e-06
sam_encoder.blocks.0.norm2.weight grad: 2.467578451614827e-05
sam_encoder.blocks.0.norm2.bias grad: -1.3395765563473105e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 7.700419700995553e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.9457190774119226e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.2999540558666922e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 7.3707210503926035e-06
sam_encoder.blocks.1.norm1.weight grad: -4.152616384089924e-06
sam_encoder.blocks.1.norm1.bias grad: 2.206246426794678e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.2108093869755976e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -4.1000944293045904e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.247813088411931e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -6.6382044678903185e-06
sam_encoder.blocks.1.norm2.weight grad: -1.0067690709547605e-05
sam_encoder.blocks.1.norm2.bias grad: -6.7837659116776194e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -9.386233614350203e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.2080556643923046e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.774463089532219e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.937692897830857e-06
sam_encoder.blocks.2.norm1.weight grad: -1.6311299987137318e-05
sam_encoder.blocks.2.norm1.bias grad: 9.414301530341618e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.2744911146000959e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.8747342639690032e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -8.732334208616521e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.053457698522834e-06
sam_encoder.blocks.2.norm2.weight grad: -4.694638846558519e-06
sam_encoder.blocks.2.norm2.bias grad: -3.360005848662695e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.711107976618223e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -5.367527364796842e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.141856935457326e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.6245095341437263e-06
sam_encoder.blocks.3.norm1.weight grad: -1.332151214228361e-06
sam_encoder.blocks.3.norm1.bias grad: 3.1300214686780237e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.921839601796819e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.922910769280861e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.5921711969422176e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.534689767548116e-06
sam_encoder.blocks.3.norm2.weight grad: -5.784843779110815e-06
sam_encoder.blocks.3.norm2.bias grad: -7.5405305324238725e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -4.855915449297754e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.635006239870563e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.617876132011588e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.234708122410666e-07
sam_encoder.blocks.4.norm1.weight grad: 3.344680862937821e-06
sam_encoder.blocks.4.norm1.bias grad: -7.945467586978339e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 4.330713636591099e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.0046330771729117e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.9878492568968795e-08
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -8.858554778612415e-09
sam_encoder.blocks.4.norm2.weight grad: -5.84558790706069e-07
sam_encoder.blocks.4.norm2.bias grad: -9.34136949126696e-07
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.205612640362233e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.995234116402571e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 9.188341891785967e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 7.944504432089161e-07
sam_encoder.blocks.5.norm1.weight grad: 1.8844327769329539e-06
sam_encoder.blocks.5.norm1.bias grad: -5.748656803916674e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.439916784169327e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.825528895300522e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -4.352791620476637e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.939628072657797e-07
sam_encoder.blocks.5.norm2.weight grad: -5.181055712455418e-06
sam_encoder.blocks.5.norm2.bias grad: 3.7902782423770986e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.3957147681794595e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.467652509745676e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 6.838909030193463e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.335481556452578e-06
sam_encoder.blocks.6.norm1.weight grad: 1.6579327848376124e-06
sam_encoder.blocks.6.norm1.bias grad: -4.433231424627593e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.2954086514582741e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 9.751028073878842e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -8.858877436068724e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.3000094440940302e-06
sam_encoder.blocks.6.norm2.weight grad: -2.90564275928773e-06
sam_encoder.blocks.6.norm2.bias grad: 2.1685741558030713e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.4930808396893553e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.1405413715692703e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -3.362708156373628e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.115342330303974e-07
sam_encoder.blocks.7.norm1.weight grad: -5.509491074917605e-06
sam_encoder.blocks.7.norm1.bias grad: -3.875261427310761e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.739373591495678e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.990262262552278e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.9093741886754287e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.6154272581588884e-07
sam_encoder.blocks.7.norm2.weight grad: -8.466079634672496e-06
sam_encoder.blocks.7.norm2.bias grad: 1.6522571968380362e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -7.29395560483681e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.7558006624749396e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.979589776776265e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 8.38337996356131e-07
sam_encoder.blocks.8.norm1.weight grad: -8.738301175981178e-07
sam_encoder.blocks.8.norm1.bias grad: 7.793834697622515e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.1702093161147786e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 9.143398074229481e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -4.761505806527566e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.633040134649491e-06
sam_encoder.blocks.8.norm2.weight grad: -4.232744231558172e-06
sam_encoder.blocks.8.norm2.bias grad: 3.7064143043608055e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.931347575620748e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.0118894756014924e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 9.355036354463664e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.1542380207174574e-06
sam_encoder.blocks.9.norm1.weight grad: 1.6088023357951897e-06
sam_encoder.blocks.9.norm1.bias grad: -6.207920932865818e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -9.743962436914444e-08
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.3337264590518316e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -7.135837449823157e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.788123651953356e-07
sam_encoder.blocks.9.norm2.weight grad: -1.973569396795938e-06
sam_encoder.blocks.9.norm2.bias grad: 2.276206032547634e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.841896952711977e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.3588198726210976e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.287782538383908e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 9.239769838131906e-07
sam_encoder.blocks.10.norm1.weight grad: -9.456274483454763e-07
sam_encoder.blocks.10.norm1.bias grad: -4.292269863981346e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.550703814245935e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -8.586793569520523e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.5409220850415295e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -8.884880458026601e-07
sam_encoder.blocks.10.norm2.weight grad: -6.912206117704045e-06
sam_encoder.blocks.10.norm2.bias grad: -2.3558945372315065e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.966350388713181e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.207789520980441e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 4.3982217334814777e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.7242893452239514e-07
sam_encoder.blocks.11.norm1.weight grad: -2.0097699234611355e-05
sam_encoder.blocks.11.norm1.bias grad: 1.7975598893826827e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -8.506746951297828e-08
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.2535191135375499e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.3209547634905903e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.316560428676894e-06
sam_encoder.blocks.11.norm2.weight grad: -7.36224455977208e-06
sam_encoder.blocks.11.norm2.bias grad: -2.979034888994647e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.951564394810703e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.6029266589612234e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 4.916723810310941e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.066927322630363e-07
sam_encoder.neck.conv1.trainable_scale grad: 8.617917046649382e-07
sam_encoder.neck.conv1.trainable_shift grad: 5.265532308840193e-06
sam_encoder.neck.conv2.trainable_scale grad: 8.866063581081107e-07
sam_encoder.neck.conv2.trainable_shift grad: -7.74759755586274e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00017300911713391542
mask_decoder.transformer.layers.0.norm1.bias grad: 1.8080281734000891e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.002853253623470664
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0005803194362670183
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00011557912512216717
mask_decoder.transformer.layers.0.norm3.bias grad: 2.4671995561220683e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -9.198307816404849e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 7.206645932456013e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -7.291936981346225e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -4.357852958492003e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00011498712410684675
mask_decoder.transformer.layers.1.norm2.bias grad: 1.7843693058239296e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -3.803672734647989e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -2.116546602337621e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 7.658458343939856e-06
mask_decoder.transformer.layers.1.norm4.bias grad: 9.513542318018153e-05
mask_decoder.transformer.norm_final_attn.weight grad: -1.838767957451637e-06
mask_decoder.transformer.norm_final_attn.bias grad: -7.923572411527857e-06
Text_Embedding_Affine.0.weight grad: 1.3896674609659154e-13
Text_Embedding_Affine.0.bias grad: 1.562218132633575e-10
Text_Embedding_Affine.2.weight grad: -1.1612008576911137e-10
Text_Embedding_Affine.2.bias grad: -3.6374240153236315e-05
Epoch 15 finished with average loss: -57.9839
Epoch 16/39
----------
Epoch 16:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 16:   0%|          | 0/3 [00:01<?, ?it/s, loss=-55.6]Epoch 16:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.00s/it, loss=-55.6]Epoch 16:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.00s/it, loss=-59.5]Epoch 16:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.58it/s, loss=-59.5]Epoch 16:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.58it/s, loss=-56.2]Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.21it/s, loss=-56.2]/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.6124631214484405e-25
Max value: 0.9999992847442627
Mean value: 0.09531079232692719

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6124631214484405e-25
Max value: 0.9999992847442627
Mean value: 0.09531079232692719

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08201360702514648

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14463412761688232

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0775146484375

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08201360702514648

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 33.96897506713867
Max value: 70.61273956298828
Mean value: 55.58435821533203

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.6124631214484405e-25
Max value: 0.9999992847442627
Mean value: 0.09531079232692719

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6124631214484405e-25
Max value: 0.9999992847442627
Mean value: 0.09531079232692719

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6124631214484405e-25
Max value: 0.9999992847442627
Mean value: 0.09531079232692719

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14463412761688232

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 33.96897506713867
Max value: 70.61273956298828
Mean value: 55.58435821533203

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.585819244384766
Max value: -55.585819244384766
Mean value: -55.585819244384766
sam_encoder.pos_embed grad: -1.708234775854578e-09
sam_encoder.blocks.0.norm1.weight grad: -1.1984293450950645e-05
sam_encoder.blocks.0.norm1.bias grad: 2.891127223847434e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -9.923865036398638e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 7.562416044493148e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 6.455516540881945e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.2193303291496704e-06
sam_encoder.blocks.0.norm2.weight grad: 6.559249595738947e-05
sam_encoder.blocks.0.norm2.bias grad: -4.925230678054504e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.412042158539407e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.5383425256441114e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 4.950586003360513e-07
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.0188123269472271e-05
sam_encoder.blocks.1.norm1.weight grad: 1.8446780813974328e-06
sam_encoder.blocks.1.norm1.bias grad: -2.310537411176483e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.00524969943217e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.85007581624086e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -8.982195140561089e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.565650215226924e-06
sam_encoder.blocks.1.norm2.weight grad: -1.130301461671479e-05
sam_encoder.blocks.1.norm2.bias grad: 4.580318545777118e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.3555493751482572e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.7258411162401899e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -8.750019333092496e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 3.8079906516941264e-07
sam_encoder.blocks.2.norm1.weight grad: -5.782846528745722e-06
sam_encoder.blocks.2.norm1.bias grad: -2.578134626674e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -5.977267392154317e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.0794667509326246e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.7823317547445185e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.5554787650180515e-06
sam_encoder.blocks.2.norm2.weight grad: -2.0566628791129915e-06
sam_encoder.blocks.2.norm2.bias grad: -1.1201896995771676e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.8480963603906275e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.255010483371734e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.577231943083461e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.415947382265585e-07
sam_encoder.blocks.3.norm1.weight grad: -1.3465745723806322e-05
sam_encoder.blocks.3.norm1.bias grad: 1.0967366506520193e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -8.003360562724993e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.6799425566205173e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.5272784114349633e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.9829104682430625e-06
sam_encoder.blocks.3.norm2.weight grad: 3.6298779377830215e-06
sam_encoder.blocks.3.norm2.bias grad: -1.1325926152494503e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.6272877019218868e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -5.2792493931974604e-08
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.8298854911336093e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.4910907541197957e-06
sam_encoder.blocks.4.norm1.weight grad: 1.1314547009533271e-05
sam_encoder.blocks.4.norm1.bias grad: -1.1459718734840862e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.7505436719366116e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.4657193787570577e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.1319410734577104e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -4.020102096546907e-06
sam_encoder.blocks.4.norm2.weight grad: 8.032966434257105e-06
sam_encoder.blocks.4.norm2.bias grad: 9.344544196210336e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.413210384271224e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.3969041390282655e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.4885416678444017e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 7.774370942570386e-07
sam_encoder.blocks.5.norm1.weight grad: 1.4923649359843694e-05
sam_encoder.blocks.5.norm1.bias grad: -2.0040299204993062e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.3424144526652526e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 7.249196187331108e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.038486400124384e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -5.4051270126365125e-08
sam_encoder.blocks.5.norm2.weight grad: 7.388738140434725e-06
sam_encoder.blocks.5.norm2.bias grad: -1.2169471119705122e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.0491685316083021e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.0616089929935697e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.4845406844397075e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 9.24576738725591e-07
sam_encoder.blocks.6.norm1.weight grad: 1.0307614502380602e-05
sam_encoder.blocks.6.norm1.bias grad: -4.71660041512223e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.1717534006456845e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.5350636860821396e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.973947392907576e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.1413453648856375e-07
sam_encoder.blocks.6.norm2.weight grad: 2.208572823292343e-06
sam_encoder.blocks.6.norm2.bias grad: 1.593900378793478e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.393698537161981e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -8.304657228563883e-08
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.6930176722526085e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.58014017365349e-06
sam_encoder.blocks.7.norm1.weight grad: 7.288563210749999e-07
sam_encoder.blocks.7.norm1.bias grad: 5.732525778512354e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.105746367917163e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.0605787110762321e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 4.187252216070192e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.6166681007234729e-06
sam_encoder.blocks.7.norm2.weight grad: -4.7102088274186826e-07
sam_encoder.blocks.7.norm2.bias grad: 3.3405854082957376e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.8964466309844283e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.1335717999827466e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.1693124381272355e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.417526047793217e-06
sam_encoder.blocks.8.norm1.weight grad: 5.311509085004218e-06
sam_encoder.blocks.8.norm1.bias grad: 4.50644790817023e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.641981260851026e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 5.319006049830932e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.88016781269107e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.705496055772528e-06
sam_encoder.blocks.8.norm2.weight grad: -9.29921213810303e-07
sam_encoder.blocks.8.norm2.bias grad: 9.285377018386498e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 4.861459501626086e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -4.187926094800787e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 3.2171947168535553e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.0177114947728114e-06
sam_encoder.blocks.9.norm1.weight grad: 1.2048365078953793e-06
sam_encoder.blocks.9.norm1.bias grad: 6.984950005062274e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.2982076214029803e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.0307080628990661e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.052767629516893e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -7.052235417859265e-08
sam_encoder.blocks.9.norm2.weight grad: -3.4891999689534714e-07
sam_encoder.blocks.9.norm2.bias grad: 1.8301223008165834e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.1733644643973093e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -7.365640044554311e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.5528935364272911e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.6784946410552948e-06
sam_encoder.blocks.10.norm1.weight grad: -1.8750467916106572e-06
sam_encoder.blocks.10.norm1.bias grad: -6.014571454215911e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.044258508249186e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -4.48668231456395e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.1903846370842075e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.8486010705819353e-07
sam_encoder.blocks.10.norm2.weight grad: -4.19457683165092e-06
sam_encoder.blocks.10.norm2.bias grad: 7.431649464706425e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.7001740363630233e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.2242104478209512e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.0179470422144732e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.4809084442931635e-07
sam_encoder.blocks.11.norm1.weight grad: -3.539523822837509e-05
sam_encoder.blocks.11.norm1.bias grad: -2.0937068256898783e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -5.708981007046532e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.7134761947090738e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.993378984683659e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.5376147075585322e-06
sam_encoder.blocks.11.norm2.weight grad: -1.0643092537065968e-05
sam_encoder.blocks.11.norm2.bias grad: -3.9037522583385e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.2763770175515674e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.254589162475895e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -3.4908453017123975e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.0599173922164482e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.0262374416925013e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.2398601029417478e-05
sam_encoder.neck.conv2.trainable_scale grad: 6.53832103125751e-07
sam_encoder.neck.conv2.trainable_shift grad: -7.428976823575795e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -2.0892974134767428e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 6.2931503634899855e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004358184523880482
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0004777781432494521
mask_decoder.transformer.layers.0.norm3.weight grad: 8.440070087090135e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 7.640817057108507e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -9.923429024638608e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.26494651340181e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 1.678466287557967e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.898677500226768e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0001614280918147415
mask_decoder.transformer.layers.1.norm2.bias grad: 2.7173075068276376e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.335004526481498e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.4975857084209565e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 1.8885217286879197e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00014783276128582656
mask_decoder.transformer.norm_final_attn.weight grad: 6.529723577841651e-06
mask_decoder.transformer.norm_final_attn.bias grad: -9.772476914804429e-06
Text_Embedding_Affine.0.weight grad: 2.0413242277084187e-11
Text_Embedding_Affine.0.bias grad: 6.169690314195009e-10
Text_Embedding_Affine.2.weight grad: -6.172187760888903e-12
Text_Embedding_Affine.2.bias grad: -4.3637945054797456e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.617788357774358e-15
Max value: 0.9998944997787476
Mean value: 0.07669737935066223

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.617788357774358e-15
Max value: 0.9998944997787476
Mean value: 0.07669737935066223

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0853567123413086

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1181005910038948

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07094764709472656

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0853567123413086

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 52.361488342285156
Max value: 85.14938354492188
Mean value: 63.32479476928711

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.192382065900234e-15
Max value: 0.9998767375946045
Mean value: 0.07689651101827621

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.192382065900234e-15
Max value: 0.9998767375946045
Mean value: 0.07689651101827621

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.192382065900234e-15
Max value: 0.9998767375946045
Mean value: 0.07689651101827621

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11770862340927124

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9627337455749512
Max value: 1.6639041900634766
Mean value: 1.000443696975708

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 52.361488342285156
Max value: 85.14938354492188
Mean value: 63.32479476928711

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -63.35179901123047
Max value: -63.35179901123047
Mean value: -63.35179901123047
sam_encoder.pos_embed grad: -2.6597137825490336e-09
sam_encoder.blocks.0.norm1.weight grad: -1.9007296941708773e-05
sam_encoder.blocks.0.norm1.bias grad: 2.785878132272046e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.8215013117005583e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.7513762884391326e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 4.870752263741451e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.415497182388208e-07
sam_encoder.blocks.0.norm2.weight grad: -5.549694378714776e-06
sam_encoder.blocks.0.norm2.bias grad: 1.13586274892441e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -8.596955012762919e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.797553861455526e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.1287691197358072e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -7.758055289741606e-06
sam_encoder.blocks.1.norm1.weight grad: -6.677222700091079e-06
sam_encoder.blocks.1.norm1.bias grad: 3.367150839039823e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.1440517886949237e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 4.772392685481464e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.562800318628433e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.4754590438315063e-06
sam_encoder.blocks.1.norm2.weight grad: 1.1889957931998651e-05
sam_encoder.blocks.1.norm2.bias grad: -4.184970293863444e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 8.774924936005846e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.0302331904531457e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 4.190520030533662e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.429882665135665e-07
sam_encoder.blocks.2.norm1.weight grad: -1.932789928105194e-07
sam_encoder.blocks.2.norm1.bias grad: 1.9912026800739113e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 6.852649221400497e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.495529886597069e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.5742163839149725e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.435823122619695e-07
sam_encoder.blocks.2.norm2.weight grad: -5.2943519222026225e-06
sam_encoder.blocks.2.norm2.bias grad: -3.1241343094734475e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -9.486974477113108e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.3057833712082356e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.4299437225417932e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.8442863115051296e-07
sam_encoder.blocks.3.norm1.weight grad: -9.256831390302978e-07
sam_encoder.blocks.3.norm1.bias grad: -4.287609954189975e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.948855581053067e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.0192843546974473e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 9.918022669808124e-08
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.1834985969016998e-07
sam_encoder.blocks.3.norm2.weight grad: 1.1496287697809748e-05
sam_encoder.blocks.3.norm2.bias grad: 1.6967524061328731e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.789665687596425e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.0666394650324946e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.2851609173812903e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.440697244310286e-08
sam_encoder.blocks.4.norm1.weight grad: -1.2319651432335377e-06
sam_encoder.blocks.4.norm1.bias grad: 1.2147836514486698e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.3090264019410824e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.064144385054533e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.564775061524415e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.6970573142316425e-06
sam_encoder.blocks.4.norm2.weight grad: -1.44233335959143e-05
sam_encoder.blocks.4.norm2.bias grad: -2.151973603758961e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -8.500193871441297e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.381768465260393e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.5453496164118405e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.183623166729376e-07
sam_encoder.blocks.5.norm1.weight grad: -6.415698408090975e-06
sam_encoder.blocks.5.norm1.bias grad: -4.1239018173655495e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.964032086718362e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -4.1921684896806255e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.2946104561706306e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -9.953237167792395e-08
sam_encoder.blocks.5.norm2.weight grad: -4.005407390650362e-06
sam_encoder.blocks.5.norm2.bias grad: -9.275065167457797e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.812006303225644e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -5.856825282535283e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.476362058383529e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.8143238612065034e-07
sam_encoder.blocks.6.norm1.weight grad: -2.4720225155761e-06
sam_encoder.blocks.6.norm1.bias grad: 1.4568480537491268e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.6897381556191249e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.268828312589903e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.110652701503568e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -8.896795407054015e-07
sam_encoder.blocks.6.norm2.weight grad: -4.095212716492824e-06
sam_encoder.blocks.6.norm2.bias grad: -1.2497301895564306e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -2.9545130928454455e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.7124142459579161e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.0384537745267153e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -4.7359054633488995e-07
sam_encoder.blocks.7.norm1.weight grad: 6.658130132564111e-06
sam_encoder.blocks.7.norm1.bias grad: -1.0222237278867397e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.674322553910315e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.471309926477261e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.2060507944843266e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -6.241372716431215e-07
sam_encoder.blocks.7.norm2.weight grad: 1.4235622529668035e-06
sam_encoder.blocks.7.norm2.bias grad: 1.9993694877484813e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.775921529973857e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.6849307371558098e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.98950326902559e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.1339720913383644e-06
sam_encoder.blocks.8.norm1.weight grad: 1.0073604244098533e-05
sam_encoder.blocks.8.norm1.bias grad: -1.4237582490750356e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 8.536157110938802e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.8426597964426037e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.187370339219342e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.29092165682232e-06
sam_encoder.blocks.8.norm2.weight grad: -1.9991366571048275e-06
sam_encoder.blocks.8.norm2.bias grad: -5.321847993400297e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.0146961813006783e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.407588735626632e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.339434220426483e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.2205032362544443e-06
sam_encoder.blocks.9.norm1.weight grad: 1.0025344181485707e-06
sam_encoder.blocks.9.norm1.bias grad: -1.027097695782686e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.1612644357228419e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 8.610485906501708e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 3.7413769859995227e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.5433998612479627e-07
sam_encoder.blocks.9.norm2.weight grad: 1.1372898143235943e-06
sam_encoder.blocks.9.norm2.bias grad: -2.2495282792078797e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.3402089962255559e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 5.891545811209653e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.4716974305883923e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.847399506819784e-07
sam_encoder.blocks.10.norm1.weight grad: 5.042716566094896e-06
sam_encoder.blocks.10.norm1.bias grad: 6.06779622103204e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.356049774083658e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.3201988622313365e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.7141267107945168e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.0877661225094926e-06
sam_encoder.blocks.10.norm2.weight grad: 9.068236295206589e-07
sam_encoder.blocks.10.norm2.bias grad: -1.5325661024689907e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.5241303117363714e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 8.418749075644882e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.1264471133642928e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.7374859946103243e-07
sam_encoder.blocks.11.norm1.weight grad: 1.613586937310174e-05
sam_encoder.blocks.11.norm1.bias grad: 1.8455496046954067e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.413781087147072e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.093250943995372e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.231634309486253e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.620500711396744e-06
sam_encoder.blocks.11.norm2.weight grad: 3.356011802679859e-06
sam_encoder.blocks.11.norm2.bias grad: -7.156435088973012e-08
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.5302845187979983e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 5.006731953471899e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.6579996870168543e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -9.401225042893202e-08
sam_encoder.neck.conv1.trainable_scale grad: -6.270638550631702e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.5062913007568568e-05
sam_encoder.neck.conv2.trainable_scale grad: -5.214478733250871e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.956659252755344e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -3.753329292521812e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -7.020535122137517e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004709869157522917
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0001679672277532518
mask_decoder.transformer.layers.0.norm3.weight grad: -4.242687646183185e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -5.241763574304059e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00010102235683007166
mask_decoder.transformer.layers.0.norm4.bias grad: -8.620760127087124e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.16205830333638e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 4.129459739488084e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -4.6521923650288954e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 2.6402631192468107e-07
mask_decoder.transformer.layers.1.norm3.weight grad: 4.198733586235903e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.0233463399345055e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.7469171982374974e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00019296008395031095
mask_decoder.transformer.norm_final_attn.weight grad: 1.8820666127794539e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.2687440175795928e-05
Text_Embedding_Affine.0.weight grad: -1.2264473291112576e-12
Text_Embedding_Affine.0.bias grad: -6.474847741300138e-11
Text_Embedding_Affine.2.weight grad: 8.924029050449978e-12
Text_Embedding_Affine.2.bias grad: 8.494513167534024e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.737784921668043e-13
Max value: 0.9999865293502808
Mean value: 0.08262451738119125

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.737784921668043e-13
Max value: 0.9999865293502808
Mean value: 0.08262451738119125

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08440685272216797

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14245259761810303

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06963634490966797

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08440685272216797

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 26.143461227416992
Max value: 63.92752456665039
Mean value: 49.49732208251953

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.05405223280475e-12
Max value: 0.9999758005142212
Mean value: 0.08340489119291306

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.05405223280475e-12
Max value: 0.9999758005142212
Mean value: 0.08340489119291306

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.05405223280475e-12
Max value: 0.9999758005142212
Mean value: 0.08340489119291306

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14105361700057983

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9200283885002136
Max value: 3.5312938690185547
Mean value: 1.0019193887710571

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 26.143461227416992
Max value: 63.92752456665039
Mean value: 49.49732208251953

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -49.544395446777344
Max value: -49.544395446777344
Mean value: -49.544395446777344
sam_encoder.pos_embed grad: 3.00046809620369e-09
sam_encoder.blocks.0.norm1.weight grad: -1.6595371562289074e-05
sam_encoder.blocks.0.norm1.bias grad: -1.8655007806955837e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.0817479910183465e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 8.331170420206035e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.6119901122001465e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.405358489137143e-06
sam_encoder.blocks.0.norm2.weight grad: -1.6266534657916054e-05
sam_encoder.blocks.0.norm2.bias grad: 3.992188794654794e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -5.105622676637722e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.1515986595186405e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 5.658786449203035e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.3009820324659813e-06
sam_encoder.blocks.1.norm1.weight grad: -7.77481727709528e-06
sam_encoder.blocks.1.norm1.bias grad: -6.364602995745372e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.1594888746913057e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.1020107396907406e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.0259569737390848e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.2781511031789705e-06
sam_encoder.blocks.1.norm2.weight grad: -4.194926077616401e-06
sam_encoder.blocks.1.norm2.bias grad: -2.992977897520177e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -8.861734386300668e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.4393766580033116e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 3.527516582835233e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -8.405988864979008e-07
sam_encoder.blocks.2.norm1.weight grad: 5.089835667604348e-06
sam_encoder.blocks.2.norm1.bias grad: -1.089617217076011e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.66377060142986e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 3.042934508812323e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.342428837844636e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.900131327507552e-06
sam_encoder.blocks.2.norm2.weight grad: 8.414395779254846e-06
sam_encoder.blocks.2.norm2.bias grad: 9.244749890058301e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 7.823303349141497e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.0578977455443237e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.0951296189887216e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.1154609182995046e-06
sam_encoder.blocks.3.norm1.weight grad: -7.767212082399055e-07
sam_encoder.blocks.3.norm1.bias grad: -7.046321115922183e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.9985064884385793e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.035582158692705e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 6.592692614049156e-08
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -8.736421364119451e-07
sam_encoder.blocks.3.norm2.weight grad: -1.6991871234495193e-06
sam_encoder.blocks.3.norm2.bias grad: -1.9218814486521296e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -2.2443834950536257e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -9.549498827254865e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.738411229889607e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.4530158952984493e-06
sam_encoder.blocks.4.norm1.weight grad: 1.354033338429872e-05
sam_encoder.blocks.4.norm1.bias grad: -1.1421095223340672e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 7.866961823310703e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.2264670203876449e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.787064997595735e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 8.601948024988815e-07
sam_encoder.blocks.4.norm2.weight grad: 2.2838064239749656e-07
sam_encoder.blocks.4.norm2.bias grad: -2.05323794943979e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.9255116967542563e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 7.991087613845593e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 6.350266630761325e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.477645466569811e-06
sam_encoder.blocks.5.norm1.weight grad: 1.4758807083126158e-05
sam_encoder.blocks.5.norm1.bias grad: 2.0524075807770714e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 7.503842425649054e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.82112511942978e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.228321929782396e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.602218501124298e-06
sam_encoder.blocks.5.norm2.weight grad: 6.091091563575901e-06
sam_encoder.blocks.5.norm2.bias grad: -1.294272578888922e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 4.527450528257759e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.9197493656974984e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.438581527210772e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.2999038264970295e-06
sam_encoder.blocks.6.norm1.weight grad: 7.466973329428583e-06
sam_encoder.blocks.6.norm1.bias grad: -1.4916676036591525e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.5022212614421733e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.1899853689101292e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.2131604876230995e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 6.675708164038952e-07
sam_encoder.blocks.6.norm2.weight grad: -1.7406940742148436e-06
sam_encoder.blocks.6.norm2.bias grad: -2.7432884053268936e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.1773220194299938e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.786278739426052e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.250696070404956e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.962319704622132e-08
sam_encoder.blocks.7.norm1.weight grad: -2.0892721295240335e-06
sam_encoder.blocks.7.norm1.bias grad: -2.8588618761205e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -2.9174912015150767e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.3182265092837042e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -8.85151166585274e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.882023181882687e-06
sam_encoder.blocks.7.norm2.weight grad: -9.000744285003748e-06
sam_encoder.blocks.7.norm2.bias grad: 2.4203425255109323e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -8.801029252936132e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.033803634229116e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.3781379948341055e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.0744664677986293e-06
sam_encoder.blocks.8.norm1.weight grad: 2.7529531507752836e-06
sam_encoder.blocks.8.norm1.bias grad: 1.4617523902415996e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -5.357712140607873e-08
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.4066175683401525e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.910196028300561e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.0354561861022376e-06
sam_encoder.blocks.8.norm2.weight grad: 3.1649165066482965e-06
sam_encoder.blocks.8.norm2.bias grad: -7.045550773909781e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.9839594642689917e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.8962681451739627e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 4.6345921873580664e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.7041933208238333e-06
sam_encoder.blocks.9.norm1.weight grad: -2.5954975626518717e-06
sam_encoder.blocks.9.norm1.bias grad: -6.211088248164742e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.67316090685199e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.3533401670429157e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.380577239426202e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 4.787890972579589e-08
sam_encoder.blocks.9.norm2.weight grad: -2.1753005512437085e-06
sam_encoder.blocks.9.norm2.bias grad: 2.690826249818201e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.717206593340961e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -7.636281225131825e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.4598604138882365e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.0910756600424065e-06
sam_encoder.blocks.10.norm1.weight grad: -5.14991825184552e-06
sam_encoder.blocks.10.norm1.bias grad: -7.75220200921467e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.830332389043178e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.1857857771246927e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.0343682081147563e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.4899503639753675e-06
sam_encoder.blocks.10.norm2.weight grad: -5.787059762951685e-06
sam_encoder.blocks.10.norm2.bias grad: 1.686460450400773e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -6.831719474575948e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.1227986053418135e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.188169219152769e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.541185892823705e-07
sam_encoder.blocks.11.norm1.weight grad: -2.5977444238378666e-05
sam_encoder.blocks.11.norm1.bias grad: 3.7438956042024074e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -7.520351118728286e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.2385711443130276e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.795027739921352e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.783609491212701e-06
sam_encoder.blocks.11.norm2.weight grad: -3.471677246125182e-06
sam_encoder.blocks.11.norm2.bias grad: -2.22238622882287e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.785761125778663e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -8.933008075473481e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.4174569287206396e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 5.993969693918189e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.8126411305274814e-06
sam_encoder.neck.conv1.trainable_shift grad: 2.4137805667123757e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.9026410882361233e-06
sam_encoder.neck.conv2.trainable_shift grad: -0.00014892019680701196
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00011410394654376432
mask_decoder.transformer.layers.0.norm1.bias grad: 4.330351657699794e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.001993500627577305
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0013414971763268113
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00010580762318568304
mask_decoder.transformer.layers.0.norm3.bias grad: -2.93354951281799e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -5.761007923865691e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 8.647404683870263e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.202480573032517e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -3.413400008867029e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 9.204864909406751e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 2.0311934349592775e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.0887481039389968e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.4526271115755662e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 2.257439700770192e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00016955651517491788
mask_decoder.transformer.norm_final_attn.weight grad: 3.0671576496388298e-06
mask_decoder.transformer.norm_final_attn.bias grad: -4.484259989112616e-06
Text_Embedding_Affine.0.weight grad: -5.927191029653223e-12
Text_Embedding_Affine.0.bias grad: -1.9500800974014965e-10
Text_Embedding_Affine.2.weight grad: 7.458961226447514e-11
Text_Embedding_Affine.2.bias grad: -2.8081780328648165e-05
Epoch 16 finished with average loss: -56.1607
Epoch 17/39
----------
Epoch 17:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 17:   0%|          | 0/3 [00:00<?, ?it/s, loss=-59.8]Epoch 17:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.10it/s, loss=-59.8]Epoch 17:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.10it/s, loss=-56.4]Epoch 17:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.69it/s, loss=-56.4]Epoch 17:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.69it/s, loss=-55.7]Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.34it/s, loss=-55.7]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.101098002800996e-14
Max value: 0.9997465014457703
Mean value: 0.09198533743619919

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.101098002800996e-14
Max value: 0.9997465014457703
Mean value: 0.09198533743619919

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08927154541015625

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13352826237678528

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08002185821533203

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08927154541015625

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 46.49492645263672
Max value: 91.81916046142578
Mean value: 59.827232360839844

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.101098002800996e-14
Max value: 0.9997465014457703
Mean value: 0.09198533743619919

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.101098002800996e-14
Max value: 0.9997465014457703
Mean value: 0.09198533743619919

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.101098002800996e-14
Max value: 0.9997465014457703
Mean value: 0.09198533743619919

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13352826237678528

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 46.49492645263672
Max value: 91.81916046142578
Mean value: 59.827232360839844

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.828514099121094
Max value: -59.828514099121094
Mean value: -59.828514099121094
sam_encoder.pos_embed grad: 4.918987883684167e-09
sam_encoder.blocks.0.norm1.weight grad: -0.00012026968761347234
sam_encoder.blocks.0.norm1.bias grad: -4.0771305066300556e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 9.632865385356126e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.245496481620648e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.211632934428053e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.6226371119264513e-07
sam_encoder.blocks.0.norm2.weight grad: 2.0184937966405414e-05
sam_encoder.blocks.0.norm2.bias grad: 3.154165460728109e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -7.663789801881649e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.0519768238737015e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.8978034606552683e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.2788154890586156e-06
sam_encoder.blocks.1.norm1.weight grad: -2.1739446310675703e-05
sam_encoder.blocks.1.norm1.bias grad: -3.5812895475828554e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 5.705335297534475e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.1293675470369635e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 5.271995178190991e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 5.942417260484945e-07
sam_encoder.blocks.1.norm2.weight grad: -2.97956466965843e-06
sam_encoder.blocks.1.norm2.bias grad: -6.932681344551384e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -5.843417511641746e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.20269498640846e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 9.339613825432025e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 2.4813043637550436e-06
sam_encoder.blocks.2.norm1.weight grad: -7.049938631098485e-06
sam_encoder.blocks.2.norm1.bias grad: -1.7093316273530945e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.223228537128307e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.4142252641468076e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.638421806177575e-08
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.250311808893457e-06
sam_encoder.blocks.2.norm2.weight grad: 1.6984542526188307e-05
sam_encoder.blocks.2.norm2.bias grad: -2.296311686222907e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.336464447376784e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.4415705865976634e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.5496906346234027e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.428806854164577e-06
sam_encoder.blocks.3.norm1.weight grad: -2.677591965039028e-06
sam_encoder.blocks.3.norm1.bias grad: -9.979352171285427e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.1277478733973112e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.1551035135635175e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.803811185003724e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.816723048861604e-06
sam_encoder.blocks.3.norm2.weight grad: 1.0034272236225661e-05
sam_encoder.blocks.3.norm2.bias grad: 7.934571840451099e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.3503545233106706e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.613629928622686e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.2607841856370214e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.4967972106205707e-07
sam_encoder.blocks.4.norm1.weight grad: 1.3988310456625186e-05
sam_encoder.blocks.4.norm1.bias grad: 7.202708275144687e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 8.776518370723352e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 9.811533345782664e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.8304360714391805e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.890934527182253e-06
sam_encoder.blocks.4.norm2.weight grad: -9.180777851724997e-06
sam_encoder.blocks.4.norm2.bias grad: -1.3350210792850703e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -6.074052180338185e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.4715649285790278e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.6471699331741547e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.3464191397360992e-06
sam_encoder.blocks.5.norm1.weight grad: 7.045318398013478e-06
sam_encoder.blocks.5.norm1.bias grad: -8.013570550247096e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.610577889252454e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.112150122637104e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 9.905668321152916e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.5793609691172605e-06
sam_encoder.blocks.5.norm2.weight grad: -1.515787880634889e-05
sam_encoder.blocks.5.norm2.bias grad: -4.44670604338171e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -7.868583452363964e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.475725295880693e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.9505522434192244e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 9.414262649443117e-07
sam_encoder.blocks.6.norm1.weight grad: 9.683419193606824e-06
sam_encoder.blocks.6.norm1.bias grad: -3.93191021430539e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.0237540613597957e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.18599461732083e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.469502977779484e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.0494072739675175e-06
sam_encoder.blocks.6.norm2.weight grad: 8.327388059115037e-07
sam_encoder.blocks.6.norm2.bias grad: 3.022785676876083e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 9.042848887474975e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.0508118748475681e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.1620757049968233e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.0820120905918884e-06
sam_encoder.blocks.7.norm1.weight grad: -4.2141214180446696e-06
sam_encoder.blocks.7.norm1.bias grad: 9.795961659619934e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -8.069877367233858e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.1016022654075641e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.972773816305562e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.9941770662844647e-06
sam_encoder.blocks.7.norm2.weight grad: -2.504247959222994e-06
sam_encoder.blocks.7.norm2.bias grad: 4.1675880311231595e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.2912354324944317e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.4061478143266868e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.108431544911582e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.2544093124233768e-06
sam_encoder.blocks.8.norm1.weight grad: 9.520263120066375e-06
sam_encoder.blocks.8.norm1.bias grad: 7.515333209084929e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.203977368888445e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.423559403221589e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -4.380316568131093e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.251497102814028e-06
sam_encoder.blocks.8.norm2.weight grad: -3.230030188206001e-06
sam_encoder.blocks.8.norm2.bias grad: -1.0076207672682358e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.2794315555074718e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.1196952982572839e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.414840653524152e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 8.220449103646388e-07
sam_encoder.blocks.9.norm1.weight grad: -7.714877938269638e-06
sam_encoder.blocks.9.norm1.bias grad: -7.835072892703465e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -9.520453204459045e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.085829004907282e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.73143643628282e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.7669889277603943e-06
sam_encoder.blocks.9.norm2.weight grad: -3.3622577575442847e-06
sam_encoder.blocks.9.norm2.bias grad: 5.57668897727126e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.6246985877805855e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.0883189790765755e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.900321078413981e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.593900833540829e-06
sam_encoder.blocks.10.norm1.weight grad: -7.493253519896825e-07
sam_encoder.blocks.10.norm1.bias grad: -1.4192301023285836e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.6834702566702617e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -4.939280415783287e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -8.846254786476493e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.777108818463603e-07
sam_encoder.blocks.10.norm2.weight grad: -2.0071194740012288e-05
sam_encoder.blocks.10.norm2.bias grad: -7.007211024756543e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.1499852917040698e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.527972007257631e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.2741329555865377e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -8.542987188775442e-07
sam_encoder.blocks.11.norm1.weight grad: -4.3669970182236284e-05
sam_encoder.blocks.11.norm1.bias grad: 3.296953764220234e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.0963142307882663e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.066443357762182e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.955413154064445e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.7247247114937636e-06
sam_encoder.blocks.11.norm2.weight grad: -1.5410525520564988e-05
sam_encoder.blocks.11.norm2.bias grad: -5.547502041736152e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -5.874312591913622e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -4.387182343634777e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -7.830017239029985e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.879415769210027e-07
sam_encoder.neck.conv1.trainable_scale grad: 9.193881851388142e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.2520765267254319e-05
sam_encoder.neck.conv2.trainable_scale grad: 3.398308763280511e-07
sam_encoder.neck.conv2.trainable_shift grad: -6.539082824019715e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00011015792551916093
mask_decoder.transformer.layers.0.norm1.bias grad: 6.293790647760034e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.001562850084155798
mask_decoder.transformer.layers.0.norm2.bias grad: -3.304088022559881e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 5.617413262370974e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.820717443479225e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 4.0861559682525694e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.0204257705481723e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.15247307298705e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.585511189565295e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0004015691811218858
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00013265659799799323
mask_decoder.transformer.layers.1.norm3.weight grad: 7.08073639543727e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.620711064897478e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 9.393421350978315e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -2.6852947485167533e-05
mask_decoder.transformer.norm_final_attn.weight grad: 3.0800752028881107e-06
mask_decoder.transformer.norm_final_attn.bias grad: 5.215229521127185e-06
Text_Embedding_Affine.0.weight grad: 4.500642220017781e-11
Text_Embedding_Affine.0.bias grad: -1.7693213560932008e-10
Text_Embedding_Affine.2.weight grad: 9.41778668939186e-11
Text_Embedding_Affine.2.bias grad: -3.175996971549466e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.139786328643989e-17
Max value: 0.9999899864196777
Mean value: 0.08374300599098206

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.139786328643989e-17
Max value: 0.9999899864196777
Mean value: 0.08374300599098206

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07301044464111328

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12937593460083008

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06474161148071289

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07301044464111328

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 26.101829528808594
Max value: 73.45335388183594
Mean value: 53.031044006347656

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.5518280191898203e-16
Max value: 0.9999879598617554
Mean value: 0.0834222286939621

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.5518280191898203e-16
Max value: 0.9999879598617554
Mean value: 0.0834222286939621

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.5518280191898203e-16
Max value: 0.9999879598617554
Mean value: 0.0834222286939621

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12882888317108154

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9342866539955139
Max value: 1.647443413734436
Mean value: 1.0006022453308105

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 26.101829528808594
Max value: 73.45335388183594
Mean value: 53.031044006347656

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.06239318847656
Max value: -53.06239318847656
Mean value: -53.06239318847656
sam_encoder.pos_embed grad: 7.055304784842065e-09
sam_encoder.blocks.0.norm1.weight grad: -0.00010054807353299111
sam_encoder.blocks.0.norm1.bias grad: -3.870811633532867e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.6005958463647403e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.7881018266052706e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.639446504166699e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.709861746552633e-06
sam_encoder.blocks.0.norm2.weight grad: 2.7283964300295338e-05
sam_encoder.blocks.0.norm2.bias grad: 1.0042527719633654e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.7874206605483778e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.6175758850731654e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.2418007827363908e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 6.516787834698334e-06
sam_encoder.blocks.1.norm1.weight grad: 2.8358549570839386e-06
sam_encoder.blocks.1.norm1.bias grad: 2.6890083972830325e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.1896268915734254e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -4.552948212221963e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.1264566637692042e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.940548024023883e-06
sam_encoder.blocks.1.norm2.weight grad: -1.5790519682923332e-05
sam_encoder.blocks.1.norm2.bias grad: -1.7226692534677568e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.817463999032043e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.762531494227005e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.2541036742040887e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -5.117504770169035e-06
sam_encoder.blocks.2.norm1.weight grad: -2.745829988270998e-06
sam_encoder.blocks.2.norm1.bias grad: 2.893831151595805e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -7.674129847146105e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.9300209714856464e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -8.1776270235423e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -8.213176442950498e-06
sam_encoder.blocks.2.norm2.weight grad: 9.602023055776954e-06
sam_encoder.blocks.2.norm2.bias grad: -1.7711028704070486e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.9624656033556676e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -7.868982265790692e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.2502749086706899e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -4.484063083509682e-06
sam_encoder.blocks.3.norm1.weight grad: -3.9293249756156e-06
sam_encoder.blocks.3.norm1.bias grad: -2.8243484848644584e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.2329681339906529e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.5034531720157247e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -7.106127213774016e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -5.4116439969220664e-06
sam_encoder.blocks.3.norm2.weight grad: -1.2228518244228326e-05
sam_encoder.blocks.3.norm2.bias grad: -1.417736984876683e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -9.076346941583324e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -8.594288374297321e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.71444479899219e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -6.456972982959996e-07
sam_encoder.blocks.4.norm1.weight grad: 1.2083977708243765e-05
sam_encoder.blocks.4.norm1.bias grad: -1.0241235941066407e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 4.5179490371083375e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 8.037193310883595e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.4413121789402794e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.8098321561410557e-06
sam_encoder.blocks.4.norm2.weight grad: -1.2606769814738072e-05
sam_encoder.blocks.4.norm2.bias grad: -1.1154181265737861e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.4444834960158914e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.261511094227899e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.0045146104384912e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.186196868729894e-06
sam_encoder.blocks.5.norm1.weight grad: 4.615230864146724e-06
sam_encoder.blocks.5.norm1.bias grad: -1.851490196713712e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.759679773589596e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.084538894247089e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 5.15529677613813e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.5965907752834028e-06
sam_encoder.blocks.5.norm2.weight grad: -1.9001256077899598e-05
sam_encoder.blocks.5.norm2.bias grad: -3.474830805316742e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.0174786439165473e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.215340029782965e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.6010361580119934e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 6.34783987152332e-07
sam_encoder.blocks.6.norm1.weight grad: -8.471165529044811e-07
sam_encoder.blocks.6.norm1.bias grad: -3.141639808745822e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.8538679543999024e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.3414390878097038e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.6631620383122936e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.520812361377466e-06
sam_encoder.blocks.6.norm2.weight grad: -7.490511052310467e-06
sam_encoder.blocks.6.norm2.bias grad: 1.6141096921273856e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -7.268683020811295e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.276467396062799e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.931717517640209e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.716019930128823e-07
sam_encoder.blocks.7.norm1.weight grad: 2.6389723188913194e-06
sam_encoder.blocks.7.norm1.bias grad: 1.8724693973126705e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.4697077403980074e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -7.829605408460338e-08
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.5503347842459334e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.3126190196999232e-06
sam_encoder.blocks.7.norm2.weight grad: -9.380631126987282e-06
sam_encoder.blocks.7.norm2.bias grad: 1.1260917744948529e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -8.097936188278254e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.400569650897523e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.703894647827838e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.7531120849744184e-07
sam_encoder.blocks.8.norm1.weight grad: 1.7777481843950227e-05
sam_encoder.blocks.8.norm1.bias grad: 2.712645255087409e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.5186471500783227e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.838207132706884e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.593698582131765e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.4056729418807663e-06
sam_encoder.blocks.8.norm2.weight grad: -9.209393283526879e-06
sam_encoder.blocks.8.norm2.bias grad: 3.0870614864397794e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -8.313065336551517e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -4.506656296143774e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 4.913883913104655e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.134346115984954e-07
sam_encoder.blocks.9.norm1.weight grad: -1.5314801657950738e-06
sam_encoder.blocks.9.norm1.bias grad: -2.566242187640455e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.972864760726225e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.6623806661518756e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.6384609554952476e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -9.205659807776101e-07
sam_encoder.blocks.9.norm2.weight grad: -2.1426785679068416e-06
sam_encoder.blocks.9.norm2.bias grad: 4.066166638949653e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -6.493315140687628e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.1029480901925126e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.486019073126954e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.0335521665183478e-06
sam_encoder.blocks.10.norm1.weight grad: 1.4763431863684673e-06
sam_encoder.blocks.10.norm1.bias grad: -8.21192543298821e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.8115009576577e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.286166136400425e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.4178416449794895e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.330154191236943e-07
sam_encoder.blocks.10.norm2.weight grad: -1.4902128896210343e-05
sam_encoder.blocks.10.norm2.bias grad: -7.896004490248743e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -9.524003871774767e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.362561412563082e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.1826298279847833e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.4331737336069637e-07
sam_encoder.blocks.11.norm1.weight grad: -1.1545976121851709e-05
sam_encoder.blocks.11.norm1.bias grad: 3.078832378378138e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 6.2600461205875035e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.514832986998954e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.9160024748998694e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -5.967872311885003e-07
sam_encoder.blocks.11.norm2.weight grad: -9.145534932031296e-06
sam_encoder.blocks.11.norm2.bias grad: -7.718680308244075e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -5.498528025782434e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.2202866603038274e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.0901535461016465e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.734782356128562e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.1859638107125647e-06
sam_encoder.neck.conv1.trainable_shift grad: 2.2718786567565985e-06
sam_encoder.neck.conv2.trainable_scale grad: 2.1812466002302244e-06
sam_encoder.neck.conv2.trainable_shift grad: -3.762028063647449e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 2.5075929443119094e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 4.311219527153298e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004759448114782572
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00017314183060079813
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00020547074382193387
mask_decoder.transformer.layers.0.norm3.bias grad: 2.7741672965930775e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -3.573313006199896e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 7.645103323739022e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.7358468287275173e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.2404156223055907e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.000238308435655199
mask_decoder.transformer.layers.1.norm2.bias grad: 8.886119758244604e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 1.0189419299422298e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.630117109627463e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -6.431306974263862e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 4.043752051074989e-05
mask_decoder.transformer.norm_final_attn.weight grad: 4.077882294950541e-06
mask_decoder.transformer.norm_final_attn.bias grad: -8.666595022077672e-06
Text_Embedding_Affine.0.weight grad: -2.3490471720566397e-12
Text_Embedding_Affine.0.bias grad: -2.7937147040191235e-10
Text_Embedding_Affine.2.weight grad: 1.6363706223376795e-10
Text_Embedding_Affine.2.bias grad: -3.6652221751865e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.305293816424637e-09
Max value: 0.9989551305770874
Mean value: 0.09766492247581482

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.305293816424637e-09
Max value: 0.9989551305770874
Mean value: 0.09766492247581482

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09485054016113281

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.206977844238281
Max value: -1.1920928244535389e-07
Mean value: -0.1380895972251892

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07726287841796875

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09485054016113281

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 28.1447811126709
Max value: 72.53816986083984
Mean value: 54.191471099853516

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.775518203103957e-09
Max value: 0.9988160133361816
Mean value: 0.09630772471427917

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.775518203103957e-09
Max value: 0.9988160133361816
Mean value: 0.09630772471427917

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.775518203103957e-09
Max value: 0.9988160133361816
Mean value: 0.09630772471427917

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.588980674743652
Max value: -1.1920928244535389e-07
Mean value: -0.1369890421628952

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.6235993504524231
Max value: 1.8552086353302002
Mean value: 1.0012552738189697

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 28.1447811126709
Max value: 72.53816986083984
Mean value: 54.191471099853516

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -54.22940444946289
Max value: -54.22940444946289
Mean value: -54.22940444946289
sam_encoder.pos_embed grad: -3.569172513095964e-09
sam_encoder.blocks.0.norm1.weight grad: -4.3525367800612e-05
sam_encoder.blocks.0.norm1.bias grad: -7.1626142016612e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.2784222153404698e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.0648350818628387e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.285927621414885e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.1266467885870952e-06
sam_encoder.blocks.0.norm2.weight grad: -2.756549474725034e-05
sam_encoder.blocks.0.norm2.bias grad: 1.8177341189584695e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.2106005669920705e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.196460198116256e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -4.251071368344128e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.1711399565683678e-05
sam_encoder.blocks.1.norm1.weight grad: -1.1216669008717872e-05
sam_encoder.blocks.1.norm1.bias grad: 2.6727079784905072e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.0873529390664771e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.249733259101049e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 7.676517270738259e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 4.466649443202186e-06
sam_encoder.blocks.1.norm2.weight grad: -1.0678668331820518e-05
sam_encoder.blocks.1.norm2.bias grad: 4.148485004407121e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 7.1400791057385504e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 7.417620508931577e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.722111382056028e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.0897641661576927e-06
sam_encoder.blocks.2.norm1.weight grad: 1.4638378161180299e-05
sam_encoder.blocks.2.norm1.bias grad: 5.428935310192173e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.964714662492042e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.3889178944737068e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 4.953056304657366e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 2.4314715574291768e-06
sam_encoder.blocks.2.norm2.weight grad: -5.114866326039191e-06
sam_encoder.blocks.2.norm2.bias grad: 3.2489740533492295e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 7.107640698222895e-08
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.849844236152421e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.329378720693057e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.2175606773089385e-06
sam_encoder.blocks.3.norm1.weight grad: 5.1068268476228695e-06
sam_encoder.blocks.3.norm1.bias grad: -3.485006800474366e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -8.60306499816943e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.2354637962962443e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.6208711883791693e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 4.007910661130154e-07
sam_encoder.blocks.3.norm2.weight grad: -1.452216565667186e-05
sam_encoder.blocks.3.norm2.bias grad: -4.035972324345494e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.2539427189039998e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -4.904737579636276e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.3704046725470107e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.0728861070674611e-06
sam_encoder.blocks.4.norm1.weight grad: 2.8968875085411128e-06
sam_encoder.blocks.4.norm1.bias grad: -5.722681635234039e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 4.0682039070816245e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.3994779237691546e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.7526257326826453e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -9.029351417666476e-07
sam_encoder.blocks.4.norm2.weight grad: -2.988898631883785e-05
sam_encoder.blocks.4.norm2.bias grad: -7.912974069768097e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.3758052773482632e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.1637827052909415e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.2193975723894255e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.96085882875741e-08
sam_encoder.blocks.5.norm1.weight grad: 1.4662144167232327e-05
sam_encoder.blocks.5.norm1.bias grad: -5.568377673625946e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.2716982382698916e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -9.637096809456125e-08
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.410518163742381e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.713783032959327e-06
sam_encoder.blocks.5.norm2.weight grad: -2.053911521215923e-05
sam_encoder.blocks.5.norm2.bias grad: -4.307422841520747e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.098150278266985e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.6062199342268286e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -3.575382834242191e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.135584922934868e-08
sam_encoder.blocks.6.norm1.weight grad: 5.636095920635853e-06
sam_encoder.blocks.6.norm1.bias grad: -3.2019852369558066e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.353828444436658e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.948894123415812e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.269833541708067e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 3.039673117655184e-07
sam_encoder.blocks.6.norm2.weight grad: -1.609381433809176e-05
sam_encoder.blocks.6.norm2.bias grad: -3.81093445867009e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -9.146060619968921e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.1334583329444285e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 3.954337444156408e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.13230475007731e-07
sam_encoder.blocks.7.norm1.weight grad: 1.681505978012865e-06
sam_encoder.blocks.7.norm1.bias grad: -4.5660817704629153e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.1119470855192048e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.4168425625248346e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.507916860849946e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 5.518195393960923e-07
sam_encoder.blocks.7.norm2.weight grad: 4.88974251311447e-07
sam_encoder.blocks.7.norm2.bias grad: 4.024625013698824e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.0407545687485253e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.822320314204262e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.95731115329545e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 4.6320744218064647e-07
sam_encoder.blocks.8.norm1.weight grad: 1.3369915905059315e-05
sam_encoder.blocks.8.norm1.bias grad: 7.303847269213293e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.6785561456345022e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 6.961837698327145e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.2124590941530187e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.170476136598154e-06
sam_encoder.blocks.8.norm2.weight grad: -6.888802090543322e-06
sam_encoder.blocks.8.norm2.bias grad: 7.059124982333742e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -7.112119419616647e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -4.299702140997397e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.6746909043140477e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.2048463677037944e-07
sam_encoder.blocks.9.norm1.weight grad: 8.271366823464632e-06
sam_encoder.blocks.9.norm1.bias grad: -1.6105844906633138e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 6.39586869510822e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -8.292985143043552e-08
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.839355149968469e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.136073365159973e-06
sam_encoder.blocks.9.norm2.weight grad: 3.4868423881562194e-06
sam_encoder.blocks.9.norm2.bias grad: 2.7193743790121516e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.2455886866955552e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.458790620745276e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.624660621426301e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.534799025648681e-06
sam_encoder.blocks.10.norm1.weight grad: 3.190402594555053e-06
sam_encoder.blocks.10.norm1.bias grad: 1.24161829262448e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.9114647165661154e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.6639762634440558e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.4285620270347863e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.418475387206854e-07
sam_encoder.blocks.10.norm2.weight grad: 7.688347977818921e-06
sam_encoder.blocks.10.norm2.bias grad: 1.3045953437540447e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 5.190995580051094e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.474936763974256e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 3.7265176615619566e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.012439156511391e-06
sam_encoder.blocks.11.norm1.weight grad: 2.8494566777226282e-06
sam_encoder.blocks.11.norm1.bias grad: 3.89775550502236e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.3071652574581094e-05
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.9576090128102805e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 4.695854840974789e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.5569868284947006e-06
sam_encoder.blocks.11.norm2.weight grad: 1.81646209966857e-05
sam_encoder.blocks.11.norm2.bias grad: 1.4886390999890864e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.288798886089353e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.7829041755467188e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.283659680164419e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.1668411161736003e-06
sam_encoder.neck.conv1.trainable_scale grad: 4.966404958395287e-07
sam_encoder.neck.conv1.trainable_shift grad: 3.0273808079073206e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.5948317013680935e-06
sam_encoder.neck.conv2.trainable_shift grad: -7.955766341183335e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 7.605487189721316e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 5.591020453721285e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0038678492419421673
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0002409556182101369
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00028786613256670535
mask_decoder.transformer.layers.0.norm3.bias grad: 0.0001085536350728944
mask_decoder.transformer.layers.0.norm4.weight grad: -4.278175038052723e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 2.2388954675989226e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 3.3275559871981386e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -3.660792572190985e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0004676324315369129
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00010446364467497915
mask_decoder.transformer.layers.1.norm3.weight grad: 2.035839861491695e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.7944277462665923e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -6.111714174039662e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -1.6936033716774546e-05
mask_decoder.transformer.norm_final_attn.weight grad: -6.072558790037874e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.2270978913875297e-05
Text_Embedding_Affine.0.weight grad: 8.1806722854183e-12
Text_Embedding_Affine.0.bias grad: 4.2710196490602925e-11
Text_Embedding_Affine.2.weight grad: 4.776960077501613e-12
Text_Embedding_Affine.2.bias grad: 1.0433777788421139e-05
Epoch 17 finished with average loss: -55.7068
Epoch 18/39
----------
Epoch 18:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 18:   0%|          | 0/3 [00:00<?, ?it/s, loss=-61.9]Epoch 18:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.06it/s, loss=-61.9]Epoch 18:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.06it/s, loss=-57.9]Epoch 18:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-57.9]Epoch 18:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-57.7]Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.29it/s, loss=-57.7]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.404770261703367e-16
Max value: 0.9998747110366821
Mean value: 0.0822056382894516

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.404770261703367e-16
Max value: 0.9998747110366821
Mean value: 0.0822056382894516

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07700443267822266

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10960301011800766

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07220077514648438

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07700443267822266

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 50.588279724121094
Max value: 88.20780181884766
Mean value: 61.899322509765625

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.404770261703367e-16
Max value: 0.9998747110366821
Mean value: 0.0822056382894516

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.404770261703367e-16
Max value: 0.9998747110366821
Mean value: 0.0822056382894516

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.404770261703367e-16
Max value: 0.9998747110366821
Mean value: 0.0822056382894516

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.10960301011800766

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 50.588279724121094
Max value: 88.20780181884766
Mean value: 61.899322509765625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -61.90049362182617
Max value: -61.90049362182617
Mean value: -61.90049362182617
sam_encoder.pos_embed grad: 6.828455023644153e-10
sam_encoder.blocks.0.norm1.weight grad: 1.5692909073550254e-05
sam_encoder.blocks.0.norm1.bias grad: -1.382746995659545e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.739229950700974e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -6.725611001456855e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 4.7927460400387645e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.1787939229179756e-06
sam_encoder.blocks.0.norm2.weight grad: 3.405363531783223e-05
sam_encoder.blocks.0.norm2.bias grad: -1.4000109331391286e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.0023286197101697e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 6.77199841447873e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.2269785404205322e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 9.635259630158544e-06
sam_encoder.blocks.1.norm1.weight grad: -2.6189734825265987e-08
sam_encoder.blocks.1.norm1.bias grad: 1.2549679013318382e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.074675310519524e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.870761247526389e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.1153242667205632e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.59894897378399e-06
sam_encoder.blocks.1.norm2.weight grad: -6.493050022982061e-06
sam_encoder.blocks.1.norm2.bias grad: -6.150683020678116e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -9.540266546537168e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.630763335924712e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.18270124605624e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.187850552421878e-06
sam_encoder.blocks.2.norm1.weight grad: -1.466856338083744e-05
sam_encoder.blocks.2.norm1.bias grad: 1.7467286852479447e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.2471940863179043e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.999793423441588e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.2424075976014137e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.880574801471084e-06
sam_encoder.blocks.2.norm2.weight grad: -7.401328730338719e-06
sam_encoder.blocks.2.norm2.bias grad: 1.3478736491379095e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -8.527244062861428e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -6.255479547689902e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.257618330593687e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.8364142988502863e-06
sam_encoder.blocks.3.norm1.weight grad: -7.492379836548935e-07
sam_encoder.blocks.3.norm1.bias grad: -2.746238806139445e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.2696240193909034e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.788005298905773e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.4599793252709787e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.919925802620128e-06
sam_encoder.blocks.3.norm2.weight grad: -4.479923518374562e-06
sam_encoder.blocks.3.norm2.bias grad: -7.032590474409517e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -5.0533722060208675e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.0856500693989801e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 7.02978354638617e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.1013075891241897e-06
sam_encoder.blocks.4.norm1.weight grad: 6.807439604017418e-06
sam_encoder.blocks.4.norm1.bias grad: -9.183311703964137e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.082100309053203e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.620989505430771e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -7.668310217923135e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.074535530027788e-07
sam_encoder.blocks.4.norm2.weight grad: -6.634951205342077e-06
sam_encoder.blocks.4.norm2.bias grad: -7.366936074504338e-07
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -7.846230801078491e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.5387439563928638e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.5456215553276706e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 9.488719570072135e-07
sam_encoder.blocks.5.norm1.weight grad: 1.133234673034167e-05
sam_encoder.blocks.5.norm1.bias grad: -7.015572009549942e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 9.362222044728696e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 5.999905170028796e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.7449342522013467e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.190974103337794e-06
sam_encoder.blocks.5.norm2.weight grad: -2.2723061192664318e-06
sam_encoder.blocks.5.norm2.bias grad: 1.8164132598030847e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.2624831217399333e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.499967864532664e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.7998098655880312e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 8.583289741181943e-07
sam_encoder.blocks.6.norm1.weight grad: 3.8887055779923685e-06
sam_encoder.blocks.6.norm1.bias grad: 5.656949610965967e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.395719204490888e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.965295950867585e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.1526895466195128e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.9873203288843797e-07
sam_encoder.blocks.6.norm2.weight grad: 1.357657083644881e-06
sam_encoder.blocks.6.norm2.bias grad: 1.1581051921893959e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.0436123147883336e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.6640068995220645e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -8.305531764563057e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.643914846586995e-08
sam_encoder.blocks.7.norm1.weight grad: -1.9957053609687136e-06
sam_encoder.blocks.7.norm1.bias grad: -3.4309039165236754e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.2458938272175146e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.0160947567783296e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -9.449926778870577e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.2165912721684435e-06
sam_encoder.blocks.7.norm2.weight grad: -3.3472947507107165e-06
sam_encoder.blocks.7.norm2.bias grad: 1.7147672224382404e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.485487923171604e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.673770839261124e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 5.321959406501264e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 7.785576485730417e-07
sam_encoder.blocks.8.norm1.weight grad: 2.101830887113465e-06
sam_encoder.blocks.8.norm1.bias grad: 3.5569050282902026e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.8018592931621242e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.758208893283154e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.7064786536357133e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.961063273687614e-06
sam_encoder.blocks.8.norm2.weight grad: 7.985435104274075e-07
sam_encoder.blocks.8.norm2.bias grad: 1.3387307262746617e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.866593800694318e-08
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.5137274544940738e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.9205358512408566e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.2380398857203545e-06
sam_encoder.blocks.9.norm1.weight grad: 1.8931011709355516e-06
sam_encoder.blocks.9.norm1.bias grad: 1.0069777545140823e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.1567781750018185e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.6529097024431394e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.664993121153202e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 7.587345862702932e-07
sam_encoder.blocks.9.norm2.weight grad: 5.457608764913857e-08
sam_encoder.blocks.9.norm2.bias grad: 3.103472863585921e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.9081679713272024e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -6.3806737671257e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.2070164479591767e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 7.445236178682535e-07
sam_encoder.blocks.10.norm1.weight grad: -1.2064433576597366e-06
sam_encoder.blocks.10.norm1.bias grad: -8.784670058048505e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.3711596693610772e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -6.780152830287989e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.4242267525332863e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -6.443435154324106e-07
sam_encoder.blocks.10.norm2.weight grad: -1.3331771242519608e-06
sam_encoder.blocks.10.norm2.bias grad: 2.3062357286107726e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.1572623154497705e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -8.817072512101731e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.077522483683424e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.909681479148276e-07
sam_encoder.blocks.11.norm1.weight grad: -1.731871088850312e-05
sam_encoder.blocks.11.norm1.bias grad: 9.684941915111267e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.212659862583678e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -3.530984429289674e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.070136815746082e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -9.275041747969226e-07
sam_encoder.blocks.11.norm2.weight grad: -2.612581283756299e-06
sam_encoder.blocks.11.norm2.bias grad: -7.7902427619847e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.5446760244230973e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -7.661143968107353e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 9.161254865830415e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.319885510360109e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.4451143215410411e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.7876363926916383e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.529635483166203e-06
sam_encoder.neck.conv2.trainable_shift grad: -4.4045027607353404e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00016132819291669875
mask_decoder.transformer.layers.0.norm1.bias grad: 1.7200654838234186e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.002489650622010231
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00041585066355764866
mask_decoder.transformer.layers.0.norm3.weight grad: 5.0943781388923526e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.1526824639295228e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00011025852290913463
mask_decoder.transformer.layers.0.norm4.bias grad: 8.724470717424992e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -1.7814147668104852e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -4.593680841935566e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 8.470952161587775e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 1.6335186955984682e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -4.017111859866418e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.4922041373210959e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 1.688472184468992e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00017394855967722833
mask_decoder.transformer.norm_final_attn.weight grad: 4.621671223503654e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.200125552713871e-05
Text_Embedding_Affine.0.weight grad: -1.1016336280700312e-11
Text_Embedding_Affine.0.bias grad: -4.6084536187152025e-10
Text_Embedding_Affine.2.weight grad: -2.363577111808013e-10
Text_Embedding_Affine.2.bias grad: -3.655160980997607e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.6576588836707264e-21
Max value: 0.9999881982803345
Mean value: 0.08184453845024109

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.6576588836707264e-21
Max value: 0.9999881982803345
Mean value: 0.08184453845024109

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08969736099243164

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14604738354682922

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07263040542602539

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08969736099243164

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 14.795310974121094
Max value: 71.89933013916016
Mean value: 53.977073669433594

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.3053675133146684e-21
Max value: 0.9999905824661255
Mean value: 0.08066028356552124

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.3053675133146684e-21
Max value: 0.9999905824661255
Mean value: 0.08066028356552124

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.3053675133146684e-21
Max value: 0.9999905824661255
Mean value: 0.08066028356552124

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14643625915050507

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.5981857180595398
Max value: 1.0775048732757568
Mean value: 0.9996981620788574

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 14.795310974121094
Max value: 71.89933013916016
Mean value: 53.977073669433594

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.981231689453125
Max value: -53.981231689453125
Mean value: -53.981231689453125
sam_encoder.pos_embed grad: -9.104438869478315e-10
sam_encoder.blocks.0.norm1.weight grad: 1.0309633580618538e-05
sam_encoder.blocks.0.norm1.bias grad: 4.8855064960662276e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 5.043105375079904e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.6803646474272682e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.26176575779391e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 7.186965262917511e-07
sam_encoder.blocks.0.norm2.weight grad: 9.149438119493425e-05
sam_encoder.blocks.0.norm2.bias grad: 3.196110628778115e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -2.7665143988997443e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -7.323155841731932e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.5427043763338588e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.292343874112703e-06
sam_encoder.blocks.1.norm1.weight grad: 5.425035851658322e-06
sam_encoder.blocks.1.norm1.bias grad: 3.4535021313786274e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.118744982406497e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.5389254031106248e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -4.410133442434017e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -7.206551799754379e-07
sam_encoder.blocks.1.norm2.weight grad: 3.4077122109010816e-05
sam_encoder.blocks.1.norm2.bias grad: -9.141444934357423e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.478221853787545e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.5517750853177859e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 8.514777618984226e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.1982898462956655e-07
sam_encoder.blocks.2.norm1.weight grad: -5.580618562817108e-06
sam_encoder.blocks.2.norm1.bias grad: 7.402173650916666e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.429647106007906e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.3001521185506135e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.702552137634484e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.105041625734884e-06
sam_encoder.blocks.2.norm2.weight grad: -3.859705429931637e-06
sam_encoder.blocks.2.norm2.bias grad: 1.511334630777128e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 5.139800123288296e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.3322286349648493e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.1182835351064568e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.0019540468420018e-06
sam_encoder.blocks.3.norm1.weight grad: -1.2523923942353576e-07
sam_encoder.blocks.3.norm1.bias grad: -2.025930371019058e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.973620318400208e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.5900122889433987e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.274627604492707e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.555889750510687e-06
sam_encoder.blocks.3.norm2.weight grad: -5.866735591553152e-06
sam_encoder.blocks.3.norm2.bias grad: -5.347357273421949e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 9.521500032860786e-09
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.2975707452133065e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 4.730520231532864e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.0887204098253278e-06
sam_encoder.blocks.4.norm1.weight grad: -6.362165549944621e-07
sam_encoder.blocks.4.norm1.bias grad: 1.3051479754722095e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.775128393750492e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 7.517921289945662e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.3487174277979648e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.217095127183711e-06
sam_encoder.blocks.4.norm2.weight grad: -2.7254753149463795e-05
sam_encoder.blocks.4.norm2.bias grad: -2.1251908037811518e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.9060724298469722e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.792737167415908e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.3272016278497176e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.39109840549645e-06
sam_encoder.blocks.5.norm1.weight grad: -5.080291430203943e-06
sam_encoder.blocks.5.norm1.bias grad: -9.805276022234466e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.231846792710712e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.4899061372707365e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.7730475267162547e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.2776799849234521e-06
sam_encoder.blocks.5.norm2.weight grad: -1.1865833585034125e-05
sam_encoder.blocks.5.norm2.bias grad: -7.085736342560267e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.994432401872473e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.8530154193285853e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 9.13003191271855e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.0845100177903078e-06
sam_encoder.blocks.6.norm1.weight grad: -6.7754344854620285e-06
sam_encoder.blocks.6.norm1.bias grad: 4.334006007411517e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -4.581046596285887e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.042760570475366e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -6.64734670863254e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.9883128718211083e-06
sam_encoder.blocks.6.norm2.weight grad: -8.96572873898549e-06
sam_encoder.blocks.6.norm2.bias grad: 1.8397817029836006e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -8.886827345122583e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.918098627764266e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.5793284546816722e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.7457161877464387e-07
sam_encoder.blocks.7.norm1.weight grad: 6.9278971750463825e-06
sam_encoder.blocks.7.norm1.bias grad: -1.2521029475465184e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.6192584502714453e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.727884520936641e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 9.174972319669905e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.597663069536793e-06
sam_encoder.blocks.7.norm2.weight grad: -1.8099229919243953e-06
sam_encoder.blocks.7.norm2.bias grad: 2.0819056771870237e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -9.099434095105607e-08
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.865873227619886e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.4229884754968225e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -4.918657481312039e-08
sam_encoder.blocks.8.norm1.weight grad: 8.118429832393304e-06
sam_encoder.blocks.8.norm1.bias grad: 1.6530724451513379e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.864992090209853e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 7.674004223190423e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.4652517847935087e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.8951744777950807e-06
sam_encoder.blocks.8.norm2.weight grad: -3.6499532143352553e-06
sam_encoder.blocks.8.norm2.bias grad: -2.2546323634742294e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.938650141004473e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -9.847013870967203e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.7145642914329073e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -9.640766620577779e-07
sam_encoder.blocks.9.norm1.weight grad: -1.2736602172935818e-07
sam_encoder.blocks.9.norm1.bias grad: -1.318242084380472e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 6.32991202564881e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -3.998653426151577e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.9410673480233527e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.0254565242794342e-06
sam_encoder.blocks.9.norm2.weight grad: -1.845074962147919e-06
sam_encoder.blocks.9.norm2.bias grad: 4.8440675470828864e-08
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.8052387531497516e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.2890399148091092e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -9.222441121892189e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.157703751341614e-07
sam_encoder.blocks.10.norm1.weight grad: 1.025202618620824e-05
sam_encoder.blocks.10.norm1.bias grad: -8.807834888102661e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 6.60755904391408e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.5928079594450537e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.165543264709413e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.380641606374411e-06
sam_encoder.blocks.10.norm2.weight grad: -9.477149660597206e-07
sam_encoder.blocks.10.norm2.bias grad: -5.669368761118676e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.4115629483058e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.0773357789494185e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 6.205634406342142e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -9.213742657721014e-08
sam_encoder.blocks.11.norm1.weight grad: -8.775892638368532e-06
sam_encoder.blocks.11.norm1.bias grad: 1.7417066544567206e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.3159582269727252e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.45322630373812e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.2712112038570922e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.024908205086831e-07
sam_encoder.blocks.11.norm2.weight grad: -8.116359822452068e-06
sam_encoder.blocks.11.norm2.bias grad: -1.0006327784140012e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -4.919183993479237e-08
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.4674189969809959e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -8.930471722123912e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.878417598774831e-07
sam_encoder.neck.conv1.trainable_scale grad: -7.482594810426235e-07
sam_encoder.neck.conv1.trainable_shift grad: -5.7126533647533506e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.4878551155561581e-06
sam_encoder.neck.conv2.trainable_shift grad: 3.569131877156906e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0001430278061889112
mask_decoder.transformer.layers.0.norm1.bias grad: -5.752419383497909e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0014656460843980312
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0001915169123094529
mask_decoder.transformer.layers.0.norm3.weight grad: 2.6983274437952787e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.184063876280561e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 7.356816058745608e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -2.374777977820486e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.5907504348433577e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.753981218324043e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -4.236031963955611e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -4.311139855417423e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.526353950495832e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.1887752407346852e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -6.049055446055718e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00023718984448350966
mask_decoder.transformer.norm_final_attn.weight grad: 3.4215506730106426e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.96011478692526e-05
Text_Embedding_Affine.0.weight grad: -1.187966478660707e-11
Text_Embedding_Affine.0.bias grad: 1.7629220305792614e-10
Text_Embedding_Affine.2.weight grad: 9.297820326159556e-12
Text_Embedding_Affine.2.bias grad: -2.5217366783181205e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.6921629327409692e-15
Max value: 0.9999654293060303
Mean value: 0.0851130336523056

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.6921629327409692e-15
Max value: 0.9999654293060303
Mean value: 0.0851130336523056

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08577156066894531

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13109031319618225

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06872844696044922

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08577156066894531

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 46.523860931396484
Max value: 74.86466979980469
Mean value: 57.190494537353516

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.5584549703686153e-15
Max value: 0.9999662637710571
Mean value: 0.08191715180873871

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.5584549703686153e-15
Max value: 0.9999662637710571
Mean value: 0.08191715180873871

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.5584549703686153e-15
Max value: 0.9999662637710571
Mean value: 0.08191715180873871

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1301356703042984

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.5070648789405823
Max value: 1.0941252708435059
Mean value: 1.0011122226715088

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 46.523860931396484
Max value: 74.86466979980469
Mean value: 57.190494537353516

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.24673080444336
Max value: -57.24673080444336
Mean value: -57.24673080444336
sam_encoder.pos_embed grad: 4.951877130565663e-09
sam_encoder.blocks.0.norm1.weight grad: -1.4272998669184744e-05
sam_encoder.blocks.0.norm1.bias grad: -9.976623687180108e-07
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 8.772145520197228e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -6.894061925777351e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 4.72520878247451e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.909791757905623e-06
sam_encoder.blocks.0.norm2.weight grad: 5.429330485640094e-05
sam_encoder.blocks.0.norm2.bias grad: -2.010423304454889e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.9082348444499075e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.1820959116448648e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.2057049389113672e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 7.202126653282903e-06
sam_encoder.blocks.1.norm1.weight grad: 2.9252973035909235e-05
sam_encoder.blocks.1.norm1.bias grad: 4.594097390508978e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -5.9174271882511675e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.02911439575837e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -8.587553566030692e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.151808298047399e-06
sam_encoder.blocks.1.norm2.weight grad: -1.2977010555914603e-05
sam_encoder.blocks.1.norm2.bias grad: -1.2440517593859113e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -6.054811819922179e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 8.970006888375792e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.504131018416956e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -5.7058987295022234e-06
sam_encoder.blocks.2.norm1.weight grad: -8.51876029628329e-06
sam_encoder.blocks.2.norm1.bias grad: 9.89986801869236e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -8.377943231607787e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.5487316836224636e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.096231572882971e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.8397807909641415e-06
sam_encoder.blocks.2.norm2.weight grad: -3.6064825508219656e-06
sam_encoder.blocks.2.norm2.bias grad: -4.530687419901369e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -6.687259428872494e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.3947591241958435e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.559633165015839e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.978230779466685e-06
sam_encoder.blocks.3.norm1.weight grad: -5.306448656483553e-06
sam_encoder.blocks.3.norm1.bias grad: -6.15163389738882e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.4781759091420099e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.069709004601464e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -8.90505725692492e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -6.7562409640231635e-06
sam_encoder.blocks.3.norm2.weight grad: -1.614684151718393e-05
sam_encoder.blocks.3.norm2.bias grad: 1.2243245691934135e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -9.890746696328279e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.1036392777441506e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -7.477075087081175e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.9615302992169745e-06
sam_encoder.blocks.4.norm1.weight grad: -3.578768428269541e-06
sam_encoder.blocks.4.norm1.bias grad: -6.715719791827723e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.6162597350776196e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -7.666361625524587e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.0598449737008195e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.3647103262192104e-06
sam_encoder.blocks.4.norm2.weight grad: -1.1861508028232493e-05
sam_encoder.blocks.4.norm2.bias grad: -2.062499333987944e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.3752181985182688e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.4063851924438495e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -5.718699867429677e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -3.3543647077749483e-06
sam_encoder.blocks.5.norm1.weight grad: 1.61822455879701e-07
sam_encoder.blocks.5.norm1.bias grad: -2.2557880583917722e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.7315177248965483e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.0842767298745457e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.220717820160644e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.5368322010544944e-06
sam_encoder.blocks.5.norm2.weight grad: -1.625044023967348e-05
sam_encoder.blocks.5.norm2.bias grad: 3.7453883123816922e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -8.75777823239332e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.0862594283244107e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.4625810536017525e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.8101516729984723e-07
sam_encoder.blocks.6.norm1.weight grad: -3.270190063631162e-06
sam_encoder.blocks.6.norm1.bias grad: -8.20156310510356e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -3.5661348647408886e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.4089273463468999e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.2781517852999968e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -6.936556360415125e-07
sam_encoder.blocks.6.norm2.weight grad: -9.727343240228947e-06
sam_encoder.blocks.6.norm2.bias grad: 1.982500634767348e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -7.746076335024554e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.940079295716714e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 8.341236821252096e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.570620598722599e-07
sam_encoder.blocks.7.norm1.weight grad: -2.1803130039188545e-06
sam_encoder.blocks.7.norm1.bias grad: -8.457859621557873e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.7246513784339186e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.354498635919299e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.079636826441856e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.614203251345316e-06
sam_encoder.blocks.7.norm2.weight grad: -6.987412689340999e-06
sam_encoder.blocks.7.norm2.bias grad: -2.0711331671918742e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -5.928147402300965e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.3225146580662113e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -8.774350135354325e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.6325218388810754e-09
sam_encoder.blocks.8.norm1.weight grad: 1.1871861715917476e-05
sam_encoder.blocks.8.norm1.bias grad: 4.843036549573299e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.696743523410987e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.7094550912588602e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.307346110479557e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -5.965557647868991e-08
sam_encoder.blocks.8.norm2.weight grad: -1.2561416951939464e-05
sam_encoder.blocks.8.norm2.bias grad: -2.179289367632009e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.0062488399853464e-05
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -5.8774703575181775e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.8508026187191717e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.1589636415010318e-06
sam_encoder.blocks.9.norm1.weight grad: -8.771531611273531e-06
sam_encoder.blocks.9.norm1.bias grad: 9.439368113817181e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -9.649260391597636e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.108410394110251e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.4330148537264904e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.377758619331871e-06
sam_encoder.blocks.9.norm2.weight grad: -6.397165634552948e-06
sam_encoder.blocks.9.norm2.bias grad: -3.2856291909411084e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.280705525161466e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.891896201617783e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.979853095690487e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 7.135474220376636e-07
sam_encoder.blocks.10.norm1.weight grad: -3.9593951441929676e-06
sam_encoder.blocks.10.norm1.bias grad: -1.4162105799186975e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.5529262731870404e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -8.964183280113502e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.2030326388412504e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.959096150334517e-07
sam_encoder.blocks.10.norm2.weight grad: -1.2256138688826468e-05
sam_encoder.blocks.10.norm2.bias grad: -5.14457269673585e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -6.912538992764894e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.2592288334853947e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 5.392185897790114e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -9.470761597185628e-08
sam_encoder.blocks.11.norm1.weight grad: -1.8019802155322395e-05
sam_encoder.blocks.11.norm1.bias grad: 2.0321172087278683e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -9.599656181080718e-08
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.0389687759015942e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.4851242440272472e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -4.6742422910028836e-07
sam_encoder.blocks.11.norm2.weight grad: -5.470591986522777e-06
sam_encoder.blocks.11.norm2.bias grad: -3.09830147671164e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.2780103538243566e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.6962876543402672e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 6.162016461530584e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.8530775491854e-07
sam_encoder.neck.conv1.trainable_scale grad: -8.297483873320743e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.2080895430699456e-05
sam_encoder.neck.conv2.trainable_scale grad: -6.1097125581e-07
sam_encoder.neck.conv2.trainable_shift grad: -7.206203918030951e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -4.611064650816843e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 2.6516063371673226e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0032212776131927967
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00021082611056044698
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00011503093992359936
mask_decoder.transformer.layers.0.norm3.bias grad: -4.726945189759135e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 4.588876981870271e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -7.718183496763231e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 2.9497423383872956e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -7.8629072959302e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00018389253818895668
mask_decoder.transformer.layers.1.norm2.bias grad: 7.072859443724155e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.353991607786156e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.7785655877087265e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 6.193386070663109e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -5.847551074111834e-05
mask_decoder.transformer.norm_final_attn.weight grad: 3.2297041343554156e-06
mask_decoder.transformer.norm_final_attn.bias grad: 2.601982941996539e-06
Text_Embedding_Affine.0.weight grad: -4.167082477690709e-12
Text_Embedding_Affine.0.bias grad: 1.8973911330988358e-10
Text_Embedding_Affine.2.weight grad: 2.9478478685840415e-11
Text_Embedding_Affine.2.bias grad: -2.1362900952226482e-05
Epoch 18 finished with average loss: -57.7095
Epoch 19/39
----------
Epoch 19:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 19:   0%|          | 0/3 [00:00<?, ?it/s, loss=-56.2]Epoch 19:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.05it/s, loss=-56.2]Epoch 19:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.05it/s, loss=-57.5]Epoch 19:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.63it/s, loss=-57.5]Epoch 19:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.63it/s, loss=-55]  Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.27it/s, loss=-55]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                 
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.646069167752898e-10
Max value: 0.9984649419784546
Mean value: 0.08772106468677521

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.646069167752898e-10
Max value: 0.9984649419784546
Mean value: 0.08772106468677521

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08638811111450195

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -12.066889762878418
Max value: -1.1920928244535389e-07
Mean value: -0.1261925846338272

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07257556915283203

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08638811111450195

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 38.883140563964844
Max value: 75.51358032226562
Mean value: 56.20519256591797

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.646069167752898e-10
Max value: 0.9984649419784546
Mean value: 0.08772106468677521

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.646069167752898e-10
Max value: 0.9984649419784546
Mean value: 0.08772106468677521

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.646069167752898e-10
Max value: 0.9984649419784546
Mean value: 0.08772106468677521

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -12.066889762878418
Max value: -1.1920928244535389e-07
Mean value: -0.1261925846338272

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 38.883140563964844
Max value: 75.51358032226562
Mean value: 56.20519256591797

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.20653533935547
Max value: -56.20653533935547
Mean value: -56.20653533935547
sam_encoder.pos_embed grad: 5.619790410804626e-09
sam_encoder.blocks.0.norm1.weight grad: 3.583566649467684e-05
sam_encoder.blocks.0.norm1.bias grad: -1.959426299436018e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.2709212973713875e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.456835884207976e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -7.429599918395979e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.1185846321714052e-07
sam_encoder.blocks.0.norm2.weight grad: 1.7853299141279422e-05
sam_encoder.blocks.0.norm2.bias grad: 1.2134503322158707e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.407147630696272e-07
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.921266736346297e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.537850039312616e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 7.2672473834245466e-06
sam_encoder.blocks.1.norm1.weight grad: 4.044114120915765e-06
sam_encoder.blocks.1.norm1.bias grad: 8.24197650217684e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.336773251154227e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.7447495085652918e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.858359822421335e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.8884533094242215e-06
sam_encoder.blocks.1.norm2.weight grad: -5.864566446689423e-06
sam_encoder.blocks.1.norm2.bias grad: 6.231119186850265e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.0987256246153265e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.9485137272567954e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.1616844858508557e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.3197351310955128e-06
sam_encoder.blocks.2.norm1.weight grad: -1.1453851584519725e-05
sam_encoder.blocks.2.norm1.bias grad: 3.6957560496375663e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -7.324963007704355e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.5057221389724873e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.274099410395138e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.7947693272144534e-06
sam_encoder.blocks.2.norm2.weight grad: 1.0567749086476397e-05
sam_encoder.blocks.2.norm2.bias grad: -1.417471025888517e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 3.224790361855412e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.8238611119159032e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.07331388790044e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.9503753466997296e-06
sam_encoder.blocks.3.norm1.weight grad: -1.6091302086351789e-06
sam_encoder.blocks.3.norm1.bias grad: -1.1944197240154608e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -6.201365977176465e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.9253947104734834e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.451854692888446e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.815871761820745e-06
sam_encoder.blocks.3.norm2.weight grad: -1.6165378838195466e-05
sam_encoder.blocks.3.norm2.bias grad: -8.423418876191135e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.1766949683078565e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.344007953070104e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.3519055503129493e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.2185128070996143e-06
sam_encoder.blocks.4.norm1.weight grad: 7.083341188263148e-06
sam_encoder.blocks.4.norm1.bias grad: -1.1552698197192512e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 3.7418139982037246e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.599235474714078e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.7576307698163873e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -6.393197509169113e-07
sam_encoder.blocks.4.norm2.weight grad: -2.385925881753792e-06
sam_encoder.blocks.4.norm2.bias grad: 1.4156264569464838e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.253859060554532e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.960817818755459e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.005286776489811e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.061072556600266e-07
sam_encoder.blocks.5.norm1.weight grad: 4.3661393647198565e-06
sam_encoder.blocks.5.norm1.bias grad: -1.6382276953663677e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.6990332925342955e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.88324054054101e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.6075758796650916e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.0796919670829084e-06
sam_encoder.blocks.5.norm2.weight grad: -9.23760853765998e-06
sam_encoder.blocks.5.norm2.bias grad: 5.854420123796444e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -6.41496217212989e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.7802875618144753e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 8.956179726737901e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.5450532348259003e-07
sam_encoder.blocks.6.norm1.weight grad: -1.022954165819101e-07
sam_encoder.blocks.6.norm1.bias grad: -5.29613589606015e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.2892051017843187e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 5.35764570486208e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.656633116908779e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.5251923741743667e-06
sam_encoder.blocks.6.norm2.weight grad: -7.460318443008873e-07
sam_encoder.blocks.6.norm2.bias grad: 5.640498329739785e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.8008958022619481e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -6.986520020291209e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.974038685963023e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.0654659945430467e-06
sam_encoder.blocks.7.norm1.weight grad: -6.356837900511891e-08
sam_encoder.blocks.7.norm1.bias grad: -1.1060632232329226e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.8942780570796458e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.0482842753845034e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.59984426520532e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.3032462220508023e-06
sam_encoder.blocks.7.norm2.weight grad: -9.4990382422111e-06
sam_encoder.blocks.7.norm2.bias grad: 1.3211797522671986e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -8.423601684626192e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.509832822601311e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.430928477930138e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.2506171742643346e-06
sam_encoder.blocks.8.norm1.weight grad: 6.239287813514238e-06
sam_encoder.blocks.8.norm1.bias grad: 1.1918418749701232e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.249541572993621e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.424106696707895e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.9588986762973946e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.0855595721513964e-06
sam_encoder.blocks.8.norm2.weight grad: -6.261745056690415e-06
sam_encoder.blocks.8.norm2.bias grad: 1.6051601505751023e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.187252438394353e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.609400326036848e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 6.266621994654997e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 7.552388296971912e-07
sam_encoder.blocks.9.norm1.weight grad: -1.610646904737223e-06
sam_encoder.blocks.9.norm1.bias grad: -6.9796794832655e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.5946587811631616e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.1051107523817336e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.5227112726279302e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.743139108612013e-07
sam_encoder.blocks.9.norm2.weight grad: -6.700357971567428e-06
sam_encoder.blocks.9.norm2.bias grad: 1.665776721893053e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -7.145615654735593e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.4940443381638033e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.3523143707061536e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.121095579037501e-06
sam_encoder.blocks.10.norm1.weight grad: -4.0167878978536464e-06
sam_encoder.blocks.10.norm1.bias grad: -8.146534469233302e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.1422114261658862e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.2352450085018063e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.1245673451630864e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -7.545087896687619e-07
sam_encoder.blocks.10.norm2.weight grad: -1.2472897651605308e-05
sam_encoder.blocks.10.norm2.bias grad: -4.933846753374382e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.511498890584335e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.2285749966831645e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 3.936566486117954e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 8.116293415127984e-09
sam_encoder.blocks.11.norm1.weight grad: -2.0109542674617842e-05
sam_encoder.blocks.11.norm1.bias grad: 2.2223277937882813e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.4660882849711925e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.858845621427463e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -3.697938154800795e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.9442427401372697e-06
sam_encoder.blocks.11.norm2.weight grad: -1.105875890061725e-05
sam_encoder.blocks.11.norm2.bias grad: -2.3710417735856026e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -6.66268533677794e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.9325386801938294e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 8.427279567513324e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.1643060083297314e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.0523417586227879e-06
sam_encoder.neck.conv1.trainable_shift grad: 4.2273713916074485e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.411033736076206e-06
sam_encoder.neck.conv2.trainable_shift grad: -5.4409101721830666e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00014615565305575728
mask_decoder.transformer.layers.0.norm1.bias grad: 2.651853719726205e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0017516890075057745
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0003177350154146552
mask_decoder.transformer.layers.0.norm3.weight grad: 8.878380322130397e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -9.953437256626785e-07
mask_decoder.transformer.layers.0.norm4.weight grad: -7.136241038097069e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 7.79111451265635e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.152009412588086e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -7.897509931353852e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 2.355401920794975e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 1.8956825442728586e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.495557626185473e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.18309890240198e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -3.1259169190889224e-06
mask_decoder.transformer.layers.1.norm4.bias grad: 9.83743229880929e-05
mask_decoder.transformer.norm_final_attn.weight grad: -1.2810384077965864e-06
mask_decoder.transformer.norm_final_attn.bias grad: -8.979690392152406e-06
Text_Embedding_Affine.0.weight grad: -9.644811858888769e-12
Text_Embedding_Affine.0.bias grad: -2.1133847449839038e-10
Text_Embedding_Affine.2.weight grad: 2.1527965521350723e-10
Text_Embedding_Affine.2.bias grad: -3.191268115187995e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.989558962457033e-13
Max value: 0.9998290538787842
Mean value: 0.06972471624612808

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.989558962457033e-13
Max value: 0.9998290538787842
Mean value: 0.06972471624612808

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0780954360961914

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.79162883758545
Max value: -1.1920928244535389e-07
Mean value: -0.11436464637517929

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06494665145874023

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0780954360961914

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 22.302698135375977
Max value: 84.73053741455078
Mean value: 58.817195892333984

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.725193876120378e-14
Max value: 0.9998300075531006
Mean value: 0.06917481124401093

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.725193876120378e-14
Max value: 0.9998300075531006
Mean value: 0.06917481124401093

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.725193876120378e-14
Max value: 0.9998300075531006
Mean value: 0.06917481124401093

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11496032774448395

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.6395271420478821
Max value: 1.0519617795944214
Mean value: 0.999442458152771

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 22.302698135375977
Max value: 84.73053741455078
Mean value: 58.817195892333984

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.79723358154297
Max value: -58.79723358154297
Mean value: -58.79723358154297
sam_encoder.pos_embed grad: -3.5364098316392756e-09
sam_encoder.blocks.0.norm1.weight grad: -1.8182885241913027e-06
sam_encoder.blocks.0.norm1.bias grad: 2.9693959731957875e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.9992370400577784e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.278997494111536e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.8155354812042788e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.2440178807082702e-06
sam_encoder.blocks.0.norm2.weight grad: -1.0557897439866792e-05
sam_encoder.blocks.0.norm2.bias grad: 1.3905162631999701e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -5.776672878710087e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -5.445081114885397e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.7365184248774312e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -8.150400390150025e-06
sam_encoder.blocks.1.norm1.weight grad: -2.375481926719658e-07
sam_encoder.blocks.1.norm1.bias grad: 2.4226737878052518e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.750270363729214e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 8.772954060987104e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.1054054236155935e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.488619884388754e-06
sam_encoder.blocks.1.norm2.weight grad: 1.7055441276170313e-05
sam_encoder.blocks.1.norm2.bias grad: -2.0092588783882093e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.2061851521139033e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.0130298707954353e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 3.0805485948803835e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -5.6562743111499e-07
sam_encoder.blocks.2.norm1.weight grad: 8.173104788511409e-07
sam_encoder.blocks.2.norm1.bias grad: -5.818222689413233e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.4127894019111409e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.2132635990601557e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.0721133132137766e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.7164788346235582e-07
sam_encoder.blocks.2.norm2.weight grad: -7.207197995739989e-06
sam_encoder.blocks.2.norm2.bias grad: -7.076791916915681e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.4697065984801156e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.643691916797252e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.2120671019365545e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.821436370619267e-07
sam_encoder.blocks.3.norm1.weight grad: -1.7419254163542064e-06
sam_encoder.blocks.3.norm1.bias grad: -8.258506568381563e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.9426686037604668e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.087431883206591e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 8.248475751315709e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 5.974740702185954e-07
sam_encoder.blocks.3.norm2.weight grad: 1.0048336662293877e-05
sam_encoder.blocks.3.norm2.bias grad: -1.3033545087637322e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.406594704661984e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.2896183509146795e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.882947228499688e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 9.608983191355946e-07
sam_encoder.blocks.4.norm1.weight grad: -1.5031185967018246e-06
sam_encoder.blocks.4.norm1.bias grad: -1.5237128536682576e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.2410698622697964e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.0237695278192405e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.7755900216798182e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.041862444457365e-06
sam_encoder.blocks.4.norm2.weight grad: -1.6254070942522958e-05
sam_encoder.blocks.4.norm2.bias grad: -2.080408376059495e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -9.374642104376107e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.041567990498152e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.4308404792682268e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.3792432557456777e-07
sam_encoder.blocks.5.norm1.weight grad: -1.1939280284423148e-06
sam_encoder.blocks.5.norm1.bias grad: -2.6610159693518654e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.5853236163820839e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.0765704701043433e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.6413127923442516e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -8.989217121779802e-07
sam_encoder.blocks.5.norm2.weight grad: -3.3143921882583527e-06
sam_encoder.blocks.5.norm2.bias grad: -6.804045369790401e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -8.200166803362663e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.642025324599672e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.4868841162751778e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.6617196858278476e-07
sam_encoder.blocks.6.norm1.weight grad: 2.044666416622931e-06
sam_encoder.blocks.6.norm1.bias grad: 5.9413432609289885e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.1608971135501633e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.3126104647653847e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.4941223298592377e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.986275937175378e-07
sam_encoder.blocks.6.norm2.weight grad: -2.508514626242686e-06
sam_encoder.blocks.6.norm2.bias grad: -2.831681513271178e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.4313620795292081e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -6.592687213924364e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 8.158726245710568e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.131215855020855e-07
sam_encoder.blocks.7.norm1.weight grad: 8.15311614132952e-06
sam_encoder.blocks.7.norm1.bias grad: 1.1804878568000277e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 5.470504220284056e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.7588052944338415e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.6702216473495355e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 5.457120089147338e-09
sam_encoder.blocks.7.norm2.weight grad: 2.2605668164032977e-06
sam_encoder.blocks.7.norm2.bias grad: 1.4508525048029242e-08
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.0513780327746645e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 5.349695584300207e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.916336694004713e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.2563031077661435e-06
sam_encoder.blocks.8.norm1.weight grad: 9.268676876672544e-06
sam_encoder.blocks.8.norm1.bias grad: -1.932902705448214e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 8.10654728411464e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.963819042633986e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.3775759220588952e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.4371558993152576e-06
sam_encoder.blocks.8.norm2.weight grad: 8.30721717193228e-07
sam_encoder.blocks.8.norm2.bias grad: -5.991541911498643e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.3236484619483235e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.1738684406736866e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -5.3004964684078e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.614418677803769e-07
sam_encoder.blocks.9.norm1.weight grad: 1.1768769354603137e-06
sam_encoder.blocks.9.norm1.bias grad: 1.5514933693339117e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.6646725953251007e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.42298210903391e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 3.569252271518053e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.8848760419132304e-07
sam_encoder.blocks.9.norm2.weight grad: 3.7087429518578574e-06
sam_encoder.blocks.9.norm2.bias grad: -4.6199360781429277e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.5470235414104536e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.2366529063001508e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.3334374671103433e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.00713519816054e-07
sam_encoder.blocks.10.norm1.weight grad: 6.708076398354024e-06
sam_encoder.blocks.10.norm1.bias grad: 7.715070751146413e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 4.740827080240706e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.8722673758020392e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.973732196347555e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.3749549907515757e-06
sam_encoder.blocks.10.norm2.weight grad: 3.9261831261683255e-06
sam_encoder.blocks.10.norm2.bias grad: -4.299361933135515e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.200956942033372e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.169620645669056e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -5.341419182514073e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.143474825468729e-07
sam_encoder.blocks.11.norm1.weight grad: 1.8805538275046274e-05
sam_encoder.blocks.11.norm1.bias grad: 7.463344218194834e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.679782599239843e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.562342716482817e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.274580765515566e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 8.776942195254378e-07
sam_encoder.blocks.11.norm2.weight grad: 4.300526597944554e-06
sam_encoder.blocks.11.norm2.bias grad: 1.8934528611680435e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.40320730174426e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 7.514840945077594e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -4.321133815210487e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.39566638433098e-08
sam_encoder.neck.conv1.trainable_scale grad: -3.0711998988408595e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.070997222996084e-05
sam_encoder.neck.conv2.trainable_scale grad: -6.237887646420859e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.3137483620084822e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00011715263099176809
mask_decoder.transformer.layers.0.norm1.bias grad: -9.84075086307712e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003929398022592068
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0001318249269388616
mask_decoder.transformer.layers.0.norm3.weight grad: -6.071766256354749e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.878217830788344e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 9.802776185097173e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -6.467859293479705e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 9.299024895881303e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 3.445194124651607e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -5.0696427933871746e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 7.080892828525975e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 4.1149578464683145e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.760497980285436e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -4.4644108129432425e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00021595112048089504
mask_decoder.transformer.norm_final_attn.weight grad: 2.9643815651070327e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.8499500583857298e-05
Text_Embedding_Affine.0.weight grad: 1.2386894461535736e-11
Text_Embedding_Affine.0.bias grad: 2.528893205955285e-10
Text_Embedding_Affine.2.weight grad: 6.000740876421773e-11
Text_Embedding_Affine.2.bias grad: 1.690202407189645e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.1340944849891343e-09
Max value: 0.9985834360122681
Mean value: 0.07190646231174469

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1340944849891343e-09
Max value: 0.9985834360122681
Mean value: 0.07190646231174469

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09044456481933594

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.15176135301589966

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.057738304138183594

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09044456481933594

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 47.52521896362305
Max value: 52.593910217285156
Mean value: 49.975528717041016

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 9.940716028111751e-10
Max value: 0.9989727735519409
Mean value: 0.06999671459197998

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 9.940716028111751e-10
Max value: 0.9989727735519409
Mean value: 0.06999671459197998

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 9.940716028111751e-10
Max value: 0.9989727735519409
Mean value: 0.06999671459197998

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1541169285774231

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.31476840376853943
Max value: 1.0945532321929932
Mean value: 0.997982382774353

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 47.52521896362305
Max value: 52.593910217285156
Mean value: 49.975528717041016

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -49.87837600708008
Max value: -49.87837600708008
Mean value: -49.87837600708008
sam_encoder.pos_embed grad: -4.0156105107769235e-09
sam_encoder.blocks.0.norm1.weight grad: 2.925804437836632e-05
sam_encoder.blocks.0.norm1.bias grad: 3.7392961530713364e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.469195351295639e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.627980274563015e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.1340747363419723e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.4357890993087494e-07
sam_encoder.blocks.0.norm2.weight grad: 5.2299546950962394e-06
sam_encoder.blocks.0.norm2.bias grad: 1.708105810394045e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -5.080863047624007e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.949848749267403e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.555293907695159e-07
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.9886100492149126e-06
sam_encoder.blocks.1.norm1.weight grad: -7.520503459090833e-06
sam_encoder.blocks.1.norm1.bias grad: -1.8385981093160808e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.620640773580817e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -4.626584484412888e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.351721933446242e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.5717525292966457e-07
sam_encoder.blocks.1.norm2.weight grad: 1.0140087397303432e-05
sam_encoder.blocks.1.norm2.bias grad: -5.8007804000226315e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.3423360693850555e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 8.864226401783526e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -4.889980118605308e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.188116243611148e-06
sam_encoder.blocks.2.norm1.weight grad: 1.5756679658807116e-06
sam_encoder.blocks.2.norm1.bias grad: -5.350382707547396e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 9.588525244907942e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -7.644968036402133e-08
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.071947164949961e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -9.113538794736087e-07
sam_encoder.blocks.2.norm2.weight grad: 2.8348258638288826e-06
sam_encoder.blocks.2.norm2.bias grad: -5.937265086686239e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 7.676648010601639e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.8482467112335144e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.855744696717011e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 8.577921448704728e-07
sam_encoder.blocks.3.norm1.weight grad: -2.8502036002464592e-06
sam_encoder.blocks.3.norm1.bias grad: -3.34513697453076e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.6264558528055204e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.988103228242835e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.358583621273283e-08
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 3.1681275913797435e-07
sam_encoder.blocks.3.norm2.weight grad: 1.3453987776301801e-05
sam_encoder.blocks.3.norm2.bias grad: 6.111103630246362e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.0087416740134358e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 4.063154847244732e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.4439294773183065e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 7.702125230935053e-07
sam_encoder.blocks.4.norm1.weight grad: 1.5332534530898556e-06
sam_encoder.blocks.4.norm1.bias grad: 4.2377664044579433e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.0631298437147052e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.6193607166314905e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.2283827572900918e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.002657993216417e-06
sam_encoder.blocks.4.norm2.weight grad: -1.6788733773864806e-05
sam_encoder.blocks.4.norm2.bias grad: -8.837668246997055e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.1426755008869804e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.192301275907084e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 9.283625104217208e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -4.922339940094389e-07
sam_encoder.blocks.5.norm1.weight grad: 2.1885505248064874e-06
sam_encoder.blocks.5.norm1.bias grad: -4.086114131496288e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.277060960092058e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -5.549708248508978e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.986966137541458e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 6.198957862579846e-07
sam_encoder.blocks.5.norm2.weight grad: -2.865290070985793e-06
sam_encoder.blocks.5.norm2.bias grad: -3.375752157808165e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.1644745967487324e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.619600536490907e-08
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.2118524637116934e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.683390327249072e-07
sam_encoder.blocks.6.norm1.weight grad: 2.9967875434522284e-06
sam_encoder.blocks.6.norm1.bias grad: 4.9463537834526505e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 6.332688258225971e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -4.203979528938362e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.3939766176918056e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 5.477794502439792e-07
sam_encoder.blocks.6.norm2.weight grad: -2.0224383661116008e-06
sam_encoder.blocks.6.norm2.bias grad: -1.5153534604905872e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.2144861329943524e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -9.159342653219937e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 3.855339798519708e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -5.332618115971854e-07
sam_encoder.blocks.7.norm1.weight grad: 1.7291298490818008e-06
sam_encoder.blocks.7.norm1.bias grad: 1.1440906746429391e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.9778453861363232e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 8.160479296748235e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.5567688933515456e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -9.288230273796216e-08
sam_encoder.blocks.7.norm2.weight grad: 1.6002848042262485e-06
sam_encoder.blocks.7.norm2.bias grad: -1.3103986020723823e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.9949764009652426e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 7.852291901144781e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -6.156778908916749e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -7.774764299028902e-07
sam_encoder.blocks.8.norm1.weight grad: 4.404239007271826e-06
sam_encoder.blocks.8.norm1.bias grad: -5.93075981214497e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.106784788542427e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 8.969747966602881e-08
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.9793950488965493e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.239448804175481e-06
sam_encoder.blocks.8.norm2.weight grad: 2.1676032702089287e-06
sam_encoder.blocks.8.norm2.bias grad: 4.704062916971452e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.827605158017832e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.783688276191242e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 9.680659331934294e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -2.274007329106098e-07
sam_encoder.blocks.9.norm1.weight grad: -1.7056262890946527e-07
sam_encoder.blocks.9.norm1.bias grad: 6.590805123884991e-10
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 3.5590232982940506e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.057083409250481e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 8.343030089008607e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.327994247432798e-07
sam_encoder.blocks.9.norm2.weight grad: 3.136762416033889e-06
sam_encoder.blocks.9.norm2.bias grad: -8.985454655885405e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.274996288382681e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.783150082701468e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.1925704629666143e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.645713940793939e-07
sam_encoder.blocks.10.norm1.weight grad: 3.2323578125215136e-06
sam_encoder.blocks.10.norm1.bias grad: 6.914857522133389e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.5309755073976703e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.05485651147319e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.0659275631041965e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 7.942852562337066e-07
sam_encoder.blocks.10.norm2.weight grad: 4.588856427290011e-06
sam_encoder.blocks.10.norm2.bias grad: -2.4645868279549177e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.0554674594895914e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.635705984881497e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.597516584046389e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.13220169800843e-07
sam_encoder.blocks.11.norm1.weight grad: 1.1833895769086666e-05
sam_encoder.blocks.11.norm1.bias grad: 5.051017524237977e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.7206601796715404e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.799389436513593e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.8464428421793855e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 9.717699640532373e-07
sam_encoder.blocks.11.norm2.weight grad: 6.070839845051523e-06
sam_encoder.blocks.11.norm2.bias grad: 7.404129291899153e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.3388150768587366e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.2954322983205202e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.8931119661356206e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.6068592856299801e-07
sam_encoder.neck.conv1.trainable_scale grad: -4.1443854570388794e-08
sam_encoder.neck.conv1.trainable_shift grad: -1.400474320689682e-05
sam_encoder.neck.conv2.trainable_scale grad: -5.466808943310753e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.2886725016869605e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -1.2472251000872348e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 4.706453182734549e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005562444683164358
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0003826842876151204
mask_decoder.transformer.layers.0.norm3.weight grad: -4.541189264273271e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.7099144062958658e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0001152334370999597
mask_decoder.transformer.layers.0.norm4.bias grad: -1.2681509360845666e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 1.0878209650400095e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 4.312430519348709e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00016083875379990786
mask_decoder.transformer.layers.1.norm2.bias grad: -1.2937083738506772e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 1.7590491552255116e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 7.519520295318216e-07
mask_decoder.transformer.layers.1.norm4.weight grad: -4.571736280922778e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0002008708834182471
mask_decoder.transformer.norm_final_attn.weight grad: 9.09845994101488e-08
mask_decoder.transformer.norm_final_attn.bias grad: 1.254235758096911e-05
Text_Embedding_Affine.0.weight grad: 7.777974445066782e-12
Text_Embedding_Affine.0.bias grad: 2.903155771338817e-10
Text_Embedding_Affine.2.weight grad: 1.3945790702796224e-11
Text_Embedding_Affine.2.bias grad: 9.925095582730137e-06
Epoch 19 finished with average loss: -54.9607
Epoch 20/39
----------
Epoch 20:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 20:   0%|          | 0/3 [00:00<?, ?it/s, loss=-51.2]Epoch 20:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.07it/s, loss=-51.2]Epoch 20:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.07it/s, loss=-54.8]Epoch 20:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-54.8]Epoch 20:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-55.4]Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.30it/s, loss=-55.4]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.04946585645866e-20
Max value: 0.9998923540115356
Mean value: 0.06429320573806763

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.04946585645866e-20
Max value: 0.9998923540115356
Mean value: 0.06429320573806763

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08160829544067383

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1391115039587021

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.058245182037353516

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08160829544067383

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 4.851653099060059
Max value: 77.26766967773438
Mean value: 51.163604736328125

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.04946585645866e-20
Max value: 0.9998923540115356
Mean value: 0.06429320573806763

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.04946585645866e-20
Max value: 0.9998923540115356
Mean value: 0.06429320573806763

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.04946585645866e-20
Max value: 0.9998923540115356
Mean value: 0.06429320573806763

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1391115039587021

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 4.851653099060059
Max value: 77.26766967773438
Mean value: 51.163604736328125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -51.164424896240234
Max value: -51.164424896240234
Mean value: -51.164424896240234
sam_encoder.pos_embed grad: -4.617275006779664e-09
sam_encoder.blocks.0.norm1.weight grad: 6.757485238040317e-08
sam_encoder.blocks.0.norm1.bias grad: 3.321186522953212e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.1012998584192246e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 2.4650529439895763e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 4.613523287844146e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.8144048397061852e-07
sam_encoder.blocks.0.norm2.weight grad: 6.410447440430289e-06
sam_encoder.blocks.0.norm2.bias grad: 1.2471677109715529e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.535230916895671e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.154452653892804e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.077814679068979e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -8.448731023236178e-06
sam_encoder.blocks.1.norm1.weight grad: -6.254176696529612e-06
sam_encoder.blocks.1.norm1.bias grad: -3.2632433430990204e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.7471575119998306e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 3.4202193432975037e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.595724026832613e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.033680630120216e-06
sam_encoder.blocks.1.norm2.weight grad: 1.4846458725514822e-05
sam_encoder.blocks.1.norm2.bias grad: 1.3151528719390626e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 7.93275648902636e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.6419156736446894e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 3.2880259368539555e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -8.193973144443589e-07
sam_encoder.blocks.2.norm1.weight grad: 7.593802138217143e-07
sam_encoder.blocks.2.norm1.bias grad: -3.3679657462926116e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.0812058210140094e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -9.506019864602422e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.3627623047796078e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.7837946870713495e-06
sam_encoder.blocks.2.norm2.weight grad: -1.018078137349221e-06
sam_encoder.blocks.2.norm2.bias grad: -7.393412488454487e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 5.977034334136988e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -5.530347380044986e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 5.001862973585958e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.2447973176676896e-06
sam_encoder.blocks.3.norm1.weight grad: -6.847703389212256e-06
sam_encoder.blocks.3.norm1.bias grad: -5.596654773398768e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.2721379739086842e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 5.679942205460975e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.8490186448616441e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 3.1089734875422437e-07
sam_encoder.blocks.3.norm2.weight grad: 1.61070693138754e-05
sam_encoder.blocks.3.norm2.bias grad: -1.3489049877080106e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.1291958799120039e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.865232883981662e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.016243787598796e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.3621045127365505e-06
sam_encoder.blocks.4.norm1.weight grad: 7.230312803585548e-06
sam_encoder.blocks.4.norm1.bias grad: 2.841205059667118e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.6163094187504612e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.1269312238937346e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.6987177079718094e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.219651378254639e-06
sam_encoder.blocks.4.norm2.weight grad: -2.4319710064446554e-05
sam_encoder.blocks.4.norm2.bias grad: -2.4305982151417993e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.6117810446303338e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.880614819237962e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.161625500069931e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.2012202432742924e-07
sam_encoder.blocks.5.norm1.weight grad: 1.0381700121797621e-05
sam_encoder.blocks.5.norm1.bias grad: -2.436127033433877e-08
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.0092934290878475e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.521184623878071e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.0339065233420115e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.603881827350051e-07
sam_encoder.blocks.5.norm2.weight grad: -4.74458420285373e-06
sam_encoder.blocks.5.norm2.bias grad: -7.600161097798264e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.2235196865949547e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -6.974895541134174e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.5127219487330876e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.134977527632145e-07
sam_encoder.blocks.6.norm1.weight grad: 4.239069312461652e-06
sam_encoder.blocks.6.norm1.bias grad: 7.026855200820137e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.6211835120193427e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 5.270931069389917e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.9223343770136125e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.0619651220622472e-06
sam_encoder.blocks.6.norm2.weight grad: -1.8313344298803713e-06
sam_encoder.blocks.6.norm2.bias grad: -2.0737254544656025e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.6337556871803827e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -9.39091023610672e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.8303945782681694e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.083667696861085e-08
sam_encoder.blocks.7.norm1.weight grad: 1.0163785191252828e-05
sam_encoder.blocks.7.norm1.bias grad: 1.1151709031764767e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 7.497837486880599e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 3.537042857715278e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.164811005262891e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.4837520956898516e-07
sam_encoder.blocks.7.norm2.weight grad: 1.268143478228012e-06
sam_encoder.blocks.7.norm2.bias grad: -1.482663378737925e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.2109225028543733e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 6.320655643321516e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -8.90815243792531e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -9.490610750617634e-07
sam_encoder.blocks.8.norm1.weight grad: 1.4809515050728805e-05
sam_encoder.blocks.8.norm1.bias grad: -6.939644663361832e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.313263965130318e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.4450162022258155e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.803690105996793e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.0476516056078253e-06
sam_encoder.blocks.8.norm2.weight grad: 1.9981707737315446e-06
sam_encoder.blocks.8.norm2.bias grad: -4.5691123773394793e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.0666476504848106e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.876240617093572e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 8.534015023542452e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.223786843089329e-07
sam_encoder.blocks.9.norm1.weight grad: 3.7580798561975826e-06
sam_encoder.blocks.9.norm1.bias grad: 2.3092920287126617e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 3.516483729981701e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.1709693101001903e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 7.587254344798566e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 5.000870260118973e-07
sam_encoder.blocks.9.norm2.weight grad: 4.240709586156299e-06
sam_encoder.blocks.9.norm2.bias grad: 4.711513952315727e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.2010182167141465e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.2908034225110896e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.0023390117908093e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.474323299698881e-07
sam_encoder.blocks.10.norm1.weight grad: 6.487152859335765e-06
sam_encoder.blocks.10.norm1.bias grad: 7.721629344814573e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 4.570836154016433e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.864176624621905e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.7985402109843562e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.16194314614404e-06
sam_encoder.blocks.10.norm2.weight grad: 7.401231414405629e-06
sam_encoder.blocks.10.norm2.bias grad: 1.4118963918008376e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.559678589226678e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.3588463591295294e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 5.19715968039236e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.7772842397789645e-07
sam_encoder.blocks.11.norm1.weight grad: 1.970973789866548e-05
sam_encoder.blocks.11.norm1.bias grad: 1.182486357720336e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.224441454425687e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.5570551568089286e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.5489275685686152e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.089890361072321e-06
sam_encoder.blocks.11.norm2.weight grad: 3.9974902392714284e-06
sam_encoder.blocks.11.norm2.bias grad: 1.7207552218678757e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.6047907795145875e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 8.776282811595593e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.6862847473930742e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.2691978668044612e-07
sam_encoder.neck.conv1.trainable_scale grad: -6.97982613928616e-08
sam_encoder.neck.conv1.trainable_shift grad: -2.0495328499237075e-05
sam_encoder.neck.conv2.trainable_scale grad: -8.492042979924008e-07
sam_encoder.neck.conv2.trainable_shift grad: 5.121418780618114e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -6.442189624067396e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -2.3511674953624606e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004366245586425066
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00021603383356705308
mask_decoder.transformer.layers.0.norm3.weight grad: -2.3318103558267467e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.360889240866527e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00011933768109884113
mask_decoder.transformer.layers.0.norm4.bias grad: -7.626349997735815e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.1144099921220914e-07
mask_decoder.transformer.layers.1.norm1.bias grad: 5.326167411112692e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00017077109077945352
mask_decoder.transformer.layers.1.norm2.bias grad: -3.4442724427208304e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.1718951757065952e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -5.1821471060975455e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -5.646731733577326e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0002257862943224609
mask_decoder.transformer.norm_final_attn.weight grad: 2.559634140197886e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.4984507288318127e-05
Text_Embedding_Affine.0.weight grad: -1.2165086646365175e-12
Text_Embedding_Affine.0.bias grad: -2.2744570116195462e-10
Text_Embedding_Affine.2.weight grad: -4.550513091339248e-11
Text_Embedding_Affine.2.bias grad: 1.1600011930568144e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.337526632637426e-13
Max value: 0.9998599290847778
Mean value: 0.07053771615028381

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.337526632637426e-13
Max value: 0.9998599290847778
Mean value: 0.07053771615028381

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07848787307739258

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11132650077342987

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06248617172241211

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07848787307739258

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 30.624135971069336
Max value: 86.6524658203125
Mean value: 58.429771423339844

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.6207001019008516e-12
Max value: 0.9998528957366943
Mean value: 0.07110276073217392

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6207001019008516e-12
Max value: 0.9998528957366943
Mean value: 0.07110276073217392

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6207001019008516e-12
Max value: 0.9998528957366943
Mean value: 0.07110276073217392

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11100650578737259

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9642838835716248
Max value: 1.4081403017044067
Mean value: 1.0003504753112793

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 30.624135971069336
Max value: 86.6524658203125
Mean value: 58.429771423339844

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.44987487792969
Max value: -58.44987487792969
Mean value: -58.44987487792969
sam_encoder.pos_embed grad: -4.0355110364487246e-09
sam_encoder.blocks.0.norm1.weight grad: -6.515471613965929e-05
sam_encoder.blocks.0.norm1.bias grad: 2.716995368245989e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.9464397357514827e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.034683094758293e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 5.428082658909261e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.6663247993118375e-09
sam_encoder.blocks.0.norm2.weight grad: -3.4474858239263995e-06
sam_encoder.blocks.0.norm2.bias grad: 1.72363143065013e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.895017016475322e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.8864159301301697e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.2239495592657477e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -6.375582870532526e-06
sam_encoder.blocks.1.norm1.weight grad: -1.438516164853354e-06
sam_encoder.blocks.1.norm1.bias grad: -1.0679437764338218e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 6.812795163568808e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 9.158828788713436e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 5.5932446230144706e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.2203568025579443e-06
sam_encoder.blocks.1.norm2.weight grad: 1.792066359485034e-05
sam_encoder.blocks.1.norm2.bias grad: 5.8848250716891926e-08
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.2573392420308664e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 9.789190471565234e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 9.246297850040719e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.3528992326428124e-07
sam_encoder.blocks.2.norm1.weight grad: 1.5461037037312053e-06
sam_encoder.blocks.2.norm1.bias grad: -7.009622095210943e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.972488573504961e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.7523456108392566e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -9.796258382266387e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.546290261307149e-06
sam_encoder.blocks.2.norm2.weight grad: 5.320351192494854e-06
sam_encoder.blocks.2.norm2.bias grad: -4.965861080563627e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 3.8985908759059384e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.6235512134699093e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 3.3864225770230405e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -4.3902599600187386e-07
sam_encoder.blocks.3.norm1.weight grad: -2.640307172896428e-07
sam_encoder.blocks.3.norm1.bias grad: -7.517518952226965e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.103077349602245e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.2179241554454165e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 7.466123292942939e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.476444595027715e-06
sam_encoder.blocks.3.norm2.weight grad: 7.218377504614182e-06
sam_encoder.blocks.3.norm2.bias grad: 6.3183920246956404e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.6743684833927546e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.155494257749524e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 4.319824256526772e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.593804021624237e-07
sam_encoder.blocks.4.norm1.weight grad: 9.789882824406959e-06
sam_encoder.blocks.4.norm1.bias grad: -1.7260575759792118e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 4.203332537144888e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.5993027773220092e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.759688297577668e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.5327510684292065e-06
sam_encoder.blocks.4.norm2.weight grad: -1.9441671611275524e-05
sam_encoder.blocks.4.norm2.bias grad: -1.3147960999049246e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.3450505321088713e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.1648603403009474e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.470222514399211e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -8.004702749531134e-07
sam_encoder.blocks.5.norm1.weight grad: 1.3110773579683155e-05
sam_encoder.blocks.5.norm1.bias grad: -8.128823537845165e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 9.881081496132538e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.9650043416040717e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 5.0517501222202554e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.0036249022959964e-06
sam_encoder.blocks.5.norm2.weight grad: -1.2551007785077672e-05
sam_encoder.blocks.5.norm2.bias grad: -5.108170626044739e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.802520379598718e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.7999140027313842e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 9.445342925573641e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.746870096525527e-07
sam_encoder.blocks.6.norm1.weight grad: 2.6600191631587222e-06
sam_encoder.blocks.6.norm1.bias grad: 2.7357925773685565e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -4.305850325181382e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.467974114661047e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.742329100641655e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 7.565672035525495e-07
sam_encoder.blocks.6.norm2.weight grad: -5.522909759747563e-06
sam_encoder.blocks.6.norm2.bias grad: -1.9480239643598907e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -4.204275228403276e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.0401773781486554e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -3.941029262932716e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -8.524208396920585e-07
sam_encoder.blocks.7.norm1.weight grad: 7.591717803734355e-06
sam_encoder.blocks.7.norm1.bias grad: 1.1065822036471218e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.832487775274785e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.5503845790808555e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 9.97424649540335e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.723097170724941e-06
sam_encoder.blocks.7.norm2.weight grad: -3.262415702920407e-06
sam_encoder.blocks.7.norm2.bias grad: -5.205144475439738e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -4.3331283450243063e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.200970522560965e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -2.781063983547938e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.880849016648426e-07
sam_encoder.blocks.8.norm1.weight grad: -4.6541447318304563e-07
sam_encoder.blocks.8.norm1.bias grad: -5.413755275185395e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.913512278406415e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.4817404664645437e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 8.201104719773866e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 3.9904051618577796e-07
sam_encoder.blocks.8.norm2.weight grad: -4.660822014557198e-06
sam_encoder.blocks.8.norm2.bias grad: -2.9966229249112075e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.6507468646741472e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.3736685104959179e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -7.560880703749717e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -8.017574941732164e-07
sam_encoder.blocks.9.norm1.weight grad: 5.13000145474507e-07
sam_encoder.blocks.9.norm1.bias grad: 9.941205547647769e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 5.11482198817248e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 5.235363005340332e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 6.335589830541721e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.69012950488468e-08
sam_encoder.blocks.9.norm2.weight grad: -6.297610752881155e-07
sam_encoder.blocks.9.norm2.bias grad: -3.6108608583163004e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.4798368965784903e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.9752573027508333e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.765908331843093e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.737515612556308e-07
sam_encoder.blocks.10.norm1.weight grad: 7.112684670573799e-06
sam_encoder.blocks.10.norm1.bias grad: 5.724864422518294e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 4.432011337485164e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.557205678182072e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.5692141914769309e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.544128261040896e-07
sam_encoder.blocks.10.norm2.weight grad: 4.045655259687919e-06
sam_encoder.blocks.10.norm2.bias grad: -2.7387459340388887e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.499587480997434e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.2231827213327051e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 6.153901495054015e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.9497262826462247e-07
sam_encoder.blocks.11.norm1.weight grad: 1.065268133970676e-05
sam_encoder.blocks.11.norm1.bias grad: 1.185815904136689e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.7345686248736456e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 6.927045888005523e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.5937995360436616e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.0478900094312849e-06
sam_encoder.blocks.11.norm2.weight grad: 9.549145943310577e-06
sam_encoder.blocks.11.norm2.bias grad: 4.892815468338085e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.206860810678336e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.3214655609772308e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 8.671069053889369e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.0967487418820383e-07
sam_encoder.neck.conv1.trainable_scale grad: 5.376314220484346e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.5718178221723065e-05
sam_encoder.neck.conv2.trainable_scale grad: -5.09164237882942e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.2424702617863659e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -4.11610963055864e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -8.998176781460643e-08
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00474949786439538
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0003694815677590668
mask_decoder.transformer.layers.0.norm3.weight grad: -1.8575556168798357e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -5.630168743664399e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00018384169379714876
mask_decoder.transformer.layers.0.norm4.bias grad: -1.1671496395138092e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 2.4388573365285993e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 7.495428690162953e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0002352424489799887
mask_decoder.transformer.layers.1.norm2.bias grad: -3.9088983612600714e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.8968894184799865e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.2192181202408392e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -5.71084747207351e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00024186847440432757
mask_decoder.transformer.norm_final_attn.weight grad: 9.067933888218249e-07
mask_decoder.transformer.norm_final_attn.bias grad: 1.4653345715487376e-05
Text_Embedding_Affine.0.weight grad: -2.4249269259257744e-11
Text_Embedding_Affine.0.bias grad: -6.909339211880194e-10
Text_Embedding_Affine.2.weight grad: 1.1094627994090445e-10
Text_Embedding_Affine.2.bias grad: 2.9502443794626743e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 6.610259561945497e-10
Max value: 0.9996724128723145
Mean value: 0.08939202129840851

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.610259561945497e-10
Max value: 0.9996724128723145
Mean value: 0.08939202129840851

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0981903076171875

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.075827598571777
Max value: -1.1920928244535389e-07
Mean value: -0.15016329288482666

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07722663879394531

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0981903076171875

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 49.22996139526367
Max value: 62.794734954833984
Mean value: 56.480010986328125

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.75119763135001e-09
Max value: 0.9995597004890442
Mean value: 0.09141525626182556

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.75119763135001e-09
Max value: 0.9995597004890442
Mean value: 0.09141525626182556

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.75119763135001e-09
Max value: 0.9995597004890442
Mean value: 0.09141525626182556

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.396337509155273
Max value: -1.1920928244535389e-07
Mean value: -0.14886437356472015

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9446636438369751
Max value: 1.9935702085494995
Mean value: 1.0015690326690674

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 49.22996139526367
Max value: 62.794734954833984
Mean value: 56.480010986328125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.5463981628418
Max value: -56.5463981628418
Mean value: -56.5463981628418
sam_encoder.pos_embed grad: -4.141007092783866e-09
sam_encoder.blocks.0.norm1.weight grad: -7.14086854713969e-05
sam_encoder.blocks.0.norm1.bias grad: -4.463094228412956e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.7676661577279447e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.2577049801620888e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -3.122397629340412e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.741613116086228e-06
sam_encoder.blocks.0.norm2.weight grad: 8.997644727060106e-06
sam_encoder.blocks.0.norm2.bias grad: 1.9656368749565445e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -8.156162039085757e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -7.293652288353769e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -3.312369153718464e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -8.288816388812847e-06
sam_encoder.blocks.1.norm1.weight grad: -1.0417220437375363e-05
sam_encoder.blocks.1.norm1.bias grad: 5.07288768858416e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.588905201468151e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.1260816538415384e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -4.66435767521034e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.7819601200462785e-06
sam_encoder.blocks.1.norm2.weight grad: 6.26060864306055e-06
sam_encoder.blocks.1.norm2.bias grad: -5.970573511149269e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.5050916317704832e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.329630663349235e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -8.038218766159844e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.540750867614406e-06
sam_encoder.blocks.2.norm1.weight grad: -7.496752004954033e-06
sam_encoder.blocks.2.norm1.bias grad: 7.535630857091746e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -5.897740265936591e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.1531654965656344e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.295752427831758e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.0325209081638604e-06
sam_encoder.blocks.2.norm2.weight grad: 4.301127319195075e-06
sam_encoder.blocks.2.norm2.bias grad: -2.09325116884429e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.2185269042674918e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -6.416803444153629e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -5.708493517886382e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.6102741230715765e-06
sam_encoder.blocks.3.norm1.weight grad: 6.771081643819343e-06
sam_encoder.blocks.3.norm1.bias grad: -4.833857474295655e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -8.005723429960199e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.6664372398954583e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.421731657406781e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.69911299458181e-06
sam_encoder.blocks.3.norm2.weight grad: 5.475598072735011e-07
sam_encoder.blocks.3.norm2.bias grad: -3.648804977274267e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 3.750134780489134e-08
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.1287780782586196e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.9078743207501248e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.6575112340433407e-06
sam_encoder.blocks.4.norm1.weight grad: 1.0507053048058879e-05
sam_encoder.blocks.4.norm1.bias grad: -3.1475769901589956e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 6.546488293679431e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 9.014086117531406e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 4.056659690832021e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.6240980989532545e-06
sam_encoder.blocks.4.norm2.weight grad: -4.3841380829690024e-05
sam_encoder.blocks.4.norm2.bias grad: -2.8475329600041732e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.9303249903023243e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -9.761973160493653e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.021749426399765e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.445891939511057e-06
sam_encoder.blocks.5.norm1.weight grad: 1.1811351214419119e-05
sam_encoder.blocks.5.norm1.bias grad: -1.2401154890540056e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 5.348077593225753e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.1437582492799265e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.6303625822474714e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 4.38894858234562e-06
sam_encoder.blocks.5.norm2.weight grad: -2.5396742785233073e-05
sam_encoder.blocks.5.norm2.bias grad: -1.1020290912711062e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.108500873669982e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.7722963952546706e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.548663698893506e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.81709514335671e-07
sam_encoder.blocks.6.norm1.weight grad: -2.023210981860757e-06
sam_encoder.blocks.6.norm1.bias grad: -8.493701670886367e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.432698693155544e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -8.051528084251913e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -6.750862553417392e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.418619260424748e-06
sam_encoder.blocks.6.norm2.weight grad: -1.2431277355062775e-05
sam_encoder.blocks.6.norm2.bias grad: -2.9160373742342927e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -9.892196430882905e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.968106284446549e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 7.483328658963728e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.7347528569189308e-07
sam_encoder.blocks.7.norm1.weight grad: 4.886234819423407e-06
sam_encoder.blocks.7.norm1.bias grad: -1.1102656571893021e-09
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.60438435159449e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.5901582628430333e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.7614571962431e-08
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -7.480762178602163e-07
sam_encoder.blocks.7.norm2.weight grad: -3.1220649816532386e-06
sam_encoder.blocks.7.norm2.bias grad: -1.0265856644764426e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -7.751950761303306e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.6479559690196766e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 7.807588531250076e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 3.815033267073886e-07
sam_encoder.blocks.8.norm1.weight grad: 5.912992492085323e-06
sam_encoder.blocks.8.norm1.bias grad: -4.3518383563423413e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.0306709959404543e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.4807046682108194e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.3108870007272344e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -9.568501582180033e-07
sam_encoder.blocks.8.norm2.weight grad: -7.469703177775955e-06
sam_encoder.blocks.8.norm2.bias grad: -3.912527972715907e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.041962478775531e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.1812624001759104e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 5.144000283507921e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.33452817358193e-07
sam_encoder.blocks.9.norm1.weight grad: 2.0525455965980655e-06
sam_encoder.blocks.9.norm1.bias grad: -1.4608980336561217e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 3.21522151125464e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -5.766160597886483e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -7.659875791432569e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.2183852504676906e-06
sam_encoder.blocks.9.norm2.weight grad: -3.851531289456034e-07
sam_encoder.blocks.9.norm2.bias grad: -9.02997840057651e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -9.025624194691773e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 6.544370023675583e-08
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.2623253244091757e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.8648685201915214e-07
sam_encoder.blocks.10.norm1.weight grad: 7.878201358835213e-06
sam_encoder.blocks.10.norm1.bias grad: 5.352158041205257e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.986356205132324e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.2798529951396631e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.3510598364518955e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.0727302424129448e-06
sam_encoder.blocks.10.norm2.weight grad: -4.025714133604197e-06
sam_encoder.blocks.10.norm2.bias grad: -2.0738982584589394e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.721950866340194e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -7.077923100951011e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 8.191778988475562e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.0188615457736887e-07
sam_encoder.blocks.11.norm1.weight grad: 1.4928449445505976e-06
sam_encoder.blocks.11.norm1.bias grad: 4.123904545849655e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.5723230666917516e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.3971839507576078e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.184053303404653e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 6.395016498572659e-07
sam_encoder.blocks.11.norm2.weight grad: 1.0391413525212556e-05
sam_encoder.blocks.11.norm2.bias grad: 3.3270748645009007e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.006915903824847e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.113465827984328e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.366553189858678e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.936423584287695e-07
sam_encoder.neck.conv1.trainable_scale grad: 3.252134774811566e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.9539356799214147e-05
sam_encoder.neck.conv2.trainable_scale grad: 3.8685902836732566e-07
sam_encoder.neck.conv2.trainable_shift grad: -3.309216845082119e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 8.514150977134705e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 8.289534889627248e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0052609979175031185
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0004552753234747797
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00010019702313002199
mask_decoder.transformer.layers.0.norm3.bias grad: -6.059117004042491e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 7.245937013067305e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -4.050882125739008e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -3.625230419856962e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 2.2359718059306033e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -2.705913721001707e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 1.32383775053313e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 3.806129370786948e-06
mask_decoder.transformer.layers.1.norm3.bias grad: -1.4254927918955218e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -4.290874130674638e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00017439288785681129
mask_decoder.transformer.norm_final_attn.weight grad: -2.879397243304993e-06
mask_decoder.transformer.norm_final_attn.bias grad: 7.514557637477992e-06
Text_Embedding_Affine.0.weight grad: -4.496276614918138e-12
Text_Embedding_Affine.0.bias grad: -1.5532228281323057e-11
Text_Embedding_Affine.2.weight grad: 4.819131205202609e-11
Text_Embedding_Affine.2.bias grad: 1.3342076272238046e-05
Epoch 20 finished with average loss: -55.3869
Epoch 21/39
----------
Epoch 21:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 21:   0%|          | 0/3 [00:00<?, ?it/s, loss=-59.6]Epoch 21:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.13it/s, loss=-59.6]Epoch 21:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.13it/s, loss=-55.5]Epoch 21:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.72it/s, loss=-55.5]Epoch 21:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.72it/s, loss=-58.8]Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.36it/s, loss=-58.8]/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.0312950691539654e-14
Max value: 0.9999732971191406
Mean value: 0.07937375456094742

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.0312950691539654e-14
Max value: 0.9999732971191406
Mean value: 0.07937375456094742

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08522176742553711

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.128492534160614

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07117938995361328

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08522176742553711

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 31.100645065307617
Max value: 75.48505401611328
Mean value: 59.61940383911133

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.0312950691539654e-14
Max value: 0.9999732971191406
Mean value: 0.07937375456094742

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.0312950691539654e-14
Max value: 0.9999732971191406
Mean value: 0.07937375456094742

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.0312950691539654e-14
Max value: 0.9999732971191406
Mean value: 0.07937375456094742

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.128492534160614

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 31.100645065307617
Max value: 75.48505401611328
Mean value: 59.61940383911133

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.62044143676758
Max value: -59.62044143676758
Mean value: -59.62044143676758
sam_encoder.pos_embed grad: -3.82396070364166e-09
sam_encoder.blocks.0.norm1.weight grad: -3.117617961834185e-05
sam_encoder.blocks.0.norm1.bias grad: 6.281306559685618e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -7.017759344307706e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.6154832489264663e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.3595177935931133e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.8887469366291043e-07
sam_encoder.blocks.0.norm2.weight grad: 4.255839940014994e-06
sam_encoder.blocks.0.norm2.bias grad: 4.905588866677135e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -4.575315870170016e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 9.729956218507141e-08
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -4.861379238718655e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.934080700038976e-07
sam_encoder.blocks.1.norm1.weight grad: -3.8787079574831296e-06
sam_encoder.blocks.1.norm1.bias grad: 1.1475405699457042e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.850081611744827e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -8.512203066857182e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -4.298781277611852e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -6.574277904292103e-07
sam_encoder.blocks.1.norm2.weight grad: 1.6530775610590354e-05
sam_encoder.blocks.1.norm2.bias grad: -7.407102657452924e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.626568968684296e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.6686244634911418e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 3.6872665987175424e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -6.363090392369486e-07
sam_encoder.blocks.2.norm1.weight grad: 5.172114470042288e-06
sam_encoder.blocks.2.norm1.bias grad: -2.6400691695016576e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -8.870861165632959e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 1.114770611820859e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.2813683269996545e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.9825273486494552e-06
sam_encoder.blocks.2.norm2.weight grad: 3.2625425205878855e-07
sam_encoder.blocks.2.norm2.bias grad: -1.9145831174682826e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.293791910939035e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 4.2671905475799576e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.8893933884100989e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.303218131302856e-07
sam_encoder.blocks.3.norm1.weight grad: 3.064817065023817e-06
sam_encoder.blocks.3.norm1.bias grad: -7.968151294335257e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.1278153806415503e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 4.193916538497433e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.2484532280486746e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 9.435934771317989e-07
sam_encoder.blocks.3.norm2.weight grad: 7.887811079854146e-06
sam_encoder.blocks.3.norm2.bias grad: 1.9480055470921798e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.843678758945316e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.8812150958401617e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.210343469892905e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.3962937828182476e-07
sam_encoder.blocks.4.norm1.weight grad: 1.1080801414209418e-05
sam_encoder.blocks.4.norm1.bias grad: -3.409928467590362e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 4.226345481583849e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.6798161343322136e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.115788220180548e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.4362285583047196e-06
sam_encoder.blocks.4.norm2.weight grad: -3.817786819126923e-06
sam_encoder.blocks.4.norm2.bias grad: -1.1539730621734634e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -6.92437151883496e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.821701284323353e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.4274859242723323e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.54409906372166e-06
sam_encoder.blocks.5.norm1.weight grad: 5.9583935581031255e-06
sam_encoder.blocks.5.norm1.bias grad: -2.0695229977718554e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.771716703544371e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.513041065161815e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.5072680525918258e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -3.1168672194326064e-06
sam_encoder.blocks.5.norm2.weight grad: -4.798923328053206e-06
sam_encoder.blocks.5.norm2.bias grad: -4.700995759776561e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.812285856634844e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.172852194031293e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.491438635843224e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.1134843589388765e-06
sam_encoder.blocks.6.norm1.weight grad: -2.51423125519068e-06
sam_encoder.blocks.6.norm1.bias grad: -8.938579298956029e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -3.0887983939464903e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -4.8774461447465e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.9287783692998346e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -5.963552212051582e-07
sam_encoder.blocks.6.norm2.weight grad: 6.0603488236665726e-06
sam_encoder.blocks.6.norm2.bias grad: 1.0472064104760648e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.3263661458040588e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.0122177940274923e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.1802729861519765e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.562153203049093e-07
sam_encoder.blocks.7.norm1.weight grad: 5.867535946890712e-06
sam_encoder.blocks.7.norm1.bias grad: 2.2152348719828296e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.986644969700137e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.521597480154014e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.4766230549412285e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -9.811886769739431e-08
sam_encoder.blocks.7.norm2.weight grad: 4.098798854101915e-06
sam_encoder.blocks.7.norm2.bias grad: -8.072053674368362e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.1129786798846908e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.5609900805866346e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.2402578022374655e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.0201794964359578e-07
sam_encoder.blocks.8.norm1.weight grad: 7.760647349641658e-06
sam_encoder.blocks.8.norm1.bias grad: -1.1728034223779105e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 6.309557193162618e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.1647305200312985e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.5870123206696007e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.0606826208459097e-06
sam_encoder.blocks.8.norm2.weight grad: -2.7799414965556934e-06
sam_encoder.blocks.8.norm2.bias grad: 4.233851029766811e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.1443337320524734e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.2913336604469805e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.837465219978185e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.2504399364843266e-06
sam_encoder.blocks.9.norm1.weight grad: -7.908339512141538e-07
sam_encoder.blocks.9.norm1.bias grad: 9.626867267797934e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.0171324902330525e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.4147819626941782e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.22939330949157e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.438854664887913e-07
sam_encoder.blocks.9.norm2.weight grad: 3.5529965316527523e-06
sam_encoder.blocks.9.norm2.bias grad: -2.472152687005291e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.0768598005815875e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.243473207068746e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.2492972107102105e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.4108514885010663e-07
sam_encoder.blocks.10.norm1.weight grad: 7.05290131008951e-06
sam_encoder.blocks.10.norm1.bias grad: 4.751364031108096e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 4.156437626079423e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.7907714209286496e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.3257915725262137e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.0391279374744045e-06
sam_encoder.blocks.10.norm2.weight grad: 2.216917209807434e-06
sam_encoder.blocks.10.norm2.bias grad: -5.074989530839957e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.1761511561635416e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.1275843664625427e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -4.208432073937729e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.5877210418912e-07
sam_encoder.blocks.11.norm1.weight grad: 1.711276672722306e-05
sam_encoder.blocks.11.norm1.bias grad: 5.793772857032309e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.764614459418226e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.6196736396523193e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.090539510390954e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 8.084630280791316e-07
sam_encoder.blocks.11.norm2.weight grad: 5.23844482813729e-06
sam_encoder.blocks.11.norm2.bias grad: 9.740458608575864e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.013625584775582e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 8.676011020725127e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.773639948827622e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -9.247130350331645e-08
sam_encoder.neck.conv1.trainable_scale grad: 3.41809936799109e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.18446584767662e-05
sam_encoder.neck.conv2.trainable_scale grad: 8.259303285740316e-08
sam_encoder.neck.conv2.trainable_shift grad: 5.437773324956652e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -9.926142956828699e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.8955834093503654e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0035378215834498405
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0004870095872320235
mask_decoder.transformer.layers.0.norm3.weight grad: 2.2684253053739667e-06
mask_decoder.transformer.layers.0.norm3.bias grad: -2.9682467356906272e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00013571971794590354
mask_decoder.transformer.layers.0.norm4.bias grad: -4.3439540604595095e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.3733675334369764e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.8753571566776372e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -2.0380321075208485e-07
mask_decoder.transformer.layers.1.norm2.bias grad: 5.467176379170269e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 4.692309084930457e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.9768933018203825e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -4.953372263116762e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0002482670242898166
mask_decoder.transformer.norm_final_attn.weight grad: 6.052089702279773e-06
mask_decoder.transformer.norm_final_attn.bias grad: 2.0518880774034187e-05
Text_Embedding_Affine.0.weight grad: 4.629591848770431e-12
Text_Embedding_Affine.0.bias grad: 5.713566286758009e-10
Text_Embedding_Affine.2.weight grad: 1.2300214666249865e-11
Text_Embedding_Affine.2.bias grad: 5.36858533450868e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.583790824183362e-12
Max value: 0.9997400641441345
Mean value: 0.07594993710517883

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.583790824183362e-12
Max value: 0.9997400641441345
Mean value: 0.07594993710517883

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07895135879516602

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.223116874694824
Max value: -1.1920928244535389e-07
Mean value: -0.1213223785161972

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.061595916748046875

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07895135879516602

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 18.33682632446289
Max value: 63.51255798339844
Mean value: 51.276634216308594

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.089535788661224e-12
Max value: 0.9997127652168274
Mean value: 0.0782749280333519

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.089535788661224e-12
Max value: 0.9997127652168274
Mean value: 0.0782749280333519

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.089535788661224e-12
Max value: 0.9997127652168274
Mean value: 0.0782749280333519

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.852060317993164
Max value: -1.1920928244535389e-07
Mean value: -0.12100712209939957

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9488294720649719
Max value: 1.472546935081482
Mean value: 1.0004546642303467

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 18.33682632446289
Max value: 63.51255798339844
Mean value: 51.276634216308594

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -51.28699493408203
Max value: -51.28699493408203
Mean value: -51.28699493408203
sam_encoder.pos_embed grad: 4.53369730646358e-10
sam_encoder.blocks.0.norm1.weight grad: -3.125215516774915e-05
sam_encoder.blocks.0.norm1.bias grad: -2.486380071786698e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.952796992554795e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.3565694340941263e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.6346043594239745e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -8.536264317626774e-07
sam_encoder.blocks.0.norm2.weight grad: 2.802692961267894e-06
sam_encoder.blocks.0.norm2.bias grad: -9.192417564918287e-07
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.7885674878925784e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.772478865153971e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.582588422228582e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.0395131034310907e-06
sam_encoder.blocks.1.norm1.weight grad: 2.9275868200784316e-06
sam_encoder.blocks.1.norm1.bias grad: 1.2567415069497656e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.451638000726234e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.5330086828034837e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -6.37673929304583e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.495456212476711e-06
sam_encoder.blocks.1.norm2.weight grad: 7.2114453359972686e-06
sam_encoder.blocks.1.norm2.bias grad: -6.451635272242129e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 8.679635357111692e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.412528376931732e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.1796772014349699e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.054790229522041e-06
sam_encoder.blocks.2.norm1.weight grad: -1.0825575373019092e-05
sam_encoder.blocks.2.norm1.bias grad: 4.32077740697423e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -9.028655767906457e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.1448770439747022e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.197667062224355e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.781200691970298e-06
sam_encoder.blocks.2.norm2.weight grad: -2.739016963460017e-06
sam_encoder.blocks.2.norm2.bias grad: -8.77253114595078e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.797659246629337e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.9270611296160496e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.0989984730258584e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.3272008295170963e-06
sam_encoder.blocks.3.norm1.weight grad: 5.045352281740634e-06
sam_encoder.blocks.3.norm1.bias grad: -4.395648716126743e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.944938048836775e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.4500327552013914e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.718266614465392e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.9684160836040974e-06
sam_encoder.blocks.3.norm2.weight grad: -8.7980370153673e-06
sam_encoder.blocks.3.norm2.bias grad: -6.957006007723976e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -7.51790639696992e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.693304511718452e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.974430910602678e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.4037804021427291e-06
sam_encoder.blocks.4.norm1.weight grad: 4.389333753351821e-06
sam_encoder.blocks.4.norm1.bias grad: -2.890601535909809e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.7710623246312025e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.624295175086445e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 6.287726250775449e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.239137302240124e-07
sam_encoder.blocks.4.norm2.weight grad: -4.214324235363165e-06
sam_encoder.blocks.4.norm2.bias grad: -1.5367233572760597e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.84375550513505e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.6664250779285794e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.4620707133872202e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.311417889837685e-07
sam_encoder.blocks.5.norm1.weight grad: 9.385887096868828e-06
sam_encoder.blocks.5.norm1.bias grad: -8.573995728511363e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.046776888979366e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.442550794512499e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -6.695322554151062e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.5980028820195002e-06
sam_encoder.blocks.5.norm2.weight grad: -8.350882126251236e-06
sam_encoder.blocks.5.norm2.bias grad: -2.6344812340539647e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.89528019897989e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.5538411162197008e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.282711193402065e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.011099801777164e-07
sam_encoder.blocks.6.norm1.weight grad: 3.9448200368497055e-06
sam_encoder.blocks.6.norm1.bias grad: -4.276153958926443e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.9123244783258997e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.7496467989985831e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 8.474020063431453e-08
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 6.610750915569952e-07
sam_encoder.blocks.6.norm2.weight grad: -1.678786134107213e-06
sam_encoder.blocks.6.norm2.bias grad: 5.535522973332263e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -4.17346700487542e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.0575073449435877e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -6.606216516047425e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.560106496384833e-08
sam_encoder.blocks.7.norm1.weight grad: 5.0356366045889445e-06
sam_encoder.blocks.7.norm1.bias grad: 2.0618826965801418e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 6.149700304547423e-09
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.180599238954528e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -8.499527552885411e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -8.619758773420472e-07
sam_encoder.blocks.7.norm2.weight grad: -4.365000677353237e-06
sam_encoder.blocks.7.norm2.bias grad: -1.1682386684697121e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -4.015757440356538e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.130353550455766e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.061390761009534e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 2.9637152465511463e-07
sam_encoder.blocks.8.norm1.weight grad: 6.1959372033015825e-06
sam_encoder.blocks.8.norm1.bias grad: 1.2915933211843367e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.500091901922133e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.807074906741036e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.4572209465768537e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.2199127468193183e-06
sam_encoder.blocks.8.norm2.weight grad: -2.540002469686442e-06
sam_encoder.blocks.8.norm2.bias grad: 8.344863431375416e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.545647930674022e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.104827333620051e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 7.623048077221029e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 7.649158533240552e-07
sam_encoder.blocks.9.norm1.weight grad: 7.149934390326962e-06
sam_encoder.blocks.9.norm1.bias grad: 4.020080837108253e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.724000973510556e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.059653413904016e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.1923677902814234e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.9204840100428555e-06
sam_encoder.blocks.9.norm2.weight grad: -3.385888248885749e-06
sam_encoder.blocks.9.norm2.bias grad: 2.1732387267547892e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.7376910313469125e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.1708324311475735e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 5.887284260097658e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.294463676364103e-07
sam_encoder.blocks.10.norm1.weight grad: 4.626345798897091e-06
sam_encoder.blocks.10.norm1.bias grad: -7.573741633848385e-09
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.804461021492898e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.487589654265321e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -4.355184728410677e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.6895161653328614e-08
sam_encoder.blocks.10.norm2.weight grad: -4.492128937272355e-06
sam_encoder.blocks.10.norm2.bias grad: -7.163446298363851e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.842087153316243e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.6207009139179718e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.602326982208524e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.2591259235250618e-07
sam_encoder.blocks.11.norm1.weight grad: 4.701269062934443e-06
sam_encoder.blocks.11.norm1.bias grad: 2.9470952540577855e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.67617724603042e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.0835020109188918e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 6.203803195603541e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.2926596443539893e-07
sam_encoder.blocks.11.norm2.weight grad: -3.2624934647174086e-06
sam_encoder.blocks.11.norm2.bias grad: -3.9146510033560844e-08
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.89204353975947e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -8.786778380454052e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.465654915795312e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 6.490759574262484e-08
sam_encoder.neck.conv1.trainable_scale grad: 1.6916010281420313e-06
sam_encoder.neck.conv1.trainable_shift grad: -2.7368841983843595e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.5455116226803511e-06
sam_encoder.neck.conv2.trainable_shift grad: -8.065645488386508e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 9.764754940988496e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 1.9205363059882075e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0036513556260615587
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0006453673122450709
mask_decoder.transformer.layers.0.norm3.weight grad: 3.734221900231205e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.575428854674101e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -1.2563014934130479e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -4.062847438035533e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -1.4240287100619753e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 4.60467663288e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -5.8589073887560517e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -3.976045627496205e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.1855901902890764e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -2.0668114302679896e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 4.0861195884644985e-06
mask_decoder.transformer.layers.1.norm4.bias grad: 1.9761875591939315e-05
mask_decoder.transformer.norm_final_attn.weight grad: -1.9828912627417594e-06
mask_decoder.transformer.norm_final_attn.bias grad: -8.474238484268426e-07
Text_Embedding_Affine.0.weight grad: -1.054735899314041e-11
Text_Embedding_Affine.0.bias grad: 1.951633299412947e-10
Text_Embedding_Affine.2.weight grad: -3.8947466779459816e-11
Text_Embedding_Affine.2.bias grad: -1.2995555152883753e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.3358754102910098e-08
Max value: 0.9996614456176758
Mean value: 0.09191077202558517

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.3358754102910098e-08
Max value: 0.9996614456176758
Mean value: 0.09191077202558517

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09007549285888672

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -11.131735801696777
Max value: -1.1920928244535389e-07
Mean value: -0.10978202521800995

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08539485931396484

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09007549285888672

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 56.624813079833984
Max value: 83.04613494873047
Mean value: 65.57809448242188

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.360671385621572e-08
Max value: 0.9995434880256653
Mean value: 0.09538742154836655

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.360671385621572e-08
Max value: 0.9995434880256653
Mean value: 0.09538742154836655

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.360671385621572e-08
Max value: 0.9995434880256653
Mean value: 0.09538742154836655

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -10.577593803405762
Max value: -1.1920928244535389e-07
Mean value: -0.11052025109529495

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8962634205818176
Max value: 1.9242087602615356
Mean value: 0.9995348453521729

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 56.624813079833984
Max value: 83.04613494873047
Mean value: 65.57809448242188

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.52958679199219
Max value: -65.52958679199219
Mean value: -65.52958679199219
sam_encoder.pos_embed grad: 3.1669902256226123e-09
sam_encoder.blocks.0.norm1.weight grad: -1.3763397873844951e-05
sam_encoder.blocks.0.norm1.bias grad: -2.970490413645166e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.0405072998764808e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.469764979196043e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.4037007076694863e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.6265405520243803e-06
sam_encoder.blocks.0.norm2.weight grad: 3.510994429234415e-05
sam_encoder.blocks.0.norm2.bias grad: -1.7494445273769088e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.1455168532847892e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.2745125559376902e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 8.22829042590456e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.447978881216841e-06
sam_encoder.blocks.1.norm1.weight grad: 3.4809518183465116e-06
sam_encoder.blocks.1.norm1.bias grad: 1.632620842428878e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.609783667954616e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.468509137543151e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.4076979217352346e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.060977971676039e-06
sam_encoder.blocks.1.norm2.weight grad: -3.578331416065339e-06
sam_encoder.blocks.1.norm2.bias grad: -6.142495749372756e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -5.391088052419946e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.8847367755370215e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.3096305337967351e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.33624950851663e-06
sam_encoder.blocks.2.norm1.weight grad: -7.790262316120788e-06
sam_encoder.blocks.2.norm1.bias grad: 7.513129730796209e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -8.856540262058843e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.0025772755616345e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.108097634045407e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.254668394627515e-06
sam_encoder.blocks.2.norm2.weight grad: -6.94499885867117e-06
sam_encoder.blocks.2.norm2.bias grad: -1.7060350501196808e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.368749720626511e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.056361043083598e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.017179996182676e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.9970877929154085e-06
sam_encoder.blocks.3.norm1.weight grad: 5.224774213274941e-06
sam_encoder.blocks.3.norm1.bias grad: -2.4680748538230546e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.7101703519983857e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.470378141581023e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.9004486350459047e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.7155517727806e-06
sam_encoder.blocks.3.norm2.weight grad: -7.730965080554597e-06
sam_encoder.blocks.3.norm2.bias grad: -6.865807790745748e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -6.4273926909663714e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.7186753211717587e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -9.879049684968777e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -6.164790420370991e-07
sam_encoder.blocks.4.norm1.weight grad: 1.0713114534155466e-05
sam_encoder.blocks.4.norm1.bias grad: -5.482699634740129e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 5.231040631770156e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.3001020988667733e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.0244800680302433e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.6107053113501024e-07
sam_encoder.blocks.4.norm2.weight grad: -1.7685717921267496e-06
sam_encoder.blocks.4.norm2.bias grad: 4.1123516325569653e-07
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.0242694012704305e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.2025011528749019e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -6.999370043558883e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.056151136135668e-08
sam_encoder.blocks.5.norm1.weight grad: 6.549797944899183e-06
sam_encoder.blocks.5.norm1.bias grad: -8.865421477821656e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.8998519964225125e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.6295455174695235e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.069473111987463e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.013925495703006e-06
sam_encoder.blocks.5.norm2.weight grad: -2.9590580652438803e-06
sam_encoder.blocks.5.norm2.bias grad: 1.8553553218225716e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.1262828795443056e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.083774805010762e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.0774899692478357e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 9.073041837837081e-07
sam_encoder.blocks.6.norm1.weight grad: 1.4283826885730377e-06
sam_encoder.blocks.6.norm1.bias grad: -3.230041784263449e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.982775529540959e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.7181589555548271e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -7.638902275175496e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -9.728344139148248e-07
sam_encoder.blocks.6.norm2.weight grad: -3.3004232591338223e-06
sam_encoder.blocks.6.norm2.bias grad: -4.816922114514455e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.898916020261822e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.8133372350348509e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.6210907460845192e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.699861051449261e-07
sam_encoder.blocks.7.norm1.weight grad: -1.3385269994614646e-06
sam_encoder.blocks.7.norm1.bias grad: -4.4999887904850766e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.5243429061229108e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -5.182338327358593e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.450638137612259e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 7.1536089762958e-07
sam_encoder.blocks.7.norm2.weight grad: -1.1846647112179198e-06
sam_encoder.blocks.7.norm2.bias grad: 1.3111161933920812e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.9853941921610385e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.2285694310776307e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 7.459156847744453e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 9.523141102363297e-07
sam_encoder.blocks.8.norm1.weight grad: 2.7372575459594373e-06
sam_encoder.blocks.8.norm1.bias grad: -9.481018423684873e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 5.356440851755906e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.8620393095479812e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.393519025645219e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.2107333279564045e-06
sam_encoder.blocks.8.norm2.weight grad: -2.55286977335345e-06
sam_encoder.blocks.8.norm2.bias grad: 1.712078642412962e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.7847471503482666e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.4463333829771727e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -4.9754657993617e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.888743265179073e-07
sam_encoder.blocks.9.norm1.weight grad: -3.4529077197476e-07
sam_encoder.blocks.9.norm1.bias grad: -4.78229310374445e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.0499438758415636e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.2809875897801248e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -6.971872608119156e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -7.477679986322983e-08
sam_encoder.blocks.9.norm2.weight grad: -4.689028628490632e-06
sam_encoder.blocks.9.norm2.bias grad: 1.3224766917119268e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.619526746158954e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.885483354475582e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -9.618119065635256e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.9766903847084905e-07
sam_encoder.blocks.10.norm1.weight grad: -2.3813470306777162e-06
sam_encoder.blocks.10.norm1.bias grad: -8.745006994104187e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.515069127184688e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.2029488516418496e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.41807663567306e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -7.998268074516091e-07
sam_encoder.blocks.10.norm2.weight grad: -7.822724001016468e-06
sam_encoder.blocks.10.norm2.bias grad: 2.8973903454243555e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.5146648517402355e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.376916199864354e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.2468585453007108e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.8601797080464166e-07
sam_encoder.blocks.11.norm1.weight grad: -1.2767733096552547e-05
sam_encoder.blocks.11.norm1.bias grad: -2.0086660867946193e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.3277634707264951e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.9236367165831325e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.5022732213765266e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -7.401001766993431e-07
sam_encoder.blocks.11.norm2.weight grad: -8.157407137332484e-06
sam_encoder.blocks.11.norm2.bias grad: -9.196486985274532e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.8754196793888696e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.6571923424635315e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.5079157833497447e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.8623556741204084e-07
sam_encoder.neck.conv1.trainable_scale grad: 6.305162969511002e-07
sam_encoder.neck.conv1.trainable_shift grad: 7.222346539492719e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.3162016330170445e-06
sam_encoder.neck.conv2.trainable_shift grad: -8.353251359949354e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00011615102994255722
mask_decoder.transformer.layers.0.norm1.bias grad: 1.5368514141300693e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0030161896720528603
mask_decoder.transformer.layers.0.norm2.bias grad: -4.15601534768939e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 5.2100163884460926e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 5.072350177215412e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00011862095561809838
mask_decoder.transformer.layers.0.norm4.bias grad: 1.01327859738376e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -3.834876679320587e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -1.983597485377686e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00012454444367904216
mask_decoder.transformer.layers.1.norm2.bias grad: 2.963317820103839e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -2.4348264560103416e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -9.159007277048659e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 4.206816083751619e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00017736181325744838
mask_decoder.transformer.norm_final_attn.weight grad: -3.1276708796212915e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.3346591003937647e-05
Text_Embedding_Affine.0.weight grad: 5.348196928725568e-13
Text_Embedding_Affine.0.bias grad: -1.6113776979409522e-12
Text_Embedding_Affine.2.weight grad: 3.761949432523615e-11
Text_Embedding_Affine.2.bias grad: -6.169019798107911e-06
Epoch 21 finished with average loss: -58.8123
Epoch 22/39
----------
Epoch 22:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 22:   0%|          | 0/3 [00:00<?, ?it/s, loss=-57.3]Epoch 22:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.07it/s, loss=-57.3]Epoch 22:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.07it/s, loss=-56.7]Epoch 22:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-56.7]Epoch 22:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-55.8]Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.31it/s, loss=-55.8]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.653132905709569e-12
Max value: 0.9999009370803833
Mean value: 0.07802200317382812

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.653132905709569e-12
Max value: 0.9999009370803833
Mean value: 0.07802200317382812

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08306455612182617

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12710091471672058

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06774187088012695

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08306455612182617

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 41.394065856933594
Max value: 91.62101745605469
Mean value: 57.31208038330078

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.653132905709569e-12
Max value: 0.9999009370803833
Mean value: 0.07802200317382812

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.653132905709569e-12
Max value: 0.9999009370803833
Mean value: 0.07802200317382812

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.653132905709569e-12
Max value: 0.9999009370803833
Mean value: 0.07802200317382812

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12710091471672058

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 41.394065856933594
Max value: 91.62101745605469
Mean value: 57.31208038330078

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.31311798095703
Max value: -57.31311798095703
Mean value: -57.31311798095703
sam_encoder.pos_embed grad: -3.8853609218847396e-09
sam_encoder.blocks.0.norm1.weight grad: 5.696767402696423e-05
sam_encoder.blocks.0.norm1.bias grad: 3.5504039260558784e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.1145293683512136e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -7.748000712126668e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.7758766261977144e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.2927711142983753e-06
sam_encoder.blocks.0.norm2.weight grad: -1.0510774700378533e-05
sam_encoder.blocks.0.norm2.bias grad: -2.6924767553282436e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -6.7061423578707036e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.5300460631806345e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.661772512306925e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.391755913322413e-07
sam_encoder.blocks.1.norm1.weight grad: 9.161827620118856e-06
sam_encoder.blocks.1.norm1.bias grad: 4.65919720227248e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.3864951142750215e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.6350244891327748e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -6.058814392417844e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.315458575845696e-06
sam_encoder.blocks.1.norm2.weight grad: 2.1771935280412436e-05
sam_encoder.blocks.1.norm2.bias grad: 6.87690203449165e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 8.056439583015162e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.6303469010381377e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -7.225104127428494e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -9.624905032978859e-07
sam_encoder.blocks.2.norm1.weight grad: -1.3506658433470875e-05
sam_encoder.blocks.2.norm1.bias grad: -1.9086473912466317e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -7.5899724834016524e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.26912720791006e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.0048059822293e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.2158087631396484e-06
sam_encoder.blocks.2.norm2.weight grad: -9.93958929029759e-06
sam_encoder.blocks.2.norm2.bias grad: 2.6025859369838145e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.034420377749484e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.1090621683251811e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.8114579890825553e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.5093835372681497e-06
sam_encoder.blocks.3.norm1.weight grad: -4.1543144106981345e-06
sam_encoder.blocks.3.norm1.bias grad: -3.4459135349607095e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.3676187740638852e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -7.609312433487503e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.652776290939073e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.5512058553213137e-06
sam_encoder.blocks.3.norm2.weight grad: 9.826439963944722e-06
sam_encoder.blocks.3.norm2.bias grad: 8.627097827229591e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.276748874573968e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.5938926430389984e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.9118238014925737e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.5891482689767145e-06
sam_encoder.blocks.4.norm1.weight grad: -4.331786840339191e-06
sam_encoder.blocks.4.norm1.bias grad: -4.5120822278477135e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -6.021666195010766e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.3078048343450064e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.1418260328355245e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.897586909966776e-06
sam_encoder.blocks.4.norm2.weight grad: -1.9275077647762373e-05
sam_encoder.blocks.4.norm2.bias grad: -1.3720421520702075e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.2600942682183813e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.724352947960142e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.4961517485498916e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.0795520211104304e-07
sam_encoder.blocks.5.norm1.weight grad: -7.480993190256413e-06
sam_encoder.blocks.5.norm1.bias grad: -2.633083568071015e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.0731684596976265e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -4.573133992380463e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -6.552779154844757e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.6774184789246647e-06
sam_encoder.blocks.5.norm2.weight grad: 4.459650426724693e-07
sam_encoder.blocks.5.norm2.bias grad: -6.738471711287275e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.95013717529946e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.4157699297356885e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 7.437540716637159e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.011535103629285e-07
sam_encoder.blocks.6.norm1.weight grad: 5.6073076848406345e-06
sam_encoder.blocks.6.norm1.bias grad: 8.138182238326408e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.441744754833053e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.0103719577946322e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.199508799094474e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.2294838143134257e-06
sam_encoder.blocks.6.norm2.weight grad: -2.068418780254433e-06
sam_encoder.blocks.6.norm2.bias grad: -1.8321823063160991e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.494947127866908e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.473581043384911e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.5635603176633595e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.0259493592457147e-06
sam_encoder.blocks.7.norm1.weight grad: 9.309596862294711e-06
sam_encoder.blocks.7.norm1.bias grad: -5.726072771494728e-08
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 7.098363766999682e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.7720740288496017e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.9092728911782615e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 4.076559889654163e-08
sam_encoder.blocks.7.norm2.weight grad: 6.688123903586529e-07
sam_encoder.blocks.7.norm2.bias grad: -1.7911537497639074e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.5471536016775644e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.011916424431547e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.5400055417558178e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.6717285689082928e-06
sam_encoder.blocks.8.norm1.weight grad: 9.983691597881261e-06
sam_encoder.blocks.8.norm1.bias grad: -1.2717919162241742e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.577326869068202e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.0110870789503679e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 5.139382665220182e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 4.528464160102885e-06
sam_encoder.blocks.8.norm2.weight grad: 4.175547474005725e-06
sam_encoder.blocks.8.norm2.bias grad: -7.441046534495399e-08
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 5.337534730642801e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.055906290683197e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 9.587317890691338e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.367235189623898e-07
sam_encoder.blocks.9.norm1.weight grad: 1.774349016159249e-06
sam_encoder.blocks.9.norm1.bias grad: -1.7178301447984268e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.710963599383831e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.4675639451743336e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 7.706931910433923e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.1933154553389613e-07
sam_encoder.blocks.9.norm2.weight grad: 5.599245469056768e-06
sam_encoder.blocks.9.norm2.bias grad: -4.3339287003618665e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.440291377250105e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.5478007046331186e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 4.6143064480475005e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.94932487274491e-07
sam_encoder.blocks.10.norm1.weight grad: 7.447868483723141e-06
sam_encoder.blocks.10.norm1.bias grad: 4.141422138559392e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 5.946249075350352e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.1685034425900085e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.7814579678088194e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.7549377844261471e-06
sam_encoder.blocks.10.norm2.weight grad: 7.212818218249595e-06
sam_encoder.blocks.10.norm2.bias grad: 8.335172196893836e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.318655217299238e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.4251494323834777e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.722101726249093e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.508728300654184e-07
sam_encoder.blocks.11.norm1.weight grad: 1.9152577806380577e-05
sam_encoder.blocks.11.norm1.bias grad: 1.6581150248384802e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.0614761549732066e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 4.2629511654013186e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 8.157400657182734e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.618385449044581e-07
sam_encoder.blocks.11.norm2.weight grad: 5.629785846394952e-06
sam_encoder.blocks.11.norm2.bias grad: 2.0797895103896735e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.540844207032933e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.4437355275731534e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.203413830808131e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.938652071155957e-08
sam_encoder.neck.conv1.trainable_scale grad: 7.628841558471322e-08
sam_encoder.neck.conv1.trainable_shift grad: -1.0244407349091489e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.536232048238162e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.9759358110604808e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -6.953260890441015e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -8.269453246612102e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004113404080271721
mask_decoder.transformer.layers.0.norm2.bias grad: -9.986718941945583e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00011865397391375154
mask_decoder.transformer.layers.0.norm3.bias grad: -7.844223728170618e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00011449340672697872
mask_decoder.transformer.layers.0.norm4.bias grad: -1.2531219908851199e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 3.4009176488325465e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 3.4940890145662706e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0001714816316962242
mask_decoder.transformer.layers.1.norm2.bias grad: -3.164317604387179e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 9.364955985802226e-06
mask_decoder.transformer.layers.1.norm3.bias grad: -5.562206752074417e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -5.371633596951142e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0002092642680509016
mask_decoder.transformer.norm_final_attn.weight grad: 2.723542593230377e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.731719203235116e-05
Text_Embedding_Affine.0.weight grad: 4.127460092456792e-12
Text_Embedding_Affine.0.bias grad: 2.593785464188869e-10
Text_Embedding_Affine.2.weight grad: 3.717960314619795e-11
Text_Embedding_Affine.2.bias grad: -5.772853910457343e-07

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.319636149827886e-10
Max value: 0.9990473389625549
Mean value: 0.094681516289711

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.319636149827886e-10
Max value: 0.9990473389625549
Mean value: 0.094681516289711

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09118986129760742

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -12.288384437561035
Max value: -1.1920928244535389e-07
Mean value: -0.13398654758930206

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08023357391357422

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09118986129760742

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 40.51476287841797
Max value: 73.60957336425781
Mean value: 56.164581298828125

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.5087610594786156e-10
Max value: 0.999010443687439
Mean value: 0.0963020920753479

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.5087610594786156e-10
Max value: 0.999010443687439
Mean value: 0.0963020920753479

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.5087610594786156e-10
Max value: 0.999010443687439
Mean value: 0.0963020920753479

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -12.237613677978516
Max value: -1.1920928244535389e-07
Mean value: -0.1339385211467743

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9351901412010193
Max value: 1.250087022781372
Mean value: 1.00010085105896

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 40.51476287841797
Max value: 73.60957336425781
Mean value: 56.164581298828125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.15961456298828
Max value: -56.15961456298828
Mean value: -56.15961456298828
sam_encoder.pos_embed grad: -4.5277674942667545e-09
sam_encoder.blocks.0.norm1.weight grad: 4.426013674674323e-06
sam_encoder.blocks.0.norm1.bias grad: -4.572276884573512e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 5.402426722866949e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.7164438759209588e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.332673375349259e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 8.990658528773565e-08
sam_encoder.blocks.0.norm2.weight grad: -1.6668212992954068e-05
sam_encoder.blocks.0.norm2.bias grad: 1.0554684195085429e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.9472909116302617e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -9.936151172951213e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -9.845032764133066e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 6.432986765503301e-07
sam_encoder.blocks.1.norm1.weight grad: -2.6219390747428406e-06
sam_encoder.blocks.1.norm1.bias grad: 8.705535947228782e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.082972853007959e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.136801413143985e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -8.115308446576819e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.1367347876075655e-06
sam_encoder.blocks.1.norm2.weight grad: 2.4828386813169345e-06
sam_encoder.blocks.1.norm2.bias grad: -3.5166635825589765e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -9.419823072676081e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -7.599318223583396e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -9.142832823272329e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.170057756411552e-07
sam_encoder.blocks.2.norm1.weight grad: 1.3536044207285158e-05
sam_encoder.blocks.2.norm1.bias grad: 1.0683470463845879e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.3090636861743405e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 5.751413709731423e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.8724090296018403e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.0537054322412587e-06
sam_encoder.blocks.2.norm2.weight grad: -1.781534774636384e-05
sam_encoder.blocks.2.norm2.bias grad: -1.4355372286445345e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.1612212801992428e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.4012130122864619e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.1124581760668661e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -4.462808192329248e-06
sam_encoder.blocks.3.norm1.weight grad: 2.8333149657555623e-06
sam_encoder.blocks.3.norm1.bias grad: -7.063431439746637e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 3.702016329043545e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.8848051531203964e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 6.492869033536408e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.0300605026714038e-06
sam_encoder.blocks.3.norm2.weight grad: -3.2637594813422766e-06
sam_encoder.blocks.3.norm2.bias grad: -2.294781370437704e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -6.329655207082396e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -4.979322511644568e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 4.392604751046747e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.6916437743930146e-06
sam_encoder.blocks.4.norm1.weight grad: 3.875811671605334e-05
sam_encoder.blocks.4.norm1.bias grad: -1.8334250853513367e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.729378527670633e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 5.6201088227680884e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 5.183079338166863e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 6.665314685960766e-06
sam_encoder.blocks.4.norm2.weight grad: -3.0616381536674453e-06
sam_encoder.blocks.4.norm2.bias grad: 4.027297109132633e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.825314590561902e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.573166855450836e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.7176134861074388e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 8.571975627091888e-07
sam_encoder.blocks.5.norm1.weight grad: 1.5090131455508526e-05
sam_encoder.blocks.5.norm1.bias grad: -2.301256245118566e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 8.438240001851227e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.04825141231413e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.1059069038310554e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 8.174489266821183e-06
sam_encoder.blocks.5.norm2.weight grad: 7.096015451679705e-06
sam_encoder.blocks.5.norm2.bias grad: 4.4741991587216035e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.226504759368254e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.039651917584706e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.287177605670877e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.10183100332506e-06
sam_encoder.blocks.6.norm1.weight grad: 1.4055253814149182e-05
sam_encoder.blocks.6.norm1.bias grad: -2.372126346017467e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 6.550265425175894e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.672000391612528e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.331838449114002e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 9.211762517224997e-07
sam_encoder.blocks.6.norm2.weight grad: -4.311473730922444e-06
sam_encoder.blocks.6.norm2.bias grad: -6.526855713673285e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -8.243445336120203e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.07468303112546e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -9.086995760299033e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.8322719458628853e-07
sam_encoder.blocks.7.norm1.weight grad: 6.072186806704849e-07
sam_encoder.blocks.7.norm1.bias grad: -5.936949492024723e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.5997309219528688e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.645703150643385e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -7.137235797927133e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.086667336698156e-06
sam_encoder.blocks.7.norm2.weight grad: -2.4961473172879778e-06
sam_encoder.blocks.7.norm2.bias grad: 8.416582204517908e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -6.8904514591849875e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.6540529890771722e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.9700469238159712e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 9.909998652801733e-07
sam_encoder.blocks.8.norm1.weight grad: 1.4382882909558248e-05
sam_encoder.blocks.8.norm1.bias grad: -3.0919825348973973e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.6753894669818692e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 5.990968020341825e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.610965000509168e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 5.241082590146107e-07
sam_encoder.blocks.8.norm2.weight grad: 1.1833132695926452e-08
sam_encoder.blocks.8.norm2.bias grad: 4.793744665221311e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.906914000457618e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.138202944479417e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.309683623025194e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.4149493381410139e-06
sam_encoder.blocks.9.norm1.weight grad: 9.617496289138217e-06
sam_encoder.blocks.9.norm1.bias grad: -1.3782073438051157e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 6.231687621038873e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.6144410608376347e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 8.268035571745713e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.217095698142657e-06
sam_encoder.blocks.9.norm2.weight grad: 4.262752554495819e-06
sam_encoder.blocks.9.norm2.bias grad: 3.598067223720136e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.6631553257393534e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.2887184059072752e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 4.5337983465287834e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.628203901622328e-06
sam_encoder.blocks.10.norm1.weight grad: 6.068074981158134e-06
sam_encoder.blocks.10.norm1.bias grad: 2.5838880901574157e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.4632416827662382e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 7.414539027195133e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.2011242915832554e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.2555393996981365e-08
sam_encoder.blocks.10.norm2.weight grad: 5.857932592334691e-07
sam_encoder.blocks.10.norm2.bias grad: 5.077275091025513e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 6.023412879585521e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 5.27262045579846e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 3.7393110687844455e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.4854206256131874e-06
sam_encoder.blocks.11.norm1.weight grad: -2.568619493104052e-06
sam_encoder.blocks.11.norm1.bias grad: 4.476451067603193e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.056528723594965e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.2991774838155834e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 4.843121246267401e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.935521704079292e-07
sam_encoder.blocks.11.norm2.weight grad: 1.1111800631624646e-05
sam_encoder.blocks.11.norm2.bias grad: -2.1825080693815835e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.8441661419929005e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.934505917233764e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 4.379137862997595e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.0818820303247776e-06
sam_encoder.neck.conv1.trainable_scale grad: 1.7783349903766066e-06
sam_encoder.neck.conv1.trainable_shift grad: 6.620935164391994e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.8542035579448566e-06
sam_encoder.neck.conv2.trainable_shift grad: -9.614531882107258e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00019484441145323217
mask_decoder.transformer.layers.0.norm1.bias grad: 9.857096301857382e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0004552991595119238
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0005513642681762576
mask_decoder.transformer.layers.0.norm3.weight grad: -3.566323721315712e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 4.912356598651968e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00011348197585903108
mask_decoder.transformer.layers.0.norm4.bias grad: 1.5871075447648764e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 3.4240235891047632e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 1.0327421477995813e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 9.486946510151029e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 3.1418519938597456e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -7.037318027869333e-06
mask_decoder.transformer.layers.1.norm3.bias grad: -2.4042378754529636e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 5.863299156771973e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00016665898147039115
mask_decoder.transformer.norm_final_attn.weight grad: -1.438206595594238e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.4942088455427438e-05
Text_Embedding_Affine.0.weight grad: 4.0527331490736174e-11
Text_Embedding_Affine.0.bias grad: 1.3822322175727209e-09
Text_Embedding_Affine.2.weight grad: -7.095553311575742e-12
Text_Embedding_Affine.2.bias grad: -5.017020157538354e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.976508621764048e-14
Max value: 0.99994957447052
Mean value: 0.0690477192401886

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.976508621764048e-14
Max value: 0.99994957447052
Mean value: 0.0690477192401886

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07120513916015625

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11439720541238785

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.058104515075683594

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07120513916015625

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 48.9199333190918
Max value: 57.98128128051758
Mean value: 54.04587173461914

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.661380855759811e-14
Max value: 0.9999505281448364
Mean value: 0.07230270653963089

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.661380855759811e-14
Max value: 0.9999505281448364
Mean value: 0.07230270653963089

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.661380855759811e-14
Max value: 0.9999505281448364
Mean value: 0.07230270653963089

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11441498249769211

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8671888709068298
Max value: 1.5741273164749146
Mean value: 1.0002305507659912

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 48.9199333190918
Max value: 57.98128128051758
Mean value: 54.04587173461914

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -54.05126190185547
Max value: -54.05126190185547
Mean value: -54.05126190185547
sam_encoder.pos_embed grad: 2.1925625759422473e-09
sam_encoder.blocks.0.norm1.weight grad: 3.946419383282773e-05
sam_encoder.blocks.0.norm1.bias grad: 9.740079258335754e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -7.723579074081499e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 8.458023614821286e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.1667079888866283e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.000358219651389e-06
sam_encoder.blocks.0.norm2.weight grad: 9.790567855816334e-05
sam_encoder.blocks.0.norm2.bias grad: -8.878039079718292e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.843684342224151e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 9.22502476896625e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.4881632523611188e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.567571522784419e-06
sam_encoder.blocks.1.norm1.weight grad: 2.0009563741041347e-05
sam_encoder.blocks.1.norm1.bias grad: -2.964723307741224e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.806917331734439e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.2767986845574342e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.535741365747526e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.023022029286949e-06
sam_encoder.blocks.1.norm2.weight grad: -6.152620699140243e-06
sam_encoder.blocks.1.norm2.bias grad: 5.5319114835583605e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -8.030767276068218e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -6.17378361766896e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.585575930424966e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.5516557090886636e-06
sam_encoder.blocks.2.norm1.weight grad: -8.700332728039939e-06
sam_encoder.blocks.2.norm1.bias grad: 8.037128282012418e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -6.736715931765502e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.3795312245056266e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.151670731924241e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.788226189906709e-06
sam_encoder.blocks.2.norm2.weight grad: -2.387082167842891e-05
sam_encoder.blocks.2.norm2.bias grad: -6.653951913904166e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.3631094589072745e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.6506722886333591e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.802424079272896e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.766163558793778e-07
sam_encoder.blocks.3.norm1.weight grad: -1.4305131116998382e-05
sam_encoder.blocks.3.norm1.bias grad: 8.377861377084628e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.551385321363341e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.5506091080605984e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -6.545197720697615e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.7035998755309265e-06
sam_encoder.blocks.3.norm2.weight grad: -6.600903361686505e-06
sam_encoder.blocks.3.norm2.bias grad: -8.791806749286479e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -4.199487193545792e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -6.079475269871182e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.6070366604690207e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.7380186818627408e-06
sam_encoder.blocks.4.norm1.weight grad: 4.753929715661798e-06
sam_encoder.blocks.4.norm1.bias grad: 8.152062946464866e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.1152168326589162e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.5612866945957649e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.9740677998925094e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.4582494663482066e-06
sam_encoder.blocks.4.norm2.weight grad: -1.81537980097346e-05
sam_encoder.blocks.4.norm2.bias grad: -7.97412940301001e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.6290943676722236e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.960351700196043e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.251365342293866e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.1200019091338618e-06
sam_encoder.blocks.5.norm1.weight grad: 3.087508503085701e-06
sam_encoder.blocks.5.norm1.bias grad: -6.878732165205292e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.2023493784217862e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.6706325115810614e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.932026629627217e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -3.3607393561396748e-06
sam_encoder.blocks.5.norm2.weight grad: -2.768682634268771e-06
sam_encoder.blocks.5.norm2.bias grad: -6.356212452374166e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.5041495089462842e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -6.425638048312976e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.0084413588629104e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -9.787868293642532e-08
sam_encoder.blocks.6.norm1.weight grad: -2.6381540010333993e-06
sam_encoder.blocks.6.norm1.bias grad: -4.2822165369216236e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 8.266867723705218e-08
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -6.645012717854115e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.7732232865673723e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -6.144952635622758e-07
sam_encoder.blocks.6.norm2.weight grad: 4.290519427740946e-06
sam_encoder.blocks.6.norm2.bias grad: 2.830491212080233e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.090688949214382e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.528294764189923e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 7.061534574859252e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.29397528780828e-06
sam_encoder.blocks.7.norm1.weight grad: 5.273486749501899e-06
sam_encoder.blocks.7.norm1.bias grad: 1.6922807617447688e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.7160386909818044e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 6.111250741014373e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -8.450303425888706e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -8.746912385504402e-07
sam_encoder.blocks.7.norm2.weight grad: -8.907272786018439e-08
sam_encoder.blocks.7.norm2.bias grad: 7.436760824930388e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.941443542818888e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.3639754920832274e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.9585358757012727e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 3.527956664584053e-07
sam_encoder.blocks.8.norm1.weight grad: 8.128381523420103e-06
sam_encoder.blocks.8.norm1.bias grad: -1.6814650507512852e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.570382877020165e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.3216726983955596e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.5210861192826997e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.7028540898754727e-06
sam_encoder.blocks.8.norm2.weight grad: -7.6128626460558735e-06
sam_encoder.blocks.8.norm2.bias grad: -3.1231170396495145e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -7.005806310189655e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -5.13279474034789e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.4684733236645116e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.5325434787882841e-06
sam_encoder.blocks.9.norm1.weight grad: -2.559770564403152e-06
sam_encoder.blocks.9.norm1.bias grad: 2.957677338599751e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.8886003090301529e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.1518112614794518e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.1234944850002648e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.5313189578591846e-06
sam_encoder.blocks.9.norm2.weight grad: -4.19364823756041e-06
sam_encoder.blocks.9.norm2.bias grad: -1.6484759726154152e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.069842366836383e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.754976210577297e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.4245118791222922e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.2983451231084473e-07
sam_encoder.blocks.10.norm1.weight grad: -3.4571729656818206e-07
sam_encoder.blocks.10.norm1.bias grad: 1.5894997318355308e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.6419559162604855e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 3.7891899751230085e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.6401105540353456e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.9159192277129478e-07
sam_encoder.blocks.10.norm2.weight grad: -7.336534963542363e-06
sam_encoder.blocks.10.norm2.bias grad: -3.903160177287646e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.3247010833292734e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.9454963623720687e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -8.006711027519486e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.5264855569039355e-07
sam_encoder.blocks.11.norm1.weight grad: 2.102512553392444e-06
sam_encoder.blocks.11.norm1.bias grad: -1.2506216080510058e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.5196411570505006e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.0601089428519117e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.225777623403701e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -8.508470727974782e-08
sam_encoder.blocks.11.norm2.weight grad: -1.1913240086869337e-05
sam_encoder.blocks.11.norm2.bias grad: -2.4513919925084338e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.9081556931487285e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.7875103114638478e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.8776451443945916e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.6427043192379642e-07
sam_encoder.neck.conv1.trainable_scale grad: 2.1775849745608866e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.8788022973458283e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.1636111594270915e-06
sam_encoder.neck.conv2.trainable_shift grad: 1.9150540538248606e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00012513302499428391
mask_decoder.transformer.layers.0.norm1.bias grad: -3.5907214623875916e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.003661251161247492
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0005237029399722815
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00012394848454277962
mask_decoder.transformer.layers.0.norm3.bias grad: 3.89340020774398e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 1.6846941434778273e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 6.24768654233776e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 7.269264642673079e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 5.328911356627941e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -2.0486837456701323e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -8.796079782769084e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 2.939186197181698e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.994702688534744e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 2.7744150429498404e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 3.3385524147888646e-05
mask_decoder.transformer.norm_final_attn.weight grad: 4.904622073809151e-06
mask_decoder.transformer.norm_final_attn.bias grad: 5.776447551397723e-07
Text_Embedding_Affine.0.weight grad: 2.038175184182478e-11
Text_Embedding_Affine.0.bias grad: 6.155226328630192e-10
Text_Embedding_Affine.2.weight grad: 4.318204474551557e-11
Text_Embedding_Affine.2.bias grad: -1.5909499779809266e-06
Epoch 22 finished with average loss: -55.8413
Epoch 23/39
----------
Epoch 23:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 23:   0%|          | 0/3 [00:00<?, ?it/s, loss=-56.9]Epoch 23:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.18it/s, loss=-56.9]Epoch 23:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.18it/s, loss=-56.7]Epoch 23:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.76it/s, loss=-56.7]Epoch 23:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.76it/s, loss=-56.2]Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.42it/s, loss=-56.2]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.501029796334777e-14
Max value: 0.9996238946914673
Mean value: 0.08730675280094147

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.501029796334777e-14
Max value: 0.9996238946914673
Mean value: 0.08730675280094147

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08212566375732422

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12635083496570587

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07636308670043945

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08212566375732422

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 37.56151580810547
Max value: 72.33861541748047
Mean value: 56.932945251464844

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.501029796334777e-14
Max value: 0.9996238946914673
Mean value: 0.08730675280094147

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.501029796334777e-14
Max value: 0.9996238946914673
Mean value: 0.08730675280094147

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.501029796334777e-14
Max value: 0.9996238946914673
Mean value: 0.08730675280094147

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12635083496570587

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 37.56151580810547
Max value: 72.33861541748047
Mean value: 56.932945251464844

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.93415832519531
Max value: -56.93415832519531
Mean value: -56.93415832519531
sam_encoder.pos_embed grad: 7.87701814886077e-09
sam_encoder.blocks.0.norm1.weight grad: 4.087379238626454e-06
sam_encoder.blocks.0.norm1.bias grad: 4.265707320882939e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.245445779815782e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.7300916372041684e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.7877380287245614e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.1418817393860081e-06
sam_encoder.blocks.0.norm2.weight grad: 4.008410178357735e-05
sam_encoder.blocks.0.norm2.bias grad: -3.6079651181353256e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.634091131563764e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 8.073635399341583e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 5.852348294865806e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 6.492429292848101e-06
sam_encoder.blocks.1.norm1.weight grad: 1.6260426491498947e-05
sam_encoder.blocks.1.norm1.bias grad: 4.759034709422849e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.689315460382204e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 8.261918083007913e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.003274292088463e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.1154221510878415e-06
sam_encoder.blocks.1.norm2.weight grad: -1.1574580639717169e-05
sam_encoder.blocks.1.norm2.bias grad: 3.313576598884538e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -2.812270395224914e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.2888740457128733e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -5.601910288532963e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.529647306597326e-07
sam_encoder.blocks.2.norm1.weight grad: -9.359817340737209e-06
sam_encoder.blocks.2.norm1.bias grad: -4.5197994040790945e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -6.816880159021821e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.0968369679176249e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.538730991043849e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.098120371054392e-06
sam_encoder.blocks.2.norm2.weight grad: -7.160638688219478e-06
sam_encoder.blocks.2.norm2.bias grad: -9.1036254161736e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.100784619571641e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.078033614656306e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.591191777260974e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.014066459807509e-07
sam_encoder.blocks.3.norm1.weight grad: -2.2780277504352853e-06
sam_encoder.blocks.3.norm1.bias grad: -1.0076777101630796e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.086461558472365e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -8.908584163691557e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.04782792631886e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.5862398110330105e-06
sam_encoder.blocks.3.norm2.weight grad: -2.2040055682737147e-06
sam_encoder.blocks.3.norm2.bias grad: 9.351186236017384e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -4.371241175249452e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -9.324654683950939e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.5957232335495064e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -7.58974110226518e-08
sam_encoder.blocks.4.norm1.weight grad: -9.918892828864045e-06
sam_encoder.blocks.4.norm1.bias grad: 1.2904008144687396e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -8.680011887918226e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.7353030443700845e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.510344297159463e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -4.249080575391417e-06
sam_encoder.blocks.4.norm2.weight grad: -1.1364820238668472e-05
sam_encoder.blocks.4.norm2.bias grad: 1.2375162441458087e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -9.938587027136236e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.5388100059208227e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -5.114819032314699e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.279643013025634e-06
sam_encoder.blocks.5.norm1.weight grad: 7.016239464974205e-07
sam_encoder.blocks.5.norm1.bias grad: 3.7373381474026246e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.7503460842126515e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.2438109681388596e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -6.514000006063725e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -4.858456122747157e-06
sam_encoder.blocks.5.norm2.weight grad: -8.837369932734873e-06
sam_encoder.blocks.5.norm2.bias grad: -2.9225964226498036e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -7.534308679169044e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.7412929739512037e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.973979806280113e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.4768487466863007e-07
sam_encoder.blocks.6.norm1.weight grad: 5.814062660647323e-06
sam_encoder.blocks.6.norm1.bias grad: -4.14079477195628e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.636393325403333e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.837311967596179e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.3304620551934931e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.6541216609766707e-06
sam_encoder.blocks.6.norm2.weight grad: 1.186923236673465e-05
sam_encoder.blocks.6.norm2.bias grad: 3.910102805093629e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 8.970688213594258e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 4.1220810089726e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.680649004105362e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.110567720592371e-06
sam_encoder.blocks.7.norm1.weight grad: -9.152426514447143e-07
sam_encoder.blocks.7.norm1.bias grad: -6.17287696513813e-08
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -9.95459458863479e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.3466641348713893e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.0795529306051321e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -7.390355563074991e-07
sam_encoder.blocks.7.norm2.weight grad: 1.997629169636639e-06
sam_encoder.blocks.7.norm2.bias grad: 1.71883442590115e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.345571736839247e-08
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 7.831494031051989e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 4.80832341054338e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 9.2589010591837e-07
sam_encoder.blocks.8.norm1.weight grad: 8.504120160068851e-06
sam_encoder.blocks.8.norm1.bias grad: 1.5710063507867744e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 8.755834642215632e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.484533752067364e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.6999000536088715e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.1861419554625172e-06
sam_encoder.blocks.8.norm2.weight grad: -1.117631654778961e-06
sam_encoder.blocks.8.norm2.bias grad: -1.9684929952745733e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.310897800976818e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.0784273172248504e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.0991304577601113e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.2388987847298267e-07
sam_encoder.blocks.9.norm1.weight grad: -5.85956331633497e-06
sam_encoder.blocks.9.norm1.bias grad: -6.714366804771998e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -5.286520718073007e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.1255579011049122e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.3166021492215805e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.4989143437560415e-06
sam_encoder.blocks.9.norm2.weight grad: -2.5944382286979817e-06
sam_encoder.blocks.9.norm2.bias grad: 8.343217814399395e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.958967681683134e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.2973077900824137e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 5.609646223092568e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.66976723348489e-07
sam_encoder.blocks.10.norm1.weight grad: -1.7104787275457056e-06
sam_encoder.blocks.10.norm1.bias grad: -1.622739432605158e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.4388863291969756e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -5.488967644851073e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -5.93011861838022e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.6458652630244615e-07
sam_encoder.blocks.10.norm2.weight grad: -1.2005404641968198e-05
sam_encoder.blocks.10.norm2.bias grad: -2.526595380913932e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.658821570861619e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.633918706531404e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.928167876030784e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.895518716490187e-07
sam_encoder.blocks.11.norm1.weight grad: -2.1020485291955993e-05
sam_encoder.blocks.11.norm1.bias grad: -1.180401113742846e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.8194657463463955e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -6.868497166578891e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.8508316063380335e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.5706852991570486e-06
sam_encoder.blocks.11.norm2.weight grad: -1.3027154636802152e-05
sam_encoder.blocks.11.norm2.bias grad: -2.5384467789990595e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -5.09558731209836e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.702935262277606e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.379872050070844e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.0270921886076394e-07
sam_encoder.neck.conv1.trainable_scale grad: 5.3248641052050516e-08
sam_encoder.neck.conv1.trainable_shift grad: -1.1238289516768418e-05
sam_encoder.neck.conv2.trainable_scale grad: -4.4997159420745447e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.857872095773928e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00018603919306769967
mask_decoder.transformer.layers.0.norm1.bias grad: -1.4896213542670012e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005336904898285866
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0006300096865743399
mask_decoder.transformer.layers.0.norm3.weight grad: -1.8060953152598813e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 4.7696394176455215e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -1.6340496586053632e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.0175284842262045e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 3.066981662414037e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -7.386050128843635e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00018043605086859316
mask_decoder.transformer.layers.1.norm2.bias grad: 4.2578671127557755e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.4189248506445438e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.817783337784931e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 1.974369297386147e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0001149308227468282
mask_decoder.transformer.norm_final_attn.weight grad: 6.284040864557028e-06
mask_decoder.transformer.norm_final_attn.bias grad: -2.123595095326891e-06
Text_Embedding_Affine.0.weight grad: 6.359175686032614e-11
Text_Embedding_Affine.0.bias grad: 1.999908461058908e-09
Text_Embedding_Affine.2.weight grad: -7.551811606609782e-12
Text_Embedding_Affine.2.bias grad: 8.054619684116915e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.8128291796464255e-12
Max value: 0.9998708963394165
Mean value: 0.0882529690861702

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.8128291796464255e-12
Max value: 0.9998708963394165
Mean value: 0.0882529690861702

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08702898025512695

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12402061372995377

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07436227798461914

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08702898025512695

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 26.80133819580078
Max value: 79.03730010986328
Mean value: 56.477203369140625

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.841368629436959e-12
Max value: 0.9998613595962524
Mean value: 0.08880329132080078

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.841368629436959e-12
Max value: 0.9998613595962524
Mean value: 0.08880329132080078

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.841368629436959e-12
Max value: 0.9998613595962524
Mean value: 0.08880329132080078

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.916168212890625
Max value: -1.1920928244535389e-07
Mean value: -0.12406346201896667

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9794775247573853
Max value: 1.2326208353042603
Mean value: 0.9999653100967407

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 26.80133819580078
Max value: 79.03730010986328
Mean value: 56.477203369140625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.4766960144043
Max value: -56.4766960144043
Mean value: -56.4766960144043
sam_encoder.pos_embed grad: 4.687506383049822e-09
sam_encoder.blocks.0.norm1.weight grad: 3.2265713798551587e-06
sam_encoder.blocks.0.norm1.bias grad: -7.70569658925524e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.2672405723133124e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.826321824997649e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.1740073659893824e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 4.803953288501361e-07
sam_encoder.blocks.0.norm2.weight grad: 3.326957084937021e-05
sam_encoder.blocks.0.norm2.bias grad: -2.9250175430206582e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.6796520867501386e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.587029252434149e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.8716596969170496e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 8.696328222868033e-06
sam_encoder.blocks.1.norm1.weight grad: 8.7177540990524e-06
sam_encoder.blocks.1.norm1.bias grad: 9.910014341585338e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -8.361678737855982e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.6936284029943636e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -9.368935934617184e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.408618224260863e-06
sam_encoder.blocks.1.norm2.weight grad: -1.0924013622570783e-06
sam_encoder.blocks.1.norm2.bias grad: -2.560533971518453e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.516041371971369e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -9.949796719865844e-08
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.569191226735711e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.9358799363544676e-06
sam_encoder.blocks.2.norm1.weight grad: -1.2973081538802944e-05
sam_encoder.blocks.2.norm1.bias grad: 8.538345355191268e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.1194569196959492e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.2935257675271714e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.197019840532448e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.722487574326806e-06
sam_encoder.blocks.2.norm2.weight grad: -1.1821104635600932e-05
sam_encoder.blocks.2.norm2.bias grad: -4.199208433419699e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.0925854439847171e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.4676863884233171e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.0315920007997192e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.2731154533394147e-06
sam_encoder.blocks.3.norm1.weight grad: 2.8033707621943904e-06
sam_encoder.blocks.3.norm1.bias grad: -4.114269358979072e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -8.472171657558647e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -7.983318823789887e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.7226324164075777e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.1996983125281986e-06
sam_encoder.blocks.3.norm2.weight grad: -3.419914492042153e-06
sam_encoder.blocks.3.norm2.bias grad: -4.797724159288919e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -5.16077807333204e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.2173550203442574e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.2484905457531568e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -6.142853408164228e-07
sam_encoder.blocks.4.norm1.weight grad: 7.143981747503858e-06
sam_encoder.blocks.4.norm1.bias grad: -6.555093477800256e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.5698473134762025e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 7.480882118215959e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.6578113647701684e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.1283016192464856e-06
sam_encoder.blocks.4.norm2.weight grad: 2.3356724341283552e-06
sam_encoder.blocks.4.norm2.bias grad: 5.854748451383784e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.021291831828421e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.157789483841043e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.8647677936533e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -9.083709073820501e-07
sam_encoder.blocks.5.norm1.weight grad: 3.2877858302526874e-06
sam_encoder.blocks.5.norm1.bias grad: -1.6446507288492285e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.6023326326103415e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.618479579221457e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.966335159726441e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 4.83388419070252e-07
sam_encoder.blocks.5.norm2.weight grad: 3.396309239178663e-06
sam_encoder.blocks.5.norm2.bias grad: 2.4644714358146302e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.739995690921205e-08
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.5514699686368658e-08
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.8999575079069473e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 9.417109936293855e-07
sam_encoder.blocks.6.norm1.weight grad: -1.7305985693383263e-06
sam_encoder.blocks.6.norm1.bias grad: -5.814551514049526e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 7.723745056864573e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.874837380455574e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.2259996537977713e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.105487285713025e-06
sam_encoder.blocks.6.norm2.weight grad: -1.1950696716667153e-06
sam_encoder.blocks.6.norm2.bias grad: 2.212925380717934e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.043195420104894e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.555301423650235e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.442434094973578e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 8.111337592708878e-07
sam_encoder.blocks.7.norm1.weight grad: 4.351811071501288e-07
sam_encoder.blocks.7.norm1.bias grad: -1.3209523785917554e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.6594216845078336e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -6.060190571588464e-09
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.3998953818372684e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.485677098069573e-07
sam_encoder.blocks.7.norm2.weight grad: -4.932016395287064e-07
sam_encoder.blocks.7.norm2.bias grad: -5.12957285536686e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.6250726275757188e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -8.462992582281004e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 3.3523377851452096e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 6.02478564815101e-07
sam_encoder.blocks.8.norm1.weight grad: 7.026706043689046e-06
sam_encoder.blocks.8.norm1.bias grad: -1.6738893009460298e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.0004358045989648e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.685152816819027e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -7.91706156633154e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -5.03313344779599e-07
sam_encoder.blocks.8.norm2.weight grad: -4.197080670564901e-06
sam_encoder.blocks.8.norm2.bias grad: 9.691943887446541e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.21244931203546e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.455751427987707e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -9.643620160204591e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.043830325097588e-08
sam_encoder.blocks.9.norm1.weight grad: -3.5521355812306865e-07
sam_encoder.blocks.9.norm1.bias grad: 2.8469034418776573e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.1120596354885492e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.1259764960414032e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.034743015945423e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.9082715851936882e-08
sam_encoder.blocks.9.norm2.weight grad: -5.3774742809764575e-06
sam_encoder.blocks.9.norm2.bias grad: 9.484579095442314e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.75983267481206e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.2447146622871514e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -9.289214517593791e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.868283874273402e-07
sam_encoder.blocks.10.norm1.weight grad: -2.0250222405593377e-06
sam_encoder.blocks.10.norm1.bias grad: -9.626853625377407e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.250886382171302e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -7.712557135164388e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.1571318054848234e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -4.7437447392439935e-07
sam_encoder.blocks.10.norm2.weight grad: -9.153844075626694e-06
sam_encoder.blocks.10.norm2.bias grad: -6.226965609812396e-08
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.919567800243385e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.990118446177803e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -4.372842283828504e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -6.253562556679526e-09
sam_encoder.blocks.11.norm1.weight grad: -1.694991806289181e-05
sam_encoder.blocks.11.norm1.bias grad: -3.566863142623333e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.739242063398706e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.1744252503831376e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -9.462304433327517e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.672457810604101e-07
sam_encoder.blocks.11.norm2.weight grad: -8.66427035361994e-06
sam_encoder.blocks.11.norm2.bias grad: -2.5316148821730167e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.6387270938575966e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.8275244428878068e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -4.7447429096791893e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.257085552377248e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.6086232790257782e-07
sam_encoder.neck.conv1.trainable_shift grad: 4.151315806666389e-06
sam_encoder.neck.conv2.trainable_scale grad: 9.924192454491276e-07
sam_encoder.neck.conv2.trainable_shift grad: -4.153828740527388e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 2.049409886240028e-06
mask_decoder.transformer.layers.0.norm1.bias grad: 1.553165930090472e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005500975530594587
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0003440509899519384
mask_decoder.transformer.layers.0.norm3.weight grad: -3.3224296203115955e-06
mask_decoder.transformer.layers.0.norm3.bias grad: 4.277138941688463e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -8.233508560806513e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 9.522249456495047e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 9.54557708610082e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -1.0776202543638647e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00020999388652853668
mask_decoder.transformer.layers.1.norm2.bias grad: 4.7387009544763714e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.3396361181512475e-06
mask_decoder.transformer.layers.1.norm3.bias grad: 1.50950936586014e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 5.603585304925218e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00016057598986662924
mask_decoder.transformer.norm_final_attn.weight grad: -4.159146556048654e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.1399057257222012e-05
Text_Embedding_Affine.0.weight grad: 1.1006276185582253e-12
Text_Embedding_Affine.0.bias grad: 1.608166377842224e-10
Text_Embedding_Affine.2.weight grad: 3.2479310907440606e-11
Text_Embedding_Affine.2.bias grad: -1.9571525626815856e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 8.32268476358422e-10
Max value: 0.9998733997344971
Mean value: 0.06586689502000809

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 8.32268476358422e-10
Max value: 0.9998733997344971
Mean value: 0.06586689502000809

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08081626892089844

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.840883255004883
Max value: -1.1920928244535389e-07
Mean value: -0.12610380351543427

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05816841125488281

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08081626892089844

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 20.613872528076172
Max value: 86.91246032714844
Mean value: 55.048004150390625

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0371942193998507e-09
Max value: 0.9998613595962524
Mean value: 0.06620065867900848

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0371942193998507e-09
Max value: 0.9998613595962524
Mean value: 0.06620065867900848

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0371942193998507e-09
Max value: 0.9998613595962524
Mean value: 0.06620065867900848

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.674934387207031
Max value: -1.1920928244535389e-07
Mean value: -0.12589412927627563

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9518594741821289
Max value: 1.1805126667022705
Mean value: 1.0002236366271973

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 20.613872528076172
Max value: 86.91246032714844
Mean value: 55.048004150390625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.062896728515625
Max value: -55.062896728515625
Mean value: -55.062896728515625
sam_encoder.pos_embed grad: -3.21444515449798e-09
sam_encoder.blocks.0.norm1.weight grad: -4.043255466967821e-05
sam_encoder.blocks.0.norm1.bias grad: -2.2203580556379166e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.1998516785970423e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -7.807739166310057e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -3.888148057740182e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.023577725500218e-07
sam_encoder.blocks.0.norm2.weight grad: 5.162062734598294e-06
sam_encoder.blocks.0.norm2.bias grad: -2.648497172685893e-07
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 6.638880222453736e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 2.8713852771034e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -8.991386494017206e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.865360097028315e-06
sam_encoder.blocks.1.norm1.weight grad: 4.587145667755976e-06
sam_encoder.blocks.1.norm1.bias grad: -1.0088552699016873e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.4086474209307198e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 4.6453624236164615e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.1004469513409276e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 6.221242756510037e-07
sam_encoder.blocks.1.norm2.weight grad: 2.227499135187827e-05
sam_encoder.blocks.1.norm2.bias grad: 4.211654868413461e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 8.712030648894142e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.8042386500383145e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 6.013980964780785e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 9.284501629736042e-07
sam_encoder.blocks.2.norm1.weight grad: 6.059317456674762e-06
sam_encoder.blocks.2.norm1.bias grad: -5.2162640713504516e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.073510353919119e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 7.639566312889201e-09
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.0036016817593918e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -7.163335880022714e-08
sam_encoder.blocks.2.norm2.weight grad: -3.7203230363047624e-07
sam_encoder.blocks.2.norm2.bias grad: 1.0174320408395943e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -9.176917501463322e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.293661625823006e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 4.274791535863187e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 9.108812548674905e-08
sam_encoder.blocks.3.norm1.weight grad: -1.8317166450287914e-06
sam_encoder.blocks.3.norm1.bias grad: -4.3895988710573874e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.109790332520788e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 7.687235097364464e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 8.999644478535629e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 9.8957593763771e-07
sam_encoder.blocks.3.norm2.weight grad: -1.8673463273444213e-06
sam_encoder.blocks.3.norm2.bias grad: -1.150388811765879e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.0714819609347614e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 7.356238711508922e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -5.58421561436262e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -5.583762572314299e-07
sam_encoder.blocks.4.norm1.weight grad: -6.993222996243276e-07
sam_encoder.blocks.4.norm1.bias grad: -1.257511712537962e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.2010086720692925e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.8702623328390473e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.5066860871447716e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.3761590480498853e-06
sam_encoder.blocks.4.norm2.weight grad: -3.1851154744799715e-06
sam_encoder.blocks.4.norm2.bias grad: -1.730404437694233e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.1625636489043245e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.2613338640221627e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.788363420018868e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 5.353788168349638e-08
sam_encoder.blocks.5.norm1.weight grad: -2.233862687717192e-06
sam_encoder.blocks.5.norm1.bias grad: 5.706936462956946e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.569691554934252e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.4478240447933786e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.7809269340650644e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -3.348720269968908e-07
sam_encoder.blocks.5.norm2.weight grad: -5.945275461272104e-06
sam_encoder.blocks.5.norm2.bias grad: -1.2652397344936617e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -9.420256787961989e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.425277614293009e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.194554665242322e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -6.420386853278615e-07
sam_encoder.blocks.6.norm1.weight grad: 1.649703676775971e-06
sam_encoder.blocks.6.norm1.bias grad: 5.265480922389543e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 9.207042239722796e-09
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -8.494409371451184e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.457650556512817e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 9.174874548989465e-07
sam_encoder.blocks.6.norm2.weight grad: -3.853179350699065e-06
sam_encoder.blocks.6.norm2.bias grad: -2.6251159397361334e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.9885656001861207e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.31472476741601e-08
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.4664778973383363e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -9.869685300145647e-07
sam_encoder.blocks.7.norm1.weight grad: 7.881812052801251e-06
sam_encoder.blocks.7.norm1.bias grad: -2.352599892674334e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 5.255230917100562e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.317749476787867e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.1966270651319064e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.567648778040166e-07
sam_encoder.blocks.7.norm2.weight grad: 1.327892618974147e-06
sam_encoder.blocks.7.norm2.bias grad: -1.379451930461073e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 4.415948296809802e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.5856479624053463e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.1007799685103237e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.140086965278897e-06
sam_encoder.blocks.8.norm1.weight grad: -2.7983181993818107e-08
sam_encoder.blocks.8.norm1.bias grad: -1.1692811767716194e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.6183324760277173e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.988925760088023e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.7826394014264224e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.513117240392603e-06
sam_encoder.blocks.8.norm2.weight grad: 1.4825243397353915e-06
sam_encoder.blocks.8.norm2.bias grad: -1.7244223045054241e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.711831368491403e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.8585618590805097e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.709662112465594e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.618861678158282e-07
sam_encoder.blocks.9.norm1.weight grad: -1.2320219866523985e-07
sam_encoder.blocks.9.norm1.bias grad: 7.874326684031985e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 3.1578474590787664e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.157630208581395e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 2.6892024607150233e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 3.359664049185085e-07
sam_encoder.blocks.9.norm2.weight grad: 2.504574922568281e-06
sam_encoder.blocks.9.norm2.bias grad: -9.95639993561781e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.464439487288473e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.274578835364082e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.1111653697735164e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.050690899428446e-07
sam_encoder.blocks.10.norm1.weight grad: 5.7044758250413e-06
sam_encoder.blocks.10.norm1.bias grad: 6.98506198659743e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 4.236258064338472e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.8725629615801154e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.7734803350322181e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.236542971128074e-06
sam_encoder.blocks.10.norm2.weight grad: 4.283731868781615e-06
sam_encoder.blocks.10.norm2.bias grad: -4.985092800779967e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.741119715210516e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.450073796149809e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.9958681579955737e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.934834301664523e-07
sam_encoder.blocks.11.norm1.weight grad: 1.015495308820391e-05
sam_encoder.blocks.11.norm1.bias grad: 6.209475031937473e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.0812751725097769e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.576398602765039e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.6745170796639286e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.516778915331088e-07
sam_encoder.blocks.11.norm2.weight grad: 6.0753332036256324e-06
sam_encoder.blocks.11.norm2.bias grad: 1.5975708720361581e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.250439476687461e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.2073181778760045e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.910413421375324e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.0062083194716251e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.2403324944898486e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.343149779131636e-05
sam_encoder.neck.conv2.trainable_scale grad: -7.408107194351032e-07
sam_encoder.neck.conv2.trainable_shift grad: -7.973928404680919e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00014702518819831312
mask_decoder.transformer.layers.0.norm1.bias grad: -6.787304300814867e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003139988286420703
mask_decoder.transformer.layers.0.norm2.bias grad: 3.390153869986534e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00011874939809786156
mask_decoder.transformer.layers.0.norm3.bias grad: -6.169148400658742e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00013668651808984578
mask_decoder.transformer.layers.0.norm4.bias grad: -8.681970939505845e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.725508006231394e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 3.2499565350008197e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00017176639812532812
mask_decoder.transformer.layers.1.norm2.bias grad: -4.0654711483512074e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.2298932385165244e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.68967671925202e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -4.420643745106645e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00022921992058400065
mask_decoder.transformer.norm_final_attn.weight grad: 3.775625373236835e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.5993548004189506e-05
Text_Embedding_Affine.0.weight grad: 1.0401077785507362e-12
Text_Embedding_Affine.0.bias grad: -3.9522329853269866e-11
Text_Embedding_Affine.2.weight grad: 4.4099085494408996e-11
Text_Embedding_Affine.2.bias grad: -7.464444934157655e-06
Epoch 23 finished with average loss: -56.1579
Epoch 24/39
----------
Epoch 24:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 24:   0%|          | 0/3 [00:00<?, ?it/s, loss=-54.9]Epoch 24:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.08it/s, loss=-54.9]Epoch 24:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.08it/s, loss=-57.1]Epoch 24:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.67it/s, loss=-57.1]Epoch 24:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.67it/s, loss=-55.8]Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.32it/s, loss=-55.8]/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.3290214816589541e-15
Max value: 0.999913215637207
Mean value: 0.09149575233459473

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.3290214816589541e-15
Max value: 0.999913215637207
Mean value: 0.09149575233459473

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08335018157958984

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13536573946475983

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07868719100952148

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08335018157958984

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 29.056081771850586
Max value: 72.45548248291016
Mean value: 54.84941864013672

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.3290214816589541e-15
Max value: 0.999913215637207
Mean value: 0.09149575233459473

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.3290214816589541e-15
Max value: 0.999913215637207
Mean value: 0.09149575233459473

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.3290214816589541e-15
Max value: 0.999913215637207
Mean value: 0.09149575233459473

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13536573946475983

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 29.056081771850586
Max value: 72.45548248291016
Mean value: 54.84941864013672

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -54.85072326660156
Max value: -54.85072326660156
Mean value: -54.85072326660156
sam_encoder.pos_embed grad: -6.803476448880019e-09
sam_encoder.blocks.0.norm1.weight grad: -2.0961959307896905e-05
sam_encoder.blocks.0.norm1.bias grad: -8.549872291041538e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 8.715272088011261e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.2787723708006524e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.1860519154870417e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.986421688750852e-06
sam_encoder.blocks.0.norm2.weight grad: -1.034976594382897e-05
sam_encoder.blocks.0.norm2.bias grad: -3.776441371883266e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.2786958652432077e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.4525436199619435e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 6.634017154283356e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 7.169897344283527e-06
sam_encoder.blocks.1.norm1.weight grad: 5.750000127591193e-06
sam_encoder.blocks.1.norm1.bias grad: 2.0422765373950824e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -5.833122031617677e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.4029429823713144e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.2142557352490257e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -6.105636202846654e-06
sam_encoder.blocks.1.norm2.weight grad: -1.2146978406235576e-05
sam_encoder.blocks.1.norm2.bias grad: -1.3478385881171562e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.8295271729584783e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.2811842680093832e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.0833778762607835e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.55126453904586e-08
sam_encoder.blocks.2.norm1.weight grad: 2.2691336198477075e-05
sam_encoder.blocks.2.norm1.bias grad: -1.447646354790777e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 1.2766240615746938e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 2.0965360363334185e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 4.420533059601439e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 5.09638766743592e-06
sam_encoder.blocks.2.norm2.weight grad: -3.8955597119638696e-05
sam_encoder.blocks.2.norm2.bias grad: 1.8333099433220923e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.3539174435427412e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.034108769701561e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.1961845050100237e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -6.224277512956178e-06
sam_encoder.blocks.3.norm1.weight grad: 3.3459364203736186e-06
sam_encoder.blocks.3.norm1.bias grad: -1.1723019269993529e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.2397410955600208e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 4.398922825998852e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.6235052271440509e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.9147134935337817e-06
sam_encoder.blocks.3.norm2.weight grad: -1.6443480490124784e-05
sam_encoder.blocks.3.norm2.bias grad: -1.5961808458087035e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.548293039377313e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -7.929193088784814e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.3025078260398004e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.761470568657387e-06
sam_encoder.blocks.4.norm1.weight grad: 2.3411976144416258e-05
sam_encoder.blocks.4.norm1.bias grad: -2.5427532818866894e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 5.8865061873802915e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.1335810035670875e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.0575980670400895e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.74058311333647e-06
sam_encoder.blocks.4.norm2.weight grad: 4.702572368842084e-06
sam_encoder.blocks.4.norm2.bias grad: 2.788079291349277e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.140812628364074e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 4.85420514451107e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.819649464276154e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -7.24103927041142e-07
sam_encoder.blocks.5.norm1.weight grad: 2.9728403205808718e-06
sam_encoder.blocks.5.norm1.bias grad: -3.6004159483127296e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.0053554433397949e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 6.246288648981135e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.7243182810489088e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 7.862493475840893e-06
sam_encoder.blocks.5.norm2.weight grad: 1.3102875527692959e-05
sam_encoder.blocks.5.norm2.bias grad: 9.208721166942269e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 5.009441338188481e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 4.164783604210243e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.5118141568091232e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 7.78755179453583e-07
sam_encoder.blocks.6.norm1.weight grad: 1.7477639630669728e-05
sam_encoder.blocks.6.norm1.bias grad: -5.54073449166026e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 8.00514408183517e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.3223254831682425e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.1171740627323743e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.3316358692682115e-06
sam_encoder.blocks.6.norm2.weight grad: -5.4227384680416435e-06
sam_encoder.blocks.6.norm2.bias grad: 2.043889253400266e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -7.981000635481905e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.400092049967498e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.274845428473782e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 8.049953521549469e-07
sam_encoder.blocks.7.norm1.weight grad: -3.7131628687347984e-06
sam_encoder.blocks.7.norm1.bias grad: -1.3019896414334653e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -4.338457983976696e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.3384055768692633e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -7.690643428759358e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.5660001483629458e-06
sam_encoder.blocks.7.norm2.weight grad: -9.656863397822235e-08
sam_encoder.blocks.7.norm2.bias grad: 1.0691180705180159e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -5.106297976453789e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.26140661854879e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.7515866349858698e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.3610397218144499e-06
sam_encoder.blocks.8.norm1.weight grad: 1.2200601304357406e-05
sam_encoder.blocks.8.norm1.bias grad: -4.766015536006307e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.515140502306167e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.4246730794839095e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.1265577743179165e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.8532513195168576e-06
sam_encoder.blocks.8.norm2.weight grad: 3.326892965560546e-06
sam_encoder.blocks.8.norm2.bias grad: 5.19769810125581e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.92471292798291e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.377963371851365e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 3.2463055958942277e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.229247456853045e-06
sam_encoder.blocks.9.norm1.weight grad: 4.007868483313359e-06
sam_encoder.blocks.9.norm1.bias grad: 1.235109152730729e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.5646152102563065e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.115296410920564e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.71434611629229e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.7825711893237894e-06
sam_encoder.blocks.9.norm2.weight grad: 8.788676495896652e-06
sam_encoder.blocks.9.norm2.bias grad: 5.091643743071472e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.2966439701122e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.0598803328321083e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 7.036687748041004e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.193777385808062e-06
sam_encoder.blocks.10.norm1.weight grad: 4.43498447566526e-06
sam_encoder.blocks.10.norm1.bias grad: -9.215435738951783e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.0841503101109993e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 7.29143380340247e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.399806817265926e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.3729413694818504e-07
sam_encoder.blocks.10.norm2.weight grad: 1.5267972912624828e-06
sam_encoder.blocks.10.norm2.bias grad: 5.669975507771596e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.2286569623684045e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.8153045289182046e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 4.720597189589171e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.09105814974464e-06
sam_encoder.blocks.11.norm1.weight grad: -1.7579857740201987e-05
sam_encoder.blocks.11.norm1.bias grad: -2.106856754835462e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.6299995309054793e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 6.589892791453167e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.0342490668335813e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.5767394618014805e-07
sam_encoder.blocks.11.norm2.weight grad: 9.390483683091588e-06
sam_encoder.blocks.11.norm2.bias grad: -6.25128222964122e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.1715086303593125e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.2878074358013691e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 4.944059583067428e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.2802527130115777e-06
sam_encoder.neck.conv1.trainable_scale grad: 2.3708271328359842e-06
sam_encoder.neck.conv1.trainable_shift grad: 8.61455628182739e-05
sam_encoder.neck.conv2.trainable_scale grad: 3.0793780751992017e-06
sam_encoder.neck.conv2.trainable_shift grad: -8.481926488457248e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 9.74727954599075e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 1.738622086122632e-05
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00013028259854763746
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0005867931176908314
mask_decoder.transformer.layers.0.norm3.weight grad: -8.366683323401958e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 9.614825830794871e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00013041484635323286
mask_decoder.transformer.layers.0.norm4.bias grad: 2.0922074327245355e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 2.3750300897518173e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.468265953822993e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 9.792590572033077e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 9.598847100278363e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -8.056418664637022e-06
mask_decoder.transformer.layers.1.norm3.bias grad: 2.5356504920637235e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 6.471526285167783e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00025983439991250634
mask_decoder.transformer.norm_final_attn.weight grad: 8.878419976099394e-06
mask_decoder.transformer.norm_final_attn.bias grad: -7.146568805183051e-06
Text_Embedding_Affine.0.weight grad: 1.4356390208580816e-11
Text_Embedding_Affine.0.bias grad: 8.636148463025961e-10
Text_Embedding_Affine.2.weight grad: -3.8443213890015926e-11
Text_Embedding_Affine.2.bias grad: -9.590001354808919e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.168310571179724e-11
Max value: 0.9997658133506775
Mean value: 0.0967368483543396

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.168310571179724e-11
Max value: 0.9997658133506775
Mean value: 0.0967368483543396

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08313703536987305

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.93148422241211
Max value: -1.1920928244535389e-07
Mean value: -0.1258348524570465

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07720184326171875

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08313703536987305

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 46.733524322509766
Max value: 82.94587707519531
Mean value: 59.362892150878906

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.169749697775394e-11
Max value: 0.9997826218605042
Mean value: 0.09662268310785294

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.169749697775394e-11
Max value: 0.9997826218605042
Mean value: 0.09662268310785294

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.169749697775394e-11
Max value: 0.9997826218605042
Mean value: 0.09662268310785294

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12569043040275574

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9135119318962097
Max value: 1.069559097290039
Mean value: 1.0001463890075684

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 46.733524322509766
Max value: 82.94587707519531
Mean value: 59.362892150878906

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.37522888183594
Max value: -59.37522888183594
Mean value: -59.37522888183594
sam_encoder.pos_embed grad: 5.257303481442932e-09
sam_encoder.blocks.0.norm1.weight grad: 7.347420250880532e-06
sam_encoder.blocks.0.norm1.bias grad: -2.3384438463835977e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.12655936088413e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.5588202018079755e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.423204932711087e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.419709747096931e-06
sam_encoder.blocks.0.norm2.weight grad: 1.8473203454050235e-05
sam_encoder.blocks.0.norm2.bias grad: -1.1357880794093944e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.3829810995957814e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 6.687022505502682e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.0731415133923292e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.6012641935958527e-05
sam_encoder.blocks.1.norm1.weight grad: 1.9931819679186447e-06
sam_encoder.blocks.1.norm1.bias grad: 7.641405318281613e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.1301361155346967e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.0651845008833334e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.114840961236041e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.460498414322501e-06
sam_encoder.blocks.1.norm2.weight grad: -1.4174554962664843e-05
sam_encoder.blocks.1.norm2.bias grad: -1.790142391655536e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.2608606994035654e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.5852314138319343e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.2314120795053896e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -9.741715985001065e-07
sam_encoder.blocks.2.norm1.weight grad: -3.1389433843287406e-06
sam_encoder.blocks.2.norm1.bias grad: 3.4329596019233577e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.436285962583497e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -4.7207362285917043e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.0022442842891905e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.634920636206516e-06
sam_encoder.blocks.2.norm2.weight grad: 4.9419722927268595e-06
sam_encoder.blocks.2.norm2.bias grad: -3.2898419703997206e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.815310722326103e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.374691009914386e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.0494371053937357e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.6262666779075516e-06
sam_encoder.blocks.3.norm1.weight grad: 1.3804408354189945e-06
sam_encoder.blocks.3.norm1.bias grad: 2.69518341156072e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.498284513625549e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -7.083507966854086e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.514542979450198e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.193028871668503e-06
sam_encoder.blocks.3.norm2.weight grad: -1.33938137878431e-05
sam_encoder.blocks.3.norm2.bias grad: -3.984954673796892e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.0892315913224593e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.8315779420372564e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -6.37319953966653e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -7.255789569171611e-07
sam_encoder.blocks.4.norm1.weight grad: 4.85390773974359e-06
sam_encoder.blocks.4.norm1.bias grad: -5.634569788526278e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.8770272163237678e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.5702944438089617e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.6555526346783154e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.9829552659066394e-06
sam_encoder.blocks.4.norm2.weight grad: 1.848890315159224e-05
sam_encoder.blocks.4.norm2.bias grad: 1.8270791770191863e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 7.813339834683575e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.988596406794386e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -5.522309038497042e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -8.865416702974471e-07
sam_encoder.blocks.5.norm1.weight grad: 3.618525170168141e-06
sam_encoder.blocks.5.norm1.bias grad: -1.8154123608837835e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 3.903445758624002e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 5.8141863519267645e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.616766207414912e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.5474424230887962e-07
sam_encoder.blocks.5.norm2.weight grad: 6.79869935993338e-06
sam_encoder.blocks.5.norm2.bias grad: 9.860133104666602e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 9.955072073353222e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 5.080373171040264e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.791891861557815e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.759522991866106e-07
sam_encoder.blocks.6.norm1.weight grad: -1.1466438536444912e-06
sam_encoder.blocks.6.norm1.bias grad: -8.503669960191473e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.8183591237175278e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.678702344383055e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.3016028788115364e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -5.406258196671843e-07
sam_encoder.blocks.6.norm2.weight grad: 1.4510651453747414e-06
sam_encoder.blocks.6.norm2.bias grad: 4.153894224145915e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.110616368459887e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.192032806964562e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.0887347343668807e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 8.534299240636756e-07
sam_encoder.blocks.7.norm1.weight grad: -5.519079422811046e-06
sam_encoder.blocks.7.norm1.bias grad: 3.7430089605550165e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.295869414112531e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.8522459868108854e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.1508186566497898e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.09274582832586e-07
sam_encoder.blocks.7.norm2.weight grad: -2.295199010404758e-06
sam_encoder.blocks.7.norm2.bias grad: 1.8269433894602116e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -5.169053110876121e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.0612849311874015e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -5.511294034477032e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.5946401390465326e-06
sam_encoder.blocks.8.norm1.weight grad: -6.277636202867143e-06
sam_encoder.blocks.8.norm1.bias grad: 2.521555870771408e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -4.236989752826048e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -8.372751381102717e-08
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -5.236009656073293e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.8883921459055273e-06
sam_encoder.blocks.8.norm2.weight grad: -3.992089659732301e-06
sam_encoder.blocks.8.norm2.bias grad: 1.6624642285023583e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.797921974386554e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.8177653348393505e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -4.552677523861348e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.1483816706459038e-06
sam_encoder.blocks.9.norm1.weight grad: -4.1633743421698455e-06
sam_encoder.blocks.9.norm1.bias grad: 5.087367185296898e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.962980710843112e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.4739506443438586e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.3140082728568814e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 4.4598687054531183e-07
sam_encoder.blocks.9.norm2.weight grad: -5.802849955216516e-06
sam_encoder.blocks.9.norm2.bias grad: 1.4465877029579133e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -6.532901807076996e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.8609206310648005e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.3866459980249601e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.1770645187425544e-06
sam_encoder.blocks.10.norm1.weight grad: -9.574485375196673e-06
sam_encoder.blocks.10.norm1.bias grad: -4.220530058773875e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -7.090711733326316e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.3117108867154457e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.677999418665422e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.327752897850587e-06
sam_encoder.blocks.10.norm2.weight grad: -1.077289016393479e-05
sam_encoder.blocks.10.norm2.bias grad: -1.4378512958046485e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -6.881842182338005e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.264867700636387e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.431131633784389e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 3.838656255084061e-07
sam_encoder.blocks.11.norm1.weight grad: -3.0070716093177907e-05
sam_encoder.blocks.11.norm1.bias grad: 9.917539500747807e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -6.233883141248953e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.5631347878297674e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -3.6529199860524386e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.856786525422649e-06
sam_encoder.blocks.11.norm2.weight grad: -1.1806854672613554e-05
sam_encoder.blocks.11.norm2.bias grad: -1.8467017071088776e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -5.631494332192233e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.0298350591474446e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.1253049336801269e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.0168326980419806e-07
sam_encoder.neck.conv1.trainable_scale grad: 8.222541509894654e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.0529292922001332e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.3347653293749318e-06
sam_encoder.neck.conv2.trainable_shift grad: -3.179667692165822e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00010805277997860685
mask_decoder.transformer.layers.0.norm1.bias grad: 2.3439097276423126e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0037463956978172064
mask_decoder.transformer.layers.0.norm2.bias grad: 6.912084063515067e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 5.0057155021931976e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.6380921553936787e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00011630741209955886
mask_decoder.transformer.layers.0.norm4.bias grad: 1.1717987945303321e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 1.0369638403062709e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -9.754165148478933e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00019114646420348436
mask_decoder.transformer.layers.1.norm2.bias grad: 3.6966252082493156e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.4887689758324996e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 5.404931471275631e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 5.945328302914277e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00021328296861611307
mask_decoder.transformer.norm_final_attn.weight grad: 1.0532301075727446e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.5996080037439242e-05
Text_Embedding_Affine.0.weight grad: -2.697200535833888e-12
Text_Embedding_Affine.0.bias grad: -1.6806156466486755e-10
Text_Embedding_Affine.2.weight grad: 1.076415762080174e-10
Text_Embedding_Affine.2.bias grad: -2.291139571752865e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.5076902360199327e-13
Max value: 0.9995786547660828
Mean value: 0.08094075322151184

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.5076902360199327e-13
Max value: 0.9995786547660828
Mean value: 0.08094075322151184

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08597183227539062

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13284489512443542

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07379817962646484

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08597183227539062

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 42.23237991333008
Max value: 63.78541946411133
Mean value: 53.2359619140625

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.019803188634331e-13
Max value: 0.9996110796928406
Mean value: 0.08024293184280396

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.019803188634331e-13
Max value: 0.9996110796928406
Mean value: 0.08024293184280396

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.019803188634331e-13
Max value: 0.9996110796928406
Mean value: 0.08024293184280396

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1327892541885376

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.7959392666816711
Max value: 1.027232050895691
Mean value: 1.0000789165496826

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 42.23237991333008
Max value: 63.78541946411133
Mean value: 53.2359619140625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.244876861572266
Max value: -53.244876861572266
Mean value: -53.244876861572266
sam_encoder.pos_embed grad: -6.522689055543651e-09
sam_encoder.blocks.0.norm1.weight grad: 2.3115722797228955e-05
sam_encoder.blocks.0.norm1.bias grad: 3.552340785972774e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.1024052330176346e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.6827214583136083e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 4.472718956094468e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.750749435013859e-07
sam_encoder.blocks.0.norm2.weight grad: 1.8563578123576008e-05
sam_encoder.blocks.0.norm2.bias grad: 1.0037554147857009e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.9732384064118378e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.0468512300576549e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.2878884919919074e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 9.218247214448638e-07
sam_encoder.blocks.1.norm1.weight grad: 7.051079137454508e-06
sam_encoder.blocks.1.norm1.bias grad: 5.222831077844603e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.0549387045321055e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 6.638470040343236e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.3580273616753402e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.2483907002879278e-07
sam_encoder.blocks.1.norm2.weight grad: 2.0160998246865347e-05
sam_encoder.blocks.1.norm2.bias grad: 3.359717538842233e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.560879006021423e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.0306773674528813e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.6606804769689916e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.001236680371221e-06
sam_encoder.blocks.2.norm1.weight grad: 2.936526925623184e-06
sam_encoder.blocks.2.norm1.bias grad: -1.1062702469644137e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 5.568205665440473e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -9.230975024365762e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.332555469474755e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.2847896161692915e-06
sam_encoder.blocks.2.norm2.weight grad: -2.2801394152338617e-05
sam_encoder.blocks.2.norm2.bias grad: 1.2324328963586595e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.57766007760074e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.3801975405367557e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 3.423674570512958e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 6.023125251886086e-07
sam_encoder.blocks.3.norm1.weight grad: -2.221958766313037e-06
sam_encoder.blocks.3.norm1.bias grad: -2.156567461497616e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 5.207702542975312e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.637157194840256e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 2.328417622265988e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.0009592870119377e-06
sam_encoder.blocks.3.norm2.weight grad: 1.2480295481509529e-05
sam_encoder.blocks.3.norm2.bias grad: 7.079688657540828e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.1094753062934615e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 5.300130851537688e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.0206408559461124e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.2291321783995954e-06
sam_encoder.blocks.4.norm1.weight grad: 4.1753501136554405e-06
sam_encoder.blocks.4.norm1.bias grad: -9.103609045268968e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.1056389439545455e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.3633063506167673e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.1291699542634888e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.4555223464849405e-06
sam_encoder.blocks.4.norm2.weight grad: -4.500108843785711e-06
sam_encoder.blocks.4.norm2.bias grad: -1.1565992281248327e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.8695983473880915e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.176463340219925e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.9247173592448235e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 6.933660188224167e-07
sam_encoder.blocks.5.norm1.weight grad: 1.0920162822003476e-05
sam_encoder.blocks.5.norm1.bias grad: -1.4854080063742003e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.3270390455727465e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.8471663426898886e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.413091119204182e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.2047685231664218e-06
sam_encoder.blocks.5.norm2.weight grad: 1.3447895526041975e-06
sam_encoder.blocks.5.norm2.bias grad: -1.3678316463483498e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.396433385205455e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.4463000752584776e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.1891568735554756e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.2890009202237707e-06
sam_encoder.blocks.6.norm1.weight grad: -7.948133315949235e-07
sam_encoder.blocks.6.norm1.bias grad: 8.285137482744176e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.9391526961953787e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -9.117770787270274e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.676218488455561e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.0827845926542068e-06
sam_encoder.blocks.6.norm2.weight grad: -2.5846215976343956e-06
sam_encoder.blocks.6.norm2.bias grad: -4.838836957787862e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.090876816713717e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.0083550705530797e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.836786279658554e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.8416440070723183e-06
sam_encoder.blocks.7.norm1.weight grad: 5.318970579537563e-06
sam_encoder.blocks.7.norm1.bias grad: 7.038726721475541e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 6.513540483865654e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.183094693464227e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.2764662591944216e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 4.0141399040294345e-06
sam_encoder.blocks.7.norm2.weight grad: 8.06961179478094e-06
sam_encoder.blocks.7.norm2.bias grad: -9.993973435484804e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 6.283298716880381e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.840260433207732e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.3570472674473422e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.9911077231427043e-07
sam_encoder.blocks.8.norm1.weight grad: 3.119376515314798e-06
sam_encoder.blocks.8.norm1.bias grad: -3.480112809484126e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.83618896396365e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 5.943094834037765e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.9488708150893217e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 3.145593382214429e-06
sam_encoder.blocks.8.norm2.weight grad: 5.8622863434720784e-06
sam_encoder.blocks.8.norm2.bias grad: 3.935749646188924e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 5.3622779887518845e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.6139572330284864e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.4028013310962706e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.104561751068104e-08
sam_encoder.blocks.9.norm1.weight grad: 8.717842092664796e-07
sam_encoder.blocks.9.norm1.bias grad: 5.30682655153214e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 3.236470433876093e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.5157911548158154e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 5.597942163149128e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.3624375014842371e-06
sam_encoder.blocks.9.norm2.weight grad: 3.7919935493846424e-06
sam_encoder.blocks.9.norm2.bias grad: 6.679078978777397e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.6991729100700468e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 6.676847874587111e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.4500444649456767e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -8.342269097738608e-07
sam_encoder.blocks.10.norm1.weight grad: 5.794902790512424e-06
sam_encoder.blocks.10.norm1.bias grad: -9.239400924343499e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.335119799885433e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.4165063930704491e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 9.277407002628024e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.530270866278443e-07
sam_encoder.blocks.10.norm2.weight grad: 1.1338801414240152e-05
sam_encoder.blocks.10.norm2.bias grad: 3.531156380631728e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 6.1977834775461815e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.670194135134807e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 9.393037316840491e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.3736078585679934e-07
sam_encoder.blocks.11.norm1.weight grad: 1.636920205783099e-05
sam_encoder.blocks.11.norm1.bias grad: -2.455860339978244e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -7.55015548747906e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -4.547492693518507e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.6066672969827778e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.135902370057011e-07
sam_encoder.blocks.11.norm2.weight grad: 9.588289685780182e-06
sam_encoder.blocks.11.norm2.bias grad: 2.267231138830539e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.066707101126667e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.6881816691238782e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.7092559307106967e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.324358518990266e-07
sam_encoder.neck.conv1.trainable_scale grad: 6.263489922275767e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.3284614396980032e-05
sam_encoder.neck.conv2.trainable_scale grad: 3.869045031024143e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.6246096240356565e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -5.1900933613069355e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -2.11861333809793e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005653609521687031
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0003357918467372656
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00013095373287796974
mask_decoder.transformer.layers.0.norm3.bias grad: -2.641802711877972e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 6.0374484746716917e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -4.313719728088472e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 1.4677956642117351e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.2881764632766135e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.000193592015421018
mask_decoder.transformer.layers.1.norm2.bias grad: -2.2675063519272953e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.0063465854036622e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.064940862415824e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -4.06152248615399e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00013261208368930966
mask_decoder.transformer.norm_final_attn.weight grad: 5.4916217777645215e-06
mask_decoder.transformer.norm_final_attn.bias grad: 7.355050456681056e-06
Text_Embedding_Affine.0.weight grad: 2.386264796871984e-12
Text_Embedding_Affine.0.bias grad: 2.3604559973300354e-10
Text_Embedding_Affine.2.weight grad: -5.818494124010254e-12
Text_Embedding_Affine.2.bias grad: -1.6493891962454654e-05
Epoch 24 finished with average loss: -55.8236
Epoch 25/39
----------
Epoch 25:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 25:   0%|          | 0/3 [00:00<?, ?it/s, loss=-58]Epoch 25:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.08it/s, loss=-58]Epoch 25:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.08it/s, loss=-56.4]Epoch 25:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.67it/s, loss=-56.4]Epoch 25:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.67it/s, loss=-57.2]Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.32it/s, loss=-57.2]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.851554592435637e-13
Max value: 0.9995172023773193
Mean value: 0.09036103636026382

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.851554592435637e-13
Max value: 0.9995172023773193
Mean value: 0.09036103636026382

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08054542541503906

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11994586884975433

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08053016662597656

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08054542541503906

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 47.58517074584961
Max value: 71.54241180419922
Mean value: 57.96044921875

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 5.851554592435637e-13
Max value: 0.9995172023773193
Mean value: 0.09036103636026382

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.851554592435637e-13
Max value: 0.9995172023773193
Mean value: 0.09036103636026382

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 5.851554592435637e-13
Max value: 0.9995172023773193
Mean value: 0.09036103636026382

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11994586884975433

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 47.58517074584961
Max value: 71.54241180419922
Mean value: 57.96044921875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -57.96168518066406
Max value: -57.96168518066406
Mean value: -57.96168518066406
sam_encoder.pos_embed grad: 6.245533423765437e-09
sam_encoder.blocks.0.norm1.weight grad: 2.0035391571582295e-05
sam_encoder.blocks.0.norm1.bias grad: -7.698396075284109e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 5.853928087162785e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 5.697581855201861e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.8754881239146926e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -9.727303762474548e-08
sam_encoder.blocks.0.norm2.weight grad: 3.16811929224059e-06
sam_encoder.blocks.0.norm2.bias grad: -8.200558659154922e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.5509018087177537e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 8.440568308287766e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.8209357222076505e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 9.808016329770908e-06
sam_encoder.blocks.1.norm1.weight grad: 1.758968210197054e-05
sam_encoder.blocks.1.norm1.bias grad: 1.480655737395864e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.6404732150476775e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.2547970982268453e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.98088536207797e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.933876087103272e-06
sam_encoder.blocks.1.norm2.weight grad: -4.8432262701680884e-05
sam_encoder.blocks.1.norm2.bias grad: 7.853388524381444e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.5980767784640193e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.179309715051204e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.2202035072259605e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.56637644674629e-06
sam_encoder.blocks.2.norm1.weight grad: -1.321312265645247e-05
sam_encoder.blocks.2.norm1.bias grad: -1.0017656677518971e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -6.489131010312121e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -5.968090590613429e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.368325219023973e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.3879261473448423e-07
sam_encoder.blocks.2.norm2.weight grad: -2.0894809495075606e-05
sam_encoder.blocks.2.norm2.bias grad: 6.7130558818462305e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.4656746316177305e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.9697818061104044e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.5272958989953622e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.7154555937158875e-06
sam_encoder.blocks.3.norm1.weight grad: 1.2922936548420694e-05
sam_encoder.blocks.3.norm1.bias grad: -5.4655674830428325e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 4.064460881636478e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.1333388506027404e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.451180762363947e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.926920610159868e-06
sam_encoder.blocks.3.norm2.weight grad: -1.8765198547043838e-05
sam_encoder.blocks.3.norm2.bias grad: 1.578850788064301e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.625139339012094e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -4.915016688755713e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -5.308196705300361e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.130996096776471e-07
sam_encoder.blocks.4.norm1.weight grad: -6.674523319816217e-06
sam_encoder.blocks.4.norm1.bias grad: -1.0426274457131512e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -9.208166375174187e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.3549619072582573e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.054806029467727e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.173808070438099e-06
sam_encoder.blocks.4.norm2.weight grad: 1.597345544723794e-05
sam_encoder.blocks.4.norm2.bias grad: 1.2768892702297308e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 7.5876173468714114e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 3.3614892345212866e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.8741673102340428e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.7295624274993315e-06
sam_encoder.blocks.5.norm1.weight grad: -6.053251127013937e-06
sam_encoder.blocks.5.norm1.bias grad: -1.2380887710605748e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.3604675334354397e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.8357214887364535e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.6171418337762589e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -9.080524421278824e-08
sam_encoder.blocks.5.norm2.weight grad: 2.6563673145574285e-06
sam_encoder.blocks.5.norm2.bias grad: 4.854874532611575e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 5.19252864705777e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.0283106348651927e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.3705251805949956e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 7.525867431468214e-07
sam_encoder.blocks.6.norm1.weight grad: -4.444718797458336e-06
sam_encoder.blocks.6.norm1.bias grad: -4.978381184628233e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.815949644878856e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.1860228354976243e-08
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -5.002260650144308e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.6898114192117646e-07
sam_encoder.blocks.6.norm2.weight grad: -2.044409256996005e-06
sam_encoder.blocks.6.norm2.bias grad: 2.573675146777532e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.4049880974198459e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.685722103658918e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.6424186216900125e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -5.508759386430029e-07
sam_encoder.blocks.7.norm1.weight grad: 2.5705226107675117e-06
sam_encoder.blocks.7.norm1.bias grad: 4.311185364258563e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -4.994823825654748e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -5.03309649957373e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.0997475783369737e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.1671138508972945e-06
sam_encoder.blocks.7.norm2.weight grad: 1.5200464531517355e-06
sam_encoder.blocks.7.norm2.bias grad: -8.598620979682892e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.8199696114606922e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -9.855914413492428e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.1618849384831265e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 6.575355655513704e-07
sam_encoder.blocks.8.norm1.weight grad: -3.247003519391001e-07
sam_encoder.blocks.8.norm1.bias grad: -9.770567430678057e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 9.559905720379902e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.829827624533209e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.50147581937199e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.412391379242763e-06
sam_encoder.blocks.8.norm2.weight grad: -3.0788334015596774e-07
sam_encoder.blocks.8.norm2.bias grad: 3.6036631172464695e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.83775113732554e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.1491563327581389e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 6.465267574640166e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.3566958614319446e-06
sam_encoder.blocks.9.norm1.weight grad: -2.194999751736759e-06
sam_encoder.blocks.9.norm1.bias grad: -1.8154455005969794e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.613785111156176e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.412999947409844e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.413144539394125e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.5182010884018382e-06
sam_encoder.blocks.9.norm2.weight grad: -5.686185431841295e-06
sam_encoder.blocks.9.norm2.bias grad: 2.6362581593275536e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -6.848298653494567e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.4077106647600885e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -7.101681944732263e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.057980725249763e-07
sam_encoder.blocks.10.norm1.weight grad: -3.7051847812108463e-06
sam_encoder.blocks.10.norm1.bias grad: -2.7148184926772956e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.015891136077698e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.5731402527308092e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.3512784562408342e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 7.89151926028353e-08
sam_encoder.blocks.10.norm2.weight grad: -1.4347761862154584e-05
sam_encoder.blocks.10.norm2.bias grad: 6.840577952971216e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.77771799423499e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.311798304319382e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.4397148788702907e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.191835157347668e-07
sam_encoder.blocks.11.norm1.weight grad: -4.514018201007275e-06
sam_encoder.blocks.11.norm1.bias grad: 1.8400851331534795e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.9161866475769784e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -8.001293139159316e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -5.806941771879792e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.5855782698490657e-07
sam_encoder.blocks.11.norm2.weight grad: -4.618121238308959e-06
sam_encoder.blocks.11.norm2.bias grad: 3.878560050907254e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -3.911986823368352e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.3449500784190604e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.433316351220128e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 4.662223886953143e-07
sam_encoder.neck.conv1.trainable_scale grad: 2.0712832338176668e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.3117456546751782e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.7260703063802794e-06
sam_encoder.neck.conv2.trainable_shift grad: 8.403855645156e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 6.853104423498735e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 8.718921890249476e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0018131921533495188
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0005448035662993789
mask_decoder.transformer.layers.0.norm3.weight grad: 2.3882714231149293e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -4.454710870049894e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -8.99203514563851e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.662100839894265e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 1.635727494431194e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.2008344128844328e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 9.880491415970027e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 8.055577927734703e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -7.666663805139251e-06
mask_decoder.transformer.layers.1.norm3.bias grad: 4.564015398500487e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.0743296772707254e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00017429268336854875
mask_decoder.transformer.norm_final_attn.weight grad: 6.0332213251967914e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.1308828106848523e-05
Text_Embedding_Affine.0.weight grad: -8.640714879715183e-12
Text_Embedding_Affine.0.bias grad: -2.1586515908111892e-10
Text_Embedding_Affine.2.weight grad: -1.1679583689083728e-10
Text_Embedding_Affine.2.bias grad: -1.9085338863078505e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.9805364077369453e-17
Max value: 0.999976396560669
Mean value: 0.07983829081058502

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.9805364077369453e-17
Max value: 0.999976396560669
Mean value: 0.07983829081058502

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08963823318481445

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1425447314977646

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0717325210571289

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08963823318481445

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 24.720048904418945
Max value: 76.11547088623047
Mean value: 54.85074996948242

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 9.496954911311142e-18
Max value: 0.9999806880950928
Mean value: 0.07943171262741089

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.496954911311142e-18
Max value: 0.9999806880950928
Mean value: 0.07943171262741089

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 9.496954911311142e-18
Max value: 0.9999806880950928
Mean value: 0.07943171262741089

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1428450345993042

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.7274856567382812
Max value: 1.2180628776550293
Mean value: 0.9997251629829407

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 24.720048904418945
Max value: 76.11547088623047
Mean value: 54.85074996948242

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -54.83497619628906
Max value: -54.83497619628906
Mean value: -54.83497619628906
sam_encoder.pos_embed grad: -3.6520808599505017e-09
sam_encoder.blocks.0.norm1.weight grad: 2.281763227074407e-05
sam_encoder.blocks.0.norm1.bias grad: 2.9361948691075668e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.187964812743303e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -8.702633635948587e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 9.483428016210382e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.6795597446161992e-07
sam_encoder.blocks.0.norm2.weight grad: 1.8472995861884556e-06
sam_encoder.blocks.0.norm2.bias grad: 2.130046368620242e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.2330347090028226e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.904407665482722e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.4436167248277343e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.282135028508492e-06
sam_encoder.blocks.1.norm1.weight grad: 3.372663513800944e-06
sam_encoder.blocks.1.norm1.bias grad: -3.7362583498179447e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.372693754499778e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 9.86047098194831e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.0965380826964974e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.2118979359220248e-06
sam_encoder.blocks.1.norm2.weight grad: 1.2032653103233315e-05
sam_encoder.blocks.1.norm2.bias grad: 1.758370672177989e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.22114453613176e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 3.0099815262474294e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.6203409813897451e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.1840367026015883e-07
sam_encoder.blocks.2.norm1.weight grad: 2.8088602448406164e-06
sam_encoder.blocks.2.norm1.bias grad: -6.177338946145028e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 3.7377371882030275e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 3.5485936678014696e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 8.082708973233821e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 8.560314199712593e-07
sam_encoder.blocks.2.norm2.weight grad: -3.991628545918502e-06
sam_encoder.blocks.2.norm2.bias grad: 1.0505929139981163e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.512447852292098e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -6.477844181063119e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.2325816644297447e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 5.687797965947539e-07
sam_encoder.blocks.3.norm1.weight grad: -6.119614226918202e-06
sam_encoder.blocks.3.norm1.bias grad: -4.7502458073722664e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.0342339414346498e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.144723331795831e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.3432419854761974e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.5234726308553945e-08
sam_encoder.blocks.3.norm2.weight grad: 8.956011697591748e-06
sam_encoder.blocks.3.norm2.bias grad: 6.036989361746237e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.241131243063137e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.955680429295171e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.8053026451525511e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 6.766404112568125e-07
sam_encoder.blocks.4.norm1.weight grad: -6.597025276278146e-06
sam_encoder.blocks.4.norm1.bias grad: 1.5570246603147098e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -4.806724973605014e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.3325283134690835e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.7472856345411856e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.9920268812256836e-07
sam_encoder.blocks.4.norm2.weight grad: -9.494182449998334e-06
sam_encoder.blocks.4.norm2.bias grad: -9.473069439991377e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.195315225137165e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.3736427010589978e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.20674008030619e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.21899503824352e-07
sam_encoder.blocks.5.norm1.weight grad: -5.285333827487193e-06
sam_encoder.blocks.5.norm1.bias grad: -4.099290435988223e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -5.737772426073207e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.8222248147358187e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.148009059510514e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.465377292537596e-06
sam_encoder.blocks.5.norm2.weight grad: -3.0420496841543354e-06
sam_encoder.blocks.5.norm2.bias grad: -5.26830081071239e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -6.823763669672189e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.597414893694804e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 6.083988068894541e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.35339040652616e-07
sam_encoder.blocks.6.norm1.weight grad: 1.2518817129603121e-06
sam_encoder.blocks.6.norm1.bias grad: 3.573582716853707e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.01205176356234e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -3.024375132554269e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.2453290310077136e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.415107355271175e-07
sam_encoder.blocks.6.norm2.weight grad: -1.815048378261963e-08
sam_encoder.blocks.6.norm2.bias grad: -1.43383692829957e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.5328775759826385e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.3164432743906218e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 9.276778882849612e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.3847985630709445e-07
sam_encoder.blocks.7.norm1.weight grad: 4.999567863706034e-06
sam_encoder.blocks.7.norm1.bias grad: 1.1171152891620295e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.135919425607426e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.8413214775137021e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.1713331079808995e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.7108316541225577e-08
sam_encoder.blocks.7.norm2.weight grad: 1.7600971204956295e-06
sam_encoder.blocks.7.norm2.bias grad: 1.005903868644964e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.07852326639113e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 9.802279237192124e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -8.620786218216381e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -8.583398880546156e-07
sam_encoder.blocks.8.norm1.weight grad: 5.7570573517296e-06
sam_encoder.blocks.8.norm1.bias grad: -1.0953007176794927e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.0792224353936035e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 5.569204972744046e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.8406188903318252e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.298622237300151e-06
sam_encoder.blocks.8.norm2.weight grad: 1.8749824448605068e-06
sam_encoder.blocks.8.norm2.bias grad: -8.040854027058231e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 2.8109943741583265e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.7138935390903498e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 6.255497169149749e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.4812151145379175e-07
sam_encoder.blocks.9.norm1.weight grad: 6.359151711876621e-07
sam_encoder.blocks.9.norm1.bias grad: 3.773966170683707e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.2930674984090729e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.0364890385972103e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 3.7698004007324926e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -3.38746048100802e-07
sam_encoder.blocks.9.norm2.weight grad: 2.6201901164313313e-06
sam_encoder.blocks.9.norm2.bias grad: -8.936424364947015e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.1863235108176013e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.4358427051774925e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.6261424207186792e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -7.263890324793465e-07
sam_encoder.blocks.10.norm1.weight grad: 5.794574462925084e-06
sam_encoder.blocks.10.norm1.bias grad: 3.2349620937566215e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.9852175177657045e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.5970690583344549e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.7293928067374509e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.507425033916661e-07
sam_encoder.blocks.10.norm2.weight grad: 4.673933290177956e-06
sam_encoder.blocks.10.norm2.bias grad: -5.375054570322391e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.2365448987548007e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.2360699201963143e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.7387273487656785e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.5224109612718166e-07
sam_encoder.blocks.11.norm1.weight grad: 9.810086339712143e-06
sam_encoder.blocks.11.norm1.bias grad: -6.594518708880059e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.0810274488903815e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 6.054918912923313e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.486384801159147e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.0235419267701218e-06
sam_encoder.blocks.11.norm2.weight grad: 3.884123998432187e-06
sam_encoder.blocks.11.norm2.bias grad: -1.3308462598615733e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.537061274982989e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 7.58031433178985e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.122269612911623e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.610037234760057e-08
sam_encoder.neck.conv1.trainable_scale grad: -3.436107363086194e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.9784632968367077e-05
sam_encoder.neck.conv2.trainable_scale grad: -6.728018888679799e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.540659650345333e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00011914489732589573
mask_decoder.transformer.layers.0.norm1.bias grad: -4.942558007314801e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.002575415186583996
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00010467797983437777
mask_decoder.transformer.layers.0.norm3.weight grad: -7.88777251727879e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.5115929272724316e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.0001017531321849674
mask_decoder.transformer.layers.0.norm4.bias grad: -6.317681254586205e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.481746858189581e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 2.558554115239531e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -8.542186697013676e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -3.159111656714231e-07
mask_decoder.transformer.layers.1.norm3.weight grad: 3.650314101832919e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.160618532798253e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.3821463148342445e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00016665799194015563
mask_decoder.transformer.norm_final_attn.weight grad: 2.483195885361056e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.2705491826636717e-05
Text_Embedding_Affine.0.weight grad: -1.0202953933113879e-11
Text_Embedding_Affine.0.bias grad: -2.9516095123582886e-10
Text_Embedding_Affine.2.weight grad: 2.731013332146759e-12
Text_Embedding_Affine.2.bias grad: 1.811369202187052e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0366879577006216e-09
Max value: 0.9991872906684875
Mean value: 0.07996456325054169

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0366879577006216e-09
Max value: 0.9991872906684875
Mean value: 0.07996456325054169

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07917308807373047

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.942869186401367
Max value: -1.1920928244535389e-07
Mean value: -0.11020129919052124

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06441783905029297

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07917308807373047

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 46.013031005859375
Max value: 87.16493225097656
Mean value: 58.88853454589844

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.1173216796223073e-09
Max value: 0.9992006421089172
Mean value: 0.07935436069965363

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1173216796223073e-09
Max value: 0.9992006421089172
Mean value: 0.07935436069965363

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1173216796223073e-09
Max value: 0.9992006421089172
Mean value: 0.07935436069965363

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.91207504272461
Max value: -1.1920928244535389e-07
Mean value: -0.11020341515541077

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8768840432167053
Max value: 1.0920196771621704
Mean value: 1.0000097751617432

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 46.013031005859375
Max value: 87.16493225097656
Mean value: 58.88853454589844

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.89107131958008
Max value: -58.89107131958008
Mean value: -58.89107131958008
sam_encoder.pos_embed grad: 1.1951936662590867e-10
sam_encoder.blocks.0.norm1.weight grad: -2.9319293389562517e-05
sam_encoder.blocks.0.norm1.bias grad: -3.0060429708100855e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.8954459594388027e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.3925210257402796e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -8.471813544019824e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -7.416676339744299e-07
sam_encoder.blocks.0.norm2.weight grad: 1.7506801668787375e-05
sam_encoder.blocks.0.norm2.bias grad: -4.1746545321075246e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.2285461707506329e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 5.268220320431283e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.5820822884270456e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.4359881030686665e-06
sam_encoder.blocks.1.norm1.weight grad: 3.702148660522653e-06
sam_encoder.blocks.1.norm1.bias grad: 7.948968232085463e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.468063813576009e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.5512315460218815e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.944972821860574e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.851041012443602e-06
sam_encoder.blocks.1.norm2.weight grad: -8.362886546819936e-06
sam_encoder.blocks.1.norm2.bias grad: 2.323071839782642e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -7.848014320188668e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -4.5780484470014926e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.7592587028048e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.4801490781101165e-06
sam_encoder.blocks.2.norm1.weight grad: -1.710378819552716e-05
sam_encoder.blocks.2.norm1.bias grad: 6.338904768199427e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.2595175576279871e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.8640324671869166e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.619722509843996e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.663087682070909e-06
sam_encoder.blocks.2.norm2.weight grad: -2.5863071186904563e-06
sam_encoder.blocks.2.norm2.bias grad: -3.71828582501621e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.263000846549403e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -9.03249528505512e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.870824447309133e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.5200132565951208e-06
sam_encoder.blocks.3.norm1.weight grad: 5.706819138140418e-06
sam_encoder.blocks.3.norm1.bias grad: 2.866790964617394e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.027562686635065e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.187123530144163e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.766984036701615e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.051287876587594e-06
sam_encoder.blocks.3.norm2.weight grad: -6.777965154469712e-06
sam_encoder.blocks.3.norm2.bias grad: -7.0548535404668655e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -7.797161742928438e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.7572160686540883e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -9.000365821520973e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -7.918355322544812e-07
sam_encoder.blocks.4.norm1.weight grad: 1.5059165889397264e-05
sam_encoder.blocks.4.norm1.bias grad: -1.609233891031181e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 7.482718501705676e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.757715608619037e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.7963673094054684e-08
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.254483549928409e-06
sam_encoder.blocks.4.norm2.weight grad: -8.067207090789452e-06
sam_encoder.blocks.4.norm2.bias grad: -2.170007746826741e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -8.389475624426268e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.403780399617972e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.3424194094113773e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -4.2381506659694423e-07
sam_encoder.blocks.5.norm1.weight grad: 1.2792252164217643e-05
sam_encoder.blocks.5.norm1.bias grad: -6.1696423472312745e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 9.051622328115627e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.940274837077595e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.3351441339182202e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.5167482817778364e-06
sam_encoder.blocks.5.norm2.weight grad: -6.117744760558708e-06
sam_encoder.blocks.5.norm2.bias grad: 4.7546518544550054e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.305197191773914e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.5312533605538192e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 7.77429136178398e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.356674819267937e-07
sam_encoder.blocks.6.norm1.weight grad: -2.7952319214819e-06
sam_encoder.blocks.6.norm1.bias grad: -4.662395895138616e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -6.774823191335599e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.0818455393746262e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.3860271792509593e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.152124013970024e-06
sam_encoder.blocks.6.norm2.weight grad: -1.5371296058219741e-06
sam_encoder.blocks.6.norm2.bias grad: 3.79845346287766e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.612011823861394e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.3884613281334168e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.397015580550942e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.7047335038332676e-07
sam_encoder.blocks.7.norm1.weight grad: -3.8751395550207235e-06
sam_encoder.blocks.7.norm1.bias grad: -7.118273970263544e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.4618228710314725e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.7677848518360406e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.1366304281400517e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -5.308917820912029e-07
sam_encoder.blocks.7.norm2.weight grad: 2.483194236901909e-07
sam_encoder.blocks.7.norm2.bias grad: 9.545047987558064e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -9.716825388750294e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -9.57095721787482e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.6260153756775253e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.1138156423839973e-06
sam_encoder.blocks.8.norm1.weight grad: -1.5424773209815612e-06
sam_encoder.blocks.8.norm1.bias grad: -7.448592782566266e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.4585870289351988e-08
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.0537611905856465e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.887441380356904e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.692302587092854e-06
sam_encoder.blocks.8.norm2.weight grad: -1.425436494173482e-06
sam_encoder.blocks.8.norm2.bias grad: 1.4949640672057285e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.533585984565434e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.2761893231072463e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.856168919151969e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 5.079444918010267e-07
sam_encoder.blocks.9.norm1.weight grad: -6.205325462360634e-07
sam_encoder.blocks.9.norm1.bias grad: -3.3469859772594646e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.897449465104728e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.4299655504146358e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.0434123396407813e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.0884067336291992e-07
sam_encoder.blocks.9.norm2.weight grad: -4.749613708554534e-06
sam_encoder.blocks.9.norm2.bias grad: 1.0315217195966397e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.846730007557198e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.741425987551338e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.1079367229503987e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 5.519066235137871e-07
sam_encoder.blocks.10.norm1.weight grad: -1.9098852135357447e-06
sam_encoder.blocks.10.norm1.bias grad: 8.815967476039077e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.816985215758905e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -9.673489103079191e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.4924387414794182e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -8.897974339561188e-07
sam_encoder.blocks.10.norm2.weight grad: -7.5055845627503e-06
sam_encoder.blocks.10.norm2.bias grad: -1.2375139135656354e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.7518507269851398e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.2858685042592697e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.3195926246444287e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.2750894856926607e-07
sam_encoder.blocks.11.norm1.weight grad: -1.5794055798323825e-05
sam_encoder.blocks.11.norm1.bias grad: 1.0715260714277974e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.163286746461381e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -3.094082501320372e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.3995862673255033e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.6220391785282118e-07
sam_encoder.blocks.11.norm2.weight grad: -5.693211278412491e-06
sam_encoder.blocks.11.norm2.bias grad: -1.4020342860021628e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.13633711609873e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.4114237956164288e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 6.120225748418306e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.0609205958189705e-07
sam_encoder.neck.conv1.trainable_scale grad: 3.616169124143198e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.608579623280093e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.4878382899041753e-06
sam_encoder.neck.conv2.trainable_shift grad: -3.1793253583600745e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00011632977111730725
mask_decoder.transformer.layers.0.norm1.bias grad: 2.3965731088537723e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0044334218837320805
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00018927015480585396
mask_decoder.transformer.layers.0.norm3.weight grad: 8.488900493830442e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.4705967007321306e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00013515334285330027
mask_decoder.transformer.layers.0.norm4.bias grad: 2.282466084579937e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -1.3722859875997528e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.37498534261249e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00013301959552336484
mask_decoder.transformer.layers.1.norm2.bias grad: -9.269824658986181e-06
mask_decoder.transformer.layers.1.norm3.weight grad: -2.4247492547146976e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.8839857148122974e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 6.407443288480863e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0002084387233480811
mask_decoder.transformer.norm_final_attn.weight grad: -2.826346417350578e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.7922575352713466e-05
Text_Embedding_Affine.0.weight grad: -7.844658950206806e-12
Text_Embedding_Affine.0.bias grad: -4.0455139238559923e-10
Text_Embedding_Affine.2.weight grad: 1.6218991427674467e-11
Text_Embedding_Affine.2.bias grad: -1.8659960915101692e-05
Epoch 25 finished with average loss: -57.2292
Epoch 26/39
----------
Epoch 26:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 26:   0%|          | 0/3 [00:00<?, ?it/s, loss=-54.1]Epoch 26:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.07it/s, loss=-54.1]Epoch 26:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.07it/s, loss=-56.6]Epoch 26:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-56.6]Epoch 26:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-58.8]Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.31it/s, loss=-58.8]/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.361521032172135e-11
Max value: 0.9998844861984253
Mean value: 0.0766739547252655

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.361521032172135e-11
Max value: 0.9998844861984253
Mean value: 0.0766739547252655

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07439804077148438

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12127427756786346

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06348896026611328

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07439804077148438

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 45.22148132324219
Max value: 64.37421417236328
Mean value: 54.054901123046875

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.361521032172135e-11
Max value: 0.9998844861984253
Mean value: 0.0766739547252655

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.361521032172135e-11
Max value: 0.9998844861984253
Mean value: 0.0766739547252655

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.361521032172135e-11
Max value: 0.9998844861984253
Mean value: 0.0766739547252655

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12127427756786346

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 45.22148132324219
Max value: 64.37421417236328
Mean value: 54.054901123046875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -54.05595779418945
Max value: -54.05595779418945
Mean value: -54.05595779418945
sam_encoder.pos_embed grad: 1.7871010227210604e-09
sam_encoder.blocks.0.norm1.weight grad: -3.0060469725867733e-05
sam_encoder.blocks.0.norm1.bias grad: -7.205016117950436e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.8606443669996224e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.044601442070416e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.9126825634430134e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.3299135162014863e-06
sam_encoder.blocks.0.norm2.weight grad: -1.4441611710935831e-05
sam_encoder.blocks.0.norm2.bias grad: 1.373232748846931e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 7.470789569197223e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.710891516879201e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.3321659025677945e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.3336521078599617e-06
sam_encoder.blocks.1.norm1.weight grad: 2.1951916551188333e-06
sam_encoder.blocks.1.norm1.bias grad: 1.0849302270798944e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.361249234032584e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.0890577161480905e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.187730039324379e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -2.2084232114139013e-06
sam_encoder.blocks.1.norm2.weight grad: 1.167211621577735e-06
sam_encoder.blocks.1.norm2.bias grad: -7.019100848992821e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.5165245486059575e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.3973727770207915e-08
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -6.724851118633524e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.2549476195999887e-06
sam_encoder.blocks.2.norm1.weight grad: -6.183723598951474e-06
sam_encoder.blocks.2.norm1.bias grad: -1.020289118969231e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.7757594074937515e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.3545821957450244e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.345900722706574e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.5595454669892206e-06
sam_encoder.blocks.2.norm2.weight grad: 1.0685826964618172e-05
sam_encoder.blocks.2.norm2.bias grad: -1.2080203305231407e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 4.964291292708367e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 6.675587655990967e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -5.211473308008863e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.4895413187332451e-06
sam_encoder.blocks.3.norm1.weight grad: -5.008914286008803e-06
sam_encoder.blocks.3.norm1.bias grad: -4.415734110807534e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -6.155751179903746e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.5596391449435032e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.868270485123503e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.251172645628685e-06
sam_encoder.blocks.3.norm2.weight grad: 1.2804980542568956e-06
sam_encoder.blocks.3.norm2.bias grad: 1.1353662330293446e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.177303196684079e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.7211775684700115e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.1384192194773277e-08
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -5.850854449818144e-07
sam_encoder.blocks.4.norm1.weight grad: 4.740122676594183e-06
sam_encoder.blocks.4.norm1.bias grad: -3.7443815017468296e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.8899927454185672e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.5711741525592515e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.1447484666859964e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.7176270123163704e-07
sam_encoder.blocks.4.norm2.weight grad: -6.505299097625539e-06
sam_encoder.blocks.4.norm2.bias grad: -2.05290962185245e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.994396815367509e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.7812985788623337e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -9.064175969797361e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.0028958286056877e-06
sam_encoder.blocks.5.norm1.weight grad: 5.107207243781886e-07
sam_encoder.blocks.5.norm1.bias grad: -1.3776572814094834e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.257729410208412e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -9.052695304490044e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.717223196668783e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 7.176872713898774e-07
sam_encoder.blocks.5.norm2.weight grad: -7.486606591555756e-06
sam_encoder.blocks.5.norm2.bias grad: 4.2136889533139765e-09
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.88185514768702e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.4690560874441871e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.5283446828107117e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.161628564565035e-07
sam_encoder.blocks.6.norm1.weight grad: -2.23358983930666e-06
sam_encoder.blocks.6.norm1.bias grad: -2.587539256637683e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.4814495443715714e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.2846148201315373e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.795889930799603e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.361282321951876e-07
sam_encoder.blocks.6.norm2.weight grad: 2.778548605419928e-06
sam_encoder.blocks.6.norm2.bias grad: 3.791057679336518e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.5893955353240017e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 5.84536735459551e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.5446255474671489e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.871997584312339e-07
sam_encoder.blocks.7.norm1.weight grad: 6.316382723525749e-07
sam_encoder.blocks.7.norm1.bias grad: 4.940044959766965e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.434569629869657e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.708791839722835e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -5.796466098217934e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.0746337011369178e-06
sam_encoder.blocks.7.norm2.weight grad: 1.5116996792130521e-06
sam_encoder.blocks.7.norm2.bias grad: 2.403511132342828e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.216952677576046e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.4601447162476688e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -8.41662654238462e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.1633456153958832e-07
sam_encoder.blocks.8.norm1.weight grad: 1.0492330147826578e-05
sam_encoder.blocks.8.norm1.bias grad: -1.446096575818956e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 8.217964932555333e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.766664126989781e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.0136600394616835e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.8786463818496486e-08
sam_encoder.blocks.8.norm2.weight grad: -3.723696408997057e-06
sam_encoder.blocks.8.norm2.bias grad: 1.093636797122599e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.7562091418076307e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -7.587629511363048e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.0605331226543058e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.702464017711463e-07
sam_encoder.blocks.9.norm1.weight grad: -1.7502413811598672e-06
sam_encoder.blocks.9.norm1.bias grad: 2.1229907076758536e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.990695065818727e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -8.790192964625021e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.6014512311812723e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.0031903912022244e-06
sam_encoder.blocks.9.norm2.weight grad: -6.001816359457735e-07
sam_encoder.blocks.9.norm2.bias grad: 6.797616691756048e-08
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.2797536328434944e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.4749928090604953e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.0231331276931996e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 7.549303404630336e-08
sam_encoder.blocks.10.norm1.weight grad: 2.518303858778381e-07
sam_encoder.blocks.10.norm1.bias grad: 9.967073992811493e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.913005113849067e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.395134970356594e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.9834629938486614e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.3191562326683197e-07
sam_encoder.blocks.10.norm2.weight grad: -6.012279300193768e-06
sam_encoder.blocks.10.norm2.bias grad: -6.912379717505246e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.5408829717198387e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.4816669136052951e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -8.449289339296229e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.000311608047923e-07
sam_encoder.blocks.11.norm1.weight grad: 8.511038686265238e-06
sam_encoder.blocks.11.norm1.bias grad: 1.668131858423294e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.3468910512747243e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.024186743365135e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 9.369656339686117e-08
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.3961630429548677e-07
sam_encoder.blocks.11.norm2.weight grad: -1.414814505551476e-07
sam_encoder.blocks.11.norm2.bias grad: 4.3788531911559403e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.5370871981067467e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -4.7607358055756777e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.617644838665001e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.535613460480818e-08
sam_encoder.neck.conv1.trainable_scale grad: -9.438790584681556e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.2367634553811513e-05
sam_encoder.neck.conv2.trainable_scale grad: -3.7671998143196106e-07
sam_encoder.neck.conv2.trainable_shift grad: 3.4305423469049856e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00014846553676761687
mask_decoder.transformer.layers.0.norm1.bias grad: 1.5579280443489552e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0006919121369719505
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0002691340632736683
mask_decoder.transformer.layers.0.norm3.weight grad: 9.644906094763428e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -1.1472060577943921e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 1.7474796550231986e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 4.011179044027813e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.0179799321340397e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -8.041280125326011e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00017407527775503695
mask_decoder.transformer.layers.1.norm2.bias grad: 7.228167669381946e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.192229243926704e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.67541033483576e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 1.6011545085348189e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -9.697958739707246e-05
mask_decoder.transformer.norm_final_attn.weight grad: 3.5222828955738805e-06
mask_decoder.transformer.norm_final_attn.bias grad: 9.791381671675481e-06
Text_Embedding_Affine.0.weight grad: -6.170893657175824e-12
Text_Embedding_Affine.0.bias grad: -4.914743056971815e-10
Text_Embedding_Affine.2.weight grad: 2.2268324337271217e-11
Text_Embedding_Affine.2.bias grad: -2.4596211005700752e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.422808383103195e-15
Max value: 0.9997584223747253
Mean value: 0.08741483092308044

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.422808383103195e-15
Max value: 0.9997584223747253
Mean value: 0.08741483092308044

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08525753021240234

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1388634592294693

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07637596130371094

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08525753021240234

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 39.43670654296875
Max value: 87.49034118652344
Mean value: 59.105018615722656

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.107462252005156e-15
Max value: 0.9997559189796448
Mean value: 0.0870174765586853

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.107462252005156e-15
Max value: 0.9997559189796448
Mean value: 0.0870174765586853

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.107462252005156e-15
Max value: 0.9997559189796448
Mean value: 0.0870174765586853

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13856123387813568

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9065308570861816
Max value: 1.1534587144851685
Mean value: 1.0003082752227783

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 39.43670654296875
Max value: 87.49034118652344
Mean value: 59.105018615722656

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.119842529296875
Max value: -59.119842529296875
Mean value: -59.119842529296875
sam_encoder.pos_embed grad: 2.2390806986294365e-09
sam_encoder.blocks.0.norm1.weight grad: 3.263536200392991e-05
sam_encoder.blocks.0.norm1.bias grad: 4.641731266019633e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.2323192752082832e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.645953489060048e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -7.479716714442475e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.935458429779828e-08
sam_encoder.blocks.0.norm2.weight grad: -2.8506110538728535e-06
sam_encoder.blocks.0.norm2.bias grad: -7.142871618270874e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.5060291843838058e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 9.521922038402408e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 5.122277798363939e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.7002886326954467e-06
sam_encoder.blocks.1.norm1.weight grad: 2.2515872842632234e-05
sam_encoder.blocks.1.norm1.bias grad: -1.5304165117413504e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.3207718438934535e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 5.438927246359526e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.9613098629633896e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 7.629399760844535e-07
sam_encoder.blocks.1.norm2.weight grad: -4.566987627185881e-06
sam_encoder.blocks.1.norm2.bias grad: 1.492815681558568e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -8.133478331728838e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.3755015970673412e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.8604971046443097e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.6585940961231245e-06
sam_encoder.blocks.2.norm1.weight grad: -4.4378589336702134e-06
sam_encoder.blocks.2.norm1.bias grad: -1.911769504658878e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -7.144966502892203e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -6.857588914499502e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.7544648421317106e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 4.5638927304025856e-07
sam_encoder.blocks.2.norm2.weight grad: -9.468307325732894e-06
sam_encoder.blocks.2.norm2.bias grad: 2.0234929252183065e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -6.605638191103935e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -9.133897833635274e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.281837158894632e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.965140820127999e-07
sam_encoder.blocks.3.norm1.weight grad: -4.323940629546996e-06
sam_encoder.blocks.3.norm1.bias grad: -2.0438201318029314e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.313065801397897e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.918117732202518e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.421423116378719e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -5.04839772474952e-06
sam_encoder.blocks.3.norm2.weight grad: 1.2478845746954903e-05
sam_encoder.blocks.3.norm2.bias grad: 6.491868589364458e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 8.040893590077758e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 4.498864655033685e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.6791639104194473e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.2219592210603878e-07
sam_encoder.blocks.4.norm1.weight grad: -3.745861704373965e-06
sam_encoder.blocks.4.norm1.bias grad: -5.433013939182274e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -9.21551418286981e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.8663702121557435e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.3887018894820358e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -6.271451411521412e-07
sam_encoder.blocks.4.norm2.weight grad: -1.2685171896009706e-05
sam_encoder.blocks.4.norm2.bias grad: -6.62630918668583e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.2503393008955754e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.917003363720141e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.530417188812862e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.155758465960389e-06
sam_encoder.blocks.5.norm1.weight grad: 9.670684448792599e-06
sam_encoder.blocks.5.norm1.bias grad: -1.5993240594980307e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 7.096612534951419e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 5.113760835229186e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.732509296445642e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.7463973733811144e-07
sam_encoder.blocks.5.norm2.weight grad: -1.0376865247962996e-05
sam_encoder.blocks.5.norm2.bias grad: -2.9385907964751823e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.495179721037857e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.496940952478326e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 9.227507575815252e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -8.859386753101717e-07
sam_encoder.blocks.6.norm1.weight grad: 8.779253221291583e-06
sam_encoder.blocks.6.norm1.bias grad: 5.45376224181382e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.414188424561871e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.4836249420113745e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.527401304381783e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.0642178242269438e-06
sam_encoder.blocks.6.norm2.weight grad: -1.522381353424862e-06
sam_encoder.blocks.6.norm2.bias grad: 4.067993359058164e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.8212800745895947e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.3369179302790144e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.924024329331587e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.266670039967721e-07
sam_encoder.blocks.7.norm1.weight grad: 8.789374987827614e-07
sam_encoder.blocks.7.norm1.bias grad: 2.273078280268237e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 8.476922630507033e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.2029541923984652e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.2147377219662303e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.448239453973656e-07
sam_encoder.blocks.7.norm2.weight grad: 1.0399137408967363e-06
sam_encoder.blocks.7.norm2.bias grad: -1.0870526239159517e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.1851518542680424e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.2843828446639236e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.707715959284542e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 5.4053771236795e-08
sam_encoder.blocks.8.norm1.weight grad: 1.0348466275900137e-05
sam_encoder.blocks.8.norm1.bias grad: -3.285346792836208e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 9.992831110139377e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.1039542136568343e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.6091825020557735e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -6.824408842476259e-07
sam_encoder.blocks.8.norm2.weight grad: 1.2403756954881828e-07
sam_encoder.blocks.8.norm2.bias grad: 2.397170192125486e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 9.591246907802997e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.2007501482003136e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.027956841426203e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.490719512275973e-07
sam_encoder.blocks.9.norm1.weight grad: -6.409872185031418e-06
sam_encoder.blocks.9.norm1.bias grad: 9.583616247255122e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -5.86543683311902e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -5.802961595691158e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.491196940150985e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.20112883475565e-09
sam_encoder.blocks.9.norm2.weight grad: -7.040859600238036e-06
sam_encoder.blocks.9.norm2.bias grad: 3.5952325561083853e-09
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.399591373134172e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.3366462755802786e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.1470906429167371e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -7.684760703341453e-07
sam_encoder.blocks.10.norm1.weight grad: 8.241437967626553e-07
sam_encoder.blocks.10.norm1.bias grad: -1.732063992676558e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.26685421264483e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.90336889874743e-08
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 9.715680562294438e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.5084050346558797e-06
sam_encoder.blocks.10.norm2.weight grad: -1.2780057659256272e-05
sam_encoder.blocks.10.norm2.bias grad: -6.853010745544452e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.188182619051076e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.955420197598869e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.5831741393412813e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.1822564829344628e-06
sam_encoder.blocks.11.norm1.weight grad: -3.6022174754180014e-06
sam_encoder.blocks.11.norm1.bias grad: -6.999147785791138e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.0081000709760701e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -3.5804470144285006e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 9.159170986094978e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.718513935131341e-07
sam_encoder.blocks.11.norm2.weight grad: -1.3026422493567225e-05
sam_encoder.blocks.11.norm2.bias grad: -5.374583338380035e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -5.326504378899699e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.638204705363023e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.5999355582607677e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -4.816623686565435e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.1042957339668646e-06
sam_encoder.neck.conv1.trainable_shift grad: -2.6193791200057603e-05
sam_encoder.neck.conv2.trainable_scale grad: 7.267899491125718e-07
sam_encoder.neck.conv2.trainable_shift grad: 3.165414454997517e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00010150452726520598
mask_decoder.transformer.layers.0.norm1.bias grad: 4.29452757089166e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0038158728275448084
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0001074564061127603
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00010998119978467003
mask_decoder.transformer.layers.0.norm3.bias grad: 4.087754859938286e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 7.087402627803385e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -6.956604920560494e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.223919000243768e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -3.826585270871874e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00014539354015141726
mask_decoder.transformer.layers.1.norm2.bias grad: 2.8038448363076895e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 1.0873419341805857e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.991929457290098e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.308544910396449e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -9.399470582138747e-05
mask_decoder.transformer.norm_final_attn.weight grad: 7.889750122558326e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.1257923688390292e-05
Text_Embedding_Affine.0.weight grad: -1.2633330145894739e-11
Text_Embedding_Affine.0.bias grad: 1.5152143428842635e-10
Text_Embedding_Affine.2.weight grad: 5.182259135705358e-11
Text_Embedding_Affine.2.bias grad: -1.4065331924939528e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.587458273836887e-10
Max value: 0.9980637431144714
Mean value: 0.11310920119285583

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.587458273836887e-10
Max value: 0.9980637431144714
Mean value: 0.11310920119285583

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09943866729736328

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.174389839172363
Max value: -1.1920928244535389e-07
Mean value: -0.13704439997673035

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10228633880615234

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09943866729736328

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 53.03143310546875
Max value: 71.66800689697266
Mean value: 63.241477966308594

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 6.455765921842271e-10
Max value: 0.9980740547180176
Mean value: 0.11269468069076538

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.455765921842271e-10
Max value: 0.9980740547180176
Mean value: 0.11269468069076538

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.455765921842271e-10
Max value: 0.9980740547180176
Mean value: 0.11269468069076538

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.114749908447266
Max value: -1.1920928244535389e-07
Mean value: -0.13720960915088654

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9094194769859314
Max value: 1.1079213619232178
Mean value: 0.9998450875282288

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 53.03143310546875
Max value: 71.66800689697266
Mean value: 63.241477966308594

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -63.2346076965332
Max value: -63.2346076965332
Mean value: -63.2346076965332
sam_encoder.pos_embed grad: 8.06598432490091e-09
sam_encoder.blocks.0.norm1.weight grad: -8.3443897892721e-05
sam_encoder.blocks.0.norm1.bias grad: -5.58890969841741e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -6.8397598624869715e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.870749088084267e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.0838033631443977e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.5977369685060694e-06
sam_encoder.blocks.0.norm2.weight grad: 3.936585198971443e-05
sam_encoder.blocks.0.norm2.bias grad: 3.841359102807473e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.242144546471536e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.6312080737843644e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.3995133233256638e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.077696833817754e-05
sam_encoder.blocks.1.norm1.weight grad: 5.570816938416101e-06
sam_encoder.blocks.1.norm1.bias grad: 1.8586497390060686e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.2183796570752747e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.8763173506595194e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.1313835784676485e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.773069915449014e-06
sam_encoder.blocks.1.norm2.weight grad: -4.1061383626583847e-07
sam_encoder.blocks.1.norm2.bias grad: -9.672823580331169e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.0553107131272554e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.6068255490608863e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.3815719285048544e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.385429752393975e-06
sam_encoder.blocks.2.norm1.weight grad: -4.687540240411181e-06
sam_encoder.blocks.2.norm1.bias grad: 5.431589670479298e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -6.0214215409359895e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.0760336408566218e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.819499619974522e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.256636879697908e-06
sam_encoder.blocks.2.norm2.weight grad: -2.9765665203740355e-06
sam_encoder.blocks.2.norm2.bias grad: 6.07008405495435e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.782166226708796e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.657417207454273e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.2343100024736486e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.813103830907494e-06
sam_encoder.blocks.3.norm1.weight grad: -6.58838871459011e-06
sam_encoder.blocks.3.norm1.bias grad: 2.9078273655613884e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -9.718576620798558e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.6057991817651782e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -6.717621545249131e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -5.099750524095725e-06
sam_encoder.blocks.3.norm2.weight grad: -5.024979145673569e-06
sam_encoder.blocks.3.norm2.bias grad: -3.817456672550179e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -6.139932338555809e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -7.262182180056698e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.38951792602893e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.1420677310525207e-06
sam_encoder.blocks.4.norm1.weight grad: 3.818338427663548e-06
sam_encoder.blocks.4.norm1.bias grad: -2.753208264039131e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.651303930178983e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.4830014783437946e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.3004246284253895e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.0166636457142886e-06
sam_encoder.blocks.4.norm2.weight grad: 7.3039882408920676e-06
sam_encoder.blocks.4.norm2.bias grad: 1.9869853531417903e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -7.729277058388107e-07
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -9.248469723388553e-08
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.888053015543846e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -9.497163659943908e-07
sam_encoder.blocks.5.norm1.weight grad: -4.097918804291112e-07
sam_encoder.blocks.5.norm1.bias grad: -1.1453892511781305e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.399318408512045e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.661225551037205e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -5.801064162369585e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 7.234248187160119e-07
sam_encoder.blocks.5.norm2.weight grad: -3.6714777706947643e-06
sam_encoder.blocks.5.norm2.bias grad: 7.781858585076407e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.5027297851920594e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.273874302882177e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 5.402661713560519e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 7.359350888691552e-07
sam_encoder.blocks.6.norm1.weight grad: 5.061434649178409e-07
sam_encoder.blocks.6.norm1.bias grad: -7.114840173017001e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -5.02409193359199e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 6.457568701989658e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.0613962331262883e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -9.375723379889678e-07
sam_encoder.blocks.6.norm2.weight grad: 2.6541138140601106e-06
sam_encoder.blocks.6.norm2.bias grad: 4.523851202975493e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -7.681759939259791e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.981084202881902e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.5803178712303634e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.972673425778339e-07
sam_encoder.blocks.7.norm1.weight grad: -1.2595392036018893e-05
sam_encoder.blocks.7.norm1.bias grad: -1.1518220155437575e-08
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.0581027709122282e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.6989065392845077e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -4.935310698783724e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.869741820177296e-06
sam_encoder.blocks.7.norm2.weight grad: -5.393291758082341e-06
sam_encoder.blocks.7.norm2.bias grad: 5.248879233477055e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -4.185854777460918e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.610942258092109e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.70798692428798e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 7.989738151081838e-07
sam_encoder.blocks.8.norm1.weight grad: -9.404124284628779e-06
sam_encoder.blocks.8.norm1.bias grad: 2.623116301947448e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -8.88502017915016e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -3.968744749727193e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -7.36348101781914e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -5.891375622013584e-06
sam_encoder.blocks.8.norm2.weight grad: -7.934212590043899e-06
sam_encoder.blocks.8.norm2.bias grad: 7.013549065959523e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -8.092155439953785e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -5.030140528106131e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.1417075711506186e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 6.879190550534986e-09
sam_encoder.blocks.9.norm1.weight grad: -5.205103661864996e-06
sam_encoder.blocks.9.norm1.bias grad: -7.972676030476578e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -5.3702929108112585e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -3.2417310649179853e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.7072751461455482e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.774601951699879e-07
sam_encoder.blocks.9.norm2.weight grad: -9.505005436949432e-06
sam_encoder.blocks.9.norm2.bias grad: 2.95061084898407e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -9.358154784422368e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.170642114331713e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.6892000682419166e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.5171645979280584e-07
sam_encoder.blocks.10.norm1.weight grad: -6.279198714764789e-06
sam_encoder.blocks.10.norm1.bias grad: -5.795178594780737e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.910744337394135e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.9898088794434443e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.087412212858908e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.3063449841865804e-06
sam_encoder.blocks.10.norm2.weight grad: -1.580847310833633e-05
sam_encoder.blocks.10.norm2.bias grad: -2.8173708415124565e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.45086105982773e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.192939741187729e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.626798559253075e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 3.972390771878054e-08
sam_encoder.blocks.11.norm1.weight grad: -1.556604911456816e-05
sam_encoder.blocks.11.norm1.bias grad: 1.3562548701884225e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.925082642628695e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.402371243690141e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.4083686892263358e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -9.538059657643316e-07
sam_encoder.blocks.11.norm2.weight grad: -1.4825716789346188e-05
sam_encoder.blocks.11.norm2.bias grad: -1.913076630444266e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -7.620324140589219e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.105166342720622e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -6.499355436062615e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.748550684827933e-07
sam_encoder.neck.conv1.trainable_scale grad: 9.41137841437012e-07
sam_encoder.neck.conv1.trainable_shift grad: -6.148978172859643e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.151769538410008e-06
sam_encoder.neck.conv2.trainable_shift grad: -2.4439259505015798e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 8.985651948023587e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 1.308220817008987e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0044506145641207695
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00025861698668450117
mask_decoder.transformer.layers.0.norm3.weight grad: 8.349577547051013e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.8097187421517447e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -8.733735012356192e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 4.6513382585544605e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -3.172499873471679e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -3.058812353629037e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0001228774490300566
mask_decoder.transformer.layers.1.norm2.bias grad: 2.506535020074807e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -3.6339264624984935e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -6.153498361527454e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 1.2020120266242884e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00016141566447913647
mask_decoder.transformer.norm_final_attn.weight grad: 1.9336489458510187e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.184157736133784e-05
Text_Embedding_Affine.0.weight grad: 1.7812536385122812e-12
Text_Embedding_Affine.0.bias grad: -6.2443550330471e-11
Text_Embedding_Affine.2.weight grad: 2.663634417199301e-11
Text_Embedding_Affine.2.bias grad: -9.066590791917406e-06
Epoch 26 finished with average loss: -58.8035
Epoch 27/39
----------
Epoch 27:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 27:   0%|          | 0/3 [00:00<?, ?it/s, loss=-58.7]Epoch 27:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.01it/s, loss=-58.7]Epoch 27:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.01it/s, loss=-56.1]Epoch 27:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.60it/s, loss=-56.1]Epoch 27:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.60it/s, loss=-58.7]Epoch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.25it/s, loss=-58.7]/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.6244618091009258e-14
Max value: 0.9998799562454224
Mean value: 0.08435752987861633

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6244618091009258e-14
Max value: 0.9998799562454224
Mean value: 0.08435752987861633

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09240388870239258

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1330682337284088

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07516050338745117

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09240388870239258

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 31.887908935546875
Max value: 75.42926788330078
Mean value: 58.71744918823242

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.6244618091009258e-14
Max value: 0.9998799562454224
Mean value: 0.08435752987861633

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6244618091009258e-14
Max value: 0.9998799562454224
Mean value: 0.08435752987861633

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.6244618091009258e-14
Max value: 0.9998799562454224
Mean value: 0.08435752987861633

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1330682337284088

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 31.887908935546875
Max value: 75.42926788330078
Mean value: 58.71744918823242

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.71855545043945
Max value: -58.71855545043945
Mean value: -58.71855545043945
sam_encoder.pos_embed grad: -6.316315914745019e-09
sam_encoder.blocks.0.norm1.weight grad: -4.033818549942225e-05
sam_encoder.blocks.0.norm1.bias grad: 1.7340116755804047e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.181795247859554e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.522816089367552e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.9441548576869536e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -6.365444278344512e-07
sam_encoder.blocks.0.norm2.weight grad: 9.323615813627839e-06
sam_encoder.blocks.0.norm2.bias grad: 4.6696484787389636e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.2692328709817957e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -8.357249498658348e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.721337321214378e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -9.19757985684555e-06
sam_encoder.blocks.1.norm1.weight grad: -9.221430445904844e-06
sam_encoder.blocks.1.norm1.bias grad: 5.67197275813669e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.003457777595031e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -8.807698459456503e-10
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 4.514922238740837e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 3.6171200008539017e-06
sam_encoder.blocks.1.norm2.weight grad: 2.810117439366877e-05
sam_encoder.blocks.1.norm2.bias grad: -3.7748782233393285e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.1147441909997724e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.3104128104023403e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.3999242582940497e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 7.700828064116649e-07
sam_encoder.blocks.2.norm1.weight grad: -6.581548859685427e-06
sam_encoder.blocks.2.norm1.bias grad: -7.325440378735948e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -5.410300218500197e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.3162853065296076e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.91894457404851e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.164471081618103e-06
sam_encoder.blocks.2.norm2.weight grad: 4.904599791188957e-06
sam_encoder.blocks.2.norm2.bias grad: -1.2699357284873258e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 4.899245141132269e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 8.40242009303438e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 7.255485797941219e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 5.951969228590315e-07
sam_encoder.blocks.3.norm1.weight grad: 6.504287739517167e-06
sam_encoder.blocks.3.norm1.bias grad: -7.487396942451596e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 2.8047620617144275e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 5.91733623878099e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 2.0599882191163488e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 2.2451501990872202e-06
sam_encoder.blocks.3.norm2.weight grad: 8.170226465153974e-06
sam_encoder.blocks.3.norm2.bias grad: 2.079848854918964e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 6.62760703562526e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.3361076273431536e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.446063252951717e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 7.632974643456691e-07
sam_encoder.blocks.4.norm1.weight grad: 1.218224315380212e-05
sam_encoder.blocks.4.norm1.bias grad: -6.60341697766853e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 5.161059561942238e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.2249474821146578e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 4.8712022362451535e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 4.762597200169694e-06
sam_encoder.blocks.4.norm2.weight grad: -2.2061989511712454e-05
sam_encoder.blocks.4.norm2.bias grad: -2.4157630832633004e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.6017318557715043e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -7.03115074429661e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.0333334254682995e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 4.860137323703384e-07
sam_encoder.blocks.5.norm1.weight grad: 4.628670012607472e-06
sam_encoder.blocks.5.norm1.bias grad: -1.6951880752458237e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.4444843827732257e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.5002567579358583e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.797652089408075e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.127447231714541e-07
sam_encoder.blocks.5.norm2.weight grad: -5.45868715562392e-06
sam_encoder.blocks.5.norm2.bias grad: -8.005177733139135e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.8591989601191017e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -5.687682005373063e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.05002152142697e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -4.293129620691616e-07
sam_encoder.blocks.6.norm1.weight grad: 3.426939201744972e-06
sam_encoder.blocks.6.norm1.bias grad: 4.928413545712829e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 6.970590220589656e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -6.224237125707077e-08
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.0619889962981688e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.024305106511747e-06
sam_encoder.blocks.6.norm2.weight grad: -3.0672999855596572e-06
sam_encoder.blocks.6.norm2.bias grad: -3.99494138036971e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -2.7200171643926296e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.5763987448735861e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.4430714827540214e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -3.096633349741751e-07
sam_encoder.blocks.7.norm1.weight grad: 9.579502147971652e-06
sam_encoder.blocks.7.norm1.bias grad: 1.2641187367989914e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 4.6153782022884116e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.213768311776221e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.620998546059127e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.883750079898164e-07
sam_encoder.blocks.7.norm2.weight grad: 4.348802917775174e-07
sam_encoder.blocks.7.norm2.bias grad: -1.8875242631111178e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 9.775378657650435e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.331223640794633e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.3597840506918146e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.2850850907852873e-06
sam_encoder.blocks.8.norm1.weight grad: 1.1705669749062508e-05
sam_encoder.blocks.8.norm1.bias grad: -9.03956333786482e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 8.866474672686309e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.6279244593752082e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 3.2392667890235316e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.2142530724522658e-06
sam_encoder.blocks.8.norm2.weight grad: -2.733183235292813e-09
sam_encoder.blocks.8.norm2.bias grad: -7.808902751094138e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.303369288052636e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.5282141652714927e-09
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 7.068365448503755e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.01749968357035e-07
sam_encoder.blocks.9.norm1.weight grad: 6.237822162802331e-06
sam_encoder.blocks.9.norm1.bias grad: -4.3265549720672425e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 5.304029400576837e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.2044491743145045e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 9.666067626312724e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.6689266146840964e-07
sam_encoder.blocks.9.norm2.weight grad: 5.976778993499465e-06
sam_encoder.blocks.9.norm2.bias grad: 1.6428354854269855e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.6864339563180692e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.354039452256984e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 6.022255547577515e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.255352218431653e-07
sam_encoder.blocks.10.norm1.weight grad: 9.602669706509914e-06
sam_encoder.blocks.10.norm1.bias grad: 1.0323103651899146e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 5.88428429182386e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.1464186374942074e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.8071917793349712e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.756183771969518e-07
sam_encoder.blocks.10.norm2.weight grad: 8.253085070464294e-06
sam_encoder.blocks.10.norm2.bias grad: 1.5678597264923155e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.20468768425053e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.9321448689879617e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.3746406679615575e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.132573963033792e-07
sam_encoder.blocks.11.norm1.weight grad: 2.6837307814275846e-05
sam_encoder.blocks.11.norm1.bias grad: 1.4320456784844282e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 6.4831547206267715e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.4166106413758826e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.0672194952785503e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.5585910659865476e-06
sam_encoder.blocks.11.norm2.weight grad: 1.1945401638513431e-05
sam_encoder.blocks.11.norm2.bias grad: 2.2042213458917104e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 5.357584996090736e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.1357548121159198e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 7.017858365543361e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.973386360987206e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.019005139824003e-06
sam_encoder.neck.conv1.trainable_shift grad: -1.2929489457746968e-05
sam_encoder.neck.conv2.trainable_scale grad: 3.3536707633174956e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.5050440197228454e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -7.334723341045901e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.6413287085015327e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004353446885943413
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00031549029517918825
mask_decoder.transformer.layers.0.norm3.weight grad: -3.302452387288213e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.4879274608101696e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00012506918574217707
mask_decoder.transformer.layers.0.norm4.bias grad: -2.696504452615045e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -5.290393346513156e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 5.146746843820438e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.000197176996152848
mask_decoder.transformer.layers.1.norm2.bias grad: -4.928046837449074e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 1.1145601092721336e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -6.238979494810337e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -7.637521775905043e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00020203535677865148
mask_decoder.transformer.norm_final_attn.weight grad: 6.653156106040115e-07
mask_decoder.transformer.norm_final_attn.bias grad: 1.4081757399253547e-05
Text_Embedding_Affine.0.weight grad: 2.9103848237649332e-12
Text_Embedding_Affine.0.bias grad: 3.494584829843994e-12
Text_Embedding_Affine.2.weight grad: -9.241911402835257e-11
Text_Embedding_Affine.2.bias grad: 1.8820965124177746e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.308117169613766e-10
Max value: 0.9997764229774475
Mean value: 0.07150046527385712

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.308117169613766e-10
Max value: 0.9997764229774475
Mean value: 0.07150046527385712

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07233047485351562

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.099733352661133
Max value: -1.1920928244535389e-07
Mean value: -0.11360125243663788

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0583953857421875

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07233047485351562

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 35.481544494628906
Max value: 63.176483154296875
Mean value: 53.46577453613281

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.785400798899218e-10
Max value: 0.9997637867927551
Mean value: 0.07152819633483887

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.785400798899218e-10
Max value: 0.9997637867927551
Mean value: 0.07152819633483887

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.785400798899218e-10
Max value: 0.9997637867927551
Mean value: 0.07152819633483887

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.930879592895508
Max value: -1.1920928244535389e-07
Mean value: -0.11353491246700287

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9569604992866516
Max value: 1.183946967124939
Mean value: 1.0000731945037842

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 35.481544494628906
Max value: 63.176483154296875
Mean value: 53.46577453613281

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.470767974853516
Max value: -53.470767974853516
Mean value: -53.470767974853516
sam_encoder.pos_embed grad: 1.6887273801557967e-09
sam_encoder.blocks.0.norm1.weight grad: 2.8173728424008004e-05
sam_encoder.blocks.0.norm1.bias grad: 2.2689162506139837e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 6.883406513225054e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 6.492742841146537e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 8.916113074519671e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.121802938541805e-06
sam_encoder.blocks.0.norm2.weight grad: 2.365899672440719e-05
sam_encoder.blocks.0.norm2.bias grad: -3.07053851429373e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.4613897292292677e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.355756573204417e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.8055774489766918e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -8.13616225059377e-06
sam_encoder.blocks.1.norm1.weight grad: -4.069115675520152e-06
sam_encoder.blocks.1.norm1.bias grad: 1.6891572158783674e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.525630280724727e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.9228637029300444e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.4995000431954395e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.256769443600206e-06
sam_encoder.blocks.1.norm2.weight grad: 8.667535439599305e-06
sam_encoder.blocks.1.norm2.bias grad: -1.8070053329211078e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.679205630964134e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.9233700641052565e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.295164995302912e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -5.28448072145693e-06
sam_encoder.blocks.2.norm1.weight grad: 6.1506407291744836e-06
sam_encoder.blocks.2.norm1.bias grad: 6.979397767281625e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.4883538571884856e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.2742900895877938e-08
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.120051703968784e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -7.491850624319341e-07
sam_encoder.blocks.2.norm2.weight grad: 6.998426215432119e-06
sam_encoder.blocks.2.norm2.bias grad: -1.5014661585155409e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 1.9868741674144985e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.4948089983590762e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.255512850359082e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.720087195484666e-06
sam_encoder.blocks.3.norm1.weight grad: 3.5936623135057744e-06
sam_encoder.blocks.3.norm1.bias grad: -4.016889761260245e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -9.232085176336113e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.391508016648004e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -6.897954790474614e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.764081611734582e-06
sam_encoder.blocks.3.norm2.weight grad: 1.496208096796181e-05
sam_encoder.blocks.3.norm2.bias grad: -9.287739885621704e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.2930917364428751e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 6.766862497897819e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.011960299976636e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.5046115297300275e-06
sam_encoder.blocks.4.norm1.weight grad: 7.648535756743513e-06
sam_encoder.blocks.4.norm1.bias grad: -4.5625683924299665e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.66154415839992e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 6.75216995205119e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.0519354418647708e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.5975995160697494e-07
sam_encoder.blocks.4.norm2.weight grad: -3.850198845611885e-05
sam_encoder.blocks.4.norm2.bias grad: -2.6931220418191515e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.7613370548351668e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -8.977435754786711e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -7.105812755980878e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -9.951743322744733e-07
sam_encoder.blocks.5.norm1.weight grad: -8.23893424239941e-06
sam_encoder.blocks.5.norm1.bias grad: -1.043675365508534e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.0121570085175335e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -5.696760126738809e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.9659062218124745e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.2972162721780478e-06
sam_encoder.blocks.5.norm2.weight grad: -2.3834492822061293e-05
sam_encoder.blocks.5.norm2.bias grad: -1.206608249049168e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.193569551105611e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.951798134949058e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.579399167894735e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.1398030841955915e-07
sam_encoder.blocks.6.norm1.weight grad: -1.1873004950757604e-05
sam_encoder.blocks.6.norm1.bias grad: 5.342296205412822e-08
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -8.361543223145418e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -3.5803841456072405e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.161537395295454e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.5299423214164563e-06
sam_encoder.blocks.6.norm2.weight grad: -5.235351181909209e-06
sam_encoder.blocks.6.norm2.bias grad: 4.217818968754727e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -5.845265604875749e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.5202627966791624e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.127448740589898e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -7.491659914649063e-08
sam_encoder.blocks.7.norm1.weight grad: 1.1245674613746814e-05
sam_encoder.blocks.7.norm1.bias grad: 1.119504531743587e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 5.904988938709721e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.959177097887732e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -5.884137976863713e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.941428536156309e-06
sam_encoder.blocks.7.norm2.weight grad: -1.0943799679807853e-06
sam_encoder.blocks.7.norm2.bias grad: 5.128191560288542e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 9.803164857657976e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -8.171929835043557e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.4453048606810626e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.2521417147581815e-06
sam_encoder.blocks.8.norm1.weight grad: 2.3662176317884587e-05
sam_encoder.blocks.8.norm1.bias grad: -2.2587014427699614e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.9282793800812215e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.935320248478092e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.0953987132088514e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 4.334782488513156e-07
sam_encoder.blocks.8.norm2.weight grad: -2.7791090815298958e-06
sam_encoder.blocks.8.norm2.bias grad: -6.334223030535213e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.851674591714982e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.7842003217083402e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.1279679458530154e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.4372869827639079e-06
sam_encoder.blocks.9.norm1.weight grad: -2.038210368482396e-06
sam_encoder.blocks.9.norm1.bias grad: 4.817736112272542e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.0601944470399758e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -6.782885861866816e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.129090833273949e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.0637644436428673e-06
sam_encoder.blocks.9.norm2.weight grad: -1.223707158715115e-06
sam_encoder.blocks.9.norm2.bias grad: 6.275399755395483e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.637671516618866e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.2092044698874815e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.0688507927625324e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.8588951888887095e-07
sam_encoder.blocks.10.norm1.weight grad: 2.140265678463038e-06
sam_encoder.blocks.10.norm1.bias grad: -2.971910362248309e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.1379640909581212e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 5.78045501242741e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 7.386400966424844e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.769429887754086e-07
sam_encoder.blocks.10.norm2.weight grad: -7.748168172838632e-06
sam_encoder.blocks.10.norm2.bias grad: -1.7894305983645609e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.198671831545653e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.571242475823965e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -6.087547035349417e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.205502470242209e-07
sam_encoder.blocks.11.norm1.weight grad: 6.7210021370556206e-06
sam_encoder.blocks.11.norm1.bias grad: 3.8919910139156855e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.5291074052802287e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.4320455647975905e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.599245590317878e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.6636895452393219e-06
sam_encoder.blocks.11.norm2.weight grad: 8.639094630780164e-07
sam_encoder.blocks.11.norm2.bias grad: -2.1554478735197335e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.745849579990136e-08
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -4.4443240199143474e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.0914350241364446e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.9100493748046574e-07
sam_encoder.neck.conv1.trainable_scale grad: -3.716650098795071e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.760671329975594e-05
sam_encoder.neck.conv2.trainable_scale grad: -5.386928023654036e-07
sam_encoder.neck.conv2.trainable_shift grad: 1.1176613043062389e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00014571119390893728
mask_decoder.transformer.layers.0.norm1.bias grad: -2.0137085812166333e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0009862200822681189
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00011137197725474834
mask_decoder.transformer.layers.0.norm3.weight grad: 4.0192127926275134e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.338303213240579e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 9.57535594352521e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 3.551267582224682e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 2.863109330064617e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -6.9396792241605e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00010488003317732364
mask_decoder.transformer.layers.1.norm2.bias grad: 3.386696698726155e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 5.919405521126464e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.7918692871462554e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -4.437930329004303e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00013807712821289897
mask_decoder.transformer.norm_final_attn.weight grad: 5.29901899426477e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.1603922757785767e-05
Text_Embedding_Affine.0.weight grad: 1.991267047085632e-11
Text_Embedding_Affine.0.bias grad: 9.470658701715706e-10
Text_Embedding_Affine.2.weight grad: -4.8284518744390326e-12
Text_Embedding_Affine.2.bias grad: -8.319220796693116e-07

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.1954101304142455e-10
Max value: 0.9997033476829529
Mean value: 0.09014920890331268

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.1954101304142455e-10
Max value: 0.9997033476829529
Mean value: 0.09014920890331268

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0885171890258789

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11995183676481247

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08009910583496094

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0885171890258789

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 51.730682373046875
Max value: 87.54436492919922
Mean value: 63.79652404785156

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 6.83697098935454e-10
Max value: 0.9996229410171509
Mean value: 0.09056787937879562

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.83697098935454e-10
Max value: 0.9996229410171509
Mean value: 0.09056787937879562

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.83697098935454e-10
Max value: 0.9996229410171509
Mean value: 0.09056787937879562

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1198698952794075

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9650411605834961
Max value: 1.4729738235473633
Mean value: 1.0001275539398193

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 51.730682373046875
Max value: 87.54436492919922
Mean value: 63.79652404785156

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -63.807334899902344
Max value: -63.807334899902344
Mean value: -63.807334899902344
sam_encoder.pos_embed grad: 3.737871345776966e-09
sam_encoder.blocks.0.norm1.weight grad: -3.943932460970245e-05
sam_encoder.blocks.0.norm1.bias grad: -2.527328433643561e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -7.699612751821405e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -9.853984010987915e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -7.312615252885735e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 4.983285180060193e-07
sam_encoder.blocks.0.norm2.weight grad: -2.3651793526369147e-05
sam_encoder.blocks.0.norm2.bias grad: -1.491579860157799e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.5033525414764881e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.423094139838213e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -9.927311111823656e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.252824745279213e-06
sam_encoder.blocks.1.norm1.weight grad: 2.1117266442161053e-06
sam_encoder.blocks.1.norm1.bias grad: -8.705792424734682e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 3.245184529987455e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 1.0917158022039075e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 2.143462097592419e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.4063715525480802e-06
sam_encoder.blocks.1.norm2.weight grad: -3.688759022679733e-07
sam_encoder.blocks.1.norm2.bias grad: 4.306060873204842e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -3.0143417006911477e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -8.792172820903943e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.8537342586787418e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.0804950534293312e-07
sam_encoder.blocks.2.norm1.weight grad: -8.009752491489053e-06
sam_encoder.blocks.2.norm1.bias grad: -2.7086534828413278e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.2288016882375814e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.2748918152283295e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.0508439320110483e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.7269740598967473e-07
sam_encoder.blocks.2.norm2.weight grad: -5.284848157316446e-06
sam_encoder.blocks.2.norm2.bias grad: 6.72320766170742e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.607069058693014e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -8.90142416665185e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.267881301231682e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.4501704249123577e-06
sam_encoder.blocks.3.norm1.weight grad: -3.7789959606016055e-06
sam_encoder.blocks.3.norm1.bias grad: -6.315483460639371e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -8.492667802784126e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.7220839911024086e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.349602932052221e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.7681044230121188e-06
sam_encoder.blocks.3.norm2.weight grad: -1.1505297152325511e-05
sam_encoder.blocks.3.norm2.bias grad: 8.89373586687725e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -9.939910341927316e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.295363174198428e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.746422467225784e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.2276844927328057e-06
sam_encoder.blocks.4.norm1.weight grad: -1.3827032034896547e-06
sam_encoder.blocks.4.norm1.bias grad: 3.4043130199279403e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.1973290838795947e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.2602008609974291e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.2767668522428721e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.3811677490593866e-06
sam_encoder.blocks.4.norm2.weight grad: -6.7392029450275e-06
sam_encoder.blocks.4.norm2.bias grad: -5.939419679634739e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.4262758415716235e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 5.59476802663994e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.0706982013507513e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 4.414669092511758e-07
sam_encoder.blocks.5.norm1.weight grad: -8.746927051106468e-06
sam_encoder.blocks.5.norm1.bias grad: 3.5719335755857173e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.554343038558727e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.3081335055176169e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -8.254453121026017e-08
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.1093001006656777e-07
sam_encoder.blocks.5.norm2.weight grad: -1.1001850907632615e-05
sam_encoder.blocks.5.norm2.bias grad: -6.1413729781634174e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -6.098981884861132e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.998343350351206e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.8393369575496763e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 9.314493354395381e-08
sam_encoder.blocks.6.norm1.weight grad: -4.360053480922943e-06
sam_encoder.blocks.6.norm1.bias grad: -1.4823551737208618e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -4.595218342728913e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.6763265193731058e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.2030553762087948e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -7.068032914503419e-07
sam_encoder.blocks.6.norm2.weight grad: 4.316988452046644e-06
sam_encoder.blocks.6.norm2.bias grad: 5.2027426136191934e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.782287995411025e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.0183285894527216e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.2306494454605854e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.3999117243201908e-07
sam_encoder.blocks.7.norm1.weight grad: 2.176997895730892e-06
sam_encoder.blocks.7.norm1.bias grad: -8.229364425460517e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 5.287174644763581e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.4411212962149875e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.363315618618799e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.010108568763826e-06
sam_encoder.blocks.7.norm2.weight grad: -1.2023792805848643e-07
sam_encoder.blocks.7.norm2.bias grad: 1.4040591622688225e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.2328261789207318e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 7.864673534641042e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.81842688107281e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 7.640356898264145e-07
sam_encoder.blocks.8.norm1.weight grad: -3.468461272859713e-06
sam_encoder.blocks.8.norm1.bias grad: 1.2688074093603063e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -4.354804786999011e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -2.641106675582705e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.855916475004051e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.945086064049974e-06
sam_encoder.blocks.8.norm2.weight grad: -3.5389457480050623e-06
sam_encoder.blocks.8.norm2.bias grad: -1.2510146234490094e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.604437668196624e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -6.593204489035998e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.625713110797733e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.854424619476049e-07
sam_encoder.blocks.9.norm1.weight grad: -6.661163638455037e-07
sam_encoder.blocks.9.norm1.bias grad: 3.44719737199739e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.75619271405958e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.7460385137724188e-08
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.683240035774361e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -9.438052757104742e-07
sam_encoder.blocks.9.norm2.weight grad: -3.699860371852992e-06
sam_encoder.blocks.9.norm2.bias grad: -1.386174744766322e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.92522111319704e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -8.396957582590403e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.1922987823709263e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 1.1834275426281238e-07
sam_encoder.blocks.10.norm1.weight grad: 4.651912149711279e-06
sam_encoder.blocks.10.norm1.bias grad: 9.944805015038582e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.5421470581932226e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.1667245871649357e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 7.608534815517487e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.466030591425806e-07
sam_encoder.blocks.10.norm2.weight grad: -1.072951181413373e-05
sam_encoder.blocks.10.norm2.bias grad: -4.3399204514571466e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.307531526137609e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.838426325979526e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.2018907682431745e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.691886594329844e-07
sam_encoder.blocks.11.norm1.weight grad: -1.1191309567948338e-05
sam_encoder.blocks.11.norm1.bias grad: 2.903763743233867e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.64206323158578e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.4344094501648215e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.1307523664072505e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.769717634189874e-07
sam_encoder.blocks.11.norm2.weight grad: -3.4774736832332565e-06
sam_encoder.blocks.11.norm2.bias grad: -2.9931566132290754e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -5.040573114456492e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -8.234911774707143e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.248321078785921e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.4755964450330339e-08
sam_encoder.neck.conv1.trainable_scale grad: 5.247020453680307e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.9208519006497227e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.9528306438587606e-07
sam_encoder.neck.conv2.trainable_shift grad: -2.6042223908007145e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00014251077664084733
mask_decoder.transformer.layers.0.norm1.bias grad: -4.840476321987808e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.00350861344486475
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00033663795329630375
mask_decoder.transformer.layers.0.norm3.weight grad: -3.621489304350689e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.801992716034874e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 7.08186998963356e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 6.6298171077505685e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.3671669876202941e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -6.889335963933263e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 5.6908778788056225e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 4.416753654368222e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 5.5861361033748835e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.5428660087054595e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 8.448174412478693e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -6.473870598711073e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.678864578025241e-06
mask_decoder.transformer.norm_final_attn.bias grad: 7.050965450616786e-06
Text_Embedding_Affine.0.weight grad: 5.5018329302158886e-12
Text_Embedding_Affine.0.bias grad: 9.35333754892298e-12
Text_Embedding_Affine.2.weight grad: 5.478720602192233e-11
Text_Embedding_Affine.2.bias grad: -1.2266669727978297e-05
Epoch 27 finished with average loss: -58.6656
Epoch 28/39
----------
Epoch 28:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 28:   0%|          | 0/3 [00:00<?, ?it/s, loss=-60.5]Epoch 28:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.12it/s, loss=-60.5]Epoch 28:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.12it/s, loss=-57.4]Epoch 28:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.71it/s, loss=-57.4]Epoch 28:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.71it/s, loss=-54.4]Epoch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.25it/s, loss=-54.4]/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.602988676855082e-16
Max value: 0.9999617338180542
Mean value: 0.07802155613899231

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.602988676855082e-16
Max value: 0.9999617338180542
Mean value: 0.07802155613899231

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07866621017456055

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11741263419389725

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06427574157714844

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07866621017456055

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 42.20119094848633
Max value: 89.98225402832031
Mean value: 60.4591178894043

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.602988676855082e-16
Max value: 0.9999617338180542
Mean value: 0.07802155613899231

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.602988676855082e-16
Max value: 0.9999617338180542
Mean value: 0.07802155613899231

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.602988676855082e-16
Max value: 0.9999617338180542
Mean value: 0.07802155613899231

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11741263419389725

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 42.20119094848633
Max value: 89.98225402832031
Mean value: 60.4591178894043

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.46026611328125
Max value: -60.46026611328125
Mean value: -60.46026611328125
sam_encoder.pos_embed grad: -5.040545314471956e-09
sam_encoder.blocks.0.norm1.weight grad: 5.0202172133140266e-05
sam_encoder.blocks.0.norm1.bias grad: 3.554941213224083e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 6.975338237680262e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -6.972240953473374e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.669637583745498e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.0287014902132796e-06
sam_encoder.blocks.0.norm2.weight grad: 3.9070593629730865e-05
sam_encoder.blocks.0.norm2.bias grad: 6.078862497815862e-07
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -3.2420834941149224e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -2.698402568057645e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.458387851016596e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.5341028049297165e-06
sam_encoder.blocks.1.norm1.weight grad: 1.635565467950073e-06
sam_encoder.blocks.1.norm1.bias grad: 1.3036631571594626e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.3771272026351653e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.5672933386667864e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.6350699070244445e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 6.761478061889648e-07
sam_encoder.blocks.1.norm2.weight grad: 9.996200788009446e-06
sam_encoder.blocks.1.norm2.bias grad: -2.503174982848577e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.650585085779312e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.516864131190232e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.5973284916981356e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.579482725195703e-07
sam_encoder.blocks.2.norm1.weight grad: -1.5622512364643626e-05
sam_encoder.blocks.2.norm1.bias grad: 5.0899848247354385e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.1068298590544146e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.855253453366458e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.622260116273537e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.600659283620189e-06
sam_encoder.blocks.2.norm2.weight grad: -6.597980245715007e-06
sam_encoder.blocks.2.norm2.bias grad: -5.198607141210232e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.780909082706785e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.0021770978928544e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.7759732600097777e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.9970070752606262e-07
sam_encoder.blocks.3.norm1.weight grad: -1.153193579739309e-06
sam_encoder.blocks.3.norm1.bias grad: -6.556130301760277e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.5513091865577735e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.340218881930923e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.863732677520602e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.692174348339904e-06
sam_encoder.blocks.3.norm2.weight grad: 2.835688519553514e-06
sam_encoder.blocks.3.norm2.bias grad: 6.768327693862375e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.538753394925152e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.9021389309491497e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.331528205308132e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 6.138255912446766e-07
sam_encoder.blocks.4.norm1.weight grad: -2.8819931685575284e-06
sam_encoder.blocks.4.norm1.bias grad: 1.6463352494611172e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.5403561469138367e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.3942566258483566e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.3980519497636124e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 4.044293291372014e-07
sam_encoder.blocks.4.norm2.weight grad: -2.738128932833206e-05
sam_encoder.blocks.4.norm2.bias grad: -2.1864723748876713e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.8518567230785266e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.474310339399381e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.0918136013060575e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.7126333773376246e-07
sam_encoder.blocks.5.norm1.weight grad: -8.40044958749786e-06
sam_encoder.blocks.5.norm1.bias grad: -8.985476597445086e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -6.224230219231686e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -6.001545443723444e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.6101564597192919e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.422753484803252e-06
sam_encoder.blocks.5.norm2.weight grad: -1.168957805930404e-05
sam_encoder.blocks.5.norm2.bias grad: -6.524062882817816e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -7.197858849394834e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.0108045646338724e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 9.714103725855239e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.864605335162196e-07
sam_encoder.blocks.6.norm1.weight grad: 1.3149687561053724e-07
sam_encoder.blocks.6.norm1.bias grad: 1.4352749531099107e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 8.267769544545445e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.0773114809126128e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 9.105185654334491e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.0714894333195844e-07
sam_encoder.blocks.6.norm2.weight grad: -2.6519001039559953e-06
sam_encoder.blocks.6.norm2.bias grad: 1.754382878971228e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -2.282650712004397e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -8.634259529571864e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 3.881715656461893e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.0103146905748872e-06
sam_encoder.blocks.7.norm1.weight grad: 1.0715082680690102e-05
sam_encoder.blocks.7.norm1.bias grad: -1.6368315982617787e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 6.800606115575647e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 3.238536464778008e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.239562036265852e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -5.125685902385158e-07
sam_encoder.blocks.7.norm2.weight grad: 2.2288286345428787e-06
sam_encoder.blocks.7.norm2.bias grad: 3.8039859191485448e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.2341369003697764e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -7.82433957624562e-08
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.2183988928882172e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.0297924291080562e-06
sam_encoder.blocks.8.norm1.weight grad: 1.8071295926347375e-05
sam_encoder.blocks.8.norm1.bias grad: -3.9163205656223e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.4260974239732604e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.264682502252981e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.0663189843617147e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.4274014499023906e-07
sam_encoder.blocks.8.norm2.weight grad: -4.5231024614622584e-07
sam_encoder.blocks.8.norm2.bias grad: 1.9347353372722864e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 7.086057252081446e-08
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 7.179518775046745e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -6.235891305550467e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.1312260994600365e-06
sam_encoder.blocks.9.norm1.weight grad: 2.54677024713601e-06
sam_encoder.blocks.9.norm1.bias grad: -6.444815880968235e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.1740197553299367e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 8.750127449275169e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.959894456784241e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.5528182757407194e-06
sam_encoder.blocks.9.norm2.weight grad: 5.278785010887077e-06
sam_encoder.blocks.9.norm2.bias grad: 3.043654032808263e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.8417721321384306e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.778033038135618e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 9.911263987305574e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.46273077159276e-07
sam_encoder.blocks.10.norm1.weight grad: 9.358806892123539e-06
sam_encoder.blocks.10.norm1.bias grad: 1.3941817087470554e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 5.139284894539742e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.324698016309412e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.898857135529397e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.4578968148271088e-06
sam_encoder.blocks.10.norm2.weight grad: 2.0176212274236605e-06
sam_encoder.blocks.10.norm2.bias grad: 8.917001537156466e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 9.69562393038359e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.5927962238038162e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -4.982892960470053e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.639588493977499e-07
sam_encoder.blocks.11.norm1.weight grad: 8.107735993689857e-06
sam_encoder.blocks.11.norm1.bias grad: 2.0403410871949745e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 6.463506906584371e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.917553618113743e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.5100680431933142e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.49426591633528e-06
sam_encoder.blocks.11.norm2.weight grad: 2.2334422737912973e-06
sam_encoder.blocks.11.norm2.bias grad: 1.032763066177722e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.9122569432947785e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 4.015063836959598e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.690239853109233e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.0739704237039405e-07
sam_encoder.neck.conv1.trainable_scale grad: -3.0744195100851357e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.568891432019882e-05
sam_encoder.neck.conv2.trainable_scale grad: -2.8438989829737693e-08
sam_encoder.neck.conv2.trainable_shift grad: 1.0221629963780288e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00012570226681418717
mask_decoder.transformer.layers.0.norm1.bias grad: -1.780455932021141e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0020917081274092197
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00018748862203210592
mask_decoder.transformer.layers.0.norm3.weight grad: 4.668030305765569e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.079032128676772e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -6.895792466821149e-06
mask_decoder.transformer.layers.0.norm4.bias grad: 6.204900273587555e-07
mask_decoder.transformer.layers.1.norm1.weight grad: -9.220282208843855e-07
mask_decoder.transformer.layers.1.norm1.bias grad: 8.364113455172628e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 6.550657417392358e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -3.092085898970254e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.628480772022158e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 1.8658409317140467e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.3989981855265796e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -7.91801794548519e-05
mask_decoder.transformer.norm_final_attn.weight grad: -4.0431325487588765e-07
mask_decoder.transformer.norm_final_attn.bias grad: 1.2723603504127823e-07
Text_Embedding_Affine.0.weight grad: 2.467168656872243e-11
Text_Embedding_Affine.0.bias grad: 1.2244512070935798e-09
Text_Embedding_Affine.2.weight grad: -4.4808861482392714e-13
Text_Embedding_Affine.2.bias grad: 7.841897968319245e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.0555004365263585e-09
Max value: 0.9994884729385376
Mean value: 0.09284992516040802

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.0555004365263585e-09
Max value: 0.9994884729385376
Mean value: 0.09284992516040802

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0877838134765625

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1338457465171814

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07860422134399414

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0877838134765625

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 36.318321228027344
Max value: 74.3196029663086
Mean value: 54.42201614379883

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.02208991165287e-09
Max value: 0.9993222951889038
Mean value: 0.0936896950006485

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.02208991165287e-09
Max value: 0.9993222951889038
Mean value: 0.0936896950006485

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.02208991165287e-09
Max value: 0.9993222951889038
Mean value: 0.0936896950006485

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13397139310836792

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9688437581062317
Max value: 1.7626346349716187
Mean value: 0.9999403953552246

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 36.318321228027344
Max value: 74.3196029663086
Mean value: 54.42201614379883

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -54.413028717041016
Max value: -54.413028717041016
Mean value: -54.413028717041016
sam_encoder.pos_embed grad: 5.801659597182152e-09
sam_encoder.blocks.0.norm1.weight grad: -6.5621034082141705e-06
sam_encoder.blocks.0.norm1.bias grad: -3.391025529708713e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.94326571545389e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -8.612513511252473e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -8.085115041467361e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.0104745342687238e-06
sam_encoder.blocks.0.norm2.weight grad: 6.662543455604464e-06
sam_encoder.blocks.0.norm2.bias grad: -3.354872751515359e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.4245301776536508e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.5706452813901706e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.8723812900134362e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.1014464689651504e-05
sam_encoder.blocks.1.norm1.weight grad: 1.421075558027951e-05
sam_encoder.blocks.1.norm1.bias grad: 2.0657875211327337e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.753861503559165e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.5353252820204943e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.926773832878098e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.1564089769963175e-06
sam_encoder.blocks.1.norm2.weight grad: -1.0149829904548824e-05
sam_encoder.blocks.1.norm2.bias grad: 4.51667801826261e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.1545384040800855e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -7.654865612494177e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.2625083400052972e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.1239459329081e-06
sam_encoder.blocks.2.norm1.weight grad: 1.6311569197569042e-06
sam_encoder.blocks.2.norm1.bias grad: 3.707271389430389e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.251435378435417e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.0133252317245933e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.641619852918666e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.9396970856178086e-06
sam_encoder.blocks.2.norm2.weight grad: -9.75134753389284e-06
sam_encoder.blocks.2.norm2.bias grad: 4.800804163096473e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -9.075525667867623e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.3148058997103362e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.0825623576238286e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.554912382242037e-06
sam_encoder.blocks.3.norm1.weight grad: -1.1074387657572515e-05
sam_encoder.blocks.3.norm1.bias grad: -7.749542419333011e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.470773324603215e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -6.444044515774294e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.5076967631321168e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.063259439135436e-06
sam_encoder.blocks.3.norm2.weight grad: -6.895216756674927e-06
sam_encoder.blocks.3.norm2.bias grad: -3.1580009363096906e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -8.33156991575379e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.4884666345315054e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -5.547074579226319e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.6503822735103313e-06
sam_encoder.blocks.4.norm1.weight grad: 4.236013865011046e-06
sam_encoder.blocks.4.norm1.bias grad: -1.2870978025603108e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.53242967321421e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.3695574213888904e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.5596802920044865e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -5.48240768694086e-06
sam_encoder.blocks.4.norm2.weight grad: 2.471352490829304e-05
sam_encoder.blocks.4.norm2.bias grad: 4.949566573486663e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.2625741874217056e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 4.128350610699272e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -4.0165991777030285e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 5.779920684290119e-07
sam_encoder.blocks.5.norm1.weight grad: 1.702533154457342e-05
sam_encoder.blocks.5.norm1.bias grad: -1.7321921404800378e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.4119507795840036e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 8.325651833729353e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.7372439035389107e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.1135657587146852e-06
sam_encoder.blocks.5.norm2.weight grad: 1.1742107744794339e-05
sam_encoder.blocks.5.norm2.bias grad: 3.582935050872038e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 2.672576556506101e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.1590127542149276e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.868233425739163e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.909508509674197e-07
sam_encoder.blocks.6.norm1.weight grad: 1.1331605492159724e-05
sam_encoder.blocks.6.norm1.bias grad: -8.53530946187675e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 8.484981663059443e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 4.7543667278659996e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.668331606197171e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.1716011840690044e-06
sam_encoder.blocks.6.norm2.weight grad: -6.670323955404456e-07
sam_encoder.blocks.6.norm2.bias grad: 1.2095637202946818e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.5602906842104858e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -9.03424222542526e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -5.668694029736798e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.895324418110249e-07
sam_encoder.blocks.7.norm1.weight grad: -2.113728214681032e-07
sam_encoder.blocks.7.norm1.bias grad: -6.01759381879674e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.0480792980160913e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.0507471870369045e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.1196684681635816e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.8316613932256587e-06
sam_encoder.blocks.7.norm2.weight grad: 2.800999482133193e-06
sam_encoder.blocks.7.norm2.bias grad: -8.36840058582311e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.813811417785473e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 3.5749530979956035e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.023214619839564e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.6572373624512693e-06
sam_encoder.blocks.8.norm1.weight grad: -3.3443348002037965e-07
sam_encoder.blocks.8.norm1.bias grad: -1.6112694538605865e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.768829290289432e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.7981695918933838e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.719338226597756e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.7237846350326436e-06
sam_encoder.blocks.8.norm2.weight grad: 6.898362698848359e-07
sam_encoder.blocks.8.norm2.bias grad: 2.6097668524016626e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.312442337730317e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.7635277294612024e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.5009435401225346e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.3434344054985559e-06
sam_encoder.blocks.9.norm1.weight grad: -6.159901744240415e-08
sam_encoder.blocks.9.norm1.bias grad: 3.574130005290499e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.3198050510254689e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.1966852753175772e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -5.621899390462204e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.093620880965318e-06
sam_encoder.blocks.9.norm2.weight grad: -6.333147666737204e-06
sam_encoder.blocks.9.norm2.bias grad: 2.9170284960855497e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.9752960623882245e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.3779296043358045e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.0825100338915945e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 7.494534202123759e-07
sam_encoder.blocks.10.norm1.weight grad: -3.2556204132561106e-06
sam_encoder.blocks.10.norm1.bias grad: -8.233559469772445e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.051073463211651e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.3544204193749465e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.8026470343102119e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.0349983767810045e-06
sam_encoder.blocks.10.norm2.weight grad: -1.1406704288674518e-05
sam_encoder.blocks.10.norm2.bias grad: 2.5240460672648624e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -6.796901288907975e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.5398220461502206e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -7.219543931569206e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.4551939026860055e-08
sam_encoder.blocks.11.norm1.weight grad: -2.422553370706737e-05
sam_encoder.blocks.11.norm1.bias grad: 4.6728323432887464e-09
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.518454261415172e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.669616722210776e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.6515676836424973e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.71022452377656e-06
sam_encoder.blocks.11.norm2.weight grad: -1.0679919796530157e-05
sam_encoder.blocks.11.norm2.bias grad: 2.9684176183764066e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -4.631498086382635e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.7512347767478786e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.7113562478243693e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.9127266998330015e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.4562829164788127e-06
sam_encoder.neck.conv1.trainable_shift grad: 5.301249984768219e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.5152586456679273e-06
sam_encoder.neck.conv2.trainable_shift grad: -2.8198952350066975e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 8.214391709771007e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 2.736830538196955e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.00411571841686964
mask_decoder.transformer.layers.0.norm2.bias grad: 7.217377424240112e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 1.2376302038319409e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 9.790042895474471e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00011586157052079216
mask_decoder.transformer.layers.0.norm4.bias grad: 1.2778757081832737e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 2.391836005699588e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -6.604766895179637e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 5.9006815718021244e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 1.5359695680672303e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -2.2949261619942263e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.918282345694024e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 2.914259493991267e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.000197222747374326
mask_decoder.transformer.norm_final_attn.weight grad: 3.037816895812284e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.4329187251860276e-05
Text_Embedding_Affine.0.weight grad: 7.846829956636991e-12
Text_Embedding_Affine.0.bias grad: -1.2507300750641548e-10
Text_Embedding_Affine.2.weight grad: 4.217709168030659e-11
Text_Embedding_Affine.2.bias grad: -3.5021952498937026e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.92774940244567e-10
Max value: 0.9983356595039368
Mean value: 0.08470381051301956

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.92774940244567e-10
Max value: 0.9983356595039368
Mean value: 0.08470381051301956

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08586597442626953

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.46006965637207
Max value: -1.1920928244535389e-07
Mean value: -0.14373409748077393

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07148265838623047

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08586597442626953

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 36.86195373535156
Max value: 63.96099090576172
Mean value: 48.3603515625

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.4267638182019482e-09
Max value: 0.9979933500289917
Mean value: 0.08501887321472168

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.4267638182019482e-09
Max value: 0.9979933500289917
Mean value: 0.08501887321472168

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.4267638182019482e-09
Max value: 0.9979933500289917
Mean value: 0.08501887321472168

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -13.684120178222656
Max value: -1.1920928244535389e-07
Mean value: -0.1433836966753006

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9083083271980286
Max value: 2.172654151916504
Mean value: 1.0005011558532715

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 36.86195373535156
Max value: 63.96099090576172
Mean value: 48.3603515625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -48.38290023803711
Max value: -48.38290023803711
Mean value: -48.38290023803711
sam_encoder.pos_embed grad: -2.7567117477644842e-09
sam_encoder.blocks.0.norm1.weight grad: -4.92515682708472e-05
sam_encoder.blocks.0.norm1.bias grad: 8.53079018270364e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.730682240326132e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 4.3738268118431733e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 9.163501090370119e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.236506134067895e-06
sam_encoder.blocks.0.norm2.weight grad: -2.1051584553788416e-05
sam_encoder.blocks.0.norm2.bias grad: -5.4250074754236266e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.685064307821449e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 7.725024261162616e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 6.615370693907607e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.2915857534353563e-07
sam_encoder.blocks.1.norm1.weight grad: 1.1256333891651593e-05
sam_encoder.blocks.1.norm1.bias grad: 6.744661504853866e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 2.648282304562599e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 8.261736184067558e-08
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.9701019482454285e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.578458295625751e-06
sam_encoder.blocks.1.norm2.weight grad: -6.754661626473535e-06
sam_encoder.blocks.1.norm2.bias grad: 2.4128785298671573e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.5747250965177955e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -3.748163805994409e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.3580904123955406e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.157517885985726e-06
sam_encoder.blocks.2.norm1.weight grad: -1.0050434866570868e-05
sam_encoder.blocks.2.norm1.bias grad: -1.3792734534945339e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -5.891380169487093e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.4650958039273974e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.5398338594823144e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.21570189751219e-06
sam_encoder.blocks.2.norm2.weight grad: -9.200734893966e-06
sam_encoder.blocks.2.norm2.bias grad: -1.7713271063257707e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -6.7919963839813136e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.6395822513004532e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.348449339086073e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.2830034847866045e-06
sam_encoder.blocks.3.norm1.weight grad: -3.1687120554124704e-06
sam_encoder.blocks.3.norm1.bias grad: -4.005783921456896e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.598902938188985e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.878899524854205e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.4830992515489925e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.464697445248021e-06
sam_encoder.blocks.3.norm2.weight grad: 5.04447325511137e-06
sam_encoder.blocks.3.norm2.bias grad: 1.0502218174224254e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.2139004158816533e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.6652433032504632e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.550656174411415e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.883924364345148e-07
sam_encoder.blocks.4.norm1.weight grad: -1.0403760825283825e-05
sam_encoder.blocks.4.norm1.bias grad: -5.766156391473487e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -7.101910796336597e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.7640722944634035e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.216514306179306e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.3115050023770891e-06
sam_encoder.blocks.4.norm2.weight grad: -9.26096981856972e-06
sam_encoder.blocks.4.norm2.bias grad: -4.381024155009072e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -6.635062163695693e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.965351768580149e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.8076995900173642e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.614873437778442e-07
sam_encoder.blocks.5.norm1.weight grad: -1.288920771003177e-06
sam_encoder.blocks.5.norm1.bias grad: -3.1644358386984095e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.497795037470496e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.859369945123035e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.5756630748219322e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.264988268052548e-07
sam_encoder.blocks.5.norm2.weight grad: -8.66120615228283e-07
sam_encoder.blocks.5.norm2.bias grad: -5.6558119467808865e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -9.644030569688766e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 3.112421325113246e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.40022962114017e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.9744550172617892e-07
sam_encoder.blocks.6.norm1.weight grad: 7.15482201485429e-06
sam_encoder.blocks.6.norm1.bias grad: 3.993528025603155e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 3.759163519134745e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 6.61837191273662e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.6847092183525092e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.1537357522684033e-06
sam_encoder.blocks.6.norm2.weight grad: -3.786328989008325e-06
sam_encoder.blocks.6.norm2.bias grad: -3.052136435144348e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.5106115824892186e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -6.222826414159499e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -3.702781157244317e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -3.8920367728678684e-07
sam_encoder.blocks.7.norm1.weight grad: 2.6755787985166535e-06
sam_encoder.blocks.7.norm1.bias grad: 1.5059184761412325e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.5236469102528645e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.5581563275191002e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.119522716588108e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.831387973856181e-06
sam_encoder.blocks.7.norm2.weight grad: 2.9543787150032585e-06
sam_encoder.blocks.7.norm2.bias grad: -1.5626583262928762e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.0308835953765083e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 7.230241294564621e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.2048185378007474e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.297841880747001e-07
sam_encoder.blocks.8.norm1.weight grad: -7.082470574459876e-07
sam_encoder.blocks.8.norm1.bias grad: -8.973770491138566e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -8.509168765158392e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.1107265979480871e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 8.574781418246857e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.3780970675725257e-06
sam_encoder.blocks.8.norm2.weight grad: 3.8067071272962494e-06
sam_encoder.blocks.8.norm2.bias grad: 1.240406817260009e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 3.6530261695588706e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.1469641069415957e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.6612566469120793e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.3394485399185214e-07
sam_encoder.blocks.9.norm1.weight grad: -8.812628493615193e-08
sam_encoder.blocks.9.norm1.bias grad: 1.3892797312564653e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 2.0703714653791394e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.003652414510725e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 7.045507288694353e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 6.050947831681697e-07
sam_encoder.blocks.9.norm2.weight grad: 6.4742343965917826e-06
sam_encoder.blocks.9.norm2.bias grad: -2.2188957871094317e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.660117156163324e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.054014541703509e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.0305195701221237e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 6.108071826105288e-09
sam_encoder.blocks.10.norm1.weight grad: 3.177646021867986e-06
sam_encoder.blocks.10.norm1.bias grad: -1.147980128735071e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.5393810574314557e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.0746682619355852e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.0028796850747312e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 8.543300964447553e-07
sam_encoder.blocks.10.norm2.weight grad: 7.0700180003768764e-06
sam_encoder.blocks.10.norm2.bias grad: 2.1727002774696302e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.9195183489937335e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.6812722378745093e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.6091041149811645e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -9.310275217444541e-09
sam_encoder.blocks.11.norm1.weight grad: 8.30183762445813e-06
sam_encoder.blocks.11.norm1.bias grad: 1.9652763683097874e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 8.168058229784947e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 6.071625762160693e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 4.327000624471111e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.1657194793078816e-07
sam_encoder.blocks.11.norm2.weight grad: 8.56980295793619e-06
sam_encoder.blocks.11.norm2.bias grad: 1.2031396181555465e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.627302021413925e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.5660068584111286e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -3.168754290072684e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.348920358803298e-07
sam_encoder.neck.conv1.trainable_scale grad: 3.801656021096278e-07
sam_encoder.neck.conv1.trainable_shift grad: 3.284858394181356e-07
sam_encoder.neck.conv2.trainable_scale grad: 7.996277417987585e-08
sam_encoder.neck.conv2.trainable_shift grad: -2.3344166038441472e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -2.042581581918057e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 4.060488208779134e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005210114177316427
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00044090067967772484
mask_decoder.transformer.layers.0.norm3.weight grad: -5.1541901484597474e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.6631710827350616e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 8.37161933304742e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 3.2649859349476174e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 2.1688056222046725e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 3.6633459785662126e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -5.276577212498523e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 5.45069997315295e-06
mask_decoder.transformer.layers.1.norm3.weight grad: -3.259497361796093e-06
mask_decoder.transformer.layers.1.norm3.bias grad: 1.469643393647857e-07
mask_decoder.transformer.layers.1.norm4.weight grad: -7.089397695381194e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0001222269784193486
mask_decoder.transformer.norm_final_attn.weight grad: 1.3879615607947926e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.2056024388584774e-05
Text_Embedding_Affine.0.weight grad: -5.69626464053119e-12
Text_Embedding_Affine.0.bias grad: -9.236528208944605e-12
Text_Embedding_Affine.2.weight grad: 1.3679686723666595e-12
Text_Embedding_Affine.2.bias grad: 1.7223019312950782e-05
Epoch 28 finished with average loss: -54.4187
Epoch 29/39
----------
Epoch 29:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 29:   0%|          | 0/3 [00:00<?, ?it/s, loss=-54.9]Epoch 29:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.11it/s, loss=-54.9]Epoch 29:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.11it/s, loss=-54.9]Epoch 29:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.70it/s, loss=-54.9]Epoch 29:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.70it/s, loss=-55.1]Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.35it/s, loss=-55.1]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.715005606063642e-08
Max value: 0.9968127608299255
Mean value: 0.09405187517404556

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.715005606063642e-08
Max value: 0.9968127608299255
Mean value: 0.09405187517404556

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09613704681396484

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -11.012601852416992
Max value: -1.1920928244535389e-07
Mean value: -0.1425827443599701

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07629156112670898

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09613704681396484

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 23.68960189819336
Max value: 76.04661560058594
Mean value: 54.92167663574219

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 8.715005606063642e-08
Max value: 0.9968127608299255
Mean value: 0.09405187517404556

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.715005606063642e-08
Max value: 0.9968127608299255
Mean value: 0.09405187517404556

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 8.715005606063642e-08
Max value: 0.9968127608299255
Mean value: 0.09405187517404556

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -11.012601852416992
Max value: -1.1920928244535389e-07
Mean value: -0.1425827443599701

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 23.68960189819336
Max value: 76.04661560058594
Mean value: 54.92167663574219

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -54.9232177734375
Max value: -54.9232177734375
Mean value: -54.9232177734375
sam_encoder.pos_embed grad: 1.377319591711057e-09
sam_encoder.blocks.0.norm1.weight grad: -1.8965168919748976e-06
sam_encoder.blocks.0.norm1.bias grad: -1.497289485996589e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.602567630878184e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.336738932877779e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.0267049219692126e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.1956082062170026e-06
sam_encoder.blocks.0.norm2.weight grad: 1.995886668737512e-05
sam_encoder.blocks.0.norm2.bias grad: -2.6668965801945888e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.7353208022541367e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 7.546309461758938e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.4310651497216895e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.0332531019230373e-05
sam_encoder.blocks.1.norm1.weight grad: 6.717190899507841e-06
sam_encoder.blocks.1.norm1.bias grad: 8.040336069825571e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -8.850673111737706e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.210091224696953e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -8.517230526194908e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.480100869841408e-06
sam_encoder.blocks.1.norm2.weight grad: 1.1903755421371898e-06
sam_encoder.blocks.1.norm2.bias grad: 1.4518431044052704e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.816482942260336e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.821209363901289e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.3084409147268161e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.4312436178443022e-06
sam_encoder.blocks.2.norm1.weight grad: -1.1463984264992177e-05
sam_encoder.blocks.2.norm1.bias grad: 2.878657596738776e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -9.38096309255343e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.6500954390940024e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.575681593152694e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.6681656183645828e-06
sam_encoder.blocks.2.norm2.weight grad: -7.230290066218004e-06
sam_encoder.blocks.2.norm2.bias grad: 5.8858654483628925e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -7.900488526502158e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -5.147460342413979e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -4.858698048337828e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.271848925123777e-07
sam_encoder.blocks.3.norm1.weight grad: -3.5399302760197315e-06
sam_encoder.blocks.3.norm1.bias grad: -1.235054014614434e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -6.59682299897213e-08
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 4.811049620911945e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.7911324903252535e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.0170558602549136e-06
sam_encoder.blocks.3.norm2.weight grad: -8.913033525459468e-06
sam_encoder.blocks.3.norm2.bias grad: -4.419910510478076e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -6.461107659561094e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.7284080513491062e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.3199431780085433e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -6.200465207939487e-08
sam_encoder.blocks.4.norm1.weight grad: 1.3828025657858234e-06
sam_encoder.blocks.4.norm1.bias grad: -5.276690899336245e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -9.085781016437977e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 4.4139494548289804e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.154957201128127e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.6838597503010533e-06
sam_encoder.blocks.4.norm2.weight grad: 1.1106421879958361e-05
sam_encoder.blocks.4.norm2.bias grad: 7.466111128451303e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 4.038631232106127e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.2023673434669035e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -9.351241487820516e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 3.544315347880911e-07
sam_encoder.blocks.5.norm1.weight grad: 8.174370123015251e-07
sam_encoder.blocks.5.norm1.bias grad: -4.203438948024996e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.7200447928189533e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.803973757181666e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.5987910728654242e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -8.114496949929162e-07
sam_encoder.blocks.5.norm2.weight grad: 2.5198744424415054e-06
sam_encoder.blocks.5.norm2.bias grad: 3.1666754694015253e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.052493189490633e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.6412146780785406e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -8.603144010521646e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.41280672400535e-08
sam_encoder.blocks.6.norm1.weight grad: 7.921187261672458e-07
sam_encoder.blocks.6.norm1.bias grad: -1.3794167443847982e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.7882533711599535e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.5781358797539724e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.4314871066289925e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.879003512314739e-08
sam_encoder.blocks.6.norm2.weight grad: 2.742693595791934e-06
sam_encoder.blocks.6.norm2.bias grad: 5.882627078790392e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 8.888127922546118e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 6.181045364428428e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.5618192012188956e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.926983657085657e-07
sam_encoder.blocks.7.norm1.weight grad: -2.98643362839357e-06
sam_encoder.blocks.7.norm1.bias grad: -1.2380694158764527e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.9025650317416876e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.4821309832768748e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.0700991879275534e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 6.438236823669286e-07
sam_encoder.blocks.7.norm2.weight grad: -1.7980528355110437e-06
sam_encoder.blocks.7.norm2.bias grad: -1.046362626766495e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.1895584723097272e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.2440607355965767e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.469201245337899e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 6.638919103352237e-07
sam_encoder.blocks.8.norm1.weight grad: -5.774482815468218e-06
sam_encoder.blocks.8.norm1.bias grad: 2.971626997805288e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -3.1671197575633414e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.1978196425843635e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.739534465945326e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.1063225429097656e-06
sam_encoder.blocks.8.norm2.weight grad: 1.2338957731117262e-06
sam_encoder.blocks.8.norm2.bias grad: 1.5446834140675492e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.5568664341335534e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.5700209132774035e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.1707890002508066e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 5.22866230312502e-07
sam_encoder.blocks.9.norm1.weight grad: 1.0542375861177788e-07
sam_encoder.blocks.9.norm1.bias grad: -2.0342934448080996e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -4.240707198732707e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -3.387073661542672e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.0364851732447278e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 9.065255994755717e-07
sam_encoder.blocks.9.norm2.weight grad: -1.098190296033863e-06
sam_encoder.blocks.9.norm2.bias grad: 1.8341943359700963e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.5045364964171313e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -9.665490097177099e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.308035386202391e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 3.4129453752029804e-07
sam_encoder.blocks.10.norm1.weight grad: -2.6664454253477743e-06
sam_encoder.blocks.10.norm1.bias grad: -1.203388535486738e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -1.930387497850461e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -7.881519081820443e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.4765071227884619e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -6.272136943152873e-07
sam_encoder.blocks.10.norm2.weight grad: -3.7128152143850457e-06
sam_encoder.blocks.10.norm2.bias grad: 1.8063336710838485e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.823928070938564e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.5389836107715382e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -8.493091030459254e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.3872982524153485e-07
sam_encoder.blocks.11.norm1.weight grad: -1.0770592780318111e-05
sam_encoder.blocks.11.norm1.bias grad: 7.487453785870457e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -4.1198645703843795e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.3900626072427258e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.709482032514643e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.5263894965755753e-06
sam_encoder.blocks.11.norm2.weight grad: -4.221864401188213e-06
sam_encoder.blocks.11.norm2.bias grad: 4.3264071791782044e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.971545316337142e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -6.525049229821889e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 7.431789583733917e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -5.0845919474795664e-08
sam_encoder.neck.conv1.trainable_scale grad: 6.551917977049015e-07
sam_encoder.neck.conv1.trainable_shift grad: 4.760729098052252e-06
sam_encoder.neck.conv2.trainable_scale grad: 9.47253738559084e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.4358958651428111e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 9.391084313392639e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -5.916808731853962e-08
mask_decoder.transformer.layers.0.norm2.weight grad: 0.002022671513259411
mask_decoder.transformer.layers.0.norm2.bias grad: 2.87658185698092e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -3.880238364217803e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.1425715860677883e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00011384227400412783
mask_decoder.transformer.layers.0.norm4.bias grad: 5.226534995017573e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -6.356611720548244e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -1.921242983371485e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 3.911374369636178e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -1.9627927031251602e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.6264553778455593e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.3090034371998627e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.0003637220943347e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00013698911061510444
mask_decoder.transformer.norm_final_attn.weight grad: -3.145027676509926e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.1401162737456616e-05
Text_Embedding_Affine.0.weight grad: 8.045013440149962e-12
Text_Embedding_Affine.0.bias grad: 3.029908268725734e-10
Text_Embedding_Affine.2.weight grad: -3.0791785787798176e-11
Text_Embedding_Affine.2.bias grad: -1.4299285794550087e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.3104602953072373e-10
Max value: 0.9999427795410156
Mean value: 0.08198592066764832

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.3104602953072373e-10
Max value: 0.9999427795410156
Mean value: 0.08198592066764832

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07636260986328125

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.329011917114258
Max value: -1.1920928244535389e-07
Mean value: -0.11733154207468033

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06674432754516602

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07636260986328125

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 33.210426330566406
Max value: 80.15299224853516
Mean value: 54.92008972167969

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.614746197338036e-10
Max value: 0.9999397993087769
Mean value: 0.0817645788192749

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.614746197338036e-10
Max value: 0.9999397993087769
Mean value: 0.0817645788192749

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.614746197338036e-10
Max value: 0.9999397993087769
Mean value: 0.0817645788192749

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.223936080932617
Max value: -1.1920928244535389e-07
Mean value: -0.11725834757089615

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9645986557006836
Max value: 1.130385398864746
Mean value: 1.000076174736023

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 33.210426330566406
Max value: 80.15299224853516
Mean value: 54.92008972167969

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -54.92593765258789
Max value: -54.92593765258789
Mean value: -54.92593765258789
sam_encoder.pos_embed grad: 1.0593676158521248e-08
sam_encoder.blocks.0.norm1.weight grad: 2.3574129954795353e-05
sam_encoder.blocks.0.norm1.bias grad: -1.9858132873196155e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 9.463636160944588e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.83260439712285e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 6.252523235161789e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.950982550624758e-06
sam_encoder.blocks.0.norm2.weight grad: 1.3339394172362518e-05
sam_encoder.blocks.0.norm2.bias grad: -6.711087189614773e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.2637959520798177e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.8535669369157404e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.5146615623962134e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 6.9758207246195525e-06
sam_encoder.blocks.1.norm1.weight grad: 2.3311233235290274e-05
sam_encoder.blocks.1.norm1.bias grad: 1.0888586984947324e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.840499165467918e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.8874042072857264e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -9.948804290615954e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.569355835177703e-06
sam_encoder.blocks.1.norm2.weight grad: -8.042779882089235e-06
sam_encoder.blocks.1.norm2.bias grad: -4.977694516128395e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.889560841547791e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.2079447060386883e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.5223169359378517e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.7035151763120666e-06
sam_encoder.blocks.2.norm1.weight grad: -2.6237883048452204e-06
sam_encoder.blocks.2.norm1.bias grad: -1.1882124084650059e-07
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -6.196076355990954e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.6212090940825874e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.986209311638959e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.224578565801494e-06
sam_encoder.blocks.2.norm2.weight grad: -3.4096508443326456e-06
sam_encoder.blocks.2.norm2.bias grad: 1.9978240288764937e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.362513209343888e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.2229995718371356e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.318191587226465e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.6956601029960439e-06
sam_encoder.blocks.3.norm1.weight grad: 2.2889228148414986e-06
sam_encoder.blocks.3.norm1.bias grad: -6.581716434084228e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.4447466583078494e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.7043952311723842e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.534069259738317e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -5.440454515337478e-06
sam_encoder.blocks.3.norm2.weight grad: -1.4680072126793675e-05
sam_encoder.blocks.3.norm2.bias grad: 2.0430788936209865e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.0841347830137238e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.4881393276009476e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -8.078211976680905e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -7.223851525850478e-07
sam_encoder.blocks.4.norm1.weight grad: 2.3394402148824156e-07
sam_encoder.blocks.4.norm1.bias grad: -4.356905265012756e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.0905976018402725e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.1376092601267374e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -4.284436727175489e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -4.054470082337502e-06
sam_encoder.blocks.4.norm2.weight grad: 1.1942665878450498e-05
sam_encoder.blocks.4.norm2.bias grad: 8.425464329775423e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 4.573418209474767e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.9108915694232564e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -8.253545047409716e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.580308991033235e-07
sam_encoder.blocks.5.norm1.weight grad: -8.46974944579415e-06
sam_encoder.blocks.5.norm1.bias grad: -1.1939499927393626e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -5.4424444897449575e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.766435843819636e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.1105361156514846e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.901176347018918e-06
sam_encoder.blocks.5.norm2.weight grad: -4.270667432137998e-06
sam_encoder.blocks.5.norm2.bias grad: -7.114713298506103e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.4803449580067536e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.158924972827663e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 9.004979801829904e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.4674196791020222e-07
sam_encoder.blocks.6.norm1.weight grad: 2.29867282541818e-06
sam_encoder.blocks.6.norm1.bias grad: -3.624155851866817e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.1073034329456277e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.2791872450179653e-08
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -7.004206281635561e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.3559235273751256e-07
sam_encoder.blocks.6.norm2.weight grad: 4.252196504239691e-06
sam_encoder.blocks.6.norm2.bias grad: 3.2721879961172817e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.4389769350818824e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 6.620184080929903e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.131006795025314e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 1.0305848263669759e-07
sam_encoder.blocks.7.norm1.weight grad: -2.513841934614902e-07
sam_encoder.blocks.7.norm1.bias grad: -7.10993276697991e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.1838267255370738e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.7758328567651915e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.097645392495906e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 7.071573691064259e-07
sam_encoder.blocks.7.norm2.weight grad: 2.4371199742745375e-06
sam_encoder.blocks.7.norm2.bias grad: -2.749688746916945e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.2670991509367013e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 6.913462016200356e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.0018455895988154e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 8.830090223455045e-07
sam_encoder.blocks.8.norm1.weight grad: 1.197300480271224e-05
sam_encoder.blocks.8.norm1.bias grad: -1.0862935369004845e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.1620713848969899e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.84791837859666e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.643114385136869e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.514738298486918e-06
sam_encoder.blocks.8.norm2.weight grad: 1.0341816505388124e-06
sam_encoder.blocks.8.norm2.bias grad: 1.748267322909669e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.055513270235679e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.195387540064985e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 8.1277130448143e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.1750978501368081e-06
sam_encoder.blocks.9.norm1.weight grad: -8.06992466095835e-06
sam_encoder.blocks.9.norm1.bias grad: 5.170929853193229e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -7.367706530203577e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.2884778445586562e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.9185118819441414e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.3332378330233041e-06
sam_encoder.blocks.9.norm2.weight grad: -3.3170108508784324e-06
sam_encoder.blocks.9.norm2.bias grad: 1.4554951803802396e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.54608289146563e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.568422248965362e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 5.943259111518273e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 8.202308663385338e-07
sam_encoder.blocks.10.norm1.weight grad: -2.7038431653636508e-06
sam_encoder.blocks.10.norm1.bias grad: -2.947165285149822e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.2188091861607973e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -9.481622100793174e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.455194023947115e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -3.359172637829033e-07
sam_encoder.blocks.10.norm2.weight grad: -1.4190429283189587e-05
sam_encoder.blocks.10.norm2.bias grad: -1.5802434063516557e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -9.458078238822054e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.090130798635073e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.6471387880301336e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.145723207533592e-07
sam_encoder.blocks.11.norm1.weight grad: -2.869437957997434e-05
sam_encoder.blocks.11.norm1.bias grad: -1.040587775946733e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.4791570467641577e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.269507947654347e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -3.6544558952300576e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.7549155018059537e-06
sam_encoder.blocks.11.norm2.weight grad: -1.0651061529642902e-05
sam_encoder.blocks.11.norm2.bias grad: -8.368089652321942e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -5.444770977192093e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.461380063323304e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.828575358966191e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.4268768445144815e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.351714672637172e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.724784669931978e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.0164516172371805e-06
sam_encoder.neck.conv2.trainable_shift grad: 8.870034434949048e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -5.578740092460066e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 3.6819110391661525e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004706657957285643
mask_decoder.transformer.layers.0.norm2.bias grad: 6.268083234317601e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 5.110882193548605e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.411147918086499e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -6.230527651496232e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 1.5467167031602003e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 2.217369546997361e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.3490305718732998e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0002024901914410293
mask_decoder.transformer.layers.1.norm2.bias grad: 6.140054028946906e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -8.389971299038734e-06
mask_decoder.transformer.layers.1.norm3.bias grad: 4.138207441428676e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 1.426562994311098e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00022514037846121937
mask_decoder.transformer.norm_final_attn.weight grad: 2.941920456578373e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.0097724043589551e-05
Text_Embedding_Affine.0.weight grad: 2.268127352600402e-11
Text_Embedding_Affine.0.bias grad: 4.303352396650695e-10
Text_Embedding_Affine.2.weight grad: -6.954812420412182e-11
Text_Embedding_Affine.2.bias grad: -3.4847762435674667e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.240310769176858e-09
Max value: 0.9981681108474731
Mean value: 0.08445095270872116

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.240310769176858e-09
Max value: 0.9981681108474731
Mean value: 0.08445095270872116

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07398414611816406

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.731618881225586
Max value: -1.1920928244535389e-07
Mean value: -0.11131066828966141

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07252120971679688

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07398414611816406

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 39.768409729003906
Max value: 69.09332275390625
Mean value: 55.47291564941406

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.8130006646829315e-09
Max value: 0.9980142116546631
Mean value: 0.08408146351575851

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.8130006646829315e-09
Max value: 0.9980142116546631
Mean value: 0.08408146351575851

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.8130006646829315e-09
Max value: 0.9980142116546631
Mean value: 0.08408146351575851

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.168766975402832
Max value: -1.1920928244535389e-07
Mean value: -0.11110004782676697

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9455527067184448
Max value: 1.7641111612319946
Mean value: 1.000240683555603

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 39.768409729003906
Max value: 69.09332275390625
Mean value: 55.47291564941406

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.48653030395508
Max value: -55.48653030395508
Mean value: -55.48653030395508
sam_encoder.pos_embed grad: 5.985942408415212e-09
sam_encoder.blocks.0.norm1.weight grad: -1.752684147504624e-05
sam_encoder.blocks.0.norm1.bias grad: -2.3266917196451686e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -5.631201020150911e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -7.713919671914482e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -6.632410077145323e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.3518507532571675e-06
sam_encoder.blocks.0.norm2.weight grad: 9.623548066883814e-06
sam_encoder.blocks.0.norm2.bias grad: 3.557051513780607e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.2337612133705989e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.565861672745086e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 4.866127483182936e-07
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 5.166873506823322e-06
sam_encoder.blocks.1.norm1.weight grad: 2.1874388949072454e-06
sam_encoder.blocks.1.norm1.bias grad: 1.5969279047567397e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.442919023655122e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.4575286968465662e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.9017027120280545e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.1065656003193e-06
sam_encoder.blocks.1.norm2.weight grad: -1.1467383956187405e-05
sam_encoder.blocks.1.norm2.bias grad: -1.0003963325289078e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -5.058466285845498e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -7.794506018399261e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -7.236067176563665e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.3175305108889006e-07
sam_encoder.blocks.2.norm1.weight grad: -4.3428563003544696e-06
sam_encoder.blocks.2.norm1.bias grad: 1.032085856422782e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -5.897910796193173e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.3598797699596616e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.3674018595775124e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.2706939236959442e-06
sam_encoder.blocks.2.norm2.weight grad: -4.903506578557426e-06
sam_encoder.blocks.2.norm2.bias grad: -6.246552857192e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.544942839856958e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -8.568831617594697e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.2328210686973762e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.9247685233713128e-06
sam_encoder.blocks.3.norm1.weight grad: 2.289099484187318e-06
sam_encoder.blocks.3.norm1.bias grad: 3.8036355363146868e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.869179979825276e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.184264585343044e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.74461728319875e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.593469728002674e-06
sam_encoder.blocks.3.norm2.weight grad: -6.577692602149909e-06
sam_encoder.blocks.3.norm2.bias grad: -1.0694418961065821e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -7.234501936181914e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.4810528884700034e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.094043793476885e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -7.951234692882281e-07
sam_encoder.blocks.4.norm1.weight grad: -2.2945118871575687e-06
sam_encoder.blocks.4.norm1.bias grad: 3.4584197692311136e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.7757996576838195e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.4086349438002799e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.736850547080394e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.232793005736312e-06
sam_encoder.blocks.4.norm2.weight grad: -6.0174961618031375e-06
sam_encoder.blocks.4.norm2.bias grad: 1.7419127971152193e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.703673195966985e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.6824587873998098e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.2604475563857704e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.4731634792042314e-06
sam_encoder.blocks.5.norm1.weight grad: 3.2261823434964754e-06
sam_encoder.blocks.5.norm1.bias grad: -3.5235868836025475e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.846014235226903e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.230992095064721e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -4.719516255136114e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 6.048289833415765e-07
sam_encoder.blocks.5.norm2.weight grad: -3.4339291232754476e-06
sam_encoder.blocks.5.norm2.bias grad: 4.774149601871613e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.6615144836105173e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.1239710602239938e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -3.072523213631939e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.6894595944449975e-07
sam_encoder.blocks.6.norm1.weight grad: -1.0869641755562043e-06
sam_encoder.blocks.6.norm1.bias grad: -4.289507160137873e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.5350482246722095e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 5.476723003994266e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.4234685750125209e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -8.749320272727346e-07
sam_encoder.blocks.6.norm2.weight grad: -8.31809643386805e-07
sam_encoder.blocks.6.norm2.bias grad: 1.4198629969541798e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.6887300944290473e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.45782439631148e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.6280301906590466e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.8311168282234576e-07
sam_encoder.blocks.7.norm1.weight grad: -5.259823865344515e-06
sam_encoder.blocks.7.norm1.bias grad: -4.0036155724010314e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -4.1500766201352235e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.8547574427429936e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.112492893502349e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.970504399650963e-06
sam_encoder.blocks.7.norm2.weight grad: -1.2248237908352166e-06
sam_encoder.blocks.7.norm2.bias grad: 1.7518061667942675e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.920929318861454e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.4042824406933505e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 4.909071549263899e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 3.3827609513537027e-07
sam_encoder.blocks.8.norm1.weight grad: 1.066668673388449e-07
sam_encoder.blocks.8.norm1.bias grad: 1.3860089893569238e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.7378488337271847e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 8.277369261122658e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.3725491448421963e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.233060280967038e-06
sam_encoder.blocks.8.norm2.weight grad: -5.677450644725468e-06
sam_encoder.blocks.8.norm2.bias grad: 7.551079761469737e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.710823072353378e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -4.162802724749781e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.9134677131660283e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.5097654681994754e-07
sam_encoder.blocks.9.norm1.weight grad: 5.216700174059952e-07
sam_encoder.blocks.9.norm1.bias grad: -7.338387035815686e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -6.133170415978384e-08
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.0509919547985191e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.0429862956916622e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.8230857651578845e-07
sam_encoder.blocks.9.norm2.weight grad: -5.278634034766583e-06
sam_encoder.blocks.9.norm2.bias grad: 3.8540551372534537e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.228470399742946e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.6392051495349733e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.558408596087247e-08
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 6.986408607190242e-07
sam_encoder.blocks.10.norm1.weight grad: -9.432305887457915e-07
sam_encoder.blocks.10.norm1.bias grad: -3.6196487940287625e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.070036771328887e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.057196982401365e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.2284585864108521e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -6.859397672087653e-07
sam_encoder.blocks.10.norm2.weight grad: -1.1968459148192778e-05
sam_encoder.blocks.10.norm2.bias grad: -2.117040594384889e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -6.2395110944635235e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.4922227314382326e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -8.08978256827686e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 1.7698238252705778e-07
sam_encoder.blocks.11.norm1.weight grad: -1.0961864973069169e-05
sam_encoder.blocks.11.norm1.bias grad: 1.6275346297334181e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 6.015160579408985e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.0537262369325617e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.1596251542632672e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.3470225818964536e-07
sam_encoder.blocks.11.norm2.weight grad: -6.676370503555518e-06
sam_encoder.blocks.11.norm2.bias grad: -3.739607450370386e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -4.612167231243802e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.722155047900742e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.7256081719096983e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -8.16298992845077e-08
sam_encoder.neck.conv1.trainable_scale grad: 5.62182322028093e-07
sam_encoder.neck.conv1.trainable_shift grad: 5.437388608697802e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.4828565326752141e-06
sam_encoder.neck.conv2.trainable_shift grad: 2.691036570467986e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 4.698975681094453e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 6.844420568086207e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.005809291265904903
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0001514243776910007
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00017888506408780813
mask_decoder.transformer.layers.0.norm3.bias grad: 3.827377804554999e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00010996522178174928
mask_decoder.transformer.layers.0.norm4.bias grad: 1.0957232007058337e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -1.7120355551014654e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -5.707424861611798e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00021973736875224859
mask_decoder.transformer.layers.1.norm2.bias grad: 6.552210106747225e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -3.3236618037335575e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -2.397768184891902e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 4.340862869867124e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00024161956389434636
mask_decoder.transformer.norm_final_attn.weight grad: 1.6420847259723814e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.2969194358447567e-05
Text_Embedding_Affine.0.weight grad: 6.733670478847875e-12
Text_Embedding_Affine.0.bias grad: 1.4442119722346547e-10
Text_Embedding_Affine.2.weight grad: 2.4946801568948018e-11
Text_Embedding_Affine.2.bias grad: 7.150007149903104e-06
Epoch 29 finished with average loss: -55.1119
Epoch 30/39
----------
Epoch 30:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 30:   0%|          | 0/3 [00:00<?, ?it/s, loss=-48.1]Epoch 30:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.07it/s, loss=-48.1]Epoch 30:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.07it/s, loss=-48.8]Epoch 30:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-48.8]Epoch 30:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.65it/s, loss=-52.6]Epoch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.28it/s, loss=-52.6]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.224145534412969e-09
Max value: 0.9991750121116638
Mean value: 0.07090254873037338

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.224145534412969e-09
Max value: 0.9991750121116638
Mean value: 0.07090254873037338

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07552957534790039

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1355595886707306

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06113004684448242

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07552957534790039

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 0.050480056554079056
Max value: 79.65505981445312
Mean value: 48.058494567871094

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.224145534412969e-09
Max value: 0.9991750121116638
Mean value: 0.07090254873037338

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.224145534412969e-09
Max value: 0.9991750121116638
Mean value: 0.07090254873037338

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.224145534412969e-09
Max value: 0.9991750121116638
Mean value: 0.07090254873037338

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1355595886707306

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 0.050480056554079056
Max value: 79.65505981445312
Mean value: 48.058494567871094

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -48.05958938598633
Max value: -48.05958938598633
Mean value: -48.05958938598633
sam_encoder.pos_embed grad: -1.737124555312164e-09
sam_encoder.blocks.0.norm1.weight grad: -5.284066719468683e-05
sam_encoder.blocks.0.norm1.bias grad: -3.348239988554269e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -2.630726839925046e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -6.040601192580652e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.426441080340737e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.379199941060506e-06
sam_encoder.blocks.0.norm2.weight grad: 1.762402825988829e-05
sam_encoder.blocks.0.norm2.bias grad: -1.6044989024521783e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.181004310841672e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 5.061877800471848e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.8403534340905026e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 5.1895567594328895e-06
sam_encoder.blocks.1.norm1.weight grad: -5.7791594372247346e-06
sam_encoder.blocks.1.norm1.bias grad: 1.1875977179442998e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -8.540622729924507e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.4867449635858065e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.82214010541793e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.1668218980485108e-06
sam_encoder.blocks.1.norm2.weight grad: -7.163467671489343e-06
sam_encoder.blocks.1.norm2.bias grad: 2.921451596193947e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.0362290595367085e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -9.058027217179188e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -9.440072062716354e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.253595994261559e-06
sam_encoder.blocks.2.norm1.weight grad: 5.549068646359956e-06
sam_encoder.blocks.2.norm1.bias grad: -5.945657903794199e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -5.876156023987278e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -5.533427724913054e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.406112111610128e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.207756097050151e-06
sam_encoder.blocks.2.norm2.weight grad: -6.6345155573799275e-06
sam_encoder.blocks.2.norm2.bias grad: 7.793652002874296e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -6.033495083102025e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.7431368348752585e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.7596522613748675e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.0767645853302383e-07
sam_encoder.blocks.3.norm1.weight grad: 6.89335138304159e-07
sam_encoder.blocks.3.norm1.bias grad: -1.0895050763792824e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 9.810785741137806e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 2.1224877855274826e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 2.2857623207528377e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.979228040407179e-07
sam_encoder.blocks.3.norm2.weight grad: 7.025519153103232e-06
sam_encoder.blocks.3.norm2.bias grad: -9.15976414717079e-08
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.060475359641714e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 1.885283381852787e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.6250379505654564e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -6.822532441219664e-07
sam_encoder.blocks.4.norm1.weight grad: 1.8384742361376993e-05
sam_encoder.blocks.4.norm1.bias grad: -1.60219642566517e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 5.175182650418719e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.540934474382084e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.0334290436730953e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 6.175383191475703e-07
sam_encoder.blocks.4.norm2.weight grad: 1.1431180610088632e-05
sam_encoder.blocks.4.norm2.bias grad: 6.351245929181459e-07
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 2.2885437829245348e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.058175030266284e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.159875177516369e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.9780122784140985e-06
sam_encoder.blocks.5.norm1.weight grad: 1.953311038960237e-05
sam_encoder.blocks.5.norm1.bias grad: -1.188936221296899e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.4067787560634315e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 9.216371836373582e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -9.262597444603671e-08
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 8.400676847486466e-07
sam_encoder.blocks.5.norm2.weight grad: 1.3615175703307614e-05
sam_encoder.blocks.5.norm2.bias grad: -3.54545306890941e-07
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 4.026276656077243e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.8528834289099905e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.108773626081529e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.1605009149207035e-06
sam_encoder.blocks.6.norm1.weight grad: 4.595086465997156e-06
sam_encoder.blocks.6.norm1.bias grad: 2.0599445633706637e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.117900400364306e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 3.5412347187957494e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.820403549070761e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 3.5153661315234785e-07
sam_encoder.blocks.6.norm2.weight grad: 2.6509865165280644e-06
sam_encoder.blocks.6.norm2.bias grad: -2.8988069971092045e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -5.922438504057936e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 6.161369014989759e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.0794972240546485e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.1584690418640093e-07
sam_encoder.blocks.7.norm1.weight grad: 6.9256220740498975e-06
sam_encoder.blocks.7.norm1.bias grad: -8.081530609160836e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 6.566210686287377e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.0806413683894789e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.7668547772918828e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 5.899478310311679e-06
sam_encoder.blocks.7.norm2.weight grad: 8.516760317434091e-06
sam_encoder.blocks.7.norm2.bias grad: -1.103268914448563e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.7011245694884565e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.420144937786972e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 7.833273230062332e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 8.947810101744835e-07
sam_encoder.blocks.8.norm1.weight grad: 1.1466725482023321e-05
sam_encoder.blocks.8.norm1.bias grad: -3.1192953429126646e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.655252890486736e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 5.78250683247461e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 7.295242312466144e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 4.397787449761381e-07
sam_encoder.blocks.8.norm2.weight grad: 1.0137724530068226e-05
sam_encoder.blocks.8.norm2.bias grad: 3.4459867492842022e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 5.161457920621615e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.489329174044542e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 9.383119277117657e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.3256828879093518e-06
sam_encoder.blocks.9.norm1.weight grad: 1.944425548572326e-06
sam_encoder.blocks.9.norm1.bias grad: 5.276621095617884e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.0276233979311655e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.1540204241100582e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 5.712110464628495e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.5184031073877122e-06
sam_encoder.blocks.9.norm2.weight grad: 2.832508471328765e-06
sam_encoder.blocks.9.norm2.bias grad: 4.297927262086887e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.1803703046098235e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.257935053899928e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.1081471004436025e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.362258820833631e-08
sam_encoder.blocks.10.norm1.weight grad: -4.429436557984445e-06
sam_encoder.blocks.10.norm1.bias grad: -4.5344222598941997e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.0810986118012806e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.1623777709246497e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.506831040387624e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -6.291891168075381e-07
sam_encoder.blocks.10.norm2.weight grad: 4.374873697088333e-06
sam_encoder.blocks.10.norm2.bias grad: 6.1550827012979425e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.2983844044356374e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -9.883157048307112e-08
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 6.794698492740281e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 5.041235340286221e-07
sam_encoder.blocks.11.norm1.weight grad: -5.911000243941089e-06
sam_encoder.blocks.11.norm1.bias grad: -2.4425535229966044e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.310042302473448e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.4332314296771074e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.7376687537762336e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -9.248435048903048e-07
sam_encoder.blocks.11.norm2.weight grad: 2.5029493144757e-07
sam_encoder.blocks.11.norm2.bias grad: 2.741320258792257e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 5.556781843552017e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 3.60250794528838e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -8.017939023829967e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.982182737947369e-07
sam_encoder.neck.conv1.trainable_scale grad: 9.751965990290046e-07
sam_encoder.neck.conv1.trainable_shift grad: 2.7983423933619633e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.8690465114777908e-06
sam_encoder.neck.conv2.trainable_shift grad: 9.587337444827426e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 8.49111020215787e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 2.8378053684718907e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0013874059077352285
mask_decoder.transformer.layers.0.norm2.bias grad: -8.772977162152529e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -0.0001013851651805453
mask_decoder.transformer.layers.0.norm3.bias grad: 4.846610318054445e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00012946486822329462
mask_decoder.transformer.layers.0.norm4.bias grad: 1.558816438773647e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 6.535515240102541e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -2.6299985620426014e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 1.1181287845829502e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -1.6540896467631683e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -2.2959606212680228e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -9.63094316830393e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 2.0276411305530928e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00018895772518590093
mask_decoder.transformer.norm_final_attn.weight grad: 1.4068009477341548e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.5783332855789922e-05
Text_Embedding_Affine.0.weight grad: 7.0248216965662635e-12
Text_Embedding_Affine.0.bias grad: 9.123912736441753e-11
Text_Embedding_Affine.2.weight grad: 2.3634037435438238e-11
Text_Embedding_Affine.2.bias grad: -2.3178830815595575e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.602695890838863e-13
Max value: 0.9998905658721924
Mean value: 0.08124016225337982

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.602695890838863e-13
Max value: 0.9998905658721924
Mean value: 0.08124016225337982

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08793449401855469

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14442968368530273

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06366348266601562

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08793449401855469

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 8.322253227233887
Max value: 65.7314682006836
Mean value: 49.504093170166016

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.7946967967742006e-13
Max value: 0.9998987913131714
Mean value: 0.07952070981264114

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.7946967967742006e-13
Max value: 0.9998987913131714
Mean value: 0.07952070981264114

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.7946967967742006e-13
Max value: 0.9998987913131714
Mean value: 0.07952070981264114

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.14515650272369385

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.7762278318405151
Max value: 1.0684360265731812
Mean value: 0.9993718862533569

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 8.322253227233887
Max value: 65.7314682006836
Mean value: 49.504093170166016

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -49.50737380981445
Max value: -49.50737380981445
Mean value: -49.50737380981445
sam_encoder.pos_embed grad: -2.6345556847218177e-09
sam_encoder.blocks.0.norm1.weight grad: -7.461126187990885e-06
sam_encoder.blocks.0.norm1.bias grad: 8.429791478192783e-07
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 7.735088729532436e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.788906160982151e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 8.704064384801313e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.944051402664627e-06
sam_encoder.blocks.0.norm2.weight grad: 4.758619979838841e-05
sam_encoder.blocks.0.norm2.bias grad: 3.931721437311353e-07
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.115777417406207e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -5.0695216486928985e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -6.74211150908377e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.4076633710355964e-06
sam_encoder.blocks.1.norm1.weight grad: -6.775811471015913e-06
sam_encoder.blocks.1.norm1.bias grad: 9.23355582926888e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -5.1095066737616435e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.3393995434162207e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.837541953544132e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.29873455989582e-06
sam_encoder.blocks.1.norm2.weight grad: -1.9682618130900664e-06
sam_encoder.blocks.1.norm2.bias grad: 4.118240610750945e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -2.5625265607231995e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.886584292762564e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -7.691021892242134e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.6293988664983772e-06
sam_encoder.blocks.2.norm1.weight grad: -1.719787178444676e-05
sam_encoder.blocks.2.norm1.bias grad: 2.9955569971207296e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.2978338418179192e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -4.300578439142555e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -9.176212188322097e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.805600721942028e-06
sam_encoder.blocks.2.norm2.weight grad: -3.013486775671481e-06
sam_encoder.blocks.2.norm2.bias grad: -1.6972240700852126e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -6.7902942646469455e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.3847846932767425e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.007038645184366e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.420694611122599e-06
sam_encoder.blocks.3.norm1.weight grad: -1.694455363576708e-06
sam_encoder.blocks.3.norm1.bias grad: -4.722907760879025e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -7.126117907318985e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.6909617645287653e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.3939921852143016e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.353346866992069e-06
sam_encoder.blocks.3.norm2.weight grad: -4.229113983456045e-06
sam_encoder.blocks.3.norm2.bias grad: 3.4337049328314606e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -5.8223449741490185e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 4.432449074442957e-08
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.7387400248480844e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.027267782978015e-06
sam_encoder.blocks.4.norm1.weight grad: 1.3047053471382242e-05
sam_encoder.blocks.4.norm1.bias grad: -6.190678504935931e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 6.154738002805971e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 8.377061817554932e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.8840283903264208e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.1922265912289731e-06
sam_encoder.blocks.4.norm2.weight grad: -2.625239358167164e-05
sam_encoder.blocks.4.norm2.bias grad: -1.8620117771206424e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.1260391804389656e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -7.430281584674958e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -9.542600309941918e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.817810458414897e-07
sam_encoder.blocks.5.norm1.weight grad: 1.6666817828081548e-05
sam_encoder.blocks.5.norm1.bias grad: -8.140620593621861e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.580065509187989e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.1404196053917985e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.5524917620932683e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 4.399350473249797e-06
sam_encoder.blocks.5.norm2.weight grad: -1.3387296348810196e-05
sam_encoder.blocks.5.norm2.bias grad: -6.062796728656394e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -8.018439984880388e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.5094141165027395e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.387209406151669e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.5268286663049366e-07
sam_encoder.blocks.6.norm1.weight grad: 1.6514884464413626e-06
sam_encoder.blocks.6.norm1.bias grad: -2.403764483460691e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 6.086086159484694e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 9.475528486291296e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -5.591656986325688e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.1387849099264713e-06
sam_encoder.blocks.6.norm2.weight grad: -4.864662514592055e-06
sam_encoder.blocks.6.norm2.bias grad: -5.923372441429819e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -4.99797079100972e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.303678684256738e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.9182566575182136e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 9.337122719443869e-07
sam_encoder.blocks.7.norm1.weight grad: 4.881676431978121e-06
sam_encoder.blocks.7.norm1.bias grad: 1.766459490681882e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.279387447539193e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.1171841833856888e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 6.855752410217519e-09
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.75186841033792e-07
sam_encoder.blocks.7.norm2.weight grad: -4.328824616095517e-06
sam_encoder.blocks.7.norm2.bias grad: -1.4705617559229722e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -4.2693350223999005e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.2494658626092132e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -8.346089543920243e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.302314984741315e-07
sam_encoder.blocks.8.norm1.weight grad: 9.502691682428122e-06
sam_encoder.blocks.8.norm1.bias grad: 1.8859979888929956e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 8.874530976754613e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.694410563388374e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.1191815449128626e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.1735855878214352e-06
sam_encoder.blocks.8.norm2.weight grad: -3.3927076401596423e-06
sam_encoder.blocks.8.norm2.bias grad: 2.229817255283706e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.5420841868472053e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.5033688214316498e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 9.488057912676595e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.589577547951194e-07
sam_encoder.blocks.9.norm1.weight grad: 4.01365014113253e-06
sam_encoder.blocks.9.norm1.bias grad: -4.1850381649055635e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.4392944649443962e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 9.617755480917367e-09
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -7.437503768414899e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.3627301238302607e-07
sam_encoder.blocks.9.norm2.weight grad: -7.769654075673316e-07
sam_encoder.blocks.9.norm2.bias grad: 7.480651902369573e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.6372839531395584e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.1523186458362034e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 5.986190672047087e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 8.40259417600464e-09
sam_encoder.blocks.10.norm1.weight grad: 5.047380454925587e-06
sam_encoder.blocks.10.norm1.bias grad: 1.679526917541807e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.420698481524596e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.198079631758446e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.800841845233663e-08
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.626997570587264e-07
sam_encoder.blocks.10.norm2.weight grad: -4.7596622607670724e-06
sam_encoder.blocks.10.norm2.bias grad: -2.249952785859932e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.4838982426445e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.7059144283848582e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 8.720819266727631e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.570605938170047e-07
sam_encoder.blocks.11.norm1.weight grad: 6.432129794120556e-06
sam_encoder.blocks.11.norm1.bias grad: 3.6063236166228307e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.6865236602825462e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.7466649044072255e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.85981079425801e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -2.4661346742504975e-07
sam_encoder.blocks.11.norm2.weight grad: -1.210462130529777e-07
sam_encoder.blocks.11.norm2.bias grad: 8.571050216232834e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.6467887437320314e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -4.05655043778097e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 6.396230673999526e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.161288878392952e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.6703797882655635e-06
sam_encoder.neck.conv1.trainable_shift grad: -6.022675734129734e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.7852216842584312e-06
sam_encoder.neck.conv2.trainable_shift grad: -4.172546323388815e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 7.639022078365088e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 1.8329519662074745e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.002844837261363864
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0002230911049991846
mask_decoder.transformer.layers.0.norm3.weight grad: 4.985823397873901e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -8.237437214120291e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -2.170997322537005e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -2.512364517315291e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -9.386854799231514e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 4.79695518151857e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 1.7395528630004264e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -1.1201431334484369e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -8.130304195219651e-06
mask_decoder.transformer.layers.1.norm3.bias grad: -1.87724126590183e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -2.0225408661644906e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -8.345550668309443e-06
mask_decoder.transformer.norm_final_attn.weight grad: -3.4659401535463985e-06
mask_decoder.transformer.norm_final_attn.bias grad: -7.704054496571189e-07
Text_Embedding_Affine.0.weight grad: 3.464882200598929e-11
Text_Embedding_Affine.0.bias grad: 1.4804339976137726e-09
Text_Embedding_Affine.2.weight grad: 9.634047032358595e-12
Text_Embedding_Affine.2.bias grad: 1.549120497656986e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0218451862442635e-08
Max value: 0.9982057809829712
Mean value: 0.09998945891857147

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0218451862442635e-08
Max value: 0.9982057809829712
Mean value: 0.09998945891857147

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09160804748535156

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.15195083618164
Max value: -1.1920928244535389e-07
Mean value: -0.12891092896461487

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08029747009277344

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09160804748535156

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 52.2894287109375
Max value: 74.48466491699219
Mean value: 60.173500061035156

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 6.6526353315055076e-09
Max value: 0.9985698461532593
Mean value: 0.09690956771373749

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.6526353315055076e-09
Max value: 0.9985698461532593
Mean value: 0.09690956771373749

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 6.6526353315055076e-09
Max value: 0.9985698461532593
Mean value: 0.09690956771373749

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.616155624389648
Max value: -1.1920928244535389e-07
Mean value: -0.12762191891670227

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.6286348104476929
Max value: 1.043436884880066
Mean value: 1.0014111995697021

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 52.2894287109375
Max value: 74.48466491699219
Mean value: 60.173500061035156

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.266414642333984
Max value: -60.266414642333984
Mean value: -60.266414642333984
sam_encoder.pos_embed grad: 3.761975619909208e-09
sam_encoder.blocks.0.norm1.weight grad: 1.9005701688001864e-05
sam_encoder.blocks.0.norm1.bias grad: -9.401674105902202e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.0953549412515713e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -8.088735370392897e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.583784410286171e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.1512298076231673e-07
sam_encoder.blocks.0.norm2.weight grad: 6.040405423846096e-06
sam_encoder.blocks.0.norm2.bias grad: -6.633735665673157e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.405572670089896e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.1570052669849247e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.2365769180178177e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 8.033443009480834e-06
sam_encoder.blocks.1.norm1.weight grad: 3.4079307624779176e-06
sam_encoder.blocks.1.norm1.bias grad: 1.1845992048620246e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.699759978801012e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.9720091586350463e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -6.577326985279797e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.1331726404459914e-06
sam_encoder.blocks.1.norm2.weight grad: -1.3523385860025883e-06
sam_encoder.blocks.1.norm2.bias grad: -1.8285229543835158e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.5102951844455674e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -5.610805828837329e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -7.281323178176535e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.874472440656973e-07
sam_encoder.blocks.2.norm1.weight grad: -7.645401638001204e-06
sam_encoder.blocks.2.norm1.bias grad: 2.1424446003948105e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -6.310002845566487e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -9.343616511614528e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.8126936487969942e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.5617771370889386e-06
sam_encoder.blocks.2.norm2.weight grad: 2.223913725174498e-06
sam_encoder.blocks.2.norm2.bias grad: -2.918951850006124e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 4.4434517576519283e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.5827449715288822e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.362240921793273e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.512291873950744e-06
sam_encoder.blocks.3.norm1.weight grad: 3.4022241379716434e-07
sam_encoder.blocks.3.norm1.bias grad: 1.5171494283094944e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.7049000007318682e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.5009702514798846e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.0921067971357843e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.13611656363355e-06
sam_encoder.blocks.3.norm2.weight grad: -6.329220013867598e-06
sam_encoder.blocks.3.norm2.bias grad: -6.432180725823855e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -6.244968517421512e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.006095655815443e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.019690095447004e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -3.2266356697618903e-07
sam_encoder.blocks.4.norm1.weight grad: -2.342310381209245e-06
sam_encoder.blocks.4.norm1.bias grad: -4.910110419586999e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.4220493034808896e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -6.508709589070349e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.47971729550045e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.6789712162790238e-06
sam_encoder.blocks.4.norm2.weight grad: 1.6413487173849717e-05
sam_encoder.blocks.4.norm2.bias grad: 1.3874620890419465e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 7.39579400033108e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.81992993222957e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.744028279266786e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -5.276471028992091e-07
sam_encoder.blocks.5.norm1.weight grad: 2.677625843716669e-06
sam_encoder.blocks.5.norm1.bias grad: -1.6148624126799405e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 3.2793195714475587e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.939863290725043e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.27201792060805e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.393721842963714e-07
sam_encoder.blocks.5.norm2.weight grad: 9.292455615650397e-06
sam_encoder.blocks.5.norm2.bias grad: 1.0492576620890759e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 3.1851539006311214e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.4074646514927736e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -2.721033922625793e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.5179656404361594e-07
sam_encoder.blocks.6.norm1.weight grad: 1.0244906434309087e-06
sam_encoder.blocks.6.norm1.bias grad: -5.48066873307107e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 7.000989512562228e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.154529400082538e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -8.074066499830224e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -5.795495638949433e-08
sam_encoder.blocks.6.norm2.weight grad: 2.7223038614465622e-06
sam_encoder.blocks.6.norm2.bias grad: 2.041635070781922e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 7.241423531922919e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.912340105216572e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -4.737626113637816e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.232515943338512e-07
sam_encoder.blocks.7.norm1.weight grad: -3.9176597965706605e-06
sam_encoder.blocks.7.norm1.bias grad: -4.3101726987515576e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.54049370798748e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.877754016277322e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.2122030713944696e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.2420012391630735e-07
sam_encoder.blocks.7.norm2.weight grad: -1.8762382296699798e-06
sam_encoder.blocks.7.norm2.bias grad: -1.346621388620406e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -3.1447104902326828e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -9.88187821349129e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 3.7168305766499543e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.0146457043447299e-06
sam_encoder.blocks.8.norm1.weight grad: -3.6896788060403196e-06
sam_encoder.blocks.8.norm1.bias grad: -6.25029770162655e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -9.460920864512445e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.028714559150103e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.4691685212019365e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -9.40010693284421e-07
sam_encoder.blocks.8.norm2.weight grad: -1.6044295989559032e-06
sam_encoder.blocks.8.norm2.bias grad: 9.468018902225595e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.6697803150455e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.0677795216906816e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 3.787765123774989e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 7.64644369155576e-07
sam_encoder.blocks.9.norm1.weight grad: -1.5102232282515615e-06
sam_encoder.blocks.9.norm1.bias grad: 2.2057483306525683e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.096912339766277e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.236626303580124e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -7.140150728446315e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 6.449137117670034e-07
sam_encoder.blocks.9.norm2.weight grad: -3.828162334684748e-06
sam_encoder.blocks.9.norm2.bias grad: 1.0409561355118058e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.6018403736525215e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.8158827970182756e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.6464716168229643e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 7.781933391015627e-07
sam_encoder.blocks.10.norm1.weight grad: -6.280971774685895e-06
sam_encoder.blocks.10.norm1.bias grad: -1.3290022593537287e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.377175173431169e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.6278445400530472e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.103096448990982e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.080005063158751e-06
sam_encoder.blocks.10.norm2.weight grad: -6.790052339056274e-06
sam_encoder.blocks.10.norm2.bias grad: 3.0680655527248746e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.730997716251295e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.0095376385143027e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.706484624719451e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.814479387325264e-07
sam_encoder.blocks.11.norm1.weight grad: -1.6097130355774425e-05
sam_encoder.blocks.11.norm1.bias grad: 1.177769945570617e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.036277803403209e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.0323512924514944e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.6891591460298514e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.5346311101893662e-06
sam_encoder.blocks.11.norm2.weight grad: -7.3890892053896096e-06
sam_encoder.blocks.11.norm2.bias grad: -1.021445200422022e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -4.338910912338179e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.215748625327251e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.5044051094910174e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.8514603539188101e-07
sam_encoder.neck.conv1.trainable_scale grad: 5.835681804455817e-07
sam_encoder.neck.conv1.trainable_shift grad: 5.733737452828791e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.025277015287429e-06
sam_encoder.neck.conv2.trainable_shift grad: -1.2319738743826747e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00012211025750730187
mask_decoder.transformer.layers.0.norm1.bias grad: 2.465494617354125e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0024956597480922937
mask_decoder.transformer.layers.0.norm2.bias grad: 2.3148080799728632e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 4.694150993600488e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 5.926994163019117e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00010951331933028996
mask_decoder.transformer.layers.0.norm4.bias grad: 6.644966560998e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -2.152057732018875e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -4.409794200910255e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 6.873061647638679e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 7.194976205937564e-06
mask_decoder.transformer.layers.1.norm3.weight grad: -2.3980450350791216e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.1909970453416463e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 5.192159369471483e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00017742680211085826
mask_decoder.transformer.norm_final_attn.weight grad: -1.3846308775100624e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.2794728718290571e-05
Text_Embedding_Affine.0.weight grad: -1.1974830849137419e-11
Text_Embedding_Affine.0.bias grad: -4.468690417702703e-10
Text_Embedding_Affine.2.weight grad: -2.7447700362559502e-11
Text_Embedding_Affine.2.bias grad: -1.5619840269209817e-05
Epoch 30 finished with average loss: -52.6111
Epoch 31/39
----------
Epoch 31:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 31:   0%|          | 0/3 [00:01<?, ?it/s, loss=-60.5]Epoch 31:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.01s/it, loss=-60.5]Epoch 31:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:02,  1.01s/it, loss=-52.1]Epoch 31:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.58it/s, loss=-52.1]Epoch 31:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.58it/s, loss=-55.7]Epoch 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.21it/s, loss=-55.7]/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.452894468766956e-11
Max value: 0.9999691247940063
Mean value: 0.0755409300327301

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.452894468766956e-11
Max value: 0.9999691247940063
Mean value: 0.0755409300327301

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0874166488647461

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1260385811328888

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06886863708496094

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0874166488647461

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 20.037063598632812
Max value: 85.54486846923828
Mean value: 60.53178405761719

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.452894468766956e-11
Max value: 0.9999691247940063
Mean value: 0.0755409300327301

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.452894468766956e-11
Max value: 0.9999691247940063
Mean value: 0.0755409300327301

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.452894468766956e-11
Max value: 0.9999691247940063
Mean value: 0.0755409300327301

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1260385811328888

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 20.037063598632812
Max value: 85.54486846923828
Mean value: 60.53178405761719

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -60.532711029052734
Max value: -60.532711029052734
Mean value: -60.532711029052734
sam_encoder.pos_embed grad: -6.4058176540982e-09
sam_encoder.blocks.0.norm1.weight grad: -2.783413219731301e-05
sam_encoder.blocks.0.norm1.bias grad: 7.569417903141584e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.3280618986755144e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.327556529735375e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.6853026611206587e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.5047855868033366e-06
sam_encoder.blocks.0.norm2.weight grad: -5.227480414760066e-06
sam_encoder.blocks.0.norm2.bias grad: -1.7560512333147926e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -2.9850853024981916e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -4.818836600861687e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.0997580830007792e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -6.005638169881422e-06
sam_encoder.blocks.1.norm1.weight grad: 6.331142685667146e-07
sam_encoder.blocks.1.norm1.bias grad: -8.18112937395199e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.945540134329349e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -9.700897862785496e-10
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 8.156615649568266e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 5.449287527881097e-07
sam_encoder.blocks.1.norm2.weight grad: 1.824260652938392e-05
sam_encoder.blocks.1.norm2.bias grad: 1.6412664081144612e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 8.654626981297042e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.003965619223891e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.8584123608889058e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.3320477516317624e-07
sam_encoder.blocks.2.norm1.weight grad: 6.410880359908333e-06
sam_encoder.blocks.2.norm1.bias grad: -4.672383511206135e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.182669727015309e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 5.059490604253369e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: 1.094675425861169e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.204065527981584e-08
sam_encoder.blocks.2.norm2.weight grad: -9.297177712142002e-06
sam_encoder.blocks.2.norm2.bias grad: 1.9270495954515354e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.663177151087439e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.9696642539202003e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 4.114055627724156e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.0089830715951393e-07
sam_encoder.blocks.3.norm1.weight grad: 3.4923682505905163e-06
sam_encoder.blocks.3.norm1.bias grad: -4.317612820159411e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.443355348688783e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -5.57285133595542e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 1.1057389883717406e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 9.802861313801259e-07
sam_encoder.blocks.3.norm2.weight grad: 4.569934844766976e-06
sam_encoder.blocks.3.norm2.bias grad: 3.878874395013554e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.361692274163943e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.3541567770735128e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.8149314605107065e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.0032866839537746e-06
sam_encoder.blocks.4.norm1.weight grad: -6.496156856883317e-07
sam_encoder.blocks.4.norm1.bias grad: 7.4556317031238e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.275966496905312e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.2734175243167556e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.6938215594564099e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.783296625035291e-06
sam_encoder.blocks.4.norm2.weight grad: -1.805585816327948e-05
sam_encoder.blocks.4.norm2.bias grad: -1.9816643543890677e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.1176072803209536e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.508466190600302e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.840534534698236e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 5.714690587410587e-07
sam_encoder.blocks.5.norm1.weight grad: -6.981204478506697e-06
sam_encoder.blocks.5.norm1.bias grad: 1.6503130382261588e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -9.121793482336216e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -5.954158950771671e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.005331450367521e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.1444674328231486e-06
sam_encoder.blocks.5.norm2.weight grad: -9.373738066642545e-06
sam_encoder.blocks.5.norm2.bias grad: -9.984202733903658e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.102275852346793e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.2079821090082987e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.2894461178802885e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.851555507277226e-07
sam_encoder.blocks.6.norm1.weight grad: 9.794099469218054e-07
sam_encoder.blocks.6.norm1.bias grad: 4.171201908320654e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.9712501853064168e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -7.25572476767411e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 9.594224366082926e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.577534417014249e-07
sam_encoder.blocks.6.norm2.weight grad: -5.257360953692114e-06
sam_encoder.blocks.6.norm2.bias grad: -1.333086402155459e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -4.167059614701429e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.4630932128056884e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 4.247669380674779e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -9.361173169963877e-07
sam_encoder.blocks.7.norm1.weight grad: 8.321609129779972e-06
sam_encoder.blocks.7.norm1.bias grad: 3.124276588550856e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 6.3966958805394825e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.911534465965815e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.2624589039187413e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 8.740869361645309e-07
sam_encoder.blocks.7.norm2.weight grad: 1.8843287534764386e-06
sam_encoder.blocks.7.norm2.bias grad: 2.0791078441106947e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.8728322831739206e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 5.827080826747988e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -8.607898962509353e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.2720197446469683e-06
sam_encoder.blocks.8.norm1.weight grad: 5.6467761169187725e-06
sam_encoder.blocks.8.norm1.bias grad: -1.0487610779819079e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.415138507989468e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.3308419966051588e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.922479779954301e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.27106625061424e-06
sam_encoder.blocks.8.norm2.weight grad: -8.360325409739744e-08
sam_encoder.blocks.8.norm2.bias grad: -4.806531705980888e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 9.95935693026695e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.119201608114963e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.319496499898378e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.0782061963254819e-06
sam_encoder.blocks.9.norm1.weight grad: 3.3742776395229157e-06
sam_encoder.blocks.9.norm1.bias grad: -1.4944889414891804e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 3.6096876101510134e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.867431819846388e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.248254079655453e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.3660593367603724e-07
sam_encoder.blocks.9.norm2.weight grad: 4.8480033001396805e-06
sam_encoder.blocks.9.norm2.bias grad: -2.2706240088155027e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 4.258708031557035e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.934982492457493e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 4.0756103203420935e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.354584911605343e-07
sam_encoder.blocks.10.norm1.weight grad: 7.430152436427306e-06
sam_encoder.blocks.10.norm1.bias grad: 1.2227803836140083e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 5.064082870376296e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.0358509118523216e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.1796558939968236e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.2874988897237927e-06
sam_encoder.blocks.10.norm2.weight grad: 8.329788215633016e-06
sam_encoder.blocks.10.norm2.bias grad: 2.1664786231667676e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.663888375944225e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.5315023322036723e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 2.402753978003602e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.7296373989192944e-07
sam_encoder.blocks.11.norm1.weight grad: 1.9239076209487393e-05
sam_encoder.blocks.11.norm1.bias grad: 1.1590250323934015e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.2993963284534402e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.1780973636632552e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.8858494260930456e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.2637927966352436e-06
sam_encoder.blocks.11.norm2.weight grad: 1.097766562452307e-05
sam_encoder.blocks.11.norm2.bias grad: 1.7239717635675333e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 5.288979991746601e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.0184979803161696e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 3.817112883552909e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.499822417372343e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.4441684470511973e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.2753833289025351e-05
sam_encoder.neck.conv2.trainable_scale grad: -4.343555701780133e-07
sam_encoder.neck.conv2.trainable_shift grad: -7.2384214035992045e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -6.565629155375063e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.831424015108496e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004727013874799013
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00010603893315419555
mask_decoder.transformer.layers.0.norm3.weight grad: -4.537410131888464e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.174698940711096e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00010845337237697095
mask_decoder.transformer.layers.0.norm4.bias grad: -1.0434236173750833e-05
mask_decoder.transformer.layers.1.norm1.weight grad: 5.715406587114558e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 4.030853688163916e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -6.654167373199016e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -2.0640556613216177e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.741715772775933e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.006420567748137e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -5.12926526425872e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00024001504061743617
mask_decoder.transformer.norm_final_attn.weight grad: 1.0840378763532499e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.9216306100133806e-05
Text_Embedding_Affine.0.weight grad: 1.6775632966092857e-11
Text_Embedding_Affine.0.bias grad: 3.0144908791385205e-10
Text_Embedding_Affine.2.weight grad: 1.774608585081161e-11
Text_Embedding_Affine.2.bias grad: 1.2880118447355926e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0777134740180827e-09
Max value: 0.9993281364440918
Mean value: 0.06144922226667404

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.0777134740180827e-09
Max value: 0.9993281364440918
Mean value: 0.06144922226667404

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07305097579956055

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.690363883972168
Max value: -1.1920928244535389e-07
Mean value: -0.12770530581474304

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.046067237854003906

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07305097579956055

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 22.88938331604004
Max value: 59.53575134277344
Mean value: 43.70714569091797

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 7.013578606773763e-10
Max value: 0.9994094371795654
Mean value: 0.06093866378068924

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.013578606773763e-10
Max value: 0.9994094371795654
Mean value: 0.06093866378068924

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 7.013578606773763e-10
Max value: 0.9994094371795654
Mean value: 0.06093866378068924

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12798336148262024

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.7772285342216492
Max value: 1.0263481140136719
Mean value: 0.9997419118881226

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 22.88938331604004
Max value: 59.53575134277344
Mean value: 43.70714569091797

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -43.701053619384766
Max value: -43.701053619384766
Mean value: -43.701053619384766
sam_encoder.pos_embed grad: -5.9616906966653005e-09
sam_encoder.blocks.0.norm1.weight grad: -1.0193900379817933e-05
sam_encoder.blocks.0.norm1.bias grad: 4.0676561184227467e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.4342880376716494e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.519994666272396e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.0061867214972153e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 2.0762608698987606e-07
sam_encoder.blocks.0.norm2.weight grad: 3.046431447728537e-05
sam_encoder.blocks.0.norm2.bias grad: 2.1395640942500904e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -9.217939805239439e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -7.982856914168224e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.1582669685594738e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -3.1606195989297703e-06
sam_encoder.blocks.1.norm1.weight grad: 2.5867536805890268e-06
sam_encoder.blocks.1.norm1.bias grad: 1.4392824596143328e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -5.981014510325622e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.087909933834453e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -5.981300546409329e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.84291582172591e-06
sam_encoder.blocks.1.norm2.weight grad: 2.5302169888163917e-05
sam_encoder.blocks.1.norm2.bias grad: -4.760817319038324e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.1808493733697105e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.7778742176233209e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.782907020242419e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.5765289163027774e-06
sam_encoder.blocks.2.norm1.weight grad: -9.08947731659282e-06
sam_encoder.blocks.2.norm1.bias grad: 2.9946550057502463e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.0316352927475236e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.3302430892945267e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.3811547736113425e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.607676484942203e-06
sam_encoder.blocks.2.norm2.weight grad: -6.7135724748368375e-06
sam_encoder.blocks.2.norm2.bias grad: -1.229876943398267e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.773151431436418e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.9194476408301853e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.4452161849476397e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.8131758849904145e-07
sam_encoder.blocks.3.norm1.weight grad: 9.797377060749568e-07
sam_encoder.blocks.3.norm1.bias grad: -3.2677880881237797e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.215820692683337e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.0292818615198485e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -2.2967160475673154e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.4262400327424984e-07
sam_encoder.blocks.3.norm2.weight grad: 7.97306711319834e-07
sam_encoder.blocks.3.norm2.bias grad: 1.0267040124745108e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.6831489776668604e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.2568674467038363e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.8347836885368451e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.4066184778348543e-07
sam_encoder.blocks.4.norm1.weight grad: 7.158434073062381e-06
sam_encoder.blocks.4.norm1.bias grad: -3.6072883631277364e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 4.27988197770901e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.1291041346339625e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.953874966100557e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.921075065387413e-06
sam_encoder.blocks.4.norm2.weight grad: -3.797694807872176e-05
sam_encoder.blocks.4.norm2.bias grad: -2.6854770112549886e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.664387102413457e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -9.131992555921897e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.2457696811907226e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -9.984553344111191e-07
sam_encoder.blocks.5.norm1.weight grad: 5.399304427555762e-06
sam_encoder.blocks.5.norm1.bias grad: -3.1391753054776927e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 8.930928743211553e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.8694280470299418e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.583933676054585e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.639889598616719e-07
sam_encoder.blocks.5.norm2.weight grad: -1.784055530151818e-05
sam_encoder.blocks.5.norm2.bias grad: -1.0324040886189323e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -7.845243089832366e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.416015377093572e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.7229159513808554e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 2.065746684820624e-07
sam_encoder.blocks.6.norm1.weight grad: -2.1786472643725574e-06
sam_encoder.blocks.6.norm1.bias grad: 3.1895986012386857e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -3.404547896934673e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.4667718915006844e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -4.4143607169644383e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.019389856082853e-06
sam_encoder.blocks.6.norm2.weight grad: -1.7183126601594267e-06
sam_encoder.blocks.6.norm2.bias grad: -8.311896522172901e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.0150818020047154e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.1937554518226534e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.7308852875430603e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.7289306103739364e-07
sam_encoder.blocks.7.norm1.weight grad: 6.001520432619145e-06
sam_encoder.blocks.7.norm1.bias grad: 2.0800152924493887e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.0260550829552813e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.6850065094331512e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.1378483577573206e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -7.726101785010542e-07
sam_encoder.blocks.7.norm2.weight grad: -1.991372755583143e-06
sam_encoder.blocks.7.norm2.bias grad: -4.645091848942684e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.2569610134960385e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.2588784557010513e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.263735888798692e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -6.309229547696305e-07
sam_encoder.blocks.8.norm1.weight grad: 5.125433744979091e-06
sam_encoder.blocks.8.norm1.bias grad: 1.3145104276190978e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.3790271395919262e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -3.4927674619211757e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.7909106847801013e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 8.833839046928915e-07
sam_encoder.blocks.8.norm2.weight grad: -3.1232966648531146e-06
sam_encoder.blocks.8.norm2.bias grad: -7.528287824243307e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.051897354249377e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -5.90417016610445e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.8035620996670332e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.544917485167389e-07
sam_encoder.blocks.9.norm1.weight grad: 1.912475909193745e-06
sam_encoder.blocks.9.norm1.bias grad: -2.463012833686662e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.8007440303335898e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 9.184905138681643e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.306906594640168e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -8.871019190337393e-07
sam_encoder.blocks.9.norm2.weight grad: 4.2406445572851226e-06
sam_encoder.blocks.9.norm2.bias grad: -1.4485351584880846e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.2363220725528663e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.657934603827016e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.1258662198088132e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.3830581830661686e-07
sam_encoder.blocks.10.norm1.weight grad: 9.603246326150838e-06
sam_encoder.blocks.10.norm1.bias grad: 8.02774138719542e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 6.574600320163881e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.364799456699984e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.673222755016468e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.1427405297581572e-06
sam_encoder.blocks.10.norm2.weight grad: 6.348059741867473e-06
sam_encoder.blocks.10.norm2.bias grad: -1.6078263342933496e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.698108002936351e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.2471756437880686e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 6.513685093523236e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.4034843331955926e-07
sam_encoder.blocks.11.norm1.weight grad: 2.0596202375600114e-05
sam_encoder.blocks.11.norm1.bias grad: 2.9754046408925205e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.296567001598305e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 9.809491530177183e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.317238343290228e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 2.3445770125363197e-07
sam_encoder.blocks.11.norm2.weight grad: 6.712037247780245e-06
sam_encoder.blocks.11.norm2.bias grad: -8.260152384309549e-08
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.987122909165919e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.1651552540570265e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.3552077682277286e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.872646606670969e-07
sam_encoder.neck.conv1.trainable_scale grad: -1.2433156371116638e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.071944072667975e-05
sam_encoder.neck.conv2.trainable_scale grad: -1.0568619472905993e-06
sam_encoder.neck.conv2.trainable_shift grad: -3.5036187910009176e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -2.766305442492012e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -2.727185346884653e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.006271129474043846
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0003696305793710053
mask_decoder.transformer.layers.0.norm3.weight grad: 1.672236612648703e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -5.40710061613936e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00011119699775008485
mask_decoder.transformer.layers.0.norm4.bias grad: -7.148686563596129e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 6.15173667029012e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 5.957319899607683e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -5.306981620378792e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -1.852008790592663e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.698277578223497e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -6.772404503863072e-07
mask_decoder.transformer.layers.1.norm4.weight grad: -6.340457912301645e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0002707008388824761
mask_decoder.transformer.norm_final_attn.weight grad: -9.822164201978012e-07
mask_decoder.transformer.norm_final_attn.bias grad: 1.772207542671822e-05
Text_Embedding_Affine.0.weight grad: 8.127742402719296e-12
Text_Embedding_Affine.0.bias grad: 3.4008920679617916e-10
Text_Embedding_Affine.2.weight grad: 1.0365880376284053e-10
Text_Embedding_Affine.2.bias grad: 1.2298576621105894e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.38408606797924e-09
Max value: 0.9974309802055359
Mean value: 0.10640695691108704

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.38408606797924e-09
Max value: 0.9974309802055359
Mean value: 0.10640695691108704

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09806251525878906

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -11.462505340576172
Max value: -1.1920928244535389e-07
Mean value: -0.13327860832214355

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09232902526855469

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09806251525878906

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 54.11073303222656
Max value: 75.16466522216797
Mean value: 62.93401336669922

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 7.12231384980555e-10
Max value: 0.9979230761528015
Mean value: 0.10521644353866577

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.12231384980555e-10
Max value: 0.9979230761528015
Mean value: 0.10521644353866577

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 7.12231384980555e-10
Max value: 0.9979230761528015
Mean value: 0.10521644353866577

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.01025104522705
Max value: -1.1920928244535389e-07
Mean value: -0.13263721764087677

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.5782518982887268
Max value: 1.0489461421966553
Mean value: 1.0007144212722778

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 54.11073303222656
Max value: 75.16466522216797
Mean value: 62.93401336669922

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.983009338378906
Max value: -62.983009338378906
Mean value: -62.983009338378906
sam_encoder.pos_embed grad: 4.052628899131605e-09
sam_encoder.blocks.0.norm1.weight grad: 6.443454822147032e-06
sam_encoder.blocks.0.norm1.bias grad: -1.9381492165848613e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.1905864738537275e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -6.952299003160078e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -4.612894315414451e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -6.725778689542494e-07
sam_encoder.blocks.0.norm2.weight grad: 1.704399983282201e-05
sam_encoder.blocks.0.norm2.bias grad: -2.8868820663774386e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.3609902453026734e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.7559293559752405e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.354937169002369e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.100063218473224e-05
sam_encoder.blocks.1.norm1.weight grad: 3.9969013414520305e-06
sam_encoder.blocks.1.norm1.bias grad: 5.263465482130414e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.290345820365474e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.4153655431291554e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.1198278419615235e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.47130162481335e-06
sam_encoder.blocks.1.norm2.weight grad: -3.877560629916843e-06
sam_encoder.blocks.1.norm2.bias grad: 4.119644927413901e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -2.9174177598179085e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -2.3360291834251257e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -9.477517778577749e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -8.038729788495402e-07
sam_encoder.blocks.2.norm1.weight grad: -1.0405319699202664e-05
sam_encoder.blocks.2.norm1.bias grad: 4.134723894821946e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -8.394127689825837e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.241396032331977e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.055752808402758e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.996999228344066e-06
sam_encoder.blocks.2.norm2.weight grad: -2.4614053018012783e-06
sam_encoder.blocks.2.norm2.bias grad: -1.2741332966470509e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.931203536922112e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.40333128229031e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.934950190247037e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.721206785987306e-06
sam_encoder.blocks.3.norm1.weight grad: -6.120589659985853e-06
sam_encoder.blocks.3.norm1.bias grad: 3.4293639146198984e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.3826813705672976e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.0115059012605343e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.2160339742404176e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.411655370655353e-06
sam_encoder.blocks.3.norm2.weight grad: -7.624238605785649e-06
sam_encoder.blocks.3.norm2.bias grad: -1.8716007161856396e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -8.952417374530341e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.853404566849349e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.3662170153547777e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -5.090993226986029e-07
sam_encoder.blocks.4.norm1.weight grad: -1.676294573371706e-06
sam_encoder.blocks.4.norm1.bias grad: -7.607896804984193e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.633825261000311e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -3.564243513665133e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -3.4650784073164687e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -3.3843753044493496e-06
sam_encoder.blocks.4.norm2.weight grad: 1.5199073459370993e-05
sam_encoder.blocks.4.norm2.bias grad: 1.250101013283711e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 6.876095540064853e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.9846439701941563e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -4.488628633225744e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 8.103332902464899e-07
sam_encoder.blocks.5.norm1.weight grad: 3.857309820887167e-06
sam_encoder.blocks.5.norm1.bias grad: -1.2338130545685999e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 6.537236913572997e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 5.4045221986598335e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.426650098641403e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.4238451246105797e-08
sam_encoder.blocks.5.norm2.weight grad: 4.573985279421322e-06
sam_encoder.blocks.5.norm2.bias grad: 6.7407522692519706e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -7.250088742694061e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.6120105783556937e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 5.088304533273913e-08
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.626918191277582e-07
sam_encoder.blocks.6.norm1.weight grad: 1.023737013383652e-06
sam_encoder.blocks.6.norm1.bias grad: -5.566587333305506e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 9.924899586621905e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.8516501540943864e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -4.5657446889890707e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.107496399617048e-08
sam_encoder.blocks.6.norm2.weight grad: 2.361131919315085e-06
sam_encoder.blocks.6.norm2.bias grad: 2.4592873160145245e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 9.89293766906485e-08
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.530396159272641e-08
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.81545908364933e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 7.719096970504324e-07
sam_encoder.blocks.7.norm1.weight grad: -1.5452326351805823e-06
sam_encoder.blocks.7.norm1.bias grad: -1.3224666872702073e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.980644128707354e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -6.560115934917121e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.8552458413978457e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.834939382661105e-07
sam_encoder.blocks.7.norm2.weight grad: -3.6656783208854904e-07
sam_encoder.blocks.7.norm2.bias grad: 6.396825824594998e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.222317334599211e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -5.415773784989142e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.422317493255832e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.3187626564103994e-06
sam_encoder.blocks.8.norm1.weight grad: -3.9036053749441635e-06
sam_encoder.blocks.8.norm1.bias grad: 3.6864943808723183e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.9002100088982843e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 9.155792213277891e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -4.9909449444385245e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.000776698376285e-06
sam_encoder.blocks.8.norm2.weight grad: -9.511310850029986e-07
sam_encoder.blocks.8.norm2.bias grad: 1.924586740642553e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.894679826364154e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -5.251257562122191e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.4737824471922067e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 7.787888307575486e-07
sam_encoder.blocks.9.norm1.weight grad: -1.3296911447469029e-06
sam_encoder.blocks.9.norm1.bias grad: 4.771484327648068e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.2370691112882923e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.3056486523055355e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.0148280580324354e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.6776294131659597e-08
sam_encoder.blocks.9.norm2.weight grad: -4.268635166226886e-06
sam_encoder.blocks.9.norm2.bias grad: 1.9165570392942755e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -4.956450993631734e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.0444836081878748e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.635629353127001e-09
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 6.828987579865498e-07
sam_encoder.blocks.10.norm1.weight grad: -3.61912748303439e-06
sam_encoder.blocks.10.norm1.bias grad: -5.699064331565751e-08
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -2.9803693450958235e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.2397860018609208e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.6023366242734483e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -8.967894018496736e-07
sam_encoder.blocks.10.norm2.weight grad: -9.793126082513481e-06
sam_encoder.blocks.10.norm2.bias grad: 3.129050583083881e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.146574949321803e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.382775503268931e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -5.670723339790129e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.007939473169245e-08
sam_encoder.blocks.11.norm1.weight grad: -1.5216726751532406e-05
sam_encoder.blocks.11.norm1.bias grad: 6.910512411195668e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.464494855303201e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.2676121059485013e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.670894446055172e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.4191513173500425e-06
sam_encoder.blocks.11.norm2.weight grad: -1.0613079211907461e-05
sam_encoder.blocks.11.norm2.bias grad: -1.118590148507792e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -4.19290427089436e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.995709226321196e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.15725673722045e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.828998049153597e-07
sam_encoder.neck.conv1.trainable_scale grad: 7.522339728893712e-07
sam_encoder.neck.conv1.trainable_shift grad: 6.9155848905211315e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.4746519809705205e-06
sam_encoder.neck.conv2.trainable_shift grad: -2.2213203919818625e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 8.750287815928459e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 1.0723633749876171e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004518374800682068
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00021412753267213702
mask_decoder.transformer.layers.0.norm3.weight grad: 1.766771310940385e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 3.193235897924751e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00012984932982362807
mask_decoder.transformer.layers.0.norm4.bias grad: 9.840523489401676e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -1.5635987438145094e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -2.9682823878829367e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00011892933980561793
mask_decoder.transformer.layers.1.norm2.bias grad: 1.770958988345228e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.646594137127977e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -4.97093105877866e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 5.5289976444328204e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00021529258810915053
mask_decoder.transformer.norm_final_attn.weight grad: -8.687070476298686e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.5215926396194845e-05
Text_Embedding_Affine.0.weight grad: 1.5487968546556985e-11
Text_Embedding_Affine.0.bias grad: 3.198058484699118e-10
Text_Embedding_Affine.2.weight grad: 2.0518396010027473e-11
Text_Embedding_Affine.2.bias grad: -1.7594933524378575e-05
Epoch 31 finished with average loss: -55.7389
Epoch 32/39
----------
Epoch 32:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 32:   0%|          | 0/3 [00:00<?, ?it/s, loss=-52.2]Epoch 32:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.10it/s, loss=-52.2]Epoch 32:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.10it/s, loss=-55.6]Epoch 32:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-55.6]Epoch 32:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.68it/s, loss=-54.6]Epoch 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.33it/s, loss=-54.6]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.3800323730994712e-12
Max value: 0.9995858073234558
Mean value: 0.07148716598749161

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.3800323730994712e-12
Max value: 0.9995858073234558
Mean value: 0.07148716598749161

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08277606964111328

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13258743286132812

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05660390853881836

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08277606964111328

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 21.05597496032715
Max value: 88.27873229980469
Mean value: 52.22467803955078

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.3800323730994712e-12
Max value: 0.9995858073234558
Mean value: 0.07148716598749161

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.3800323730994712e-12
Max value: 0.9995858073234558
Mean value: 0.07148716598749161

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.3800323730994712e-12
Max value: 0.9995858073234558
Mean value: 0.07148716598749161

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13258743286132812

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 21.05597496032715
Max value: 88.27873229980469
Mean value: 52.22467803955078

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -52.22581481933594
Max value: -52.22581481933594
Mean value: -52.22581481933594
sam_encoder.pos_embed grad: -7.531836487828514e-09
sam_encoder.blocks.0.norm1.weight grad: -2.5789913706830703e-05
sam_encoder.blocks.0.norm1.bias grad: 2.254129412904149e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.1654211599961855e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -8.434603842033539e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.974732867893181e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 5.289261295615688e-08
sam_encoder.blocks.0.norm2.weight grad: 3.22795199281245e-06
sam_encoder.blocks.0.norm2.bias grad: 1.8938086213893257e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.29274257637735e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.475643097772263e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.823833710863255e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.0684214518951194e-07
sam_encoder.blocks.1.norm1.weight grad: -5.060415332991397e-06
sam_encoder.blocks.1.norm1.bias grad: -3.5565931284509134e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.736608389066532e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -5.469093480314768e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.64650054507365e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -9.363004096485383e-07
sam_encoder.blocks.1.norm2.weight grad: 2.093032526317984e-05
sam_encoder.blocks.1.norm2.bias grad: 2.3210468498291448e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.5552943700167816e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.138282525265822e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 2.622865167722921e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.8507648746890482e-07
sam_encoder.blocks.2.norm1.weight grad: 4.5461183617589995e-06
sam_encoder.blocks.2.norm1.bias grad: -4.232414539728779e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 4.4656448494606593e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.0433449233460124e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.7977595184202073e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.1225246200629044e-06
sam_encoder.blocks.2.norm2.weight grad: -7.905076927272603e-06
sam_encoder.blocks.2.norm2.bias grad: 5.797292942588683e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.715171482734149e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -2.2146946321299765e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 6.0842426137242e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 1.3011940609430894e-06
sam_encoder.blocks.3.norm1.weight grad: -6.60206524116802e-06
sam_encoder.blocks.3.norm1.bias grad: -7.974932486831676e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 2.153832156182034e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 1.7121683413279243e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 3.281811359556741e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.8981108951265924e-06
sam_encoder.blocks.3.norm2.weight grad: -5.9434219110698905e-06
sam_encoder.blocks.3.norm2.bias grad: -3.2790680393190996e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.3233769777798443e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -9.25456788536394e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.653827201967943e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 8.735234757750732e-08
sam_encoder.blocks.4.norm1.weight grad: 3.749195002455963e-06
sam_encoder.blocks.4.norm1.bias grad: -4.807608547707787e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.543526536806894e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.734628878897638e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.3901193344499916e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.0931853466900066e-06
sam_encoder.blocks.4.norm2.weight grad: -6.071360530768288e-06
sam_encoder.blocks.4.norm2.bias grad: -1.670453457336407e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.588473984767916e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -3.1810156997380545e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.9917982828919776e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 4.30001534823532e-07
sam_encoder.blocks.5.norm1.weight grad: 4.484469172894023e-06
sam_encoder.blocks.5.norm1.bias grad: 5.310703272698447e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 3.3481474019936286e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.6251369743258692e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 4.680119218392065e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.1474719485704554e-06
sam_encoder.blocks.5.norm2.weight grad: -2.6067523322126362e-06
sam_encoder.blocks.5.norm2.bias grad: -9.427454642718658e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -3.25875902262851e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 9.144702630692336e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 8.936955850913364e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -7.208344641185249e-07
sam_encoder.blocks.6.norm1.weight grad: 5.227122073847568e-06
sam_encoder.blocks.6.norm1.bias grad: 6.826106528023956e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.149791038798867e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.192108584291418e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.6306676116073504e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.0855231948880828e-06
sam_encoder.blocks.6.norm2.weight grad: -5.005610546504613e-06
sam_encoder.blocks.6.norm2.bias grad: -5.116843567520846e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.2357972941099433e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.003183228931448e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.9972138690936845e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.1951348142247298e-06
sam_encoder.blocks.7.norm1.weight grad: 1.0063395166071132e-05
sam_encoder.blocks.7.norm1.bias grad: 6.572039268348817e-08
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 8.1748057709774e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.8783447305613663e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 3.322347765788436e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 3.062106770812534e-06
sam_encoder.blocks.7.norm2.weight grad: 3.496206772979349e-06
sam_encoder.blocks.7.norm2.bias grad: -2.5900860691763228e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 4.801596332981717e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.6406748929730384e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -8.54460893151554e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -8.510954785378999e-07
sam_encoder.blocks.8.norm1.weight grad: 3.141502929793205e-06
sam_encoder.blocks.8.norm1.bias grad: -8.829795206111157e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.2481267478724476e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.6715601936521125e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.567322556184081e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.418467374809552e-06
sam_encoder.blocks.8.norm2.weight grad: 6.0433667385950685e-06
sam_encoder.blocks.8.norm2.bias grad: 5.549354114009475e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 5.6651806517038494e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.4217009670101106e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 7.342366359353036e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.2965607488222304e-07
sam_encoder.blocks.9.norm1.weight grad: 5.630316763927112e-07
sam_encoder.blocks.9.norm1.bias grad: 1.730026951918262e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 8.310871635330841e-08
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.7464183201809647e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 6.034979378455319e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.3353064787224866e-06
sam_encoder.blocks.9.norm2.weight grad: 8.136472388287075e-06
sam_encoder.blocks.9.norm2.bias grad: 1.7370909972669324e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 5.670825885317754e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.670633875823114e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.793475684688019e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.905675723421155e-07
sam_encoder.blocks.10.norm1.weight grad: 4.766111487697344e-06
sam_encoder.blocks.10.norm1.bias grad: 1.093858145395643e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.069560534640914e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.5870459719735663e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 9.801699434319744e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 7.778825761306507e-07
sam_encoder.blocks.10.norm2.weight grad: 1.1556321624084376e-05
sam_encoder.blocks.10.norm2.bias grad: 2.7042431156587554e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 6.513513653771952e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.4409082470810972e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.1974429980909918e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.7113785588662722e-07
sam_encoder.blocks.11.norm1.weight grad: 1.2536807844298892e-05
sam_encoder.blocks.11.norm1.bias grad: 7.111804620762996e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.4213726444722852e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.4458756797685055e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 7.904100129962899e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 7.974828974965931e-08
sam_encoder.blocks.11.norm2.weight grad: 1.05442559288349e-05
sam_encoder.blocks.11.norm2.bias grad: 2.5963490770664066e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.500646122731268e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.9621454612206435e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.8184218220085313e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.882800345105352e-07
sam_encoder.neck.conv1.trainable_scale grad: 9.92746208794415e-07
sam_encoder.neck.conv1.trainable_shift grad: 4.937346602673642e-06
sam_encoder.neck.conv2.trainable_scale grad: 2.3406391846947372e-07
sam_encoder.neck.conv2.trainable_shift grad: -2.0110908735659905e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -2.6463148969924077e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -4.3204636313021183e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005293788388371468
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00034461746690794826
mask_decoder.transformer.layers.0.norm3.weight grad: -7.049826672300696e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -7.164027192629874e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.966345634078607e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -6.451325134548824e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 4.654968506656587e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 3.807959728874266e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0001809214591048658
mask_decoder.transformer.layers.1.norm2.bias grad: -5.820266960654408e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 1.8073549654218368e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -7.3681417234183755e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -7.520429062424228e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00020297020091675222
mask_decoder.transformer.norm_final_attn.weight grad: 7.496622629332705e-07
mask_decoder.transformer.norm_final_attn.bias grad: 1.0175657735089771e-05
Text_Embedding_Affine.0.weight grad: 2.1323958224184203e-12
Text_Embedding_Affine.0.bias grad: -2.3146407013285852e-10
Text_Embedding_Affine.2.weight grad: -1.4115206399545333e-13
Text_Embedding_Affine.2.bias grad: -1.3280772691359743e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.328095181913792e-12
Max value: 0.9986633062362671
Mean value: 0.08150628209114075

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.328095181913792e-12
Max value: 0.9986633062362671
Mean value: 0.08150628209114075

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0865478515625

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.036248207092285
Max value: -1.1920928244535389e-07
Mean value: -0.13003036379814148

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07063007354736328

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0865478515625

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 31.925472259521484
Max value: 76.75853729248047
Mean value: 58.91094970703125

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.9042536644753305e-12
Max value: 0.9987446069717407
Mean value: 0.08158117532730103

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.9042536644753305e-12
Max value: 0.9987446069717407
Mean value: 0.08158117532730103

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.9042536644753305e-12
Max value: 0.9987446069717407
Mean value: 0.08158117532730103

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.297919273376465
Max value: -1.1920928244535389e-07
Mean value: -0.12991446256637573

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.7697641849517822
Max value: 1.0443631410598755
Mean value: 1.0001308917999268

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 31.925472259521484
Max value: 76.75853729248047
Mean value: 58.91094970703125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.92169952392578
Max value: -58.92169952392578
Mean value: -58.92169952392578
sam_encoder.pos_embed grad: -3.339955867431854e-09
sam_encoder.blocks.0.norm1.weight grad: -4.38620918430388e-06
sam_encoder.blocks.0.norm1.bias grad: 3.1274985303753056e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.4124014664248534e-08
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.8862922363259713e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.060142034883029e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.793348928913474e-06
sam_encoder.blocks.0.norm2.weight grad: 5.976595275569707e-06
sam_encoder.blocks.0.norm2.bias grad: -2.6711486498243175e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.9287861505290493e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 6.8835070123896e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.1085909136454575e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.1618375285470393e-06
sam_encoder.blocks.1.norm1.weight grad: -5.5783530115149915e-06
sam_encoder.blocks.1.norm1.bias grad: -4.05142191084451e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -3.828719854936935e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.3320338843623176e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.711975068654283e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.2507141491369111e-06
sam_encoder.blocks.1.norm2.weight grad: 8.945516128733288e-06
sam_encoder.blocks.1.norm2.bias grad: 1.666577531977964e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 3.3177454952237895e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 7.909561645647045e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -9.361397133034188e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.2232873106986517e-06
sam_encoder.blocks.2.norm1.weight grad: -1.791900444914063e-06
sam_encoder.blocks.2.norm1.bias grad: -4.210768565826584e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.13366456591757e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -8.218198672693688e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.414619070303161e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -8.912479643186089e-07
sam_encoder.blocks.2.norm2.weight grad: -4.522007202467648e-06
sam_encoder.blocks.2.norm2.bias grad: 6.312309324130183e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.949936737830285e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -4.227062504469359e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.3550624089475605e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 8.787234833107505e-07
sam_encoder.blocks.3.norm1.weight grad: -2.450247620799928e-06
sam_encoder.blocks.3.norm1.bias grad: -6.2840381360729225e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 1.2116367997805355e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 3.8472046526294434e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 4.823567678613472e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.2353939382592216e-07
sam_encoder.blocks.3.norm2.weight grad: 5.15978808834916e-06
sam_encoder.blocks.3.norm2.bias grad: 1.2459368008421734e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.675841410062276e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.3443312784365844e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 1.4506977095152251e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 9.436207051294332e-07
sam_encoder.blocks.4.norm1.weight grad: 9.467271411267575e-06
sam_encoder.blocks.4.norm1.bias grad: -4.999893462809268e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.8940571635539527e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.3926813835496432e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.0622325135045685e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.3432000944012543e-06
sam_encoder.blocks.4.norm2.weight grad: -7.6591477409238e-06
sam_encoder.blocks.4.norm2.bias grad: -4.006108611065429e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -5.991050784359686e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.905680730691529e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 3.1258175567927537e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 4.395808446133742e-07
sam_encoder.blocks.5.norm1.weight grad: 7.281292710104026e-06
sam_encoder.blocks.5.norm1.bias grad: -4.430119588505477e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.0343584310467122e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.0775537450390402e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.212452088201644e-08
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.5525331491517136e-06
sam_encoder.blocks.5.norm2.weight grad: 7.126059244910721e-07
sam_encoder.blocks.5.norm2.bias grad: -4.192302640149137e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -7.715607353020459e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.3615864108705864e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 5.380846914704307e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.8779316469117475e-07
sam_encoder.blocks.6.norm1.weight grad: 7.361171356023988e-06
sam_encoder.blocks.6.norm1.bias grad: 4.516432454693131e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 4.663841536967084e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.6408037026849343e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.6871625803105417e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.3842048929291195e-06
sam_encoder.blocks.6.norm2.weight grad: -2.155681613658089e-06
sam_encoder.blocks.6.norm2.bias grad: -1.1542085758264875e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -2.1848113647138234e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -8.7483545030409e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.4011044388316805e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -7.900929404058843e-07
sam_encoder.blocks.7.norm1.weight grad: 5.612846052827081e-06
sam_encoder.blocks.7.norm1.bias grad: 7.410518492179108e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 5.168074039829662e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 7.523411795773427e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.30356681640842e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.6865737961779814e-06
sam_encoder.blocks.7.norm2.weight grad: 7.957731895658071e-07
sam_encoder.blocks.7.norm2.bias grad: -2.2008248379279394e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.3826754639012506e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 9.237107860826654e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.770545594581563e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.329991381586296e-07
sam_encoder.blocks.8.norm1.weight grad: 6.898317224113271e-06
sam_encoder.blocks.8.norm1.bias grad: -8.523327323928243e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 6.980355465202592e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.815870746213477e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.9064074169582454e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 2.3287552721740212e-06
sam_encoder.blocks.8.norm2.weight grad: 5.049007086199708e-06
sam_encoder.blocks.8.norm2.bias grad: 8.04514627361641e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 4.897211056231754e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.786970753732021e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.2848931874032132e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 1.8320774586300104e-07
sam_encoder.blocks.9.norm1.weight grad: 3.57279168383684e-06
sam_encoder.blocks.9.norm1.bias grad: 3.0903800052328734e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 3.4026586490654154e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.0187030713714194e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 9.06424588720256e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.2865833696196205e-06
sam_encoder.blocks.9.norm2.weight grad: 2.738841430982575e-06
sam_encoder.blocks.9.norm2.bias grad: 3.227883098588791e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.320662133570295e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.407329705216398e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.198454692210362e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.641079556222394e-07
sam_encoder.blocks.10.norm1.weight grad: 3.0592077564506326e-06
sam_encoder.blocks.10.norm1.bias grad: -1.8034863558114012e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.7003311515727546e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.0837087529580458e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 5.252902610664023e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.771269459524774e-07
sam_encoder.blocks.10.norm2.weight grad: 5.4599040595348924e-06
sam_encoder.blocks.10.norm2.bias grad: 1.6698329545761226e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.954781621156144e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.41800728670205e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 8.759285492487834e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.7028912320001837e-08
sam_encoder.blocks.11.norm1.weight grad: 1.004836849460844e-05
sam_encoder.blocks.11.norm1.bias grad: -5.839312962052645e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.4531885881297057e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 6.472923814726528e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 4.3309168518135266e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.6624773024886963e-07
sam_encoder.blocks.11.norm2.weight grad: 3.6771689337911084e-06
sam_encoder.blocks.11.norm2.bias grad: 1.2257512480573496e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 2.0586060145433294e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.0255459983454784e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.688237259462767e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 2.6573633249427075e-07
sam_encoder.neck.conv1.trainable_scale grad: 3.2998832466546446e-07
sam_encoder.neck.conv1.trainable_shift grad: 5.338757546269335e-06
sam_encoder.neck.conv2.trainable_scale grad: 5.225974746281281e-07
sam_encoder.neck.conv2.trainable_shift grad: -1.168804919871036e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 2.0980025510652922e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 1.3027165550738573e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.00611697556450963
mask_decoder.transformer.layers.0.norm2.bias grad: -2.4602661142125726e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -9.628968109609559e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.8161648515379056e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 4.906835238216445e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -7.424849627568619e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 5.4144475143402815e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 1.0195562936132774e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00013420784671325237
mask_decoder.transformer.layers.1.norm2.bias grad: -1.1837215424748138e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -4.210312908980995e-06
mask_decoder.transformer.layers.1.norm3.bias grad: -8.137523764162324e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -8.795224857749417e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -7.12385808583349e-05
mask_decoder.transformer.norm_final_attn.weight grad: 2.1230321181064937e-06
mask_decoder.transformer.norm_final_attn.bias grad: 8.033708581933752e-06
Text_Embedding_Affine.0.weight grad: -1.724910665690249e-11
Text_Embedding_Affine.0.bias grad: -3.284556515659176e-10
Text_Embedding_Affine.2.weight grad: 8.400862470947512e-12
Text_Embedding_Affine.2.bias grad: 2.9962575354147702e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.145488202185078e-12
Max value: 0.9995861649513245
Mean value: 0.0649435818195343

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.145488202185078e-12
Max value: 0.9995861649513245
Mean value: 0.0649435818195343

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0804290771484375

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13052070140838623

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05766868591308594

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0804290771484375

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 35.74480056762695
Max value: 67.15290832519531
Mean value: 52.50552749633789

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.2732237059684977e-12
Max value: 0.9996542930603027
Mean value: 0.06599672883749008

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.2732237059684977e-12
Max value: 0.9996542930603027
Mean value: 0.06599672883749008

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.2732237059684977e-12
Max value: 0.9996542930603027
Mean value: 0.06599672883749008

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1304120421409607

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.7214967012405396
Max value: 1.1093592643737793
Mean value: 1.0001754760742188

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 35.74480056762695
Max value: 67.15290832519531
Mean value: 52.50552749633789

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -52.510982513427734
Max value: -52.510982513427734
Mean value: -52.510982513427734
sam_encoder.pos_embed grad: -5.059587415701117e-09
sam_encoder.blocks.0.norm1.weight grad: -2.6062687538797036e-05
sam_encoder.blocks.0.norm1.bias grad: 1.129366773966467e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.5241175788105465e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.049175347769051e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.7678094081929885e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.2394659165693156e-07
sam_encoder.blocks.0.norm2.weight grad: -1.0861525652217097e-06
sam_encoder.blocks.0.norm2.bias grad: 2.951680653495714e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.0008507160819136e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -5.395484095060965e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.354271353193326e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -6.318276973615866e-06
sam_encoder.blocks.1.norm1.weight grad: -7.925920726847835e-06
sam_encoder.blocks.1.norm1.bias grad: 3.8569163507418125e-07
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 8.488535740980296e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.125744060776924e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 3.04146215057699e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.7542097339173779e-06
sam_encoder.blocks.1.norm2.weight grad: 1.382708978781011e-05
sam_encoder.blocks.1.norm2.bias grad: -1.0887819144045352e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 5.6441485867253505e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.1721765531547135e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 8.197461283998564e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 6.400932761607692e-08
sam_encoder.blocks.2.norm1.weight grad: 2.218796225861297e-06
sam_encoder.blocks.2.norm1.bias grad: 2.9768466447421815e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -7.752045121378615e-07
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -4.4752732719643973e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.4062700276772375e-07
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -8.005154086276889e-07
sam_encoder.blocks.2.norm2.weight grad: 5.002913439966505e-06
sam_encoder.blocks.2.norm2.bias grad: -1.3931805369793437e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 4.772032298205886e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 5.861197038825594e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 4.996386905986583e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 4.869231133852736e-07
sam_encoder.blocks.3.norm1.weight grad: 1.480329956393689e-06
sam_encoder.blocks.3.norm1.bias grad: -3.7098177472216776e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.5074269299475418e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.2325055642747884e-08
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 5.97737653151853e-07
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.586721054991358e-06
sam_encoder.blocks.3.norm2.weight grad: 7.205796464404557e-06
sam_encoder.blocks.3.norm2.bias grad: 7.188024824245076e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.866078481631121e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.348947418795433e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.6173615879088175e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.5557309041014378e-07
sam_encoder.blocks.4.norm1.weight grad: 5.206702553550713e-06
sam_encoder.blocks.4.norm1.bias grad: 2.7929349926125724e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.261166173411766e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.751134502432251e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.3845681173261255e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.6953293854603544e-06
sam_encoder.blocks.4.norm2.weight grad: -1.95220964087639e-05
sam_encoder.blocks.4.norm2.bias grad: -2.0885720005026087e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.3403525372268632e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.2363029681146145e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.174052044916607e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -3.796045575654716e-07
sam_encoder.blocks.5.norm1.weight grad: 2.351406237721676e-06
sam_encoder.blocks.5.norm1.bias grad: 2.1125238163222093e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -7.038046305751777e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -1.996555511141196e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.9031684789515566e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.353924344333791e-07
sam_encoder.blocks.5.norm2.weight grad: -7.6653041105601e-06
sam_encoder.blocks.5.norm2.bias grad: -7.3137935032718815e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.4327837309101596e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.193941655714298e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 5.775936529062164e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -5.534099614123988e-07
sam_encoder.blocks.6.norm1.weight grad: 5.101132387608232e-07
sam_encoder.blocks.6.norm1.bias grad: 3.852939244097797e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.717132363410201e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.5834269788683741e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.305577453398655e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 4.326986413616396e-07
sam_encoder.blocks.6.norm2.weight grad: -3.1646036404708866e-06
sam_encoder.blocks.6.norm2.bias grad: -2.9042555524938507e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -2.3818083718651906e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.3099546549710794e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.0446424312249292e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -2.920565691511001e-07
sam_encoder.blocks.7.norm1.weight grad: 6.326708898996003e-06
sam_encoder.blocks.7.norm1.bias grad: 1.652215246394917e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 3.295548594905995e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.6426073443653877e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.4627275959355757e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -5.014554176341335e-07
sam_encoder.blocks.7.norm2.weight grad: -1.247092313860776e-06
sam_encoder.blocks.7.norm2.bias grad: -1.0931992164842086e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -4.834977289647213e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -6.696955097140744e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.6046991504481412e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.2768366559612332e-06
sam_encoder.blocks.8.norm1.weight grad: 1.0235550689685624e-05
sam_encoder.blocks.8.norm1.bias grad: -1.5874091729983775e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.248465408338234e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.0766360648849513e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.686972493393114e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.5541298807875137e-06
sam_encoder.blocks.8.norm2.weight grad: -6.761926556464459e-07
sam_encoder.blocks.8.norm2.bias grad: -1.0257060694129905e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 7.913328659014951e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.5618649008029024e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.2268977772910148e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -4.875774379797804e-07
sam_encoder.blocks.9.norm1.weight grad: 4.4856378735858016e-06
sam_encoder.blocks.9.norm1.bias grad: -8.890347658052633e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.081559382029809e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.195594788645394e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 4.7545901793455414e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -2.2173762204147351e-07
sam_encoder.blocks.9.norm2.weight grad: 5.3518242566497065e-06
sam_encoder.blocks.9.norm2.bias grad: -2.635239866322081e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.5091143217869103e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.502287998140673e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 3.562950894320238e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.663126844661747e-07
sam_encoder.blocks.10.norm1.weight grad: 7.881116289354395e-06
sam_encoder.blocks.10.norm1.bias grad: 1.0239814400847536e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 5.180021162232151e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.957917675099452e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.6675116967235226e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.075366733668488e-07
sam_encoder.blocks.10.norm2.weight grad: 7.816288416506723e-06
sam_encoder.blocks.10.norm2.bias grad: -2.3545771909994073e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 4.002020432380959e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.4097269033518387e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 6.319472589666475e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.7522972345650487e-07
sam_encoder.blocks.11.norm1.weight grad: 2.3803990188753232e-05
sam_encoder.blocks.11.norm1.bias grad: 1.437132596038282e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 5.538534423976671e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.9121268906019395e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.45738442572474e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.2832915672333911e-06
sam_encoder.blocks.11.norm2.weight grad: 8.5905330706737e-06
sam_encoder.blocks.11.norm2.bias grad: 1.9595368030422833e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.786225306612323e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.678173930486082e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.3295009182456852e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 6.385720041635068e-08
sam_encoder.neck.conv1.trainable_scale grad: 5.681922630174085e-07
sam_encoder.neck.conv1.trainable_shift grad: -9.89288128039334e-06
sam_encoder.neck.conv2.trainable_scale grad: -2.080514605040662e-07
sam_encoder.neck.conv2.trainable_shift grad: 4.2764522731886245e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -9.239329665433615e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.8138416635338217e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.004468775354325771
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00020838732598349452
mask_decoder.transformer.layers.0.norm3.weight grad: -1.3490085621015169e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -3.0720657377969474e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00010015971201937646
mask_decoder.transformer.layers.0.norm4.bias grad: -6.001817382639274e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -9.685560144134797e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 5.489139311976032e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -0.00014246569480746984
mask_decoder.transformer.layers.1.norm2.bias grad: -4.6165027015376836e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 6.222535375854932e-08
mask_decoder.transformer.layers.1.norm3.bias grad: -1.2918501852254849e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -7.211173215182498e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00019958405755460262
mask_decoder.transformer.norm_final_attn.weight grad: 1.1694642125803512e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.2656089893425815e-05
Text_Embedding_Affine.0.weight grad: -5.604790503238588e-12
Text_Embedding_Affine.0.bias grad: -1.7212598013571778e-10
Text_Embedding_Affine.2.weight grad: -1.594836762652818e-11
Text_Embedding_Affine.2.bias grad: 1.5748235455248505e-05
Epoch 32 finished with average loss: -54.5528
Epoch 33/39
----------
Epoch 33:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 33:   0%|          | 0/3 [00:00<?, ?it/s, loss=-65.5]Epoch 33:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.03it/s, loss=-65.5]Epoch 33:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.03it/s, loss=-58.2]Epoch 33:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-58.2]Epoch 33:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.59it/s, loss=-57.8]Epoch 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.22it/s, loss=-57.8]/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.2977874330744044e-10
Max value: 0.9996002316474915
Mean value: 0.10310506075620651

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.2977874330744044e-10
Max value: 0.9996002316474915
Mean value: 0.10310506075620651

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09995603561401367

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.394020080566406
Max value: -1.1920928244535389e-07
Mean value: -0.12911242246627808

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09063959121704102

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09995603561401367

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 38.416568756103516
Max value: 89.84270477294922
Mean value: 65.54011535644531

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.2977874330744044e-10
Max value: 0.9996002316474915
Mean value: 0.10310506075620651

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.2977874330744044e-10
Max value: 0.9996002316474915
Mean value: 0.10310506075620651

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.2977874330744044e-10
Max value: 0.9996002316474915
Mean value: 0.10310506075620651

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.394020080566406
Max value: -1.1920928244535389e-07
Mean value: -0.12911242246627808

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 38.416568756103516
Max value: 89.84270477294922
Mean value: 65.54011535644531

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.54155731201172
Max value: -65.54155731201172
Mean value: -65.54155731201172
sam_encoder.pos_embed grad: 3.194767783654129e-09
sam_encoder.blocks.0.norm1.weight grad: 2.2522368453792296e-05
sam_encoder.blocks.0.norm1.bias grad: -2.3784770746715367e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -6.304055659711594e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -6.009729247580253e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -3.1247586775862146e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -5.987043891764188e-07
sam_encoder.blocks.0.norm2.weight grad: 2.7553707695915364e-05
sam_encoder.blocks.0.norm2.bias grad: 3.795111751969671e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.0558035683061462e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.721419261637493e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.303513974766247e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 8.724639883439522e-06
sam_encoder.blocks.1.norm1.weight grad: 2.091425812977832e-06
sam_encoder.blocks.1.norm1.bias grad: 1.1699987226165831e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.334510544547811e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.6986427908705082e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -4.822883056476712e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.8917697843789938e-06
sam_encoder.blocks.1.norm2.weight grad: -4.178466951998416e-06
sam_encoder.blocks.1.norm2.bias grad: -3.5049095004069386e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -2.325848981854506e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -4.978877310435337e-09
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -8.239532689913176e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -6.119871613918804e-07
sam_encoder.blocks.2.norm1.weight grad: -1.065325614035828e-05
sam_encoder.blocks.2.norm1.bias grad: 3.7907307159912307e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -7.89383557275869e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.664114620325563e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.580366410460556e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.568064473962295e-06
sam_encoder.blocks.2.norm2.weight grad: 1.22068956898147e-06
sam_encoder.blocks.2.norm2.bias grad: -9.159357432508841e-07
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.911142135213595e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.3142844181857072e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.765751433908008e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.4204215403879061e-06
sam_encoder.blocks.3.norm1.weight grad: -2.4364562705159187e-06
sam_encoder.blocks.3.norm1.bias grad: -1.1102444830157765e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.788563157693716e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.053004893947218e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.8510694417273044e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.1974208266328787e-06
sam_encoder.blocks.3.norm2.weight grad: -3.051821693134116e-07
sam_encoder.blocks.3.norm2.bias grad: -2.9806792554154526e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -2.8062609089829493e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.3086959143038257e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -3.982650923717301e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -5.224055144026352e-07
sam_encoder.blocks.4.norm1.weight grad: 6.093652700656094e-06
sam_encoder.blocks.4.norm1.bias grad: -7.5451766861078795e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.45498370329733e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.241909899363236e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.7281555503577692e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.5389936152132577e-06
sam_encoder.blocks.4.norm2.weight grad: 1.673077895247843e-05
sam_encoder.blocks.4.norm2.bias grad: 1.4248997104004957e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 6.580725312232971e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.3690406578680268e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.5190317956003128e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -4.981681556159856e-08
sam_encoder.blocks.5.norm1.weight grad: 4.1594248614273965e-06
sam_encoder.blocks.5.norm1.bias grad: -1.616381632629782e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.805558546649991e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.938954589306377e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.7699068141373573e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.1791405540861888e-06
sam_encoder.blocks.5.norm2.weight grad: 8.764381163928192e-06
sam_encoder.blocks.5.norm2.bias grad: 9.214812962454744e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 2.396560148554272e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 9.043523050422664e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 8.341268085132469e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.52184758362273e-07
sam_encoder.blocks.6.norm1.weight grad: -6.267550816119183e-07
sam_encoder.blocks.6.norm1.bias grad: -4.374092895886861e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 5.41051861091546e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.5630473626515595e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -8.471130854559306e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.7583809014686267e-07
sam_encoder.blocks.6.norm2.weight grad: 4.948195964971092e-06
sam_encoder.blocks.6.norm2.bias grad: 4.33716240877402e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.2271688092369004e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 6.854663183730736e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -1.23906102089677e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.999002788328653e-07
sam_encoder.blocks.7.norm1.weight grad: -3.0257488106144592e-06
sam_encoder.blocks.7.norm1.bias grad: 2.8773229132639244e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -2.0705454062408535e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.9321832951391116e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.7950450203206856e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.9729306422486843e-07
sam_encoder.blocks.7.norm2.weight grad: 2.164297711715335e-06
sam_encoder.blocks.7.norm2.bias grad: -1.2440327736840118e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.5081944866324193e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.0427316371751658e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 6.850263503110909e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.113492317017517e-06
sam_encoder.blocks.8.norm1.weight grad: -3.4289121231267927e-06
sam_encoder.blocks.8.norm1.bias grad: -3.1299941838369705e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.8194168660556898e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.241880909219617e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.6233254832040984e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.0714692254841793e-06
sam_encoder.blocks.8.norm2.weight grad: 1.5199997278614319e-06
sam_encoder.blocks.8.norm2.bias grad: 2.7066876100434456e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.2731140941468766e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 4.1368974024180716e-08
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.412340336377383e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 5.955105280008866e-07
sam_encoder.blocks.9.norm1.weight grad: -2.611211584735429e-06
sam_encoder.blocks.9.norm1.bias grad: 3.1834900937610655e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.267233751103049e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -2.022777607635362e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.368693119729869e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.0417303286658353e-07
sam_encoder.blocks.9.norm2.weight grad: -2.035947545664385e-06
sam_encoder.blocks.9.norm2.bias grad: 1.8629832538863411e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.7905299450358143e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.117966576202889e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.2412170608276938e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 6.846387350378791e-07
sam_encoder.blocks.10.norm1.weight grad: -6.708519322273787e-06
sam_encoder.blocks.10.norm1.bias grad: -7.517982680838031e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.85235841551912e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.8300349893252132e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.586026312201284e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.403612600370252e-06
sam_encoder.blocks.10.norm2.weight grad: -5.969632184132934e-06
sam_encoder.blocks.10.norm2.bias grad: 1.1119075224996777e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.9075903259799816e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.1619439394271467e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.063109493770753e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.164319875599176e-07
sam_encoder.blocks.11.norm1.weight grad: -1.4747572095075157e-05
sam_encoder.blocks.11.norm1.bias grad: -2.11841324926354e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -3.7081690607010387e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.2151800749270478e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.75123284154688e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.1634115253400523e-06
sam_encoder.blocks.11.norm2.weight grad: -3.9447722883778624e-06
sam_encoder.blocks.11.norm2.bias grad: 4.7189155338855926e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.8652916626015212e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -6.846963742646039e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 4.051040320973698e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.4350206356539275e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.2281252566026524e-06
sam_encoder.neck.conv1.trainable_shift grad: 1.4751374692423269e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.6652084013912827e-06
sam_encoder.neck.conv2.trainable_shift grad: 4.692446054832544e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00014376705803442746
mask_decoder.transformer.layers.0.norm1.bias grad: 2.409198714303784e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0019503039075061679
mask_decoder.transformer.layers.0.norm2.bias grad: 5.113543011248112e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 3.1625746487407014e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 4.363289917819202e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00011011363676516339
mask_decoder.transformer.layers.0.norm4.bias grad: 6.735001989000011e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -5.759347914136015e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -2.7301512091071345e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 4.6995352022349834e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 9.833151125349104e-06
mask_decoder.transformer.layers.1.norm3.weight grad: -3.541321348166093e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.305540899920743e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.8356152799678966e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0001994755439227447
mask_decoder.transformer.norm_final_attn.weight grad: -2.5176564122375567e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.4996741811046377e-05
Text_Embedding_Affine.0.weight grad: 1.1612970134133871e-11
Text_Embedding_Affine.0.bias grad: 2.7607222063963377e-10
Text_Embedding_Affine.2.weight grad: 5.881882481073575e-11
Text_Embedding_Affine.2.bias grad: -1.2738119039568119e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.4459277021170655e-15
Max value: 0.9998688697814941
Mean value: 0.06215726584196091

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.4459277021170655e-15
Max value: 0.9998688697814941
Mean value: 0.06215726584196091

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06445741653442383

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11421141028404236

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.05390214920043945

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06445741653442383

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 30.20501136779785
Max value: 58.35135269165039
Mean value: 50.91533660888672

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.1966515137059068e-15
Max value: 0.9998860359191895
Mean value: 0.06257070600986481

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1966515137059068e-15
Max value: 0.9998860359191895
Mean value: 0.06257070600986481

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1966515137059068e-15
Max value: 0.9998860359191895
Mean value: 0.06257070600986481

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11440665274858475

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.6771321892738342
Max value: 1.0659438371658325
Mean value: 0.9998300075531006

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 30.20501136779785
Max value: 58.35135269165039
Mean value: 50.91533660888672

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -50.90413284301758
Max value: -50.90413284301758
Mean value: -50.90413284301758
sam_encoder.pos_embed grad: 2.4687678568113824e-09
sam_encoder.blocks.0.norm1.weight grad: -2.0540937839541584e-05
sam_encoder.blocks.0.norm1.bias grad: 1.887281541712582e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.5116479466523742e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -6.448028671002248e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.2836210316891083e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.237875378341414e-07
sam_encoder.blocks.0.norm2.weight grad: 2.4357893835258437e-06
sam_encoder.blocks.0.norm2.bias grad: -3.165821544826031e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 6.552733793796506e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.3163030366267776e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.5880536011536606e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.4161549845302943e-06
sam_encoder.blocks.1.norm1.weight grad: 8.706143489689566e-06
sam_encoder.blocks.1.norm1.bias grad: 1.4351167010318022e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.5938344328533276e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 2.103228524674705e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.6708246398120536e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 2.1647797154855652e-07
sam_encoder.blocks.1.norm2.weight grad: -3.1773338378116023e-06
sam_encoder.blocks.1.norm2.bias grad: 5.19333752890816e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -3.159314871936658e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 4.790857701664208e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -9.177938409266062e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.827693040468148e-06
sam_encoder.blocks.2.norm1.weight grad: -5.893114575883374e-06
sam_encoder.blocks.2.norm1.bias grad: -4.324183009885019e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.8228057494270615e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.2208495263621444e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.2498189739271766e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.3704196817343473e-06
sam_encoder.blocks.2.norm2.weight grad: -8.132949915307108e-06
sam_encoder.blocks.2.norm2.bias grad: -1.1579955753404647e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.477893526200205e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.1213677453270066e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.656141188912443e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.5809154041999136e-07
sam_encoder.blocks.3.norm1.weight grad: -4.6951208787504584e-07
sam_encoder.blocks.3.norm1.bias grad: 7.482257728952391e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -6.040259449946461e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.815404857552494e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.8144789868965745e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.40596216119593e-06
sam_encoder.blocks.3.norm2.weight grad: 1.0407160516479053e-05
sam_encoder.blocks.3.norm2.bias grad: 8.014021659619175e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 5.950520971964579e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.4301206142117735e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.5365588953718543e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -9.90065586847777e-07
sam_encoder.blocks.4.norm1.weight grad: -3.51571634382708e-06
sam_encoder.blocks.4.norm1.bias grad: 2.8249312435946194e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.1875413242232753e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -7.085586730681825e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.2699841533958534e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -6.321683940768708e-07
sam_encoder.blocks.4.norm2.weight grad: -1.8960174202220514e-05
sam_encoder.blocks.4.norm2.bias grad: -1.7591535652172752e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.4984650988481008e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.9023473113484215e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.716557102961815e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.204173370046192e-06
sam_encoder.blocks.5.norm1.weight grad: -1.9759136193897575e-06
sam_encoder.blocks.5.norm1.bias grad: -1.597410005160782e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.5985136769813835e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.0123081867495785e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 2.467170588715817e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.2267538213327498e-07
sam_encoder.blocks.5.norm2.weight grad: -1.6724239685572684e-05
sam_encoder.blocks.5.norm2.bias grad: -7.915188689366914e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -8.128156878228765e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.408843783996417e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.1486795301607344e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -6.320456122921314e-07
sam_encoder.blocks.6.norm1.weight grad: -1.7200549109475105e-06
sam_encoder.blocks.6.norm1.bias grad: 1.8135964410248562e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.9859883195749717e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -9.221905088452331e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 2.94449534976593e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.8907955734448478e-07
sam_encoder.blocks.6.norm2.weight grad: -1.7498859961051494e-06
sam_encoder.blocks.6.norm2.bias grad: 1.0117690862898598e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -4.863381946051959e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -6.352524906105828e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.441316943688435e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.734918886446394e-07
sam_encoder.blocks.7.norm1.weight grad: 1.4140425719233463e-06
sam_encoder.blocks.7.norm1.bias grad: 1.7837855921243317e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.6420271720107849e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.460689927374915e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 4.580168706525001e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -7.912335036053264e-07
sam_encoder.blocks.7.norm2.weight grad: 1.1830295534309698e-06
sam_encoder.blocks.7.norm2.bias grad: -1.23831455312029e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.9932987217762275e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 6.903637768118642e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.774917670147261e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.618810472336918e-07
sam_encoder.blocks.8.norm1.weight grad: 1.0009609468397684e-05
sam_encoder.blocks.8.norm1.bias grad: 2.6862852564590867e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 8.027540388866328e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.0905581550323404e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 9.046106583809888e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -5.633565933749196e-07
sam_encoder.blocks.8.norm2.weight grad: -5.054938810644671e-06
sam_encoder.blocks.8.norm2.bias grad: -1.2717475783574628e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.036504494957626e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.0686766220023856e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.0767537332867505e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.719916427755379e-07
sam_encoder.blocks.9.norm1.weight grad: -2.0850895907642553e-06
sam_encoder.blocks.9.norm1.bias grad: 1.595736875970033e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.363960220463923e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.0448612641766886e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -8.932039463616093e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.4814964894612785e-07
sam_encoder.blocks.9.norm2.weight grad: -3.180442945449613e-06
sam_encoder.blocks.9.norm2.bias grad: -1.2822713415516773e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -2.665769670784357e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.2423431599017931e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.5020964383438695e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.029552312407759e-07
sam_encoder.blocks.10.norm1.weight grad: 3.7001934742875164e-06
sam_encoder.blocks.10.norm1.bias grad: -7.366965064647957e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.8428563635097817e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 7.708865155109379e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.1433330655563623e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.1142423090859666e-06
sam_encoder.blocks.10.norm2.weight grad: -7.316669780266238e-06
sam_encoder.blocks.10.norm2.bias grad: -2.802097242238233e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -4.186126716376748e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.0442207642190624e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.0020914942288073e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -6.215645953489002e-07
sam_encoder.blocks.11.norm1.weight grad: 2.82787868854939e-06
sam_encoder.blocks.11.norm1.bias grad: 4.898107590634027e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.648637291713385e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 7.357582489930792e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.738009586915723e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 7.405423048112425e-07
sam_encoder.blocks.11.norm2.weight grad: -4.7793764679227024e-06
sam_encoder.blocks.11.norm2.bias grad: -9.827939351225723e-08
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -2.545384177210508e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.2568392548928387e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -9.070408850675449e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.4621908778499346e-07
sam_encoder.neck.conv1.trainable_scale grad: 2.592987584648654e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.9903721951995976e-05
sam_encoder.neck.conv2.trainable_scale grad: -3.7669269659090787e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.8849275622633286e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00011687161168083549
mask_decoder.transformer.layers.0.norm1.bias grad: 1.2207237887196243e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.002534403931349516
mask_decoder.transformer.layers.0.norm2.bias grad: 3.164185909554362e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -8.985713066067547e-06
mask_decoder.transformer.layers.0.norm3.bias grad: 5.411615347838961e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 7.878593896748498e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 7.484763955289964e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 2.367194610997103e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.783071977319196e-07
mask_decoder.transformer.layers.1.norm2.weight grad: -9.342427074443549e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 3.70647685485892e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.473897984600626e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.6159792469115928e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -4.057316982652992e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0001469195558456704
mask_decoder.transformer.norm_final_attn.weight grad: 6.126211701484863e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.6988116840366274e-05
Text_Embedding_Affine.0.weight grad: 6.525032250626062e-13
Text_Embedding_Affine.0.bias grad: 1.8601958862163315e-10
Text_Embedding_Affine.2.weight grad: 6.780593447830441e-12
Text_Embedding_Affine.2.bias grad: 7.015867595328018e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.462453019269617e-10
Max value: 0.9988535642623901
Mean value: 0.09206819534301758

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.462453019269617e-10
Max value: 0.9988535642623901
Mean value: 0.09206819534301758

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09022235870361328

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.859307289123535
Max value: -1.1920928244535389e-07
Mean value: -0.13368210196495056

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07998180389404297

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09022235870361328

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 52.06464767456055
Max value: 61.041351318359375
Mean value: 56.90110778808594

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.1383546882903772e-10
Max value: 0.9991901516914368
Mean value: 0.092335045337677

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1383546882903772e-10
Max value: 0.9991901516914368
Mean value: 0.092335045337677

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1383546882903772e-10
Max value: 0.9991901516914368
Mean value: 0.092335045337677

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13417717814445496

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.549197256565094
Max value: 1.0784319639205933
Mean value: 0.9996037483215332

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 52.06464767456055
Max value: 61.041351318359375
Mean value: 56.90110778808594

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.880340576171875
Max value: -56.880340576171875
Mean value: -56.880340576171875
sam_encoder.pos_embed grad: 4.857200863739308e-09
sam_encoder.blocks.0.norm1.weight grad: -6.220294744707644e-05
sam_encoder.blocks.0.norm1.bias grad: -2.9110284231137484e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.5963726077170577e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.0900930647039786e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.1252558579144534e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.7507895790913608e-06
sam_encoder.blocks.0.norm2.weight grad: -1.4087197996559553e-05
sam_encoder.blocks.0.norm2.bias grad: -3.4536577004473656e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 5.9024837355536874e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.9136066334322095e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -2.4202749955293257e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.6917872471822193e-06
sam_encoder.blocks.1.norm1.weight grad: 2.447425231366651e-06
sam_encoder.blocks.1.norm1.bias grad: -1.6015004575820058e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.3738922177708446e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -5.606532340607373e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.8027920961903874e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 4.4321717496131896e-07
sam_encoder.blocks.1.norm2.weight grad: 5.961775059404317e-06
sam_encoder.blocks.1.norm2.bias grad: 5.973506631562486e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -3.430202468734933e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -5.089231649435533e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.571700972315739e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.158414306701161e-06
sam_encoder.blocks.2.norm1.weight grad: -1.4744257896381896e-05
sam_encoder.blocks.2.norm1.bias grad: -4.855808128922945e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.962139428243972e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.168716036976548e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.294091013434809e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.523645091263461e-06
sam_encoder.blocks.2.norm2.weight grad: 4.067602731083753e-06
sam_encoder.blocks.2.norm2.bias grad: 7.113220817700494e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.0681924322852865e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.1620636541920248e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.8885059338063e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.0844325920043048e-06
sam_encoder.blocks.3.norm1.weight grad: -1.5584320863126777e-05
sam_encoder.blocks.3.norm1.bias grad: -8.413757313974202e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.2683069144259207e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.013951183878817e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -5.336457888915902e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.332584012445295e-06
sam_encoder.blocks.3.norm2.weight grad: -6.225625838851556e-06
sam_encoder.blocks.3.norm2.bias grad: -4.975976480636746e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -7.72259500081418e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.1514994184835814e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.3968483371136244e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 3.2154443374565744e-07
sam_encoder.blocks.4.norm1.weight grad: 1.1075655493186787e-05
sam_encoder.blocks.4.norm1.bias grad: 6.519812814076431e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 6.610128821193939e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.2949893718759995e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.3598663574375678e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 5.611568099084252e-07
sam_encoder.blocks.4.norm2.weight grad: -6.250310889299726e-06
sam_encoder.blocks.4.norm2.bias grad: -2.845584049282479e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.274850996604073e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.982596687521436e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.672651357395807e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.407496711181011e-06
sam_encoder.blocks.5.norm1.weight grad: 4.1931139094231185e-06
sam_encoder.blocks.5.norm1.bias grad: -6.716654297633795e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 3.216475306544453e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 4.838957465835847e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.524664978409419e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -6.892998385410465e-07
sam_encoder.blocks.5.norm2.weight grad: 8.536110271961661e-07
sam_encoder.blocks.5.norm2.bias grad: -1.2617863376362948e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.036405354985618e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 6.36751664728763e-08
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.831138201348949e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 6.220453769856249e-07
sam_encoder.blocks.6.norm1.weight grad: -5.165294169273693e-06
sam_encoder.blocks.6.norm1.bias grad: -4.7739331421325915e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -4.266408268449595e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.0057926829176722e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.760765255516162e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.604806584509788e-06
sam_encoder.blocks.6.norm2.weight grad: 6.6833363234763965e-06
sam_encoder.blocks.6.norm2.bias grad: 6.397666766133625e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.3209777307565673e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 8.187052458197286e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 9.901921202981612e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.497130928233673e-07
sam_encoder.blocks.7.norm1.weight grad: -3.1225251859723357e-06
sam_encoder.blocks.7.norm1.bias grad: -6.222479669304448e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -2.896664000218152e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.8641278529685223e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.5896332519769203e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -5.19113700647722e-06
sam_encoder.blocks.7.norm2.weight grad: 2.4493706405337434e-06
sam_encoder.blocks.7.norm2.bias grad: 2.3009322376310593e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 9.705130423753872e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.2453365267647314e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.946080712717958e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.8513294435251737e-06
sam_encoder.blocks.8.norm1.weight grad: -5.381874416343635e-06
sam_encoder.blocks.8.norm1.bias grad: 1.8967700725625036e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -4.728526619146578e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -4.752365384774748e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -5.913664608669933e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -6.714863047818653e-06
sam_encoder.blocks.8.norm2.weight grad: -6.833786756033078e-06
sam_encoder.blocks.8.norm2.bias grad: -2.695539933483815e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -7.2251677920576185e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.426458079047734e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.502875875303289e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.442724836437264e-08
sam_encoder.blocks.9.norm1.weight grad: -6.11376776760153e-07
sam_encoder.blocks.9.norm1.bias grad: 2.3778864033374703e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 8.224477454632506e-08
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -7.447282541761524e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.6577807571138692e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -6.310872322501382e-07
sam_encoder.blocks.9.norm2.weight grad: -7.716076652286574e-06
sam_encoder.blocks.9.norm2.bias grad: -1.7079564713640139e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -6.281664354901295e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.7340263386577135e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -5.704549721485819e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -9.981680193504872e-08
sam_encoder.blocks.10.norm1.weight grad: 9.596876680006972e-07
sam_encoder.blocks.10.norm1.bias grad: 2.7777832656283863e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 6.920760711182083e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.4539878040741314e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -4.3111205627610616e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -4.438714995558257e-07
sam_encoder.blocks.10.norm2.weight grad: -1.3665294318343513e-05
sam_encoder.blocks.10.norm2.bias grad: -4.847599484492093e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -7.193454621301498e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.928061232727487e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -2.005992428166792e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.403363042612909e-07
sam_encoder.blocks.11.norm1.weight grad: -1.2230819265823811e-05
sam_encoder.blocks.11.norm1.bias grad: 2.1951630060357274e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 5.504132332134759e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.2228572359163081e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.8533195316194906e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 8.053179954004008e-07
sam_encoder.blocks.11.norm2.weight grad: -1.1616213669185527e-05
sam_encoder.blocks.11.norm2.bias grad: -3.6086246382183162e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -5.010505446989555e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.3667273580940673e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.0986091183440294e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.0561375297111226e-07
sam_encoder.neck.conv1.trainable_scale grad: 5.119909474160522e-08
sam_encoder.neck.conv1.trainable_shift grad: -1.8868133338401094e-05
sam_encoder.neck.conv2.trainable_scale grad: 4.204775905236602e-07
sam_encoder.neck.conv2.trainable_shift grad: -2.851526551239658e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00011436446220614016
mask_decoder.transformer.layers.0.norm1.bias grad: -1.4512625057250261e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.003666096134111285
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0001539320801384747
mask_decoder.transformer.layers.0.norm3.weight grad: 1.771487222868018e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -5.3275074606062844e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 4.8503523430554196e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 5.8278405958844814e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.1864643713342957e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 3.8093730836408213e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 2.8789843781851232e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -1.088382487068884e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.2923870346858166e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.4228745789732784e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.685932097141631e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 3.215355900465511e-05
mask_decoder.transformer.norm_final_attn.weight grad: 7.247824214573484e-06
mask_decoder.transformer.norm_final_attn.bias grad: 2.7638598112389445e-06
Text_Embedding_Affine.0.weight grad: -1.062067708085257e-11
Text_Embedding_Affine.0.bias grad: -6.790666917666499e-10
Text_Embedding_Affine.2.weight grad: 2.1160954932764042e-12
Text_Embedding_Affine.2.bias grad: -1.1620279110502452e-05
Epoch 33 finished with average loss: -57.7753
Epoch 34/39
----------
Epoch 34:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 34:   0%|          | 0/3 [00:00<?, ?it/s, loss=-56.8]Epoch 34:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.08it/s, loss=-56.8]Epoch 34:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.08it/s, loss=-57.6]Epoch 34:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-57.6]Epoch 34:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.66it/s, loss=-56.9]Epoch 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.31it/s, loss=-56.9]/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.698723701790364e-11
Max value: 0.999201238155365
Mean value: 0.08614189177751541

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.698723701790364e-11
Max value: 0.999201238155365
Mean value: 0.08614189177751541

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09348297119140625

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13870663940906525

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07681798934936523

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09348297119140625

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 14.250176429748535
Max value: 76.02616119384766
Mean value: 56.79114532470703

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.698723701790364e-11
Max value: 0.999201238155365
Mean value: 0.08614189177751541

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.698723701790364e-11
Max value: 0.999201238155365
Mean value: 0.08614189177751541

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.698723701790364e-11
Max value: 0.999201238155365
Mean value: 0.08614189177751541

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.13870663940906525

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 14.250176429748535
Max value: 76.02616119384766
Mean value: 56.79114532470703

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.79227828979492
Max value: -56.79227828979492
Mean value: -56.79227828979492
sam_encoder.pos_embed grad: -1.0932128979845857e-08
sam_encoder.blocks.0.norm1.weight grad: -6.581122579518706e-05
sam_encoder.blocks.0.norm1.bias grad: -1.8016688045463525e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 3.917278661447199e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.817545118385169e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -5.3697840485256165e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.4262668628362007e-06
sam_encoder.blocks.0.norm2.weight grad: 6.692150782328099e-05
sam_encoder.blocks.0.norm2.bias grad: -7.235362772917142e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.1668542356346734e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -6.981842489039991e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.2687420166912489e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -1.9906255488422175e-07
sam_encoder.blocks.1.norm1.weight grad: -7.236352303152671e-06
sam_encoder.blocks.1.norm1.bias grad: -2.5187243863911135e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -5.898054951103404e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.6079404758784221e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.5283234208473004e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -8.792285370873287e-07
sam_encoder.blocks.1.norm2.weight grad: 3.0419307222473435e-05
sam_encoder.blocks.1.norm2.bias grad: 1.5426135178131517e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.8159260523352714e-07
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.8845261706701422e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 1.1325380000926089e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: 1.970367975445697e-06
sam_encoder.blocks.2.norm1.weight grad: -2.4725120965740643e-05
sam_encoder.blocks.2.norm1.bias grad: -1.2235766917001456e-05
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.1095379704784136e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -3.2397263112216024e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.102718427631771e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -6.571432095370255e-06
sam_encoder.blocks.2.norm2.weight grad: 1.869849620561581e-05
sam_encoder.blocks.2.norm2.bias grad: -2.8735682917613303e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 4.9857180783874355e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -8.818039987090742e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -3.9490614653914236e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.100392975989962e-06
sam_encoder.blocks.3.norm1.weight grad: -2.213098014181014e-05
sam_encoder.blocks.3.norm1.bias grad: -7.026912044238998e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.787282781151589e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.8508710531459656e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.974842795490986e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.6549964786681812e-06
sam_encoder.blocks.3.norm2.weight grad: -1.0918585758190602e-05
sam_encoder.blocks.3.norm2.bias grad: 1.8731177533481969e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -9.937276445270982e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.9120438992104027e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 5.843410690431483e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -8.536267159797717e-08
sam_encoder.blocks.4.norm1.weight grad: 2.0358025722089224e-05
sam_encoder.blocks.4.norm1.bias grad: -1.804944076866377e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.1339320735714864e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 4.826484655495733e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 6.4836108322197106e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 4.825795258511789e-06
sam_encoder.blocks.4.norm2.weight grad: -1.5892930605332367e-05
sam_encoder.blocks.4.norm2.bias grad: -4.319270374253392e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.5056617485242896e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.702298494725255e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.287422833229357e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 3.771263834551064e-07
sam_encoder.blocks.5.norm1.weight grad: 4.602165972755756e-06
sam_encoder.blocks.5.norm1.bias grad: -1.881938624137547e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.51425694336649e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.2769772840547375e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.0760822988231666e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -8.923363452595368e-07
sam_encoder.blocks.5.norm2.weight grad: -1.4970380107115488e-05
sam_encoder.blocks.5.norm2.bias grad: -1.173680902866181e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -9.256693374481983e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.983153081004275e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.496095021342626e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.2961179152171098e-07
sam_encoder.blocks.6.norm1.weight grad: 2.647898099894519e-06
sam_encoder.blocks.6.norm1.bias grad: -3.7925080960121704e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.715006305857969e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.8491494984118617e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.8454286393753137e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.109624569537118e-07
sam_encoder.blocks.6.norm2.weight grad: -2.9506845748983324e-06
sam_encoder.blocks.6.norm2.bias grad: 2.019276507780887e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -5.988236807752401e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.297567334608175e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.190474106100737e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 6.41283349978039e-07
sam_encoder.blocks.7.norm1.weight grad: 6.162250429042615e-06
sam_encoder.blocks.7.norm1.bias grad: 4.3856334741576575e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.75962020168663e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 1.827824917199905e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -8.890808089745406e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -3.9240321711986326e-06
sam_encoder.blocks.7.norm2.weight grad: 1.8107912183040753e-06
sam_encoder.blocks.7.norm2.bias grad: 2.4877372197806835e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -5.004230843042023e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.1579339798117871e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -7.19468403076462e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -7.349648001309106e-08
sam_encoder.blocks.8.norm1.weight grad: -3.212938736396609e-06
sam_encoder.blocks.8.norm1.bias grad: 2.045081373580615e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -4.544738203549059e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.2875843822257593e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.0512488845270127e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.46779814006004e-06
sam_encoder.blocks.8.norm2.weight grad: -4.042771251988597e-06
sam_encoder.blocks.8.norm2.bias grad: -1.9429207895882428e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -3.5348946312296903e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.490434326318791e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.7815980299928924e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -9.477448088546225e-07
sam_encoder.blocks.9.norm1.weight grad: 2.777319878077833e-06
sam_encoder.blocks.9.norm1.bias grad: 1.1780476825151709e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.2574912489071721e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 9.473674253968056e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 9.541298595650005e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.0998410289175808e-06
sam_encoder.blocks.9.norm2.weight grad: 1.41341865855793e-06
sam_encoder.blocks.9.norm2.bias grad: -3.8076700548117515e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.8328207715967437e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.5601379743657162e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.455473684965682e-09
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -4.0238475662590645e-07
sam_encoder.blocks.10.norm1.weight grad: 1.0638366802595556e-05
sam_encoder.blocks.10.norm1.bias grad: 2.0485463210206944e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 6.241456503630616e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.379234501859173e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.6268679701170186e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 9.575210242473986e-07
sam_encoder.blocks.10.norm2.weight grad: 7.617707069584867e-06
sam_encoder.blocks.10.norm2.bias grad: -4.1917878661479335e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 6.718271833960898e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 7.932055154924456e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -5.691950377695321e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.6888362703612074e-07
sam_encoder.blocks.11.norm1.weight grad: 2.0021197997266427e-05
sam_encoder.blocks.11.norm1.bias grad: 1.6271851563942619e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 4.312213604862336e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.1061893019359559e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.293469035270391e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.4802960777160479e-06
sam_encoder.blocks.11.norm2.weight grad: 6.92020603310084e-06
sam_encoder.blocks.11.norm2.bias grad: -3.2700106658012373e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.262807346502086e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 7.358976290561259e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.7668132841208717e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.829397314802918e-07
sam_encoder.neck.conv1.trainable_scale grad: -2.560827851993963e-07
sam_encoder.neck.conv1.trainable_shift grad: 1.9243962015025318e-06
sam_encoder.neck.conv2.trainable_scale grad: -1.575335772940889e-06
sam_encoder.neck.conv2.trainable_shift grad: -5.186019916436635e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.0002137668925570324
mask_decoder.transformer.layers.0.norm1.bias grad: -2.49387085204944e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.001785121625289321
mask_decoder.transformer.layers.0.norm2.bias grad: 0.000393329537473619
mask_decoder.transformer.layers.0.norm3.weight grad: -4.300444197724573e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.7834688808070496e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 0.00011354152957210317
mask_decoder.transformer.layers.0.norm4.bias grad: -6.6137081375927664e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.6224082577973604e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 1.527201311546378e-05
mask_decoder.transformer.layers.1.norm2.weight grad: -1.7016085621435195e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -5.297277675708756e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -2.417247515040799e-06
mask_decoder.transformer.layers.1.norm3.bias grad: -2.1169402316445485e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.493918484309688e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00019917867030017078
mask_decoder.transformer.norm_final_attn.weight grad: 3.1962658795237076e-06
mask_decoder.transformer.norm_final_attn.bias grad: 2.210846469097305e-05
Text_Embedding_Affine.0.weight grad: 4.705685494044154e-12
Text_Embedding_Affine.0.bias grad: 1.4356168476226117e-09
Text_Embedding_Affine.2.weight grad: 1.8564733084147633e-11
Text_Embedding_Affine.2.bias grad: 7.071863365126774e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.1179620470268639e-15
Max value: 0.9999269247055054
Mean value: 0.0740826278924942

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1179620470268639e-15
Max value: 0.9999269247055054
Mean value: 0.0740826278924942

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07447576522827148

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11356346309185028

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06633377075195312

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07447576522827148

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 43.57064437866211
Max value: 89.5230484008789
Mean value: 58.42097473144531

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 2.087576649495741e-15
Max value: 0.99991774559021
Mean value: 0.07478513568639755

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.087576649495741e-15
Max value: 0.99991774559021
Mean value: 0.07478513568639755

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 2.087576649495741e-15
Max value: 0.99991774559021
Mean value: 0.07478513568639755

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11342626810073853

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9686843156814575
Max value: 1.4038509130477905
Mean value: 1.0001649856567383

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 43.57064437866211
Max value: 89.5230484008789
Mean value: 58.42097473144531

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.432159423828125
Max value: -58.432159423828125
Mean value: -58.432159423828125
sam_encoder.pos_embed grad: 1.631053736517174e-09
sam_encoder.blocks.0.norm1.weight grad: -1.8257151168654673e-05
sam_encoder.blocks.0.norm1.bias grad: 4.238546171109192e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.048181502483203e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.6211866333578655e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 3.972182639699895e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.5055395579111064e-06
sam_encoder.blocks.0.norm2.weight grad: 3.378297697054222e-05
sam_encoder.blocks.0.norm2.bias grad: 1.22072669910267e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.4838608371501323e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -5.836764103150927e-07
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.2343301023065578e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.9657676350325346e-06
sam_encoder.blocks.1.norm1.weight grad: -8.011381396499928e-06
sam_encoder.blocks.1.norm1.bias grad: -1.0599425877444446e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -4.860214062318846e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -5.783100505141192e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.1492074918351136e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.5635530417057453e-06
sam_encoder.blocks.1.norm2.weight grad: 1.2064500879205298e-05
sam_encoder.blocks.1.norm2.bias grad: 2.5327444745926186e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.60094202531036e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.4106043977335503e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 5.127839813212631e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.8964313969481736e-07
sam_encoder.blocks.2.norm1.weight grad: -3.966926669818349e-06
sam_encoder.blocks.2.norm1.bias grad: 1.8346572687732987e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.694638508022763e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.3416287174550234e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.8885050394601421e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.3085696031776024e-06
sam_encoder.blocks.2.norm2.weight grad: 1.1806150723714381e-05
sam_encoder.blocks.2.norm2.bias grad: -1.4769040717510507e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 5.776754733233247e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 9.413756174581067e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 2.0361626411613543e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.9090042491807253e-07
sam_encoder.blocks.3.norm1.weight grad: 4.77109551866306e-08
sam_encoder.blocks.3.norm1.bias grad: -7.493953262383002e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.101006197743118e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.1801796517829644e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.5983063121893792e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -6.700687436023145e-07
sam_encoder.blocks.3.norm2.weight grad: 1.2705517292488366e-05
sam_encoder.blocks.3.norm2.bias grad: -1.2448253983166069e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 7.805915629433002e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.0499627428071108e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.841901277861325e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.5576840439734951e-07
sam_encoder.blocks.4.norm1.weight grad: 2.5222593649232294e-06
sam_encoder.blocks.4.norm1.bias grad: 7.909819942142349e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.1600423022173345e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.1140346032334492e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.6290572091293143e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.6077592590590939e-09
sam_encoder.blocks.4.norm2.weight grad: -2.039454921032302e-05
sam_encoder.blocks.4.norm2.bias grad: -1.7749247490428388e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.3566634152084589e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.127768872625893e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.4321085473056883e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.4886649069012492e-06
sam_encoder.blocks.5.norm1.weight grad: 1.7663633116171695e-06
sam_encoder.blocks.5.norm1.bias grad: 2.209508011219441e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.6287277655210346e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.0844981918344274e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.001317286863923e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.636236786202062e-06
sam_encoder.blocks.5.norm2.weight grad: -1.0971363735734485e-05
sam_encoder.blocks.5.norm2.bias grad: -1.0270552593283355e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.684562893293332e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.2183080545801204e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.3217886589700356e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -2.1514162540370307e-07
sam_encoder.blocks.6.norm1.weight grad: -7.285802894330118e-07
sam_encoder.blocks.6.norm1.bias grad: 1.2688894912571413e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.7148394110554364e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -4.3590171117102727e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.94474994891425e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.0965291039610747e-06
sam_encoder.blocks.6.norm2.weight grad: 1.9488693396851886e-06
sam_encoder.blocks.6.norm2.bias grad: 6.575334623448725e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 9.04217301922472e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.0739769840693043e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.861252144408354e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.44576244262862e-07
sam_encoder.blocks.7.norm1.weight grad: 2.5409142381249694e-06
sam_encoder.blocks.7.norm1.bias grad: 1.5206358057184843e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.4881461538607255e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 5.435271077658399e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.0690497137820785e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.8356540749664418e-06
sam_encoder.blocks.7.norm2.weight grad: 2.466527348587988e-06
sam_encoder.blocks.7.norm2.bias grad: -1.4494253264274448e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 2.8483216283348156e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 5.440426207314886e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.12571046379162e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.8119777084611997e-07
sam_encoder.blocks.8.norm1.weight grad: 1.3752384802501183e-05
sam_encoder.blocks.8.norm1.bias grad: -3.6536130210151896e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.2063933354511391e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.6440155781747308e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.4697707229061052e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 9.455319371909354e-08
sam_encoder.blocks.8.norm2.weight grad: -2.288522864546394e-06
sam_encoder.blocks.8.norm2.bias grad: -1.338749370916048e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.144711063716386e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -8.793304004939273e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.0824940090969903e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.327047342187143e-07
sam_encoder.blocks.9.norm1.weight grad: -2.5962499421439134e-06
sam_encoder.blocks.9.norm1.bias grad: 4.800699571205769e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.5564775114617078e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.702694127445284e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.124479467762285e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.9719216197700007e-06
sam_encoder.blocks.9.norm2.weight grad: 4.694137345495619e-08
sam_encoder.blocks.9.norm2.bias grad: -4.2858650317612046e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -7.933459755804506e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -6.983099751778354e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.332365056645358e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -2.8935613727298914e-07
sam_encoder.blocks.10.norm1.weight grad: 1.46975651205139e-06
sam_encoder.blocks.10.norm1.bias grad: 2.909327463385125e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 6.822332920819463e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 6.713545985803648e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 7.657945388928056e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 5.795568540634122e-07
sam_encoder.blocks.10.norm2.weight grad: -1.6814077525850735e-06
sam_encoder.blocks.10.norm2.bias grad: -1.4376480521605117e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.3671709666596144e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.641968752774119e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -6.688897968842866e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.178158797188189e-07
sam_encoder.blocks.11.norm1.weight grad: 8.665444397593092e-07
sam_encoder.blocks.11.norm1.bias grad: 3.5201401260565035e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.888435119530186e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 8.2548831414897e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 9.221788559443667e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 3.0527411354341893e-07
sam_encoder.blocks.11.norm2.weight grad: -2.987014340760652e-06
sam_encoder.blocks.11.norm2.bias grad: 5.888168743695132e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -7.541216291429009e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.1128870482934872e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.6601364905000082e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.2999970522287185e-07
sam_encoder.neck.conv1.trainable_scale grad: -7.204744179034606e-07
sam_encoder.neck.conv1.trainable_shift grad: -2.3381693608826026e-05
sam_encoder.neck.conv2.trainable_scale grad: -9.81431185209658e-07
sam_encoder.neck.conv2.trainable_shift grad: 4.679863923229277e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00015602185158059
mask_decoder.transformer.layers.0.norm1.bias grad: -1.6484336811117828e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.001710651209577918
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0003870453219860792
mask_decoder.transformer.layers.0.norm3.weight grad: -6.5362692112103105e-06
mask_decoder.transformer.layers.0.norm3.bias grad: -4.175277354079299e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 6.721664976794273e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 3.3488918234070297e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.1089575966470875e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -2.0158258848823607e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -1.2709642760455608e-07
mask_decoder.transformer.layers.1.norm2.bias grad: 8.970184353529476e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 3.0953524401411414e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 2.774616405076813e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -4.714396709459834e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -7.781532622175291e-05
mask_decoder.transformer.norm_final_attn.weight grad: 5.342282292986056e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.0024097718996927e-05
Text_Embedding_Affine.0.weight grad: 4.209860758608297e-12
Text_Embedding_Affine.0.bias grad: 1.4207926501974555e-10
Text_Embedding_Affine.2.weight grad: -5.1717477522750244e-11
Text_Embedding_Affine.2.bias grad: -2.6535017241258174e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.1175737668622787e-08
Max value: 0.9977781176567078
Mean value: 0.09776714444160461

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1175737668622787e-08
Max value: 0.9977781176567078
Mean value: 0.09776714444160461

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08347702026367188

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.241425514221191
Max value: -1.1920928244535389e-07
Mean value: -0.13149049878120422

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08233642578125

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08347702026367188

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 51.506126403808594
Max value: 66.42731475830078
Mean value: 55.66364288330078

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.1587145343792145e-08
Max value: 0.9972426891326904
Mean value: 0.10062055289745331

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.1587145343792145e-08
Max value: 0.9972426891326904
Mean value: 0.10062055289745331

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.1587145343792145e-08
Max value: 0.9972426891326904
Mean value: 0.10062055289745331

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -11.647242546081543
Max value: -1.1920928244535389e-07
Mean value: -0.13272157311439514

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9332023859024048
Max value: 1.8339200019836426
Mean value: 0.9989058375358582

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 51.506126403808594
Max value: 66.42731475830078
Mean value: 55.66364288330078

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.60092544555664
Max value: -55.60092544555664
Mean value: -55.60092544555664
sam_encoder.pos_embed grad: 7.879085828221832e-09
sam_encoder.blocks.0.norm1.weight grad: -5.688848887075437e-06
sam_encoder.blocks.0.norm1.bias grad: -1.1537582395249046e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.5113278095668647e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -8.664545703140902e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.4244261567218928e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.8729500652625575e-06
sam_encoder.blocks.0.norm2.weight grad: 2.4444158043479547e-05
sam_encoder.blocks.0.norm2.bias grad: -2.8249733077245764e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 6.157324605737813e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.1997697078622878e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 5.126426003698725e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 6.723522801621584e-06
sam_encoder.blocks.1.norm1.weight grad: 2.415287781332154e-06
sam_encoder.blocks.1.norm1.bias grad: 1.1496009392431006e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.966053090058267e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.97057704301551e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -8.075484402070288e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.99347697768826e-06
sam_encoder.blocks.1.norm2.weight grad: -1.4618519344367087e-05
sam_encoder.blocks.1.norm2.bias grad: -3.0074504593358142e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.0025636584032327e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.6579054999965592e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.699868698779028e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.506335931684589e-06
sam_encoder.blocks.2.norm1.weight grad: -1.2560230970848352e-05
sam_encoder.blocks.2.norm1.bias grad: 4.122921836824389e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -9.943379154719878e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.9550774343078956e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.73572173784487e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.0297448979108594e-06
sam_encoder.blocks.2.norm2.weight grad: -9.311244866694324e-06
sam_encoder.blocks.2.norm2.bias grad: -7.040209311526269e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -8.229810191551223e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.4552468883266556e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.1247825568716507e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.0567480280296877e-06
sam_encoder.blocks.3.norm1.weight grad: -2.4039300114964135e-06
sam_encoder.blocks.3.norm1.bias grad: 3.055689376196824e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -6.979452791711083e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.2307440303848125e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -6.003968792356318e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -4.772225111082662e-06
sam_encoder.blocks.3.norm2.weight grad: -1.1895330317202024e-05
sam_encoder.blocks.3.norm2.bias grad: -5.520337253983598e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.0016239684773609e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.1680550617020344e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.5328899962696596e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.1626642617557081e-06
sam_encoder.blocks.4.norm1.weight grad: 2.4103665055008605e-06
sam_encoder.blocks.4.norm1.bias grad: -9.642462828196585e-09
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 3.0855647992211743e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.0713158644648502e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.4143704447633354e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.2810991165679297e-06
sam_encoder.blocks.4.norm2.weight grad: -3.316384209028911e-06
sam_encoder.blocks.4.norm2.bias grad: 2.0858723814853875e-07
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.758837349072564e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.5096192025084747e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -7.511993089792668e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -4.421175106017472e-07
sam_encoder.blocks.5.norm1.weight grad: 5.132752903591609e-06
sam_encoder.blocks.5.norm1.bias grad: -3.6606797948479652e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 3.996706709585851e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.7678688613596023e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.5549895781296073e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.4660434974066447e-06
sam_encoder.blocks.5.norm2.weight grad: -5.514189069799613e-06
sam_encoder.blocks.5.norm2.bias grad: 6.794601176807191e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.299640750105027e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.457849748476292e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -2.2916296416042314e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.5755962812800135e-07
sam_encoder.blocks.6.norm1.weight grad: -1.7889049104269361e-06
sam_encoder.blocks.6.norm1.bias grad: -4.941538918501465e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -9.373117677569098e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.6831951771555396e-08
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.3680086112799472e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -1.5102948509593261e-06
sam_encoder.blocks.6.norm2.weight grad: 8.003652283150586e-07
sam_encoder.blocks.6.norm2.bias grad: 2.5297874799434794e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.080951733456459e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -6.911644732099376e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -8.143480840772099e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 4.3666409510478843e-07
sam_encoder.blocks.7.norm1.weight grad: -6.320505690382561e-06
sam_encoder.blocks.7.norm1.bias grad: -6.196896151777764e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -6.110061804065481e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.3928596419864334e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.372886112629203e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.7542319028507336e-06
sam_encoder.blocks.7.norm2.weight grad: -1.9877088561770506e-06
sam_encoder.blocks.7.norm2.bias grad: 4.71482053399086e-08
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.020713282036013e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.7464966504121548e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 9.145846320279816e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.539517484161479e-06
sam_encoder.blocks.8.norm1.weight grad: -2.7994617539661704e-06
sam_encoder.blocks.8.norm1.bias grad: 1.14852207389049e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.7350712369079702e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -3.1381944154418306e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -5.101013357489137e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.3715385800169315e-06
sam_encoder.blocks.8.norm2.weight grad: -5.464916284836363e-06
sam_encoder.blocks.8.norm2.bias grad: 1.0297309245288488e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.302970177785028e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.4343988772889134e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -9.69962570707139e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.6921863966199453e-07
sam_encoder.blocks.9.norm1.weight grad: -1.4169208952807821e-06
sam_encoder.blocks.9.norm1.bias grad: -1.3371088698477251e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.8260720935359132e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.969095819731592e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.090746857509657e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -3.3337340710204444e-07
sam_encoder.blocks.9.norm2.weight grad: -7.141526111809071e-06
sam_encoder.blocks.9.norm2.bias grad: 7.420936753987917e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -7.464636837539729e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -3.43868828167615e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -2.0258877952983312e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 6.016860538693436e-07
sam_encoder.blocks.10.norm1.weight grad: -3.6882192944176495e-06
sam_encoder.blocks.10.norm1.bias grad: -1.2004991276626242e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.000985088874586e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.486593646404799e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.548601517242787e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.0237445167149417e-06
sam_encoder.blocks.10.norm2.weight grad: -1.5041090591694228e-05
sam_encoder.blocks.10.norm2.bias grad: -1.8408575215289602e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -8.483006240567192e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -4.2479505282244645e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -6.517131510008767e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.0660036409149143e-08
sam_encoder.blocks.11.norm1.weight grad: -1.7818027117755264e-05
sam_encoder.blocks.11.norm1.bias grad: 2.0252643935236847e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.782388719424489e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.555414144149836e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.6660618484820588e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -7.018722953944234e-07
sam_encoder.blocks.11.norm2.weight grad: -1.185523251479026e-05
sam_encoder.blocks.11.norm2.bias grad: -5.654934511767351e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -7.0735504777985625e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.361198767175665e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.8460745820902957e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.3565263518321444e-07
sam_encoder.neck.conv1.trainable_scale grad: 7.93954313849099e-07
sam_encoder.neck.conv1.trainable_shift grad: 8.242077456088737e-07
sam_encoder.neck.conv2.trainable_scale grad: 1.395296294504078e-06
sam_encoder.neck.conv2.trainable_shift grad: -1.1985785022261553e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 9.407485777046531e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 4.0433224057778716e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0041191247291862965
mask_decoder.transformer.layers.0.norm2.bias grad: 7.214932702481747e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00012552941916510463
mask_decoder.transformer.layers.0.norm3.bias grad: -3.6451783671509475e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -9.666010737419128e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 6.0173642850713804e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -4.570104010781506e-07
mask_decoder.transformer.layers.1.norm1.bias grad: -4.642988642444834e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00014700541214551777
mask_decoder.transformer.layers.1.norm2.bias grad: 3.586598177207634e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.80498136614915e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 7.0208607212407514e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 4.195836663711816e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00023082343977876008
mask_decoder.transformer.norm_final_attn.weight grad: -1.976220573851606e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.309495019086171e-05
Text_Embedding_Affine.0.weight grad: -1.6789607898415326e-11
Text_Embedding_Affine.0.bias grad: -4.979129331061927e-10
Text_Embedding_Affine.2.weight grad: -6.762840287777294e-11
Text_Embedding_Affine.2.bias grad: -6.206981197465211e-06
Epoch 34 finished with average loss: -56.9418
Epoch 35/39
----------
Epoch 35:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 35:   0%|          | 0/3 [00:00<?, ?it/s, loss=-58.6]Epoch 35:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.16it/s, loss=-58.6]Epoch 35:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.16it/s, loss=-60.5]Epoch 35:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.74it/s, loss=-60.5]Epoch 35:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.74it/s, loss=-58.5]Epoch 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.39it/s, loss=-58.5]/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.269113452164518e-11
Max value: 0.9996247291564941
Mean value: 0.10144640505313873

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.269113452164518e-11
Max value: 0.9996247291564941
Mean value: 0.10144640505313873

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08317804336547852

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.212450981140137
Max value: -1.1920928244535389e-07
Mean value: -0.12568023800849915

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08554840087890625

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08317804336547852

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 44.73904800415039
Max value: 74.4524154663086
Mean value: 58.600685119628906

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.269113452164518e-11
Max value: 0.9996247291564941
Mean value: 0.10144640505313873

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.269113452164518e-11
Max value: 0.9996247291564941
Mean value: 0.10144640505313873

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.269113452164518e-11
Max value: 0.9996247291564941
Mean value: 0.10144640505313873

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.212450981140137
Max value: -1.1920928244535389e-07
Mean value: -0.12568023800849915

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 44.73904800415039
Max value: 74.4524154663086
Mean value: 58.600685119628906

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.60221481323242
Max value: -58.60221481323242
Mean value: -58.60221481323242
sam_encoder.pos_embed grad: 6.588160683662636e-09
sam_encoder.blocks.0.norm1.weight grad: -1.4930627003195696e-05
sam_encoder.blocks.0.norm1.bias grad: -2.3037142454995774e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.1170359357492998e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.6331881031183e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 2.1930495677224826e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 8.353210319000937e-07
sam_encoder.blocks.0.norm2.weight grad: 1.1168648597958963e-05
sam_encoder.blocks.0.norm2.bias grad: -2.8606824344024062e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.6989024516078644e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 6.430766916309949e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.3754349311057013e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 6.337822469504317e-06
sam_encoder.blocks.1.norm1.weight grad: -3.1585318538418505e-06
sam_encoder.blocks.1.norm1.bias grad: 8.823985808703583e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -9.308804692409467e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.404503220532206e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.417178039759165e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.228371835779399e-06
sam_encoder.blocks.1.norm2.weight grad: -9.885542567644734e-06
sam_encoder.blocks.1.norm2.bias grad: -1.2109765066270484e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -5.154724476597039e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -8.219230949180201e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.4592833394999616e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.4300907196229673e-06
sam_encoder.blocks.2.norm1.weight grad: -1.0099886821990367e-05
sam_encoder.blocks.2.norm1.bias grad: 5.9455087466631085e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -8.839022484607995e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.8306257061340148e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -5.714820872526616e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.529555897330283e-06
sam_encoder.blocks.2.norm2.weight grad: -1.3261515050544403e-06
sam_encoder.blocks.2.norm2.bias grad: -3.4964691622008104e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.7782306208100636e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 5.7795261909632245e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.228453563991934e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.7231229776371038e-06
sam_encoder.blocks.3.norm1.weight grad: -1.6422272892668843e-06
sam_encoder.blocks.3.norm1.bias grad: 7.552443094027694e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.148412361042574e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.4783257711314945e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.1931172088661697e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.105336645603529e-06
sam_encoder.blocks.3.norm2.weight grad: -9.415791282663122e-06
sam_encoder.blocks.3.norm2.bias grad: -3.838270004052902e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -8.824024007481057e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.1596722490357934e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.634956220186723e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -7.15163650966133e-07
sam_encoder.blocks.4.norm1.weight grad: 2.8613544600375462e-06
sam_encoder.blocks.4.norm1.bias grad: -9.022099902722402e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.4008830930833938e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.558021409664434e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.2101003196439706e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.2801777984350338e-06
sam_encoder.blocks.4.norm2.weight grad: 5.636103651340818e-06
sam_encoder.blocks.4.norm2.bias grad: 1.1284713764325716e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 9.316407840742613e-07
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.1106983492936706e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.4427787391468883e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -3.565053248166805e-07
sam_encoder.blocks.5.norm1.weight grad: -9.411039059159521e-07
sam_encoder.blocks.5.norm1.bias grad: -3.861947334371507e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.5376590454252437e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 1.7275959862672607e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.8340577955532353e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.2777331903635059e-07
sam_encoder.blocks.5.norm2.weight grad: 1.5558982795482734e-06
sam_encoder.blocks.5.norm2.bias grad: 7.105938038876047e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.5854036519158399e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.478583938791417e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 7.680201861148817e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 5.812478320876835e-07
sam_encoder.blocks.6.norm1.weight grad: -3.155387048536795e-06
sam_encoder.blocks.6.norm1.bias grad: -4.366748726170044e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -4.987079478269152e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 7.623301598869148e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.1366646504029632e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -7.231480481095787e-07
sam_encoder.blocks.6.norm2.weight grad: 3.886922513629543e-06
sam_encoder.blocks.6.norm2.bias grad: 3.2409304822067497e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 1.8729313069343334e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.462904487605556e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -7.602995424349501e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.3463220461271703e-07
sam_encoder.blocks.7.norm1.weight grad: -5.044252247898839e-06
sam_encoder.blocks.7.norm1.bias grad: -1.583781113367877e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.752538759727031e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.047791440418223e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.289089707119274e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.2387193919494166e-06
sam_encoder.blocks.7.norm2.weight grad: -1.1716325616362155e-06
sam_encoder.blocks.7.norm2.bias grad: -6.708017963319435e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.6923911516641965e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.1155690344821778e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 2.0186341487260506e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 6.532308702844603e-07
sam_encoder.blocks.8.norm1.weight grad: 1.759931137712556e-06
sam_encoder.blocks.8.norm1.bias grad: 1.6733177972128033e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.233860070395167e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.0296068921888946e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.6982356757798698e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.1563899938191753e-06
sam_encoder.blocks.8.norm2.weight grad: -1.866267894001794e-06
sam_encoder.blocks.8.norm2.bias grad: 1.0068446272271103e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -2.7677749585564015e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -1.6760520793468459e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -5.401751650424558e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.8105275734778843e-07
sam_encoder.blocks.9.norm1.weight grad: -6.483714969363064e-07
sam_encoder.blocks.9.norm1.bias grad: -5.524195216821681e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -9.466952519687766e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -9.369966278427455e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -6.679697435174603e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -4.120254288864089e-07
sam_encoder.blocks.9.norm2.weight grad: -4.833756975131109e-06
sam_encoder.blocks.9.norm2.bias grad: 6.240903758225613e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.178890205570497e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.5038650619535474e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -5.429712928162189e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 4.7523244006697496e-07
sam_encoder.blocks.10.norm1.weight grad: -5.016564955440117e-06
sam_encoder.blocks.10.norm1.bias grad: -7.975141897986759e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.5181142266083043e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.294215849156899e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.6288777260342613e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -8.39228675886261e-07
sam_encoder.blocks.10.norm2.weight grad: -1.0295068022969645e-05
sam_encoder.blocks.10.norm2.bias grad: -9.310799669037806e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -6.250649221328786e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -3.072676463489188e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -4.768817234435119e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 8.121206462874397e-08
sam_encoder.blocks.11.norm1.weight grad: -1.7711383407004178e-05
sam_encoder.blocks.11.norm1.bias grad: 7.156369861149869e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 1.2151575674579362e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -3.2727606935623044e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.451983618811937e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -9.893865353660658e-07
sam_encoder.blocks.11.norm2.weight grad: -1.0444191502756439e-05
sam_encoder.blocks.11.norm2.bias grad: -2.176566340494901e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -5.82853226660518e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.0161105567240156e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.4521542190948367e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.131068643189792e-07
sam_encoder.neck.conv1.trainable_scale grad: 2.816468622768298e-07
sam_encoder.neck.conv1.trainable_shift grad: 4.8457241064170375e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.3341896192287095e-06
sam_encoder.neck.conv2.trainable_shift grad: 5.419170975073939e-06
mask_decoder.transformer.layers.0.norm1.weight grad: 6.785962614230812e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 5.16105501446873e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.004737169481813908
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00017760577611625195
mask_decoder.transformer.layers.0.norm3.weight grad: 8.073361095739529e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.9900737243006006e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -8.967109170043841e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 5.447558123705676e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.858608579321299e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -3.537693373800721e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00015656481264159083
mask_decoder.transformer.layers.1.norm2.bias grad: 4.1818850149866194e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -2.3161202989285812e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 4.718935542769032e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 3.149996337015182e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0002098031691275537
mask_decoder.transformer.norm_final_attn.weight grad: -6.765640137018636e-07
mask_decoder.transformer.norm_final_attn.bias grad: -1.4053443010197952e-05
Text_Embedding_Affine.0.weight grad: 7.418329839303794e-12
Text_Embedding_Affine.0.bias grad: 1.9722191935134248e-10
Text_Embedding_Affine.2.weight grad: 2.3735197834939825e-11
Text_Embedding_Affine.2.bias grad: -8.148646884365007e-06

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.4243377310929617e-10
Max value: 0.9993047714233398
Mean value: 0.07866403460502625

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.4243377310929617e-10
Max value: 0.9993047714233398
Mean value: 0.07866403460502625

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07825613021850586

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.370675086975098
Max value: -1.1920928244535389e-07
Mean value: -0.10855302959680557

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07044458389282227

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07825613021850586

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 48.878929138183594
Max value: 89.51469421386719
Mean value: 62.33887481689453

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.464506016457534e-10
Max value: 0.9993094205856323
Mean value: 0.07854710519313812

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.464506016457534e-10
Max value: 0.9993094205856323
Mean value: 0.07854710519313812

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.464506016457534e-10
Max value: 0.9993094205856323
Mean value: 0.07854710519313812

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -14.343880653381348
Max value: -1.1920928244535389e-07
Mean value: -0.10853718221187592

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9638446569442749
Max value: 1.065022587776184
Mean value: 1.0000171661376953

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 48.878929138183594
Max value: 89.51469421386719
Mean value: 62.33887481689453

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -62.34072494506836
Max value: -62.34072494506836
Mean value: -62.34072494506836
sam_encoder.pos_embed grad: 4.270540365780562e-09
sam_encoder.blocks.0.norm1.weight grad: 0.00013953392044641078
sam_encoder.blocks.0.norm1.bias grad: -1.4998104234109633e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 1.8569608073448762e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 6.426086542887788e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -9.673221029515844e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -6.7943037720397115e-06
sam_encoder.blocks.0.norm2.weight grad: 5.908648745389655e-05
sam_encoder.blocks.0.norm2.bias grad: 3.37087367370259e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.7002515960484743e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.979985194746405e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 2.8254664357518777e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 2.114977360179182e-05
sam_encoder.blocks.1.norm1.weight grad: 4.535491825663485e-06
sam_encoder.blocks.1.norm1.bias grad: 4.397607335704379e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.928307731053792e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -9.047897037817165e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.03365198103711e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -6.372648385877255e-06
sam_encoder.blocks.1.norm2.weight grad: 2.6586640160530806e-05
sam_encoder.blocks.1.norm2.bias grad: -1.4540753909386694e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.23213048937032e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.9784026790148346e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.837895226548426e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.3665713797527133e-06
sam_encoder.blocks.2.norm1.weight grad: -4.19902426074259e-05
sam_encoder.blocks.2.norm1.bias grad: 6.542788469232619e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.840781209873967e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -6.094527179811848e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.7063466657418758e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -8.44695205159951e-06
sam_encoder.blocks.2.norm2.weight grad: 9.445840078114998e-06
sam_encoder.blocks.2.norm2.bias grad: -1.9618250007624738e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.3184488782135304e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 4.350360541138798e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.4063227101578377e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.764979970175773e-06
sam_encoder.blocks.3.norm1.weight grad: -4.1112407416221686e-06
sam_encoder.blocks.3.norm1.bias grad: -4.8669367060938384e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -5.717332442145562e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.6207507037033793e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -9.456630323256832e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.0149920854019001e-05
sam_encoder.blocks.3.norm2.weight grad: 2.6711993996286765e-05
sam_encoder.blocks.3.norm2.bias grad: 1.2053124919475522e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.392183912685141e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 5.484454050019849e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.0441191736608744e-05
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.3127956865209853e-06
sam_encoder.blocks.4.norm1.weight grad: -2.351255352550652e-05
sam_encoder.blocks.4.norm1.bias grad: 6.992280532358564e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.8669150449568406e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.5494160834350623e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -1.3336920346773695e-05
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -5.92033211432863e-06
sam_encoder.blocks.4.norm2.weight grad: 1.9009712559636682e-05
sam_encoder.blocks.4.norm2.bias grad: 3.5913133160647703e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 1.5766661363159074e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.7603922515263548e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -5.131943908054382e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 2.4172375105990795e-06
sam_encoder.blocks.5.norm1.weight grad: -3.263443795731291e-05
sam_encoder.blocks.5.norm1.bias grad: -3.194670352968387e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -2.3331875127041712e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.1662184483138844e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -8.327313480549492e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -9.439206223760266e-06
sam_encoder.blocks.5.norm2.weight grad: 3.7228701330604963e-06
sam_encoder.blocks.5.norm2.bias grad: 1.997060826397501e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -7.34670084057143e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.9190456441720016e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.050206942134537e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.4397951417777222e-06
sam_encoder.blocks.6.norm1.weight grad: -2.4663275326020084e-05
sam_encoder.blocks.6.norm1.bias grad: -1.1370540960342623e-05
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.1393261956982315e-05
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 5.626778829537216e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -5.1319602789590135e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.8864576506748563e-06
sam_encoder.blocks.6.norm2.weight grad: 3.791700873989612e-05
sam_encoder.blocks.6.norm2.bias grad: 1.48450626511476e-05
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 2.1773583284812048e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 1.0721572834881954e-05
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.0625171853462234e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 2.029061761277262e-06
sam_encoder.blocks.7.norm1.weight grad: 1.8226153315481497e-06
sam_encoder.blocks.7.norm1.bias grad: 1.9887470443791244e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -5.14982593813329e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.995067800133256e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -4.530194928520359e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -6.675901431663078e-07
sam_encoder.blocks.7.norm2.weight grad: 2.423800469841808e-05
sam_encoder.blocks.7.norm2.bias grad: 5.494764536706498e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 9.180899724015035e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.532193093429669e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.823539711651392e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -2.5078115868382156e-06
sam_encoder.blocks.8.norm1.weight grad: 5.282106030790601e-06
sam_encoder.blocks.8.norm1.bias grad: -3.7325633002183167e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 4.662676474254113e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.570880269558984e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -7.3686983341758605e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -6.8127483245916665e-06
sam_encoder.blocks.8.norm2.weight grad: 1.873407745733857e-05
sam_encoder.blocks.8.norm2.bias grad: 8.835320841171779e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 9.504874469712377e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 6.128957011242164e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 2.7671080715663265e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 2.0184249649446429e-07
sam_encoder.blocks.9.norm1.weight grad: -8.371869625989348e-06
sam_encoder.blocks.9.norm1.bias grad: 2.194662101828726e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -9.829731425270438e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -9.833502190303989e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -4.101651029486675e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.1915569757547928e-06
sam_encoder.blocks.9.norm2.weight grad: 1.5461100701941177e-05
sam_encoder.blocks.9.norm2.bias grad: 1.0061027751362417e-05
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.6420773338031722e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 2.5526915123919025e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 5.441002599582134e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.7068988828204965e-08
sam_encoder.blocks.10.norm1.weight grad: -1.2464613064366858e-05
sam_encoder.blocks.10.norm1.bias grad: 2.4090882106975187e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -8.558410627301782e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.162234522984363e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -3.175801339239115e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.5159109523210645e-07
sam_encoder.blocks.10.norm2.weight grad: 5.201480234973133e-06
sam_encoder.blocks.10.norm2.bias grad: 4.848124717682367e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.6740817702375352e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.247900854650652e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.503556177340215e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -9.66978177530109e-07
sam_encoder.blocks.11.norm1.weight grad: -5.299120857671369e-06
sam_encoder.blocks.11.norm1.bias grad: 1.98854718291841e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.763745214906521e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.7897218640428036e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -2.0113300251978217e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -4.7548266479680024e-07
sam_encoder.blocks.11.norm2.weight grad: 1.261624311155174e-05
sam_encoder.blocks.11.norm2.bias grad: 3.9335768065029697e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 4.252415237715468e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.5051800801302306e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -4.484491000766866e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.191839255123341e-07
sam_encoder.neck.conv1.trainable_scale grad: 4.0497434383723885e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.5984805941116065e-06
sam_encoder.neck.conv2.trainable_scale grad: 2.854922058759257e-06
sam_encoder.neck.conv2.trainable_shift grad: -2.474193024681881e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00011658693256322294
mask_decoder.transformer.layers.0.norm1.bias grad: -1.764710759744048e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0024359854869544506
mask_decoder.transformer.layers.0.norm2.bias grad: 8.297665044665337e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00014515226939693093
mask_decoder.transformer.layers.0.norm3.bias grad: 8.771594730205834e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00013536981714423746
mask_decoder.transformer.layers.0.norm4.bias grad: 2.5697227101773024e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 8.335609163623303e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.2855693967139814e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.0003280345699749887
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00011475323117338121
mask_decoder.transformer.layers.1.norm3.weight grad: 7.743200694676489e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 8.839985821396112e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.171872231177986e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 7.708547491347417e-05
mask_decoder.transformer.norm_final_attn.weight grad: 1.3612061593448743e-05
mask_decoder.transformer.norm_final_attn.bias grad: 7.256255230458919e-06
Text_Embedding_Affine.0.weight grad: 2.9739523343952357e-11
Text_Embedding_Affine.0.bias grad: -3.727618214099948e-10
Text_Embedding_Affine.2.weight grad: 7.64292101829156e-12
Text_Embedding_Affine.2.bias grad: -1.1920288670808077e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.015416610325673e-10
Max value: 0.9987931251525879
Mean value: 0.0914522111415863

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.015416610325673e-10
Max value: 0.9987931251525879
Mean value: 0.0914522111415863

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09652042388916016

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.531105995178223
Max value: -1.1920928244535389e-07
Mean value: -0.14367568492889404

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07643508911132812

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09652042388916016

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 47.89345169067383
Max value: 62.33106994628906
Mean value: 54.588043212890625

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 5.136638892011547e-10
Max value: 0.9986252784729004
Mean value: 0.09062358736991882

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.136638892011547e-10
Max value: 0.9986252784729004
Mean value: 0.09062358736991882

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 5.136638892011547e-10
Max value: 0.9986252784729004
Mean value: 0.09062358736991882

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.305558204650879
Max value: -1.1920928244535389e-07
Mean value: -0.1434311866760254

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8701745867729187
Max value: 1.2844736576080322
Mean value: 1.000277042388916

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 47.89345169067383
Max value: 62.33106994628906
Mean value: 54.588043212890625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -54.60540771484375
Max value: -54.60540771484375
Mean value: -54.60540771484375
sam_encoder.pos_embed grad: -4.551795329543751e-10
sam_encoder.blocks.0.norm1.weight grad: -3.768352326005697e-05
sam_encoder.blocks.0.norm1.bias grad: -1.4180497601046227e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 2.1273299353197217e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.346641221924074e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -3.7075806176289916e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.4328620068226883e-07
sam_encoder.blocks.0.norm2.weight grad: 7.637885573785752e-06
sam_encoder.blocks.0.norm2.bias grad: -4.465056554181501e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.0731316251622047e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 4.321260348660871e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -7.737304258625954e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 4.2464415628273855e-07
sam_encoder.blocks.1.norm1.weight grad: 1.3399534509517252e-05
sam_encoder.blocks.1.norm1.bias grad: -8.110545422823634e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 6.021371063980041e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.1623899354162859e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.5461823750229087e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -9.098891950998222e-07
sam_encoder.blocks.1.norm2.weight grad: 1.1714689662767341e-06
sam_encoder.blocks.1.norm2.bias grad: 9.245932233170606e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -5.0420612751622684e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -7.214063657556835e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.0462719728820957e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.3506348750524921e-06
sam_encoder.blocks.2.norm1.weight grad: -1.3921477147960104e-05
sam_encoder.blocks.2.norm1.bias grad: -1.1854335753014311e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -5.950212198513327e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.7721195035846904e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.021977474621963e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.411760194969247e-06
sam_encoder.blocks.2.norm2.weight grad: -5.624804543913342e-06
sam_encoder.blocks.2.norm2.bias grad: 6.308176125457976e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -6.273214239627123e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.0032327963926946e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.554202172992518e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.7452122139948187e-06
sam_encoder.blocks.3.norm1.weight grad: -5.624914592772257e-06
sam_encoder.blocks.3.norm1.bias grad: -6.977171324251685e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -9.482882887823507e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.7981545827060472e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.943799583794316e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.27921259465802e-06
sam_encoder.blocks.3.norm2.weight grad: -4.832148533751024e-06
sam_encoder.blocks.3.norm2.bias grad: 3.0428227546508424e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -4.314840680308407e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.423099658699357e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 2.12535155696969e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -6.305426722974516e-07
sam_encoder.blocks.4.norm1.weight grad: 8.11192330729682e-06
sam_encoder.blocks.4.norm1.bias grad: 1.739166577863216e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 5.586578481597826e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.5779112345626345e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 2.3491550109611126e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 4.016487480384967e-07
sam_encoder.blocks.4.norm2.weight grad: -1.060140766639961e-05
sam_encoder.blocks.4.norm2.bias grad: -1.3509808013623115e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -8.805505785858259e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -2.5696499506011605e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.8830451153917238e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -4.017049377580406e-07
sam_encoder.blocks.5.norm1.weight grad: -5.5831915233284235e-06
sam_encoder.blocks.5.norm1.bias grad: -5.372030045691645e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -4.35658421338303e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.1440335988008883e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.833130110957427e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -7.491239557566587e-07
sam_encoder.blocks.5.norm2.weight grad: -8.559792149753775e-06
sam_encoder.blocks.5.norm2.bias grad: -5.0628686949494295e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.755981535708997e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.537992602607119e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.193093905589194e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.397169580030777e-08
sam_encoder.blocks.6.norm1.weight grad: -4.2285128074581735e-06
sam_encoder.blocks.6.norm1.bias grad: -3.8593307181145065e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.886442189264926e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -9.39864094107179e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.4417798865906661e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -9.657428563514259e-07
sam_encoder.blocks.6.norm2.weight grad: -9.082489214051748e-07
sam_encoder.blocks.6.norm2.bias grad: 3.247488621127559e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.5491175367496908e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.5856337540753884e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 6.470180551332305e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 3.888537136731429e-08
sam_encoder.blocks.7.norm1.weight grad: 2.0879592455003149e-07
sam_encoder.blocks.7.norm1.bias grad: -8.540242788512842e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -9.561512115396908e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.8536366042098962e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.8381972495262744e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -4.171045475231949e-06
sam_encoder.blocks.7.norm2.weight grad: 6.471711344602227e-07
sam_encoder.blocks.7.norm2.bias grad: 2.0105071598663926e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 8.558496915611613e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -4.696232167589187e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.0422405694043846e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 7.55237692828814e-07
sam_encoder.blocks.8.norm1.weight grad: -1.6996214071696158e-06
sam_encoder.blocks.8.norm1.bias grad: -5.613925964098598e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.8944779185403604e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -3.334147095301887e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.2325573354464723e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.224297077191295e-06
sam_encoder.blocks.8.norm2.weight grad: -7.751545126666315e-06
sam_encoder.blocks.8.norm2.bias grad: -2.9845500648661982e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.521500381495571e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.1259658044291427e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -2.5680674298200756e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.2369939668133156e-06
sam_encoder.blocks.9.norm1.weight grad: -2.347116151213413e-06
sam_encoder.blocks.9.norm1.bias grad: 5.134841103426879e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -1.9200624592485838e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -9.845039130595978e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -6.868875743748504e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -7.926528269308619e-07
sam_encoder.blocks.9.norm2.weight grad: -6.57639520795783e-06
sam_encoder.blocks.9.norm2.bias grad: -3.128859816570184e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.567888370525907e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.4564985778852133e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.0651217507984256e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.784653870297916e-07
sam_encoder.blocks.10.norm1.weight grad: 3.894640940416139e-06
sam_encoder.blocks.10.norm1.bias grad: 1.1764656164814369e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.0352310912130633e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 8.314111141771718e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.696527066196722e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 2.474683924447163e-07
sam_encoder.blocks.10.norm2.weight grad: -8.064344001468271e-06
sam_encoder.blocks.10.norm2.bias grad: -3.7328391044866294e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.5366101656109095e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.0396803392941365e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.123438892136619e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -7.292600798791682e-07
sam_encoder.blocks.11.norm1.weight grad: -5.927895017521223e-06
sam_encoder.blocks.11.norm1.bias grad: 1.2157695437053917e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 2.170361312892055e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 6.259059546209755e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.4939843115134863e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.188683086184028e-06
sam_encoder.blocks.11.norm2.weight grad: -3.027281081813271e-06
sam_encoder.blocks.11.norm2.bias grad: -1.5489929410250625e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.3207247775426367e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.08978213120281e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -5.498595214703528e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -3.557322543201735e-07
sam_encoder.neck.conv1.trainable_scale grad: -4.065714165335521e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.3915871022618376e-05
sam_encoder.neck.conv2.trainable_scale grad: -5.962101568002254e-07
sam_encoder.neck.conv2.trainable_shift grad: -2.0663839677581564e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00010197269875789061
mask_decoder.transformer.layers.0.norm1.bias grad: -1.3841163308825344e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0033268993720412254
mask_decoder.transformer.layers.0.norm2.bias grad: 0.0003027934581041336
mask_decoder.transformer.layers.0.norm3.weight grad: -6.064477929612622e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -4.4284235627856106e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 7.470874697901309e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -8.927745511755347e-07
mask_decoder.transformer.layers.1.norm1.weight grad: -4.8930023694993e-06
mask_decoder.transformer.layers.1.norm1.bias grad: 2.5745116545294877e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -2.933823998318985e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -5.461442196974531e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.5744069716893137e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 6.4478035710635595e-06
mask_decoder.transformer.layers.1.norm4.weight grad: 3.31080227624625e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00011813984019681811
mask_decoder.transformer.norm_final_attn.weight grad: 2.9666657610505354e-06
mask_decoder.transformer.norm_final_attn.bias grad: 7.829937203496229e-06
Text_Embedding_Affine.0.weight grad: -3.5065297020187014e-12
Text_Embedding_Affine.0.bias grad: -2.458639958291542e-10
Text_Embedding_Affine.2.weight grad: -1.3450607815046478e-11
Text_Embedding_Affine.2.bias grad: -1.1961425116169266e-05
Epoch 35 finished with average loss: -58.5161
Epoch 36/39
----------
Epoch 36:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 36:   0%|          | 0/3 [00:00<?, ?it/s, loss=-59.7]Epoch 36:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.12it/s, loss=-59.7]Epoch 36:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.12it/s, loss=-59]  Epoch 36:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.70it/s, loss=-59]Epoch 36:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.70it/s, loss=-53.3]Epoch 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.36it/s, loss=-53.3]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.1607845934458183e-10
Max value: 0.9996287822723389
Mean value: 0.0796736478805542

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1607845934458183e-10
Max value: 0.9996287822723389
Mean value: 0.0796736478805542

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08548259735107422

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.072066307067871
Max value: -1.1920928244535389e-07
Mean value: -0.11834969371557236

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0712118148803711

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08548259735107422

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 41.95135498046875
Max value: 90.19734954833984
Mean value: 59.716854095458984

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.1607845934458183e-10
Max value: 0.9996287822723389
Mean value: 0.0796736478805542

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1607845934458183e-10
Max value: 0.9996287822723389
Mean value: 0.0796736478805542

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1607845934458183e-10
Max value: 0.9996287822723389
Mean value: 0.0796736478805542

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.072066307067871
Max value: -1.1920928244535389e-07
Mean value: -0.11834969371557236

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 41.95135498046875
Max value: 90.19734954833984
Mean value: 59.716854095458984

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -59.71791076660156
Max value: -59.71791076660156
Mean value: -59.71791076660156
sam_encoder.pos_embed grad: -7.716208116903545e-09
sam_encoder.blocks.0.norm1.weight grad: -1.9510296169755748e-06
sam_encoder.blocks.0.norm1.bias grad: 2.0401599613251165e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.048565187986242e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.9778842386131146e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -2.631539643971337e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.692364776317845e-06
sam_encoder.blocks.0.norm2.weight grad: -1.1807880582637154e-05
sam_encoder.blocks.0.norm2.bias grad: -7.648024620721117e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -6.7244827732793055e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -7.1990652941167355e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.2563948075694498e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -6.749594376742607e-06
sam_encoder.blocks.1.norm1.weight grad: -1.467893468998227e-07
sam_encoder.blocks.1.norm1.bias grad: 8.208911822293885e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 9.991094884753693e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -7.846842891012784e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.5919385987217538e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 4.684791861109261e-07
sam_encoder.blocks.1.norm2.weight grad: 1.666912794462405e-05
sam_encoder.blocks.1.norm2.bias grad: -2.0415081962710246e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 9.85213955573272e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.8918111663879245e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.8955415725940838e-07
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.543399078713264e-07
sam_encoder.blocks.2.norm1.weight grad: -1.0696631761675235e-05
sam_encoder.blocks.2.norm1.bias grad: -6.2922290453570895e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -5.68498217035085e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.963909880942083e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.44249939796282e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.1528401197865605e-06
sam_encoder.blocks.2.norm2.weight grad: -6.218527687451569e-06
sam_encoder.blocks.2.norm2.bias grad: 1.837757167777454e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.4349253635591595e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.762965780471859e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 4.963534934177005e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 2.3353842948381498e-07
sam_encoder.blocks.3.norm1.weight grad: -2.5498345621599583e-06
sam_encoder.blocks.3.norm1.bias grad: -8.467495717923157e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.001035449618939e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.1976926543866284e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.2956070349900983e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.8834164166037226e-06
sam_encoder.blocks.3.norm2.weight grad: 4.679350240621716e-07
sam_encoder.blocks.3.norm2.bias grad: -5.457353836391121e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.2329186322167516e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 4.837411324842833e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 7.343680408666842e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.023950173679623e-06
sam_encoder.blocks.4.norm1.weight grad: 1.0786926395667251e-05
sam_encoder.blocks.4.norm1.bias grad: -3.2330981412087567e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 2.0828483684454113e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 1.760539269923811e-08
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.530499725457048e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 3.1250765459844843e-06
sam_encoder.blocks.4.norm2.weight grad: -2.538238732086029e-05
sam_encoder.blocks.4.norm2.bias grad: -2.017163387790788e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.5690220607211813e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -6.176914666866651e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 4.685870408138726e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 1.2841776424465934e-06
sam_encoder.blocks.5.norm1.weight grad: 1.5395278296637116e-06
sam_encoder.blocks.5.norm1.bias grad: -4.3225613808317576e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -3.740654790362896e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -8.526612873538397e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 9.947805210686056e-07
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -3.145933078485541e-07
sam_encoder.blocks.5.norm2.weight grad: -1.3769643373962026e-05
sam_encoder.blocks.5.norm2.bias grad: -1.1374846508260816e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -7.5046546044177376e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.499199126759777e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.5722121133876499e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.169795661506214e-07
sam_encoder.blocks.6.norm1.weight grad: 1.1848893336718902e-05
sam_encoder.blocks.6.norm1.bias grad: 4.335308858571807e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 7.098165951902047e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.5252911655115895e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 3.1968024813977536e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.6943547507253243e-06
sam_encoder.blocks.6.norm2.weight grad: -9.430335921933874e-06
sam_encoder.blocks.6.norm2.bias grad: -9.908549145620782e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.4690516410337295e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.3146508283389267e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 9.226552037944202e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.255974085433991e-07
sam_encoder.blocks.7.norm1.weight grad: 1.5806330338818952e-05
sam_encoder.blocks.7.norm1.bias grad: 6.965602779018809e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.0183881386183202e-05
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 4.103047103853896e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 4.475395144254435e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 1.015925931824313e-06
sam_encoder.blocks.7.norm2.weight grad: 2.0700039726762043e-07
sam_encoder.blocks.7.norm2.bias grad: 3.5275988921057433e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 1.5805221664777491e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 4.88173839130468e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.0110844641531003e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.4308019444797537e-06
sam_encoder.blocks.8.norm1.weight grad: 1.2232718290761113e-05
sam_encoder.blocks.8.norm1.bias grad: -2.3792699721525423e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.0383560947957449e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.092338374699466e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 4.3967479541606735e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 3.180968178639887e-06
sam_encoder.blocks.8.norm2.weight grad: -3.2014062867347093e-07
sam_encoder.blocks.8.norm2.bias grad: 6.174084887788922e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 7.589487722725607e-07
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 3.233054428619653e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 9.17377018794241e-09
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -8.521999461663654e-07
sam_encoder.blocks.9.norm1.weight grad: 4.664286734623602e-06
sam_encoder.blocks.9.norm1.bias grad: -6.377069894369924e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.341492967796512e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.8849017351385555e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.4327456483442802e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.1488444897622685e-06
sam_encoder.blocks.9.norm2.weight grad: 2.962292228403385e-06
sam_encoder.blocks.9.norm2.bias grad: 1.087928467313759e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 3.1979311643226538e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.2715577213384677e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 4.473896240142494e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.361718760672375e-07
sam_encoder.blocks.10.norm1.weight grad: 1.0093654054799117e-05
sam_encoder.blocks.10.norm1.bias grad: 1.6327385310432874e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 5.701778718503192e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.114859398716362e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.93985169971711e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.4971569726185407e-06
sam_encoder.blocks.10.norm2.weight grad: 7.873592039686628e-06
sam_encoder.blocks.10.norm2.bias grad: 9.776531442184933e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 5.486562258738559e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.580983618827304e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.0653063782228855e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.991054088852252e-07
sam_encoder.blocks.11.norm1.weight grad: 1.8134767742594704e-05
sam_encoder.blocks.11.norm1.bias grad: 1.5049783996801125e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 7.853873285057489e-07
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 6.856470236016321e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.7713392682926496e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.418236365680059e-06
sam_encoder.blocks.11.norm2.weight grad: 1.138261541200336e-05
sam_encoder.blocks.11.norm2.bias grad: 4.822036316909362e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 6.244445103220642e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 2.0910233615722973e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.4883388743669457e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.3136294657888357e-08
sam_encoder.neck.conv1.trainable_scale grad: 1.8283571989741176e-07
sam_encoder.neck.conv1.trainable_shift grad: -7.849344910937361e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.6577905626036227e-07
sam_encoder.neck.conv2.trainable_shift grad: -2.829389995895326e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -5.045363650424406e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -4.433550202520564e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.005681248381733894
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00019605181296356022
mask_decoder.transformer.layers.0.norm3.weight grad: -8.145072206389159e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -2.411295281490311e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 7.706416363362223e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -7.817116966180038e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -5.920585408603074e-07
mask_decoder.transformer.layers.1.norm1.bias grad: 4.702988917415496e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -4.9783095164457336e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -2.3691944079473615e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 3.601737626013346e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.939654106943635e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -5.0660641136346385e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00024247501278296113
mask_decoder.transformer.norm_final_attn.weight grad: -1.2436626093403902e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.521623653388815e-05
Text_Embedding_Affine.0.weight grad: 1.1877721896313975e-11
Text_Embedding_Affine.0.bias grad: 7.576645977280805e-10
Text_Embedding_Affine.2.weight grad: 2.1149061668612745e-11
Text_Embedding_Affine.2.bias grad: 1.1561423889361322e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.193154575140909e-09
Max value: 0.9997497200965881
Mean value: 0.08932990580797195

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.193154575140909e-09
Max value: 0.9997497200965881
Mean value: 0.08932990580797195

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0941157341003418

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.511675834655762
Max value: -1.1920928244535389e-07
Mean value: -0.1328115016222

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07708597183227539

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0941157341003418

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 43.955650329589844
Max value: 74.43864440917969
Mean value: 58.352664947509766

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.4918172253075568e-09
Max value: 0.9997327923774719
Mean value: 0.08963187038898468

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.4918172253075568e-09
Max value: 0.9997327923774719
Mean value: 0.08963187038898468

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.4918172253075568e-09
Max value: 0.9997327923774719
Mean value: 0.08963187038898468

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.37852954864502
Max value: -1.1920928244535389e-07
Mean value: -0.13283373415470123

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9696899056434631
Max value: 1.2069828510284424
Mean value: 0.9999875426292419

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 43.955650329589844
Max value: 74.43864440917969
Mean value: 58.352664947509766

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.35206604003906
Max value: -58.35206604003906
Mean value: -58.35206604003906
sam_encoder.pos_embed grad: -5.8118239110172e-09
sam_encoder.blocks.0.norm1.weight grad: -6.129608664195985e-05
sam_encoder.blocks.0.norm1.bias grad: 1.1210648153792135e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.993726633983897e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -2.452439389344363e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.2287009667488746e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -2.3985323878150666e-06
sam_encoder.blocks.0.norm2.weight grad: 3.917037247447297e-05
sam_encoder.blocks.0.norm2.bias grad: 7.2088223532773554e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 9.712386599858291e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -5.269355369819095e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.535700539534446e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -6.997224772931077e-06
sam_encoder.blocks.1.norm1.weight grad: -1.1856742275995202e-05
sam_encoder.blocks.1.norm1.bias grad: 2.0550714907585643e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.4843252529317397e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -8.140068530337885e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.9126737242913805e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -6.232485247892328e-07
sam_encoder.blocks.1.norm2.weight grad: 9.477879757469054e-06
sam_encoder.blocks.1.norm2.bias grad: 3.647951871244004e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -2.6535606139077572e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.138349479238968e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.2875483409734443e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.4422699880233267e-06
sam_encoder.blocks.2.norm1.weight grad: 4.335311587055912e-06
sam_encoder.blocks.2.norm1.bias grad: 3.3677758892736165e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.3390941805701004e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.3090774473312194e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.181777057965519e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.118659944651881e-06
sam_encoder.blocks.2.norm2.weight grad: 3.146182962154853e-06
sam_encoder.blocks.2.norm2.bias grad: -1.3284825399750844e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 2.687193045858294e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 4.4350002781357034e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: 1.869716243163566e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 3.1426552027369326e-07
sam_encoder.blocks.3.norm1.weight grad: 4.2659544305934105e-06
sam_encoder.blocks.3.norm1.bias grad: -5.781864274467807e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: 5.058289843873354e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 7.215872983579175e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: 2.2213325792108662e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: 1.3048902474110946e-06
sam_encoder.blocks.3.norm2.weight grad: 5.968625373498071e-06
sam_encoder.blocks.3.norm2.bias grad: -1.4116803868091665e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 2.471865627740044e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 7.131880011002067e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.929227311047725e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.775108095600444e-07
sam_encoder.blocks.4.norm1.weight grad: 3.454691614024341e-05
sam_encoder.blocks.4.norm1.bias grad: -7.271444246725878e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.3870997463527601e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.5602395200839965e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 5.4769784583186265e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 6.5041303969337605e-06
sam_encoder.blocks.4.norm2.weight grad: -1.7091038898797706e-05
sam_encoder.blocks.4.norm2.bias grad: -2.708426836761646e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.5842917491681874e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -7.2814582381397486e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 5.194793175178347e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 6.830845222793869e-07
sam_encoder.blocks.5.norm1.weight grad: 3.354956425027922e-05
sam_encoder.blocks.5.norm1.bias grad: -9.79507967713289e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.3121099729905836e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 7.165971965150675e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.657316483440809e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.4617582969076466e-06
sam_encoder.blocks.5.norm2.weight grad: 2.1916680452704895e-06
sam_encoder.blocks.5.norm2.bias grad: -2.3269128632819047e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.246064205266521e-08
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -7.248046927088581e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 4.669018380809575e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.585645060866227e-07
sam_encoder.blocks.6.norm1.weight grad: 2.746002337516984e-06
sam_encoder.blocks.6.norm1.bias grad: 5.771187716163695e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.0238335309841204e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 1.838727939684759e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.267745884410033e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -4.656275791603548e-07
sam_encoder.blocks.6.norm2.weight grad: 6.05295554123586e-07
sam_encoder.blocks.6.norm2.bias grad: -2.438625415379647e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.6919391277479008e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -2.2842345970275346e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.2387523611323559e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.9128076900187807e-08
sam_encoder.blocks.7.norm1.weight grad: 1.1820060535683297e-05
sam_encoder.blocks.7.norm1.bias grad: -4.426240991506347e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 8.327644536620937e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 2.701937546589761e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.9744638848351315e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 2.087338316414389e-06
sam_encoder.blocks.7.norm2.weight grad: 3.717264462466119e-06
sam_encoder.blocks.7.norm2.bias grad: -7.05911361364997e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 3.2073326110548805e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 1.2492353107518284e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 7.830344088688435e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 3.0949661322665634e-07
sam_encoder.blocks.8.norm1.weight grad: 1.8112397810909897e-05
sam_encoder.blocks.8.norm1.bias grad: -1.0950664091069484e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 2.0454170226003043e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 6.698381184833124e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 2.007560169658973e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 8.240244255830476e-07
sam_encoder.blocks.8.norm2.weight grad: 6.510693850714233e-08
sam_encoder.blocks.8.norm2.bias grad: 2.5140705020021414e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.0141545772057725e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -5.694120090993238e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.267681682293187e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.241423200961435e-07
sam_encoder.blocks.9.norm1.weight grad: 7.676127097511198e-06
sam_encoder.blocks.9.norm1.bias grad: -4.463849379021667e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 6.253098035813309e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 1.978904492716538e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.3563958418671973e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.6747670770200784e-06
sam_encoder.blocks.9.norm2.weight grad: 1.6424735349573893e-06
sam_encoder.blocks.9.norm2.bias grad: 2.4681262402737048e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -9.130008038482629e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.843988511358475e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.4433397836910444e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.734811677233665e-07
sam_encoder.blocks.10.norm1.weight grad: 5.691886144632008e-06
sam_encoder.blocks.10.norm1.bias grad: 9.494641517449054e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.2017728699429426e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.1305779707981856e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 6.047664555808296e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.1630272562542814e-07
sam_encoder.blocks.10.norm2.weight grad: 5.324643097992521e-06
sam_encoder.blocks.10.norm2.bias grad: 4.584194357448723e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.5378774353157496e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.2188372693344718e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 1.4789090982958442e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 4.2986556536561693e-07
sam_encoder.blocks.11.norm1.weight grad: 2.3488462829845957e-05
sam_encoder.blocks.11.norm1.bias grad: -3.639873824567985e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 9.958004739019088e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 2.4807472982502077e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.4735500119277276e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.1666303407764644e-06
sam_encoder.blocks.11.norm2.weight grad: 5.657650945067871e-06
sam_encoder.blocks.11.norm2.bias grad: 4.918244030704955e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.8881164578488097e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 7.660078154003713e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.638621587422676e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.777383739134166e-08
sam_encoder.neck.conv1.trainable_scale grad: 1.1228103176108561e-06
sam_encoder.neck.conv1.trainable_shift grad: 5.985315510770306e-06
sam_encoder.neck.conv2.trainable_scale grad: 2.0064621821802575e-06
sam_encoder.neck.conv2.trainable_shift grad: 2.1997471776558086e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00015066700871102512
mask_decoder.transformer.layers.0.norm1.bias grad: -1.2758828233927488e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0027189769316464663
mask_decoder.transformer.layers.0.norm2.bias grad: -9.031424997374415e-05
mask_decoder.transformer.layers.0.norm3.weight grad: -4.401095793582499e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 2.7608726668404415e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -2.8670581741607748e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 3.104061761405319e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -2.7036679966840893e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 5.603897989203688e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -8.957930549513549e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -6.115641735959798e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -1.8803009879775345e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -4.152841211180203e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 7.316884875763208e-06
mask_decoder.transformer.layers.1.norm4.bias grad: 3.1661184038966894e-06
mask_decoder.transformer.norm_final_attn.weight grad: -1.6400995264120866e-06
mask_decoder.transformer.norm_final_attn.bias grad: -3.465057488938328e-06
Text_Embedding_Affine.0.weight grad: -9.604078816949357e-12
Text_Embedding_Affine.0.bias grad: -7.109895450163606e-10
Text_Embedding_Affine.2.weight grad: -1.14735911743713e-11
Text_Embedding_Affine.2.bias grad: -8.580063877161592e-07

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 2.799383391760557e-09
Max value: 0.9962258338928223
Mean value: 0.05383138358592987

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 2.799383391760557e-09
Max value: 0.9962258338928223
Mean value: 0.05383138358592987

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06029796600341797

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.490678787231445
Max value: -1.1920928244535389e-07
Mean value: -0.12195602059364319

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.04585838317871094

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06029796600341797

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 6.136876583099365
Max value: 55.301204681396484
Mean value: 41.7933349609375

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 3.719013985659103e-09
Max value: 0.9962676167488098
Mean value: 0.054499026387929916

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.719013985659103e-09
Max value: 0.9962676167488098
Mean value: 0.054499026387929916

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 3.719013985659103e-09
Max value: 0.9962676167488098
Mean value: 0.054499026387929916

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -14.400775909423828
Max value: -1.1920928244535389e-07
Mean value: -0.12094040960073471

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9518464207649231
Max value: 1.3335411548614502
Mean value: 1.0010876655578613

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 6.136876583099365
Max value: 55.301204681396484
Mean value: 41.7933349609375

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -41.79627227783203
Max value: -41.79627227783203
Mean value: -41.79627227783203
sam_encoder.pos_embed grad: 4.221461402664772e-09
sam_encoder.blocks.0.norm1.weight grad: -0.00013355445116758347
sam_encoder.blocks.0.norm1.bias grad: 1.0866820048249792e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.6651043551974e-05
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.5425897572640679e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.0270405255141668e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.5392454265092965e-06
sam_encoder.blocks.0.norm2.weight grad: 2.0970552213839255e-05
sam_encoder.blocks.0.norm2.bias grad: 7.304872269742191e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -2.0449733710847795e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.0862796443689149e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 7.123318937374279e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -2.9157490644138306e-07
sam_encoder.blocks.1.norm1.weight grad: -1.4832738088443875e-05
sam_encoder.blocks.1.norm1.bias grad: 1.7537615349283442e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.328110430331435e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -5.472035127240815e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -3.2993903005262837e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.9916976725653512e-06
sam_encoder.blocks.1.norm2.weight grad: 9.684988981462084e-06
sam_encoder.blocks.1.norm2.bias grad: -9.037779818754643e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.3888404737372184e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.0191649835178396e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.350002586444134e-08
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.2214526350362576e-06
sam_encoder.blocks.2.norm1.weight grad: -5.955378583166748e-06
sam_encoder.blocks.2.norm1.bias grad: 8.059525498538278e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -4.746687864098931e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -9.917603165376931e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.999430307681905e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.175091700948542e-06
sam_encoder.blocks.2.norm2.weight grad: -7.4825015872193035e-06
sam_encoder.blocks.2.norm2.bias grad: -1.2087249160686042e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -9.415542990609538e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.564997314242646e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.0228322935290635e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -4.902849468635395e-06
sam_encoder.blocks.3.norm1.weight grad: -6.864345778012648e-06
sam_encoder.blocks.3.norm1.bias grad: 5.498501991496596e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.425207407621201e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -9.809671155380784e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.1816598493605852e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.4551408134575468e-06
sam_encoder.blocks.3.norm2.weight grad: -3.918219590559602e-06
sam_encoder.blocks.3.norm2.bias grad: -6.09802896178735e-07
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -3.362008555995999e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.720157337738783e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -2.4029875476117013e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.8788316538120853e-06
sam_encoder.blocks.4.norm1.weight grad: -4.992437425244134e-06
sam_encoder.blocks.4.norm1.bias grad: 2.3806903470813268e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.431291022730875e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.4627479458795278e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.890840621854295e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.2589493962877896e-06
sam_encoder.blocks.4.norm2.weight grad: -1.495811011409387e-05
sam_encoder.blocks.4.norm2.bias grad: -9.724131814436987e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.200799579237355e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -5.304206752043683e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -1.4073393685976043e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.319669978438469e-07
sam_encoder.blocks.5.norm1.weight grad: -1.018833791022189e-05
sam_encoder.blocks.5.norm1.bias grad: 1.1146843093001735e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -6.30814747637487e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.200552555426839e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.114680112048518e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 3.858795025735162e-07
sam_encoder.blocks.5.norm2.weight grad: -3.669921625260031e-06
sam_encoder.blocks.5.norm2.bias grad: -7.495035788451787e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -4.772581405632081e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -5.098948463455599e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 3.1101567401492503e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 7.896016427366703e-07
sam_encoder.blocks.6.norm1.weight grad: -1.974810402316507e-06
sam_encoder.blocks.6.norm1.bias grad: -1.1514169955262332e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -3.6178286677568394e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -1.1799721733041224e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.526899945427431e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -3.071181708946824e-07
sam_encoder.blocks.6.norm2.weight grad: 4.0170116335502826e-06
sam_encoder.blocks.6.norm2.bias grad: -6.369307811837643e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 4.5721421315647603e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -4.828754640584521e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.720417561860813e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 8.973741927320589e-08
sam_encoder.blocks.7.norm1.weight grad: 5.459878593683243e-08
sam_encoder.blocks.7.norm1.bias grad: 2.505130396457389e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -2.703245627344586e-09
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.032672341556463e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -1.2850896382587962e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.003981080633821e-06
sam_encoder.blocks.7.norm2.weight grad: -5.287516160024097e-06
sam_encoder.blocks.7.norm2.bias grad: -3.1257429782272084e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.4563032638980076e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.368002014918602e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -3.391447080502985e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.5103086070666905e-06
sam_encoder.blocks.8.norm1.weight grad: -1.0393915772510809e-06
sam_encoder.blocks.8.norm1.bias grad: 1.3423567679637927e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 8.73019416758325e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.5679033822380006e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -1.0696013532651705e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -2.7470541681395844e-06
sam_encoder.blocks.8.norm2.weight grad: -7.423040187859442e-06
sam_encoder.blocks.8.norm2.bias grad: -6.521506179524295e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.78281969865202e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.6877443108096486e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.8652801827556686e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -7.71719157910411e-07
sam_encoder.blocks.9.norm1.weight grad: 4.242449904268142e-06
sam_encoder.blocks.9.norm1.bias grad: -1.75842501448642e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 4.182572411082219e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 6.852865226392169e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 1.2450157100829529e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 7.65712684369646e-07
sam_encoder.blocks.9.norm2.weight grad: -4.75141723654815e-06
sam_encoder.blocks.9.norm2.bias grad: -1.2192645044706296e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.549239181666053e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.250847956020152e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.533949557597225e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -9.526854682917474e-07
sam_encoder.blocks.10.norm1.weight grad: 1.8050909602607135e-06
sam_encoder.blocks.10.norm1.bias grad: -1.6555359252379276e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.8317707599635469e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.6241767159262963e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 4.46787424834838e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 3.746376364688331e-07
sam_encoder.blocks.10.norm2.weight grad: -5.084675194666488e-06
sam_encoder.blocks.10.norm2.bias grad: -4.033132427139208e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -2.606673206173582e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.7505735740996897e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.1331565019645495e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.427833116300462e-07
sam_encoder.blocks.11.norm1.weight grad: 7.379898306680843e-06
sam_encoder.blocks.11.norm1.bias grad: 5.596331789092801e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 5.6962499002111144e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 6.089463795433403e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.1425062186608557e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.1401144774936256e-06
sam_encoder.blocks.11.norm2.weight grad: -2.512279934308026e-06
sam_encoder.blocks.11.norm2.bias grad: -1.5984960555215366e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.5946800431265729e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -8.523774681634677e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -3.6625635857490124e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 4.854477424487413e-07
sam_encoder.neck.conv1.trainable_scale grad: 4.274852472008206e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.857334609667305e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.1204610927961767e-07
sam_encoder.neck.conv2.trainable_shift grad: 2.8004149498883635e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00016397490981034935
mask_decoder.transformer.layers.0.norm1.bias grad: 5.982510629110038e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0004910349380224943
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00013230543117970228
mask_decoder.transformer.layers.0.norm3.weight grad: -5.055492511019111e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 1.215361407957971e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 5.6816385040292516e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 4.035618076159153e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.1955245503922924e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.1014552001142874e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 8.416805940214545e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 0.00011459591769380495
mask_decoder.transformer.layers.1.norm3.weight grad: 7.559274308732711e-07
mask_decoder.transformer.layers.1.norm3.bias grad: 2.5930849005817436e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -1.0361035492678639e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -5.726752533519175e-06
mask_decoder.transformer.norm_final_attn.weight grad: 7.295344403246418e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.241590507561341e-05
Text_Embedding_Affine.0.weight grad: -4.413969190153466e-13
Text_Embedding_Affine.0.bias grad: -6.516692740987651e-11
Text_Embedding_Affine.2.weight grad: 5.170720795977246e-11
Text_Embedding_Affine.2.bias grad: -1.9658837118186057e-05
Epoch 36 finished with average loss: -53.2887
Epoch 37/39
----------
Epoch 37:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 37:   0%|          | 0/3 [00:00<?, ?it/s, loss=-55.6]Epoch 37:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.13it/s, loss=-55.6]Epoch 37:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.13it/s, loss=-54.6]Epoch 37:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.72it/s, loss=-54.6]Epoch 37:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.72it/s, loss=-54.8]Epoch 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.38it/s, loss=-54.8]/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.880176707189321e-09
Max value: 0.9998435974121094
Mean value: 0.08849015086889267

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.880176707189321e-09
Max value: 0.9998435974121094
Mean value: 0.08849015086889267

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09486103057861328

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -11.917411804199219
Max value: -1.1920928244535389e-07
Mean value: -0.13435736298561096

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07742023468017578

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09486103057861328

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 7.236306667327881
Max value: 81.30791473388672
Mean value: 55.55156707763672

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.880176707189321e-09
Max value: 0.9998435974121094
Mean value: 0.08849015086889267

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.880176707189321e-09
Max value: 0.9998435974121094
Mean value: 0.08849015086889267

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.880176707189321e-09
Max value: 0.9998435974121094
Mean value: 0.08849015086889267

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -11.917411804199219
Max value: -1.1920928244535389e-07
Mean value: -0.13435736298561096

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 7.236306667327881
Max value: 81.30791473388672
Mean value: 55.55156707763672

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.552764892578125
Max value: -55.552764892578125
Mean value: -55.552764892578125
sam_encoder.pos_embed grad: -1.1129184240843415e-09
sam_encoder.blocks.0.norm1.weight grad: -3.7220997910480946e-05
sam_encoder.blocks.0.norm1.bias grad: -4.333593460614793e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.515557300990622e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.3087205275041924e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -5.491997967510542e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.334688477072632e-06
sam_encoder.blocks.0.norm2.weight grad: -1.3690187188331038e-06
sam_encoder.blocks.0.norm2.bias grad: 1.464319029764738e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -1.772489667928312e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -1.111766596295638e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.8782999177346937e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.300502041587606e-06
sam_encoder.blocks.1.norm1.weight grad: -7.635888323420659e-06
sam_encoder.blocks.1.norm1.bias grad: 2.3339613107964396e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.1532921437028563e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.4763362514713663e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.4304422368004452e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.7350843108943081e-06
sam_encoder.blocks.1.norm2.weight grad: 1.7825990425990312e-06
sam_encoder.blocks.1.norm2.bias grad: -1.663848161115311e-05
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 6.682226285192883e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 2.7865494303114247e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -7.478709449060261e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.928087385749677e-06
sam_encoder.blocks.2.norm1.weight grad: -1.1263626220170408e-05
sam_encoder.blocks.2.norm1.bias grad: 8.25141069071833e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.2017724657198414e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.5010206172737526e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -6.366478828567779e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -4.6253599066403694e-06
sam_encoder.blocks.2.norm2.weight grad: -7.112051207514014e-06
sam_encoder.blocks.2.norm2.bias grad: -7.158945663832128e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.535363015951589e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -1.576798581481853e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -6.913433026056737e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -1.8046036984742386e-06
sam_encoder.blocks.3.norm1.weight grad: 3.6878072933177464e-06
sam_encoder.blocks.3.norm1.bias grad: -1.7033847825587145e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -2.65253856923664e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.033131577012682e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.175157300778665e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.0879573387210257e-06
sam_encoder.blocks.3.norm2.weight grad: -6.3574634623364545e-06
sam_encoder.blocks.3.norm2.bias grad: -1.2596741726156324e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -7.527265552198514e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -2.401387973804958e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 3.897600436175708e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -4.6249164142864174e-07
sam_encoder.blocks.4.norm1.weight grad: 2.1366533474065363e-05
sam_encoder.blocks.4.norm1.bias grad: -7.99030090092856e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.1315196388750337e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.575983671704307e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 3.7977720239723567e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 2.3212714950204827e-06
sam_encoder.blocks.4.norm2.weight grad: -3.0989322112873197e-05
sam_encoder.blocks.4.norm2.bias grad: -1.3776679224974941e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -2.2976357286097482e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -7.726245712547097e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -4.386190077809715e-09
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -8.115146101772552e-07
sam_encoder.blocks.5.norm1.weight grad: 1.639435504330322e-05
sam_encoder.blocks.5.norm1.bias grad: -8.863585208018776e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.415253063896671e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.567742851373623e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -1.7211905287695117e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 4.7056901166797616e-06
sam_encoder.blocks.5.norm2.weight grad: -1.0188688975176774e-05
sam_encoder.blocks.5.norm2.bias grad: 1.279456910197041e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -6.330693850031821e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.9863975921907695e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.93683786164911e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.991237349509902e-07
sam_encoder.blocks.6.norm1.weight grad: 3.4955546652781777e-06
sam_encoder.blocks.6.norm1.bias grad: -1.7678925701147818e-07
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.8982935873500537e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.3798020265530795e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.271515644584724e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.89792751573259e-07
sam_encoder.blocks.6.norm2.weight grad: -1.0981183550029527e-05
sam_encoder.blocks.6.norm2.bias grad: -7.785311026964337e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -8.769999112701043e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -3.918964466720354e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 1.6583575757067592e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -3.27408770317561e-07
sam_encoder.blocks.7.norm1.weight grad: -6.043781013431726e-07
sam_encoder.blocks.7.norm1.bias grad: -1.3952478639112087e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.5224176195260952e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -9.737330941561595e-08
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.6819813570000406e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.442409256924293e-06
sam_encoder.blocks.7.norm2.weight grad: -6.730035124746792e-07
sam_encoder.blocks.7.norm2.bias grad: -7.494513738492969e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -2.5076233214349486e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -2.717062443480245e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -9.244217835657764e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.857111773366341e-07
sam_encoder.blocks.8.norm1.weight grad: 9.098263944906648e-06
sam_encoder.blocks.8.norm1.bias grad: 4.523606946804648e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.0285412827215623e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.514599368121708e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -6.103573468863033e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.4408497008844279e-06
sam_encoder.blocks.8.norm2.weight grad: -2.563643647590652e-06
sam_encoder.blocks.8.norm2.bias grad: 1.779450940375682e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.125378720549634e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.5613651359890355e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -9.409812946614693e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.5807011045108084e-07
sam_encoder.blocks.9.norm1.weight grad: 3.7566651371889748e-06
sam_encoder.blocks.9.norm1.bias grad: -5.407799221757159e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 3.285758793936111e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 4.4428179535316303e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 6.068820539439912e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 9.638145002099918e-07
sam_encoder.blocks.9.norm2.weight grad: -8.6897642859185e-07
sam_encoder.blocks.9.norm2.bias grad: 2.722302269830834e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -3.449824362178333e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -1.0226373206023709e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 2.4133277065629954e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.459062216075836e-07
sam_encoder.blocks.10.norm1.weight grad: 4.294773134461138e-06
sam_encoder.blocks.10.norm1.bias grad: 9.502313105258509e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 1.8333811340198736e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 5.272486873764137e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 1.7971535726246657e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -2.516362087590096e-07
sam_encoder.blocks.10.norm2.weight grad: -2.727921582845738e-06
sam_encoder.blocks.10.norm2.bias grad: 1.0394617220299551e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.8032964135272778e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -6.605081921406963e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 9.460312639930635e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.769545517367078e-07
sam_encoder.blocks.11.norm1.weight grad: 2.0233287045812176e-07
sam_encoder.blocks.11.norm1.bias grad: 3.617404900069232e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 6.481892341980711e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.4709602282891865e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.097011249839852e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 4.4969112877879525e-07
sam_encoder.blocks.11.norm2.weight grad: -1.1452797110678148e-07
sam_encoder.blocks.11.norm2.bias grad: 8.420506674156059e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -9.903430964186555e-07
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -2.714268134695885e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 5.56258783035446e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -1.3383260011323728e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.0498565643501934e-06
sam_encoder.neck.conv1.trainable_shift grad: -1.702696863503661e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.8165292203775607e-06
sam_encoder.neck.conv2.trainable_shift grad: -5.2114926802460104e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00013461612979881465
mask_decoder.transformer.layers.0.norm1.bias grad: -2.560840584919788e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.003911624662578106
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00023192656226456165
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00016537106421310455
mask_decoder.transformer.layers.0.norm3.bias grad: 2.4911074433475733e-05
mask_decoder.transformer.layers.0.norm4.weight grad: -7.6532996899914e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 2.7654368750518188e-06
mask_decoder.transformer.layers.1.norm1.weight grad: -1.1753263606806286e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 2.6403949959785677e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 9.286410931963474e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 1.354635060124565e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -2.397681964794174e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -3.4050040994770825e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 4.966903361491859e-06
mask_decoder.transformer.layers.1.norm4.bias grad: 1.8061562514049e-05
mask_decoder.transformer.norm_final_attn.weight grad: -3.2299221857101656e-06
mask_decoder.transformer.norm_final_attn.bias grad: -2.4206633497669827e-06
Text_Embedding_Affine.0.weight grad: 2.3547094829545756e-11
Text_Embedding_Affine.0.bias grad: 6.183666911852015e-10
Text_Embedding_Affine.2.weight grad: 2.462246205536811e-11
Text_Embedding_Affine.2.bias grad: 1.0786834536702372e-07

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.20552890586767e-11
Max value: 0.9996297359466553
Mean value: 0.07691594213247299

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.20552890586767e-11
Max value: 0.9996297359466553
Mean value: 0.07691594213247299

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07625198364257812

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12483776360750198

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06501436233520508

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07625198364257812

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 39.79567337036133
Max value: 71.8680648803711
Mean value: 53.63288879394531

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0129076397080716e-11
Max value: 0.9996557235717773
Mean value: 0.07701009511947632

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.0129076397080716e-11
Max value: 0.9996557235717773
Mean value: 0.07701009511947632

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.0129076397080716e-11
Max value: 0.9996557235717773
Mean value: 0.07701009511947632

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.12506753206253052

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.858756959438324
Max value: 1.0157480239868164
Mean value: 0.9997755289077759

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 39.79567337036133
Max value: 71.8680648803711
Mean value: 53.63288879394531

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.623226165771484
Max value: -53.623226165771484
Mean value: -53.623226165771484
sam_encoder.pos_embed grad: 2.915312435902706e-11
sam_encoder.blocks.0.norm1.weight grad: 1.905653698486276e-05
sam_encoder.blocks.0.norm1.bias grad: 1.1622201782302e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.380841917532962e-08
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -6.071546749808476e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 5.153309530214756e-07
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.1486678153669345e-07
sam_encoder.blocks.0.norm2.weight grad: -1.1330650522722863e-05
sam_encoder.blocks.0.norm2.bias grad: 3.505884478727239e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.2094623343728017e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 9.153030077868607e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 6.4774267229950055e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 9.02426108950749e-07
sam_encoder.blocks.1.norm1.weight grad: 4.449319021659903e-06
sam_encoder.blocks.1.norm1.bias grad: -2.387506810919149e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 1.434596924809739e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: 8.099443107312254e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 6.184604899317492e-07
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 4.6638388084829785e-07
sam_encoder.blocks.1.norm2.weight grad: 1.102550186260487e-06
sam_encoder.blocks.1.norm2.bias grad: 5.286295845507993e-07
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 1.2728030469588703e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.5168932065989793e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -6.691828730254201e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.9005501599167474e-06
sam_encoder.blocks.2.norm1.weight grad: 2.916563971666619e-06
sam_encoder.blocks.2.norm1.bias grad: -4.969341262039961e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: 2.1748569452029187e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: 7.151402314775623e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.7366821793984855e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 1.1373595043551177e-07
sam_encoder.blocks.2.norm2.weight grad: -8.12260896054795e-06
sam_encoder.blocks.2.norm2.bias grad: 6.810786544519942e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -5.484366738528479e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -6.255615971895168e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.9136264199914876e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -2.676594590411696e-07
sam_encoder.blocks.3.norm1.weight grad: -5.158427939022658e-06
sam_encoder.blocks.3.norm1.bias grad: -7.833065865270328e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.409824108122848e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.7738482205895707e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.1161851034557912e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -1.2576684866871801e-06
sam_encoder.blocks.3.norm2.weight grad: 3.6869705581921153e-06
sam_encoder.blocks.3.norm2.bias grad: 4.890562195214443e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 3.7016848182247486e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.7370822408556705e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.3358516071093618e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 2.1079169698623446e-07
sam_encoder.blocks.4.norm1.weight grad: -8.52336233947426e-06
sam_encoder.blocks.4.norm1.bias grad: -2.261092276967247e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -5.954273547104094e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -1.2493312624428654e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 8.60248619005688e-08
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 4.2367727814962564e-07
sam_encoder.blocks.4.norm2.weight grad: 3.434785412537167e-06
sam_encoder.blocks.4.norm2.bias grad: -9.730392775963992e-07
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 2.2622964479523944e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 6.886811547701654e-07
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.4112968074186938e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.3497655970695632e-07
sam_encoder.blocks.5.norm1.weight grad: -7.824565727787558e-06
sam_encoder.blocks.5.norm1.bias grad: -3.1231247703544796e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -8.172029083652887e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -2.9521902433771174e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.0610733625071589e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.2120499377488159e-06
sam_encoder.blocks.5.norm2.weight grad: 1.8213861494587036e-06
sam_encoder.blocks.5.norm2.bias grad: -4.4652388169197366e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 2.420072632958181e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 1.5983348475856474e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.7238014038412075e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -8.494607754983008e-07
sam_encoder.blocks.6.norm1.weight grad: -2.8566200853674673e-06
sam_encoder.blocks.6.norm1.bias grad: 2.9408147383946925e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -2.7395979032007745e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.0727636638184777e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -3.649262794169772e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.5847029405667854e-07
sam_encoder.blocks.6.norm2.weight grad: 5.6157130501333086e-08
sam_encoder.blocks.6.norm2.bias grad: 2.0542726986150228e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 7.556035939160211e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.13598945922422e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.1447826838993933e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -1.215579914060072e-06
sam_encoder.blocks.7.norm1.weight grad: 8.765832149038033e-07
sam_encoder.blocks.7.norm1.bias grad: 3.2224056667473633e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.067685843736399e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -4.878289701082394e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 6.872572839711211e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 8.283720376311976e-07
sam_encoder.blocks.7.norm2.weight grad: 4.5509768824558705e-06
sam_encoder.blocks.7.norm2.bias grad: -7.800287562531594e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 4.371082468423992e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.273763129778672e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 7.173731546572526e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -3.267232102643902e-07
sam_encoder.blocks.8.norm1.weight grad: 2.567517185525503e-06
sam_encoder.blocks.8.norm1.bias grad: -3.918698894267436e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.25942868484708e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -1.4277027275966248e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.5105250668057124e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 9.280336144001922e-07
sam_encoder.blocks.8.norm2.weight grad: 1.6140777461259859e-06
sam_encoder.blocks.8.norm2.bias grad: -4.398864916765888e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 1.810741537155991e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 1.3392937034950592e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 3.32258132118568e-08
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -3.3605664384595e-07
sam_encoder.blocks.9.norm1.weight grad: -2.568634499766631e-06
sam_encoder.blocks.9.norm1.bias grad: 4.210144766148005e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -2.3484512894356158e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 8.572715159971267e-08
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -9.25224412640091e-08
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 3.9804803009246825e-07
sam_encoder.blocks.9.norm2.weight grad: 1.3379992651607608e-06
sam_encoder.blocks.9.norm2.bias grad: -4.1131602301902603e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.4622523849538993e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 5.293469484968227e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.639242555029341e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -3.5515262197804986e-07
sam_encoder.blocks.10.norm1.weight grad: 1.029293116516783e-06
sam_encoder.blocks.10.norm1.bias grad: -1.276288685403415e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 8.792707717475423e-07
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 5.178687274565164e-07
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 3.165016266848397e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 4.357218585937517e-07
sam_encoder.blocks.10.norm2.weight grad: 2.374335963395424e-06
sam_encoder.blocks.10.norm2.bias grad: -4.448308459359396e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 1.1629570053628413e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 2.533452914121881e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.102516075159656e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -2.9099373932695016e-07
sam_encoder.blocks.11.norm1.weight grad: 5.425295057648327e-06
sam_encoder.blocks.11.norm1.bias grad: -1.7155105069832643e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.1829256436612923e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 3.201543563591258e-08
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 1.3363345487960032e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 7.868185321058263e-07
sam_encoder.blocks.11.norm2.weight grad: 4.057963451487012e-06
sam_encoder.blocks.11.norm2.bias grad: 3.541472040069493e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.5028501820779638e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 5.03825447140116e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.9827411651695e-08
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.9915559568726167e-07
sam_encoder.neck.conv1.trainable_scale grad: 9.346967999590561e-08
sam_encoder.neck.conv1.trainable_shift grad: -3.3576734494999982e-06
sam_encoder.neck.conv2.trainable_scale grad: -6.824393494753167e-09
sam_encoder.neck.conv2.trainable_shift grad: 2.809836223605089e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00011877651559188962
mask_decoder.transformer.layers.0.norm1.bias grad: 6.93456968292594e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.002700219163671136
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00012886221520602703
mask_decoder.transformer.layers.0.norm3.weight grad: -2.6437683118274435e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -4.946802800986916e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 8.153973612934351e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 3.47433342540171e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 2.9026703487033956e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.045985744800419e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -3.6000645195599645e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 2.7684920496540144e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 2.1587078663287684e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.0608891393058e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -3.22237319778651e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -8.663548942422494e-05
mask_decoder.transformer.norm_final_attn.weight grad: 5.964483079878846e-06
mask_decoder.transformer.norm_final_attn.bias grad: 8.245974640885834e-06
Text_Embedding_Affine.0.weight grad: -1.002837222985331e-11
Text_Embedding_Affine.0.bias grad: -5.930708701917808e-10
Text_Embedding_Affine.2.weight grad: 8.612953406039736e-11
Text_Embedding_Affine.2.bias grad: -7.155571893235901e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.0210706585800366e-10
Max value: 0.9983635544776917
Mean value: 0.08787370473146439

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.0210706585800366e-10
Max value: 0.9983635544776917
Mean value: 0.08787370473146439

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07632923126220703

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.542125701904297
Max value: -1.1920928244535389e-07
Mean value: -0.12814396619796753

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07411575317382812

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07632923126220703

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 52.428462982177734
Max value: 57.95454788208008
Mean value: 55.17582321166992

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.1239150582431634e-10
Max value: 0.9983709454536438
Mean value: 0.08849096298217773

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1239150582431634e-10
Max value: 0.9983709454536438
Mean value: 0.08849096298217773

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1239150582431634e-10
Max value: 0.9983709454536438
Mean value: 0.08849096298217773

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.474068641662598
Max value: -1.1920928244535389e-07
Mean value: -0.12843649089336395

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.932515025138855
Max value: 1.1819671392440796
Mean value: 0.9997148513793945

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 52.428462982177734
Max value: 57.95454788208008
Mean value: 55.17582321166992

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -55.16064453125
Max value: -55.16064453125
Mean value: -55.16064453125
sam_encoder.pos_embed grad: 1.5268197373075054e-08
sam_encoder.blocks.0.norm1.weight grad: -6.459731230279431e-05
sam_encoder.blocks.0.norm1.bias grad: -3.6668476241175085e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 7.269849078284096e-08
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -7.773761581120198e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 4.956803422828671e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 1.3324937526704161e-06
sam_encoder.blocks.0.norm2.weight grad: 1.9079885532846674e-05
sam_encoder.blocks.0.norm2.bias grad: -6.436261901399121e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 2.2997515770839527e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.3261064850667026e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.4318671674118377e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.228886867465917e-05
sam_encoder.blocks.1.norm1.weight grad: 7.911443390185013e-06
sam_encoder.blocks.1.norm1.bias grad: 1.2489121218095534e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.9222855927364435e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.5202435861283448e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -7.504399945901241e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.186332262179349e-06
sam_encoder.blocks.1.norm2.weight grad: -2.1487318008439615e-05
sam_encoder.blocks.1.norm2.bias grad: 3.0883143153914716e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -8.046302355069201e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.4405038655240787e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.516886161174625e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.2757470762589946e-06
sam_encoder.blocks.2.norm1.weight grad: -3.5137632039550226e-06
sam_encoder.blocks.2.norm1.bias grad: 4.352863015810726e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -3.887513230438344e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.93423119299041e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.5634324174461653e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: 5.17689613843686e-07
sam_encoder.blocks.2.norm2.weight grad: 5.890199645364191e-06
sam_encoder.blocks.2.norm2.bias grad: 4.079040081705898e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -3.070568709517829e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 2.1515536445804173e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.7897058569360524e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -4.150742370256921e-06
sam_encoder.blocks.3.norm1.weight grad: -8.347767106897663e-06
sam_encoder.blocks.3.norm1.bias grad: 6.04687897975964e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -9.9513927125372e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -4.39090308645973e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -8.783445082372054e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -8.072098353295587e-06
sam_encoder.blocks.3.norm2.weight grad: -1.1463102055131458e-05
sam_encoder.blocks.3.norm2.bias grad: 2.6479660846234765e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.0037832907983102e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -1.2035104646201944e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -7.2468883445253596e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.6302260519296397e-06
sam_encoder.blocks.4.norm1.weight grad: -3.457300181253231e-06
sam_encoder.blocks.4.norm1.bias grad: 5.547897671931423e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -3.228861487514223e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -2.6056823116960004e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -6.508330443466548e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -6.16272473052959e-06
sam_encoder.blocks.4.norm2.weight grad: 9.749863238539547e-06
sam_encoder.blocks.4.norm2.bias grad: 2.323168700968381e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 9.728851182444487e-07
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 1.6328715446434217e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -3.4906734072137624e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -9.620000582799548e-07
sam_encoder.blocks.5.norm1.weight grad: 2.211909304605797e-06
sam_encoder.blocks.5.norm1.bias grad: -4.20402102463413e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 7.289717132152873e-07
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 3.108716555288993e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -2.5444421680731466e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -1.2892718359580613e-06
sam_encoder.blocks.5.norm2.weight grad: -3.2311240829585586e-06
sam_encoder.blocks.5.norm2.bias grad: 4.20056312577799e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -5.9131734815309756e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -2.6828299724002136e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.6018788073779433e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 8.636945949547226e-07
sam_encoder.blocks.6.norm1.weight grad: -5.773504653916461e-06
sam_encoder.blocks.6.norm1.bias grad: -8.589287062932272e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -3.85465409635799e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -9.990130820369814e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.978279098897474e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.751148713286966e-06
sam_encoder.blocks.6.norm2.weight grad: 1.543742837384343e-05
sam_encoder.blocks.6.norm2.bias grad: 9.754037819220684e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 8.045594768191222e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 3.2986786209221464e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -5.893679144719499e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 9.553725703881355e-07
sam_encoder.blocks.7.norm1.weight grad: -6.474247129517607e-07
sam_encoder.blocks.7.norm1.bias grad: 1.6929160437939572e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -4.552717200567713e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -2.7446453714219388e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -4.249724042892922e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.790287342373631e-06
sam_encoder.blocks.7.norm2.weight grad: -4.5922997742309235e-06
sam_encoder.blocks.7.norm2.bias grad: -1.6393245232393383e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -5.480322215589695e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.4229879020131193e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -5.7396391639485955e-08
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.9930453163397033e-06
sam_encoder.blocks.8.norm1.weight grad: 3.870933142025024e-06
sam_encoder.blocks.8.norm1.bias grad: 4.235927917761728e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.4204902021883754e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 7.374026154138846e-07
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -5.4535512390430085e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -3.990076947957277e-06
sam_encoder.blocks.8.norm2.weight grad: -8.099481419776566e-06
sam_encoder.blocks.8.norm2.bias grad: 5.733166972277104e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -8.667395377415232e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -4.512961368163815e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.188041096611414e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 5.789635793007619e-07
sam_encoder.blocks.9.norm1.weight grad: -7.184694368334021e-06
sam_encoder.blocks.9.norm1.bias grad: -1.863949137259624e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -7.510659997933544e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -4.273441390978405e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -3.148572432110086e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.7108932297560386e-06
sam_encoder.blocks.9.norm2.weight grad: -1.4088189345784485e-05
sam_encoder.blocks.9.norm2.bias grad: -1.263681951968465e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -1.3723678421229124e-05
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -6.5778685893747024e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -1.5218254247884033e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 2.1344173717352533e-07
sam_encoder.blocks.10.norm1.weight grad: -1.0811417268996593e-05
sam_encoder.blocks.10.norm1.bias grad: -2.356104232603684e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -7.76773777033668e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -2.79195660368714e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.973508344439324e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.3075864444545005e-06
sam_encoder.blocks.10.norm2.weight grad: -3.0440647606155835e-05
sam_encoder.blocks.10.norm2.bias grad: -5.763277840742376e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -1.766046989359893e-05
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -9.453005077375565e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.1106492315302603e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -1.3072526598989498e-06
sam_encoder.blocks.11.norm1.weight grad: -3.5732602555071935e-05
sam_encoder.blocks.11.norm1.bias grad: 1.3362493689328403e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -2.0427100935194176e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -2.295303147548111e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -4.404154424264561e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.8669659311854048e-06
sam_encoder.blocks.11.norm2.weight grad: -2.4813587515382096e-05
sam_encoder.blocks.11.norm2.bias grad: -3.2742618714109994e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.2547398000606336e-05
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -5.200373379921075e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.5012690230141743e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.1917810499871848e-07
sam_encoder.neck.conv1.trainable_scale grad: 6.879636202938855e-07
sam_encoder.neck.conv1.trainable_shift grad: 9.1343536041677e-06
sam_encoder.neck.conv2.trainable_scale grad: 1.7578677216079086e-06
sam_encoder.neck.conv2.trainable_shift grad: 2.6860816433327273e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -8.450879249721766e-07
mask_decoder.transformer.layers.0.norm1.bias grad: 1.9618673832155764e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.003316230606287718
mask_decoder.transformer.layers.0.norm2.bias grad: 9.633926674723625e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 0.00016166840214282274
mask_decoder.transformer.layers.0.norm3.bias grad: -7.439946784870699e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -5.833047180203721e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 4.7674002416897565e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 3.491709867375903e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.086714200937422e-05
mask_decoder.transformer.layers.1.norm2.weight grad: 0.00019525262177921832
mask_decoder.transformer.layers.1.norm2.bias grad: 6.910001684445888e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -6.24862013864913e-06
mask_decoder.transformer.layers.1.norm3.bias grad: 4.970200825482607e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 1.9897452148143202e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.0002860222302842885
mask_decoder.transformer.norm_final_attn.weight grad: 4.851516678172629e-06
mask_decoder.transformer.norm_final_attn.bias grad: -4.676950993598439e-06
Text_Embedding_Affine.0.weight grad: -1.1692487256187434e-11
Text_Embedding_Affine.0.bias grad: 4.0892972341666223e-10
Text_Embedding_Affine.2.weight grad: -3.7122770135677996e-11
Text_Embedding_Affine.2.bias grad: -1.5517172869294882e-05
Epoch 37 finished with average loss: -54.7789
Epoch 38/39
----------
Epoch 38:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 38:   0%|          | 0/3 [00:00<?, ?it/s, loss=-49.2]Epoch 38:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.14it/s, loss=-49.2]Epoch 38:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.14it/s, loss=-57.3]Epoch 38:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.72it/s, loss=-57.3]Epoch 38:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.72it/s, loss=-52.8]Epoch 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.38it/s, loss=-52.8]/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.850418244134458e-12
Max value: 0.999531626701355
Mean value: 0.07069465517997742

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.850418244134458e-12
Max value: 0.999531626701355
Mean value: 0.07069465517997742

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06993246078491211

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1263066977262497

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.054903507232666016

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06993246078491211

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 24.588123321533203
Max value: 60.3253288269043
Mean value: 49.19757080078125

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 4.850418244134458e-12
Max value: 0.999531626701355
Mean value: 0.07069465517997742

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.850418244134458e-12
Max value: 0.999531626701355
Mean value: 0.07069465517997742

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 4.850418244134458e-12
Max value: 0.999531626701355
Mean value: 0.07069465517997742

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.1263066977262497

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 24.588123321533203
Max value: 60.3253288269043
Mean value: 49.19757080078125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -49.19868087768555
Max value: -49.19868087768555
Mean value: -49.19868087768555
sam_encoder.pos_embed grad: 3.7692249321708005e-09
sam_encoder.blocks.0.norm1.weight grad: -9.949649393092841e-05
sam_encoder.blocks.0.norm1.bias grad: -6.750682950951159e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -7.743979949736968e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -4.033119694213383e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -1.3797252904623747e-05
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -3.8671851143590175e-07
sam_encoder.blocks.0.norm2.weight grad: 4.326301132095978e-05
sam_encoder.blocks.0.norm2.bias grad: -4.07027910114266e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.9397750293137506e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.4955900951463263e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.6894451619009487e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.3640556062455289e-05
sam_encoder.blocks.1.norm1.weight grad: 1.8542868929216638e-05
sam_encoder.blocks.1.norm1.bias grad: 2.9010232537984848e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -2.037869671767112e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -5.508226877282141e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -2.158894858439453e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -1.0102487067342736e-05
sam_encoder.blocks.1.norm2.weight grad: -1.3053285101705114e-06
sam_encoder.blocks.1.norm2.bias grad: -5.505723493115511e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -1.7531121557112783e-05
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.8042426290776348e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.000796277774498e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -4.518743480730336e-06
sam_encoder.blocks.2.norm1.weight grad: -1.5130368410609663e-05
sam_encoder.blocks.2.norm1.bias grad: -2.510814283596119e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.3713675798499025e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -4.667547273129458e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.384321330988314e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -7.398458365059923e-06
sam_encoder.blocks.2.norm2.weight grad: -6.605039288842818e-06
sam_encoder.blocks.2.norm2.bias grad: 1.770944072632119e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -1.511979917268036e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -3.3036171771527734e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.4184195606503636e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.859180651488714e-06
sam_encoder.blocks.3.norm1.weight grad: -1.3018554454902187e-05
sam_encoder.blocks.3.norm1.bias grad: -8.230123853536497e-07
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -1.6094636521302164e-05
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.6933935259876307e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -8.964066182670649e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -7.620710675837472e-06
sam_encoder.blocks.3.norm2.weight grad: -1.957913627848029e-05
sam_encoder.blocks.3.norm2.bias grad: 3.560405957614421e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.1290327165625058e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -8.008147460714099e-07
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -7.733039637969341e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.8816685951605905e-06
sam_encoder.blocks.4.norm1.weight grad: -2.767138482795417e-07
sam_encoder.blocks.4.norm1.bias grad: -5.660018359776586e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -5.702577254851349e-08
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -4.855992870034243e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.9648521149283624e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -1.86622219189303e-06
sam_encoder.blocks.4.norm2.weight grad: 1.539592972221726e-06
sam_encoder.blocks.4.norm2.bias grad: -1.9916215023840778e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.622163942258339e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.9067579160036985e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -4.004814400104806e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -1.4810442507950938e-06
sam_encoder.blocks.5.norm1.weight grad: -1.316023372055497e-05
sam_encoder.blocks.5.norm1.bias grad: -8.740304110688157e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -1.6191783288377337e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -8.811417501419783e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -4.422695838002255e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 1.024372863867029e-06
sam_encoder.blocks.5.norm2.weight grad: -2.278051215398591e-05
sam_encoder.blocks.5.norm2.bias grad: -2.6309639906685334e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -8.885393071977887e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.8778243884298718e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -1.352349272565334e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.276870756963035e-07
sam_encoder.blocks.6.norm1.weight grad: -6.516994289995637e-06
sam_encoder.blocks.6.norm1.bias grad: -1.8681719211599557e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -6.1000860114290845e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -2.8131544240750372e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -2.13536509363621e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.0742270407936303e-06
sam_encoder.blocks.6.norm2.weight grad: -4.0879058360587806e-08
sam_encoder.blocks.6.norm2.bias grad: 4.991601599613205e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -3.0881146813044325e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.0019898581958842e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -5.440950189949945e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -9.105276603804668e-07
sam_encoder.blocks.7.norm1.weight grad: -1.0006005140894558e-05
sam_encoder.blocks.7.norm1.bias grad: 1.5496742662435281e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -8.785325007920619e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -3.2218902106251335e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.8087423490651418e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -2.1007685973017942e-06
sam_encoder.blocks.7.norm2.weight grad: -9.890396768241771e-07
sam_encoder.blocks.7.norm2.bias grad: 1.718563339636603e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 7.862196866881277e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.3675826266990043e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.2197085652587702e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 4.808641165254812e-07
sam_encoder.blocks.8.norm1.weight grad: -9.261255399906076e-06
sam_encoder.blocks.8.norm1.bias grad: -6.989876055740751e-08
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -1.4952596757211722e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: -8.40382017486263e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -6.858191682113102e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -4.97230576002039e-06
sam_encoder.blocks.8.norm2.weight grad: -6.962846782698762e-06
sam_encoder.blocks.8.norm2.bias grad: -3.211857801943552e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.9760450312751345e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -3.4761701499519404e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -8.493620953231584e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -5.167597691979608e-07
sam_encoder.blocks.9.norm1.weight grad: -8.424481166002806e-06
sam_encoder.blocks.9.norm1.bias grad: 1.273369207410724e-06
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -9.597069947631098e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -3.682708438645932e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -2.0839124772464857e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.5307796275010332e-06
sam_encoder.blocks.9.norm2.weight grad: -6.600934284506366e-06
sam_encoder.blocks.9.norm2.bias grad: -1.2823333008782356e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -7.445970368280541e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -4.0153258851205464e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -7.918456503830384e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -1.3728177350458282e-07
sam_encoder.blocks.10.norm1.weight grad: -3.735636710189283e-06
sam_encoder.blocks.10.norm1.bias grad: -8.040314014579053e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.348233349242946e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.0631481472955784e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -6.301216899373685e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -7.688262115834732e-08
sam_encoder.blocks.10.norm2.weight grad: -1.5383462596219033e-05
sam_encoder.blocks.10.norm2.bias grad: -5.165299626241904e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -7.220834504551021e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -5.626508027489763e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -1.1352167348377407e-06
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -5.081578819954302e-07
sam_encoder.blocks.11.norm1.weight grad: -1.0649693649611436e-05
sam_encoder.blocks.11.norm1.bias grad: 1.6712701835785992e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.6955626733761164e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.053115965987672e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 7.400905701615557e-07
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.6954095372057054e-07
sam_encoder.blocks.11.norm2.weight grad: -1.0670682968338951e-05
sam_encoder.blocks.11.norm2.bias grad: -3.147959432681091e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -4.380004611448385e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.0378128030861262e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.3322613767741132e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 1.5818912402210117e-07
sam_encoder.neck.conv1.trainable_scale grad: 4.916746547678486e-07
sam_encoder.neck.conv1.trainable_shift grad: -5.412806785898283e-06
sam_encoder.neck.conv2.trainable_scale grad: 7.151757017709315e-07
sam_encoder.neck.conv2.trainable_shift grad: -2.089592999254819e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00013045883679296821
mask_decoder.transformer.layers.0.norm1.bias grad: 2.3742431949358433e-06
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0014760890044271946
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00016074691666290164
mask_decoder.transformer.layers.0.norm3.weight grad: 6.858643610030413e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -5.199269799049944e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 9.45380816119723e-06
mask_decoder.transformer.layers.0.norm4.bias grad: 6.937116268090904e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 1.9428001905907877e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -9.684762517281342e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 7.390083919744939e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 2.9006310796830803e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 1.642434290261008e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.850405482808128e-05
mask_decoder.transformer.layers.1.norm4.weight grad: -4.8134836106328294e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -6.720522651448846e-05
mask_decoder.transformer.norm_final_attn.weight grad: 9.598865290172398e-06
mask_decoder.transformer.norm_final_attn.bias grad: 2.9666946375073167e-06
Text_Embedding_Affine.0.weight grad: 4.293350397421847e-11
Text_Embedding_Affine.0.bias grad: 8.068878898370713e-10
Text_Embedding_Affine.2.weight grad: 5.493530283451342e-11
Text_Embedding_Affine.2.bias grad: -1.4485325664281845e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.1212021588935528e-10
Max value: 0.9996589422225952
Mean value: 0.10517378151416779

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.1212021588935528e-10
Max value: 0.9996589422225952
Mean value: 0.10517378151416779

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10353279113769531

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.749792098999023
Max value: -1.1920928244535389e-07
Mean value: -0.13495710492134094

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0964517593383789

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.10353279113769531

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 48.59162902832031
Max value: 89.97576141357422
Mean value: 65.47248077392578

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.3951856336902324e-10
Max value: 0.9996317625045776
Mean value: 0.10480775684118271

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.3951856336902324e-10
Max value: 0.9996317625045776
Mean value: 0.10480775684118271

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.3951856336902324e-10
Max value: 0.9996317625045776
Mean value: 0.10480775684118271

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.60912036895752
Max value: -1.1920928244535389e-07
Mean value: -0.13504795730113983

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9480094909667969
Max value: 1.1833667755126953
Mean value: 0.999918520450592

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 48.59162902832031
Max value: 89.97576141357422
Mean value: 65.47248077392578

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -65.46870422363281
Max value: -65.46870422363281
Mean value: -65.46870422363281
sam_encoder.pos_embed grad: 1.5147540999294051e-09
sam_encoder.blocks.0.norm1.weight grad: -1.30067110148957e-05
sam_encoder.blocks.0.norm1.bias grad: 6.5568724494369235e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -1.698070718703093e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -1.0168113107056342e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -3.6017297588841757e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -1.5235212913466967e-06
sam_encoder.blocks.0.norm2.weight grad: 2.509452315280214e-05
sam_encoder.blocks.0.norm2.bias grad: 8.624402653367724e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 7.704851668677293e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.356949724140577e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 7.379249836958479e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 6.990073416091036e-06
sam_encoder.blocks.1.norm1.weight grad: 6.286536518018693e-07
sam_encoder.blocks.1.norm1.bias grad: 1.6418183804489672e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -6.7656778810487594e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.5874630864564097e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -8.584470378991682e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -3.3948151667573256e-06
sam_encoder.blocks.1.norm2.weight grad: -4.989954959455645e-06
sam_encoder.blocks.1.norm2.bias grad: -8.936009180615656e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -9.38636549108196e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -6.297381673903146e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.4273831766331568e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.2706582260288997e-06
sam_encoder.blocks.2.norm1.weight grad: -9.90256194199901e-06
sam_encoder.blocks.2.norm1.bias grad: 6.533055966428947e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -8.067098860919941e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -1.092646925826557e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -3.092406132054748e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -3.2904076761042234e-06
sam_encoder.blocks.2.norm2.weight grad: 5.373988642531913e-06
sam_encoder.blocks.2.norm2.bias grad: -1.2043394235661253e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 6.632380973314866e-07
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 3.1101440072234254e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -1.0359306543250568e-05
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.2039165489550214e-06
sam_encoder.blocks.3.norm1.weight grad: -3.628898411989212e-06
sam_encoder.blocks.3.norm1.bias grad: -3.352659405209124e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -4.689181878347881e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -2.414102937109419e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.00088174501434e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.908037913584849e-06
sam_encoder.blocks.3.norm2.weight grad: -5.665907792717917e-06
sam_encoder.blocks.3.norm2.bias grad: -1.5214745872071944e-05
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -6.2838698795530945e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.075669837926398e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.637158326659119e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -1.3342340707822586e-06
sam_encoder.blocks.4.norm1.weight grad: 1.9308567061671056e-05
sam_encoder.blocks.4.norm1.bias grad: -1.2718940524791833e-05
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 6.807943918829551e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 3.502006165945204e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -8.975818843737216e-08
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 1.3594575420938781e-06
sam_encoder.blocks.4.norm2.weight grad: 5.278770458971849e-06
sam_encoder.blocks.4.norm2.bias grad: 8.74382931215223e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.3571923268027604e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.6282021988445194e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.1918845050095115e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -6.756302894928012e-08
sam_encoder.blocks.5.norm1.weight grad: 1.3471362763084471e-05
sam_encoder.blocks.5.norm1.bias grad: -3.0320876248879358e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 9.549568858346902e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 8.570656063966453e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.6479509617493022e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 7.471326171071269e-07
sam_encoder.blocks.5.norm2.weight grad: 8.566017640987411e-06
sam_encoder.blocks.5.norm2.bias grad: 4.425043698574882e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 1.3809947176923743e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 6.188495262904326e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 2.990931079693837e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 3.9344013202935457e-07
sam_encoder.blocks.6.norm1.weight grad: 6.619869964197278e-06
sam_encoder.blocks.6.norm1.bias grad: -4.403798357088817e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 2.381215153945959e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.251661953778239e-06
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -9.499306088400772e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -8.950754590841825e-07
sam_encoder.blocks.6.norm2.weight grad: 3.5235498216934502e-06
sam_encoder.blocks.6.norm2.bias grad: 1.4021106835571118e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -2.772195102807018e-06
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -1.9377127955522155e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 3.5496245232025103e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.653641892422456e-07
sam_encoder.blocks.7.norm1.weight grad: 4.227305907988921e-06
sam_encoder.blocks.7.norm1.bias grad: 5.027055749451392e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 2.551025090724579e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.7427373677492142e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -2.3980378500709776e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: 7.169630293901719e-07
sam_encoder.blocks.7.norm2.weight grad: 4.099747002328513e-06
sam_encoder.blocks.7.norm2.bias grad: -1.6664747590766638e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -1.6172092500710278e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -8.43202258238307e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 1.1260922292422038e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.701827841316117e-06
sam_encoder.blocks.8.norm1.weight grad: 4.036316113342764e-06
sam_encoder.blocks.8.norm1.bias grad: -1.2115319805161562e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 7.549682322860463e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.2184034353122115e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -2.529429139030981e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -9.062564458872657e-07
sam_encoder.blocks.8.norm2.weight grad: -1.0553173979133135e-06
sam_encoder.blocks.8.norm2.bias grad: 3.518470066410373e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -5.1337228796910495e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.4944276901806006e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -1.6080293789855205e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 3.920847007066186e-07
sam_encoder.blocks.9.norm1.weight grad: 4.418236301262368e-07
sam_encoder.blocks.9.norm1.bias grad: 4.845111334361718e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -9.670620784163475e-07
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.3284918622957775e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -8.007912128960015e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.1272644542259513e-06
sam_encoder.blocks.9.norm2.weight grad: -2.819942665155395e-06
sam_encoder.blocks.9.norm2.bias grad: 2.171863798139384e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.2869099818053655e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.218917870777659e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -3.0278147278295364e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 3.91497081864145e-07
sam_encoder.blocks.10.norm1.weight grad: -3.882720193360001e-06
sam_encoder.blocks.10.norm1.bias grad: -5.703623173758388e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -3.4923084513138747e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.3120774156050174e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -1.8261355307913618e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -8.768447514739819e-07
sam_encoder.blocks.10.norm2.weight grad: -4.848261596634984e-06
sam_encoder.blocks.10.norm2.bias grad: 1.2639883379961248e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -3.1775562092661858e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -1.9911012714146636e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 5.686995336873224e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 3.5413265209172096e-07
sam_encoder.blocks.11.norm1.weight grad: -2.249481212857063e-06
sam_encoder.blocks.11.norm1.bias grad: 2.8189933232170006e-07
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 3.905166522599757e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.2037190799674136e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 6.21635507513929e-08
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 5.000072178518167e-07
sam_encoder.blocks.11.norm2.weight grad: -1.894361275844858e-06
sam_encoder.blocks.11.norm2.bias grad: 3.301447577541694e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -1.3542392025556182e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.9004078189464053e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 1.0821499927260447e-06
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.3900670359798823e-07
sam_encoder.neck.conv1.trainable_scale grad: 1.5167834135354497e-06
sam_encoder.neck.conv1.trainable_shift grad: 2.6852922019315884e-05
sam_encoder.neck.conv2.trainable_scale grad: 2.2937720132176764e-06
sam_encoder.neck.conv2.trainable_shift grad: -2.3108001187210903e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00016757927369326353
mask_decoder.transformer.layers.0.norm1.bias grad: 4.591292963596061e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0025237174704670906
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0002921609557233751
mask_decoder.transformer.layers.0.norm3.weight grad: 8.435166819253936e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 4.972487658960745e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -5.734827936976217e-05
mask_decoder.transformer.layers.0.norm4.bias grad: 3.953982741222717e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.4684414054499939e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -5.917613634665031e-07
mask_decoder.transformer.layers.1.norm2.weight grad: 5.472613702295348e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 2.572147423052229e-05
mask_decoder.transformer.layers.1.norm3.weight grad: -2.162097007385455e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.169400547951227e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 3.624915188993327e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00012777754454873502
mask_decoder.transformer.norm_final_attn.weight grad: 1.734245188345085e-06
mask_decoder.transformer.norm_final_attn.bias grad: -3.933518655685475e-06
Text_Embedding_Affine.0.weight grad: -1.106595717836889e-11
Text_Embedding_Affine.0.bias grad: -4.1315179055700924e-10
Text_Embedding_Affine.2.weight grad: -1.3409277160869593e-11
Text_Embedding_Affine.2.bias grad: -5.9304848036845215e-06

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 9.496202046932467e-09
Max value: 0.9993273019790649
Mean value: 0.06432279944419861

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 9.496202046932467e-09
Max value: 0.9993273019790649
Mean value: 0.06432279944419861

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0720672607421875

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.26390552520752
Max value: -1.1920928244535389e-07
Mean value: -0.11809991300106049

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.04558086395263672

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0720672607421875

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 31.678749084472656
Max value: 59.077571868896484
Mean value: 43.775054931640625

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 1.1791576604025522e-08
Max value: 0.9992666840553284
Mean value: 0.06290794163942337

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1791576604025522e-08
Max value: 0.9992666840553284
Mean value: 0.06290794163942337

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 1.1791576604025522e-08
Max value: 0.9992666840553284
Mean value: 0.06290794163942337

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -12.206154823303223
Max value: -1.1920928244535389e-07
Mean value: -0.11839644610881805

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.8620185852050781
Max value: 1.11331045627594
Mean value: 0.9997546672821045

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 31.678749084472656
Max value: 59.077571868896484
Mean value: 43.775054931640625

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -43.767845153808594
Max value: -43.767845153808594
Mean value: -43.767845153808594
sam_encoder.pos_embed grad: -1.1129893451311546e-08
sam_encoder.blocks.0.norm1.weight grad: -1.4591822946385946e-05
sam_encoder.blocks.0.norm1.bias grad: 6.028784264344722e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -3.807711891568033e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.2293221516301855e-06
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 8.205352969525848e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 6.395873128894891e-07
sam_encoder.blocks.0.norm2.weight grad: 2.1455536625580862e-05
sam_encoder.blocks.0.norm2.bias grad: -3.447442941251211e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 1.4345007002702914e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 6.033040335751139e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.6064432202256285e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 3.6886128782498417e-06
sam_encoder.blocks.1.norm1.weight grad: 1.50060905070859e-05
sam_encoder.blocks.1.norm1.bias grad: 1.0405321518192068e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.860372534196358e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.579366764621227e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -9.486692761129234e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.442395038495306e-06
sam_encoder.blocks.1.norm2.weight grad: 5.610829248325899e-06
sam_encoder.blocks.1.norm2.bias grad: 9.917564966599457e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -4.9953187044593506e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -4.3958425521850586e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -3.173353979946114e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -7.240857485157903e-06
sam_encoder.blocks.2.norm1.weight grad: -2.052392483165022e-05
sam_encoder.blocks.2.norm1.bias grad: 5.6661697271920275e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -1.7358092009089887e-05
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -4.126592102693394e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -1.2372489436529577e-05
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -5.747196155425627e-06
sam_encoder.blocks.2.norm2.weight grad: -3.3299751521553844e-05
sam_encoder.blocks.2.norm2.bias grad: -4.222345978632802e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.650152237038128e-05
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: -6.20346645519021e-06
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -7.692144208704121e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -4.018103481939761e-06
sam_encoder.blocks.3.norm1.weight grad: 4.518200967140729e-06
sam_encoder.blocks.3.norm1.bias grad: -2.1452215150929987e-05
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.585798253880057e-07
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: 6.618795396207133e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.5610319223924307e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.3182323022629134e-07
sam_encoder.blocks.3.norm2.weight grad: 3.85248404199956e-06
sam_encoder.blocks.3.norm2.bias grad: -3.718673269759165e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 1.7567488157510525e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 3.1762581329530803e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 8.854665793478489e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 4.5884780774940737e-07
sam_encoder.blocks.4.norm1.weight grad: 3.1441850296687335e-05
sam_encoder.blocks.4.norm1.bias grad: -2.1972277863824274e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: 1.4556734640791547e-05
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 2.545881216065027e-06
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 6.710572051815689e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 5.306655566528207e-06
sam_encoder.blocks.4.norm2.weight grad: -4.270274075679481e-05
sam_encoder.blocks.4.norm2.bias grad: -4.908194750896655e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -3.858640411635861e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.4267649930843618e-05
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 2.6272618924849667e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.6929199066216825e-06
sam_encoder.blocks.5.norm1.weight grad: 2.8552170988405123e-05
sam_encoder.blocks.5.norm1.bias grad: -3.453196768532507e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 1.8637641915120184e-05
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 2.203304347858648e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 3.3696173886710312e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.992274630742031e-06
sam_encoder.blocks.5.norm2.weight grad: -2.2443535272032022e-05
sam_encoder.blocks.5.norm2.bias grad: -1.2596288797794841e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -1.4089953765505925e-05
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -4.548724064079579e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.5295754565158859e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -9.127978728429298e-07
sam_encoder.blocks.6.norm1.weight grad: 2.4995042622322217e-06
sam_encoder.blocks.6.norm1.bias grad: 2.6110353701369604e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.9576004888222087e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 5.417903139459668e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 6.827809784226702e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 1.02741410046292e-07
sam_encoder.blocks.6.norm2.weight grad: -1.3388818842940964e-05
sam_encoder.blocks.6.norm2.bias grad: -7.716962500126101e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.3596846656582784e-05
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -6.095785465731751e-06
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.4489646572619677e-08
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -6.00373766701523e-07
sam_encoder.blocks.7.norm1.weight grad: 1.2308052646403667e-05
sam_encoder.blocks.7.norm1.bias grad: -9.709219739306718e-08
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 9.062592653208412e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 3.2816319617268164e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 1.610228309800732e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -5.672677616530564e-07
sam_encoder.blocks.7.norm2.weight grad: -5.387388227973133e-06
sam_encoder.blocks.7.norm2.bias grad: 1.4141846804704983e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -5.019729542254936e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -3.961210950365057e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -4.111770522285951e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -1.8286464182892814e-06
sam_encoder.blocks.8.norm1.weight grad: 1.1448326404206455e-05
sam_encoder.blocks.8.norm1.bias grad: -3.19690843753051e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 1.3365528502617963e-05
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 1.524051640444668e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 1.1362099030520767e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.329517544945702e-06
sam_encoder.blocks.8.norm2.weight grad: -6.809013029851485e-06
sam_encoder.blocks.8.norm2.bias grad: -3.2084103622764815e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -6.086422217776999e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.8603044484043494e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: -3.1501363082497846e-06
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.8089530158249545e-06
sam_encoder.blocks.9.norm1.weight grad: 3.9198707781906705e-06
sam_encoder.blocks.9.norm1.bias grad: 1.4067720144339546e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 3.4018153201031964e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 9.757618499861564e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: 6.811705475229246e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 1.985815515581635e-06
sam_encoder.blocks.9.norm2.weight grad: 1.4181546248437371e-06
sam_encoder.blocks.9.norm2.bias grad: -2.3692944495223855e-08
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 7.498642844439019e-07
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 3.3771920016079093e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 7.980555665199063e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -8.625111149740405e-07
sam_encoder.blocks.10.norm1.weight grad: 1.3278222468215972e-05
sam_encoder.blocks.10.norm1.bias grad: 2.908049282268621e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 7.485874448320828e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 2.6608872758515645e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 2.026390575338155e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.1287854704278288e-06
sam_encoder.blocks.10.norm2.weight grad: 4.386144610180054e-06
sam_encoder.blocks.10.norm2.bias grad: 4.950972538608767e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.6699260615714593e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 1.496644358667254e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 5.981095085871857e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.050086204188119e-07
sam_encoder.blocks.11.norm1.weight grad: 1.9831990357488394e-05
sam_encoder.blocks.11.norm1.bias grad: 2.3491318188462174e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 6.3060956563276704e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.972977543118759e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 3.7996294395270525e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.7316215235041454e-06
sam_encoder.blocks.11.norm2.weight grad: 1.2271181731193792e-05
sam_encoder.blocks.11.norm2.bias grad: 3.2246459795715054e-06
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.9702217691228725e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.1279023510724073e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.4759555117270793e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.105327894241782e-07
sam_encoder.neck.conv1.trainable_scale grad: 8.29673808766529e-07
sam_encoder.neck.conv1.trainable_shift grad: -1.0307858246960677e-05
sam_encoder.neck.conv2.trainable_scale grad: 1.7462662071920931e-07
sam_encoder.neck.conv2.trainable_shift grad: -3.801642742473632e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 5.4286727390717715e-05
mask_decoder.transformer.layers.0.norm1.bias grad: -1.9923318177461624e-06
mask_decoder.transformer.layers.0.norm2.weight grad: -0.0034582007210701704
mask_decoder.transformer.layers.0.norm2.bias grad: -0.0003862046869471669
mask_decoder.transformer.layers.0.norm3.weight grad: -5.2353083447087556e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -8.28412885311991e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 7.924532110337168e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -1.721842636470683e-05
mask_decoder.transformer.layers.1.norm1.weight grad: -2.9281078241183423e-05
mask_decoder.transformer.layers.1.norm1.bias grad: 1.420527678419603e-05
mask_decoder.transformer.layers.1.norm2.weight grad: -0.0001626782468520105
mask_decoder.transformer.layers.1.norm2.bias grad: -0.00011390572763048112
mask_decoder.transformer.layers.1.norm3.weight grad: 1.4687053408124484e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -5.493816934176721e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 2.242806658614427e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00029169494519010186
mask_decoder.transformer.norm_final_attn.weight grad: -2.529994617361808e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.593381239217706e-05
Text_Embedding_Affine.0.weight grad: -1.6558343238215478e-11
Text_Embedding_Affine.0.bias grad: -4.624284566379089e-10
Text_Embedding_Affine.2.weight grad: 2.878845772880112e-11
Text_Embedding_Affine.2.bias grad: 2.0476869394769892e-05
Epoch 38 finished with average loss: -52.8117
Epoch 39/39
----------
Epoch 39:   0%|          | 0/3 [00:00<?, ?it/s]Epoch 39:   0%|          | 0/3 [00:00<?, ?it/s, loss=-53.6]Epoch 39:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.05it/s, loss=-53.6]Epoch 39:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:01,  1.05it/s, loss=-55.2]Epoch 39:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.64it/s, loss=-55.2]Epoch 39:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.64it/s, loss=-56.2]Epoch 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.26it/s, loss=-56.2]/home/abdelrahman.elsayed/DIAS/masks
s29_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s29.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s29_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s27_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s27.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s27_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s13_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s13.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s13_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s20_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s20.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s20_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s3_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s3.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s3_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s8_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s8.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s8_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s11_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s11.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s11_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s0_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s0.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s0_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s6_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s6.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s6_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s19_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s19.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s19_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s14_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s14.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s14_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s16_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s16.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s16_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s28_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s28.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s28_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s26_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s26.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s26_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s25_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s25.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s25_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s24_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s24.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s24_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s18_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s18.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s18_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s9_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s9.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s9_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s4_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s4.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s4_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s10_mask.png
Data point
Train:  True
Img: /home/abdelrahman.elsayed/DIAS/images/s10.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s10_mask.png
                                                                   
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.662180437313689e-14
Max value: 0.9998347759246826
Mean value: 0.06806325912475586

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.662180437313689e-14
Max value: 0.9998347759246826
Mean value: 0.06806325912475586

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06962776184082031

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11377473920583725

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.058268070220947266

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06962776184082031

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 43.1508903503418
Max value: 66.89454650878906
Mean value: 53.613494873046875

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 6.662180437313689e-14
Max value: 0.9998347759246826
Mean value: 0.06806325912475586

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.662180437313689e-14
Max value: 0.9998347759246826
Mean value: 0.06806325912475586

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 6.662180437313689e-14
Max value: 0.9998347759246826
Mean value: 0.06806325912475586

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -15.942384719848633
Max value: -1.1920928244535389e-07
Mean value: -0.11377473920583725

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.0
Max value: 1.0
Mean value: 1.0

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 43.1508903503418
Max value: 66.89454650878906
Mean value: 53.613494873046875

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -53.614471435546875
Max value: -53.614471435546875
Mean value: -53.614471435546875
sam_encoder.pos_embed grad: -2.776894048039935e-09
sam_encoder.blocks.0.norm1.weight grad: -3.775287768803537e-05
sam_encoder.blocks.0.norm1.bias grad: 1.7596119505469687e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: -4.820567482965998e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -3.761918776490347e-07
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 1.1958643426623894e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -4.1717893850545806e-07
sam_encoder.blocks.0.norm2.weight grad: 2.0258865333744325e-05
sam_encoder.blocks.0.norm2.bias grad: 2.412384856143035e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -4.36577192886034e-06
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: -6.049575858924072e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: -1.6059359040809795e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: -4.176944912614999e-06
sam_encoder.blocks.1.norm1.weight grad: -7.937211194075644e-06
sam_encoder.blocks.1.norm1.bias grad: 2.8710680908261565e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: 4.3418398831818195e-07
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -2.4939524223555054e-07
sam_encoder.blocks.1.attn.proj.trainable_scale grad: 1.5781872662046226e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: 1.0463700164109468e-06
sam_encoder.blocks.1.norm2.weight grad: 6.399428002623608e-06
sam_encoder.blocks.1.norm2.bias grad: -6.384701464412501e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 4.159053787589073e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 1.1305037332931533e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: 4.897997314401437e-06
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -3.953095983888488e-08
sam_encoder.blocks.2.norm1.weight grad: 2.915283801030455e-07
sam_encoder.blocks.2.norm1.bias grad: 1.854034053394571e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -2.655463276823866e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -4.05282406745755e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -2.0276465875213034e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.8839558606487117e-06
sam_encoder.blocks.2.norm2.weight grad: 7.424247087328695e-06
sam_encoder.blocks.2.norm2.bias grad: -1.8799573808792047e-05
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: 5.090872036817018e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 4.28176463174168e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.837435602032201e-07
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -5.901104032091098e-07
sam_encoder.blocks.3.norm1.weight grad: -1.5757909750391264e-06
sam_encoder.blocks.3.norm1.bias grad: -6.817075245635351e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.340013563501998e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.001122086563555e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -1.0141773145733168e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.7654282891708135e-07
sam_encoder.blocks.3.norm2.weight grad: 7.70802034821827e-06
sam_encoder.blocks.3.norm2.bias grad: 3.22415326081682e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: 4.862255536863813e-06
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.811717422446236e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: 6.976692361604364e-07
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -2.853713283457182e-07
sam_encoder.blocks.4.norm1.weight grad: 1.7851334632723592e-06
sam_encoder.blocks.4.norm1.bias grad: -1.7916376009452506e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -8.261444008894614e-07
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.827475320074882e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: 1.9385674931982066e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: 8.980022130344878e-07
sam_encoder.blocks.4.norm2.weight grad: -1.2294543921598233e-05
sam_encoder.blocks.4.norm2.bias grad: -1.6635622159810737e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -1.0883071809075773e-05
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -4.2354417928436305e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: 1.624689502932597e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.6258680918544997e-07
sam_encoder.blocks.5.norm1.weight grad: 1.8692926460062154e-06
sam_encoder.blocks.5.norm1.bias grad: -6.7954169935546815e-06
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 2.459045845171204e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 6.128466338850558e-07
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.133320438384544e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 2.848816507139418e-07
sam_encoder.blocks.5.norm2.weight grad: -5.22831351190689e-06
sam_encoder.blocks.5.norm2.bias grad: -3.537357315508416e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -2.2796314169681864e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -3.434757616105344e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 9.84583493846003e-07
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -3.334946256927651e-07
sam_encoder.blocks.6.norm1.weight grad: 4.387122203297622e-07
sam_encoder.blocks.6.norm1.bias grad: -2.0759953258675523e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -1.1115286042695516e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: -4.521826326708833e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.7582794953341363e-07
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -2.0133620637352578e-07
sam_encoder.blocks.6.norm2.weight grad: -1.0906309171332396e-06
sam_encoder.blocks.6.norm2.bias grad: -2.0862844394287094e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -1.0513797121802781e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: -5.951160346739925e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 2.002495421038475e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 5.944905865362671e-07
sam_encoder.blocks.7.norm1.weight grad: 1.7415408137821942e-06
sam_encoder.blocks.7.norm1.bias grad: 1.6891306131583406e-06
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -1.0853963061663308e-07
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 6.126162475084129e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 2.067131106286979e-07
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -7.821334975233185e-07
sam_encoder.blocks.7.norm2.weight grad: 1.5334442196035525e-06
sam_encoder.blocks.7.norm2.bias grad: -3.6586965279639116e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 5.401643647928722e-07
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -6.368915705934342e-07
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -8.407116069975018e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -5.804546958643186e-07
sam_encoder.blocks.8.norm1.weight grad: 1.0137764547835104e-05
sam_encoder.blocks.8.norm1.bias grad: 7.286785148608033e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 8.056492333707865e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 3.2214425118581858e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 7.314872618735535e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 1.0566994745886404e-07
sam_encoder.blocks.8.norm2.weight grad: -1.9432034150668187e-06
sam_encoder.blocks.8.norm2.bias grad: 4.007688119145314e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -1.1941723414565786e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -7.596859177283477e-07
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 1.5890984172983735e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -1.562353162398722e-07
sam_encoder.blocks.9.norm1.weight grad: 1.776575118128676e-06
sam_encoder.blocks.9.norm1.bias grad: 5.0277094487682916e-08
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: 1.0423032108519692e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 6.924048534528993e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -6.017625082677114e-07
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.1114912012999412e-06
sam_encoder.blocks.9.norm2.weight grad: 4.691774847742636e-06
sam_encoder.blocks.9.norm2.bias grad: -1.2646728464460466e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 2.698559910641052e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 1.934981355589116e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 1.179035507448134e-06
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -5.254511137309237e-08
sam_encoder.blocks.10.norm1.weight grad: 5.095374490338145e-06
sam_encoder.blocks.10.norm1.bias grad: 1.1241179436183302e-06
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 3.0808837436779868e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.2569507816806436e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 7.846438165870495e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 6.321828323052614e-07
sam_encoder.blocks.10.norm2.weight grad: 2.8201034183439333e-06
sam_encoder.blocks.10.norm2.bias grad: -2.170966581616085e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 2.282988816659781e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: 6.278593218667083e-07
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: -3.4468800436116e-07
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -3.516500441946846e-07
sam_encoder.blocks.11.norm1.weight grad: 1.0832152838702314e-05
sam_encoder.blocks.11.norm1.bias grad: 1.5412349512189394e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: 5.278804565023165e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: 1.798738821889856e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: 2.282078639836982e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: 1.2734094525512774e-06
sam_encoder.blocks.11.norm2.weight grad: 5.901485110371141e-06
sam_encoder.blocks.11.norm2.bias grad: -5.134928642291925e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 3.3416497444704873e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: 1.0290542604707298e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: 2.7563569915400876e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: 3.529583807448944e-07
sam_encoder.neck.conv1.trainable_scale grad: 5.326146492734551e-07
sam_encoder.neck.conv1.trainable_shift grad: -4.71236853627488e-06
sam_encoder.neck.conv2.trainable_scale grad: 2.177403075620532e-07
sam_encoder.neck.conv2.trainable_shift grad: -8.645460184197873e-06
mask_decoder.transformer.layers.0.norm1.weight grad: -8.28175398055464e-05
mask_decoder.transformer.layers.0.norm1.bias grad: 5.635956767946482e-07
mask_decoder.transformer.layers.0.norm2.weight grad: -0.003059897106140852
mask_decoder.transformer.layers.0.norm2.bias grad: -0.00022858503507450223
mask_decoder.transformer.layers.0.norm3.weight grad: 4.5549859351012856e-05
mask_decoder.transformer.layers.0.norm3.bias grad: -9.90682474366622e-06
mask_decoder.transformer.layers.0.norm4.weight grad: 7.727115735178813e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -3.7532663554884493e-07
mask_decoder.transformer.layers.1.norm1.weight grad: 6.356272024277132e-07
mask_decoder.transformer.layers.1.norm1.bias grad: 3.4288493679923704e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -3.91615139960777e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 1.4358520274981856e-06
mask_decoder.transformer.layers.1.norm3.weight grad: 6.399975063686725e-06
mask_decoder.transformer.layers.1.norm3.bias grad: 4.721237473859219e-06
mask_decoder.transformer.layers.1.norm4.weight grad: -5.812296876683831e-05
mask_decoder.transformer.layers.1.norm4.bias grad: -0.0001188908499898389
mask_decoder.transformer.norm_final_attn.weight grad: 3.2431676117994357e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.3250995834823698e-05
Text_Embedding_Affine.0.weight grad: 2.0296911720785182e-11
Text_Embedding_Affine.0.bias grad: 3.5292141431497726e-10
Text_Embedding_Affine.2.weight grad: 1.4727562919203407e-11
Text_Embedding_Affine.2.bias grad: 1.204735781357158e-05

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.4180632224025658e-09
Max value: 0.9991223216056824
Mean value: 0.08909986913204193

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.4180632224025658e-09
Max value: 0.9991223216056824
Mean value: 0.08909986913204193

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08959484100341797

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.894542694091797
Max value: -1.1920928244535389e-07
Mean value: -0.1262124925851822

Debugging Predicted Segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.07058238983154297

Debugging Ground Truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.08959484100341797

Debugging Computed advantages:
Shape: torch.Size([8])
Contains NaN: False
Min value: 40.2491340637207
Max value: 84.82556915283203
Mean value: 56.804962158203125

Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 1.5822776422425022e-09
Max value: 0.9990635514259338
Mean value: 0.08973612636327744

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.5822776422425022e-09
Max value: 0.9990635514259338
Mean value: 0.08973612636327744

Debugging Final probabilities:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 1.5822776422425022e-09
Max value: 0.9990635514259338
Mean value: 0.08973612636327744

Debugging Log probabilities:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: -13.805949211120605
Max value: -1.1920928244535389e-07
Mean value: -0.1263314187526703

Debugging Probability ratio:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 0.9708454608917236
Max value: 1.1384289264678955
Mean value: 0.9998880624771118

Debugging Reshaped advantages:
Shape: torch.Size([8, 1, 1])
Contains NaN: False
Min value: 40.2491340637207
Max value: 84.82556915283203
Mean value: 56.804962158203125

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -56.79690170288086
Max value: -56.79690170288086
Mean value: -56.79690170288086
sam_encoder.pos_embed grad: 3.969145900839521e-09
sam_encoder.blocks.0.norm1.weight grad: 2.8396663765306585e-05
sam_encoder.blocks.0.norm1.bias grad: -4.962594175594859e-06
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 4.5121259972802363e-07
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: -5.597640750920618e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: -5.474385034176521e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: -7.302049880308914e-07
sam_encoder.blocks.0.norm2.weight grad: -1.6239268006756902e-05
sam_encoder.blocks.0.norm2.bias grad: 2.9201523830124643e-06
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: -9.821087587624788e-07
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 3.2928296604950447e-06
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 1.7841466615209356e-05
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.2295625310798641e-05
sam_encoder.blocks.1.norm1.weight grad: -4.951268692821031e-07
sam_encoder.blocks.1.norm1.bias grad: 1.7843158275354654e-05
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -1.4321476555778645e-05
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -3.7874140161875403e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -1.2309878002270125e-05
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -5.395445896283491e-06
sam_encoder.blocks.1.norm2.weight grad: -5.586133511314983e-07
sam_encoder.blocks.1.norm2.bias grad: -1.1907285397683154e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: -8.540175258531235e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: -1.3962569482828258e-06
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -1.0424638276163023e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -1.442559550923761e-06
sam_encoder.blocks.2.norm1.weight grad: -4.462354809220415e-06
sam_encoder.blocks.2.norm1.bias grad: 7.790404197294265e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -6.776357167836977e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -8.224891985264549e-07
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -4.280904249753803e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -2.9659490792255383e-06
sam_encoder.blocks.2.norm2.weight grad: 1.026884433485975e-06
sam_encoder.blocks.2.norm2.bias grad: -9.868543202173896e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -2.031510121014435e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 9.312665838479006e-07
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -9.747527656145394e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: -3.3892451938299928e-06
sam_encoder.blocks.3.norm1.weight grad: 1.6289341147057712e-06
sam_encoder.blocks.3.norm1.bias grad: 1.4026470580574824e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -3.4082065667462302e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -3.377581379027106e-07
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -3.8048281112423865e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -2.8256197310838616e-06
sam_encoder.blocks.3.norm2.weight grad: -1.511092978034867e-05
sam_encoder.blocks.3.norm2.bias grad: -6.013232450641226e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -1.2873550986114424e-05
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: -3.98607699025888e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -4.2812266656255815e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: -8.820854304758541e-07
sam_encoder.blocks.4.norm1.weight grad: 2.177504711653455e-06
sam_encoder.blocks.4.norm1.bias grad: -7.3945366239058785e-06
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -1.1543368145794375e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: 7.351802651101025e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -2.824815510393819e-06
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -2.5967015062633436e-06
sam_encoder.blocks.4.norm2.weight grad: 1.3329821740626357e-05
sam_encoder.blocks.4.norm2.bias grad: 1.5053865354275331e-05
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: 5.721595698560122e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: 2.2652754978480516e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -2.6191996767011005e-06
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: -2.1928455851139006e-07
sam_encoder.blocks.5.norm1.weight grad: 5.795423021481838e-06
sam_encoder.blocks.5.norm1.bias grad: -1.805875035643112e-05
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: 4.436413746589096e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: 5.352097559807589e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: -3.2745890621299623e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: 4.287505817046622e-08
sam_encoder.blocks.5.norm2.weight grad: 6.305668648565188e-06
sam_encoder.blocks.5.norm2.bias grad: 7.612963145220419e-06
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: 8.675635285726457e-07
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: 2.981642808208562e-07
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: 1.0530806093811407e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: 1.855539721873356e-07
sam_encoder.blocks.6.norm1.weight grad: 4.249875473760767e-07
sam_encoder.blocks.6.norm1.bias grad: -7.880035809648689e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: -4.177715595687914e-07
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 9.259293847208028e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: -1.1059094049414853e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: -3.6100126976634783e-07
sam_encoder.blocks.6.norm2.weight grad: 3.993707196059404e-06
sam_encoder.blocks.6.norm2.bias grad: 3.2260120406135684e-06
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: 7.152709144975233e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 4.1956704421863833e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: 5.13994564244058e-07
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: 9.052870950654324e-07
sam_encoder.blocks.7.norm1.weight grad: -2.5482884211669443e-06
sam_encoder.blocks.7.norm1.bias grad: 3.2838701713444607e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: -3.371298362253583e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: -1.517537157269544e-06
sam_encoder.blocks.7.attn.proj.trainable_scale grad: -3.5723758173844544e-06
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -1.99983560378314e-06
sam_encoder.blocks.7.norm2.weight grad: -2.9844420623703627e-06
sam_encoder.blocks.7.norm2.bias grad: 5.059754357716884e-07
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: -4.821176389668835e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: -1.4771003407076932e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: 7.387972686956346e-07
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: 1.4619738522014813e-06
sam_encoder.blocks.8.norm1.weight grad: 2.134921260221745e-06
sam_encoder.blocks.8.norm1.bias grad: -3.8514616562679294e-07
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: 3.871324224746786e-06
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 2.8959284463780932e-06
sam_encoder.blocks.8.attn.proj.trainable_scale grad: -3.359291895321803e-06
sam_encoder.blocks.8.attn.proj.trainable_shift grad: -1.543031203254941e-06
sam_encoder.blocks.8.norm2.weight grad: -3.795317525145947e-06
sam_encoder.blocks.8.norm2.bias grad: 1.9461872398096602e-06
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: -4.299338343116688e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: -2.0532775124593172e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 4.400632747092459e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: 5.668499056810106e-07
sam_encoder.blocks.9.norm1.weight grad: -1.929209702211665e-06
sam_encoder.blocks.9.norm1.bias grad: 7.463688120878942e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.0047608561289962e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: -1.4762030104975565e-06
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.3961664535599994e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: 2.808882868521323e-07
sam_encoder.blocks.9.norm2.weight grad: -4.562822141451761e-06
sam_encoder.blocks.9.norm2.bias grad: 1.6816563856991706e-06
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: -5.268815584713593e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: -2.0152942852291744e-06
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: 6.133425358711975e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: 8.629265266790753e-07
sam_encoder.blocks.10.norm1.weight grad: -4.9480840971227735e-06
sam_encoder.blocks.10.norm1.bias grad: 3.4998024034393893e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: -4.057335445395438e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: -1.35988807414833e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: -2.155441961804172e-06
sam_encoder.blocks.10.attn.proj.trainable_shift grad: -1.1310924037388759e-06
sam_encoder.blocks.10.norm2.weight grad: -7.047990948194638e-06
sam_encoder.blocks.10.norm2.bias grad: 1.2216553386679152e-06
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: -5.461964519781759e-06
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -2.0164250145171536e-06
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 6.35301375950803e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: 2.733189035097894e-07
sam_encoder.blocks.11.norm1.weight grad: -9.222703738487326e-06
sam_encoder.blocks.11.norm1.bias grad: 2.5195358830387704e-06
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -1.3558927776102792e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -5.670775635735481e-07
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -3.069071681238711e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.7203697098011617e-06
sam_encoder.blocks.11.norm2.weight grad: -9.351069820695557e-06
sam_encoder.blocks.11.norm2.bias grad: -5.036335437580419e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: -4.4221337702765595e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -1.416494228578813e-06
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -1.67806476270016e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.801003233798838e-07
sam_encoder.neck.conv1.trainable_scale grad: 6.276977728703059e-07
sam_encoder.neck.conv1.trainable_shift grad: -4.620670551958028e-06
sam_encoder.neck.conv2.trainable_scale grad: 8.22287802293431e-07
sam_encoder.neck.conv2.trainable_shift grad: -3.1448005756828934e-05
mask_decoder.transformer.layers.0.norm1.weight grad: 0.00013214032514952123
mask_decoder.transformer.layers.0.norm1.bias grad: -3.247059794375673e-07
mask_decoder.transformer.layers.0.norm2.weight grad: 0.0027177738957107067
mask_decoder.transformer.layers.0.norm2.bias grad: 9.431992657482624e-05
mask_decoder.transformer.layers.0.norm3.weight grad: 6.910623051226139e-05
mask_decoder.transformer.layers.0.norm3.bias grad: 5.42901034350507e-06
mask_decoder.transformer.layers.0.norm4.weight grad: -0.00010114614997291937
mask_decoder.transformer.layers.0.norm4.bias grad: 9.455830877413973e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 1.1206911949557252e-06
mask_decoder.transformer.layers.1.norm1.bias grad: -5.865264938620385e-06
mask_decoder.transformer.layers.1.norm2.weight grad: 9.677244815975428e-05
mask_decoder.transformer.layers.1.norm2.bias grad: 9.541065082885325e-06
mask_decoder.transformer.layers.1.norm3.weight grad: -1.092669481295161e-05
mask_decoder.transformer.layers.1.norm3.bias grad: -1.0957031918223947e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 4.8791320296004415e-05
mask_decoder.transformer.layers.1.norm4.bias grad: 0.00013473541184794158
mask_decoder.transformer.norm_final_attn.weight grad: -1.481829940530588e-06
mask_decoder.transformer.norm_final_attn.bias grad: -1.1871964488818776e-05
Text_Embedding_Affine.0.weight grad: 6.498764200391083e-12
Text_Embedding_Affine.0.bias grad: 1.0984609749575824e-10
Text_Embedding_Affine.2.weight grad: -3.8134044533233435e-11
Text_Embedding_Affine.2.bias grad: -1.800247628125362e-05

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.318682356174719e-10
Max value: 0.9996469020843506
Mean value: 0.09115498512983322

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.318682356174719e-10
Max value: 0.9996469020843506
Mean value: 0.09115498512983322

Debugging Ground truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09916305541992188

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.26253604888916
Max value: -1.1920928244535389e-07
Mean value: -0.16134804487228394

Debugging Predicted Segs:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0789175033569336

Debugging Ground Truth:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.09916305541992188

Debugging Computed advantages:
Shape: torch.Size([4])
Contains NaN: False
Min value: 25.787599563598633
Max value: 80.686279296875
Mean value: 58.09480285644531

Debugging Raw model output:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 4.3376699454533707e-10
Max value: 0.9996575117111206
Mean value: 0.09193667769432068

Debugging Processed model output:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.3376699454533707e-10
Max value: 0.9996575117111206
Mean value: 0.09193667769432068

Debugging Final probabilities:
Shape: torch.Size([4, 1, 512, 512])
Contains NaN: False
Min value: 4.3376699454533707e-10
Max value: 0.9996575117111206
Mean value: 0.09193667769432068

Debugging Log probabilities:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: -15.26430892944336
Max value: -1.1920928244535389e-07
Mean value: -0.16113555431365967

Debugging Probability ratio:
Shape: torch.Size([4, 512, 512])
Contains NaN: False
Min value: 0.9631936550140381
Max value: 1.104703426361084
Mean value: 1.0002285242080688

Debugging Reshaped advantages:
Shape: torch.Size([4, 1, 1])
Contains NaN: False
Min value: 25.787599563598633
Max value: 80.686279296875
Mean value: 58.09480285644531

Debugging Total loss:
Shape: torch.Size([])
Contains NaN: False
Min value: -58.09816360473633
Max value: -58.09816360473633
Mean value: -58.09816360473633
sam_encoder.pos_embed grad: -1.2070547894538208e-09
sam_encoder.blocks.0.norm1.weight grad: 5.117528417031281e-05
sam_encoder.blocks.0.norm1.bias grad: 3.196422403561883e-05
sam_encoder.blocks.0.attn.qkv.trainable_scale grad: 9.275216143578291e-06
sam_encoder.blocks.0.attn.qkv.trainable_shift grad: 1.8973121740373244e-08
sam_encoder.blocks.0.attn.proj.trainable_scale grad: 5.395444077294087e-06
sam_encoder.blocks.0.attn.proj.trainable_shift grad: 3.977736469096271e-06
sam_encoder.blocks.0.norm2.weight grad: 1.7451891835662536e-05
sam_encoder.blocks.0.norm2.bias grad: -5.579442949965596e-05
sam_encoder.blocks.0.mlp.lin1.trainable_scale grad: 3.2759613532107323e-05
sam_encoder.blocks.0.mlp.lin1.trainable_shift grad: 1.2108497685403563e-05
sam_encoder.blocks.0.mlp.lin2.trainable_scale grad: 9.751063771545887e-06
sam_encoder.blocks.0.mlp.lin2.trainable_shift grad: 1.983041784114903e-06
sam_encoder.blocks.1.norm1.weight grad: 2.3858701752033085e-06
sam_encoder.blocks.1.norm1.bias grad: -6.101617145759519e-06
sam_encoder.blocks.1.attn.qkv.trainable_scale grad: -7.544996151409578e-06
sam_encoder.blocks.1.attn.qkv.trainable_shift grad: -1.462788304706919e-06
sam_encoder.blocks.1.attn.proj.trainable_scale grad: -8.170824003173038e-06
sam_encoder.blocks.1.attn.proj.trainable_shift grad: -4.456703209143598e-06
sam_encoder.blocks.1.norm2.weight grad: 4.981379333912628e-06
sam_encoder.blocks.1.norm2.bias grad: 4.5295487325347494e-06
sam_encoder.blocks.1.mlp.lin1.trainable_scale grad: 2.5806791654758854e-06
sam_encoder.blocks.1.mlp.lin1.trainable_shift grad: 5.897013579669874e-07
sam_encoder.blocks.1.mlp.lin2.trainable_scale grad: -2.0913472326355986e-05
sam_encoder.blocks.1.mlp.lin2.trainable_shift grad: -2.4851476609910605e-06
sam_encoder.blocks.2.norm1.weight grad: -1.240015626535751e-05
sam_encoder.blocks.2.norm1.bias grad: -3.543615775924991e-06
sam_encoder.blocks.2.attn.qkv.trainable_scale grad: -7.66622179071419e-06
sam_encoder.blocks.2.attn.qkv.trainable_shift grad: -2.2757456008548616e-06
sam_encoder.blocks.2.attn.proj.trainable_scale grad: -7.756350896670483e-06
sam_encoder.blocks.2.attn.proj.trainable_shift grad: -1.1133716952826944e-06
sam_encoder.blocks.2.norm2.weight grad: -1.0567564459051937e-06
sam_encoder.blocks.2.norm2.bias grad: 4.8193974180321675e-06
sam_encoder.blocks.2.mlp.lin1.trainable_scale grad: -4.147106210439233e-06
sam_encoder.blocks.2.mlp.lin1.trainable_shift grad: 1.5254954632837325e-08
sam_encoder.blocks.2.mlp.lin2.trainable_scale grad: -2.253509819638566e-06
sam_encoder.blocks.2.mlp.lin2.trainable_shift grad: 4.463354343897663e-07
sam_encoder.blocks.3.norm1.weight grad: -4.987634838471422e-06
sam_encoder.blocks.3.norm1.bias grad: -2.0880233932984993e-06
sam_encoder.blocks.3.attn.qkv.trainable_scale grad: -8.92685420694761e-06
sam_encoder.blocks.3.attn.qkv.trainable_shift grad: -1.4264642231864855e-06
sam_encoder.blocks.3.attn.proj.trainable_scale grad: -4.259314209775766e-06
sam_encoder.blocks.3.attn.proj.trainable_shift grad: -3.4925838008348364e-06
sam_encoder.blocks.3.norm2.weight grad: -3.141768047498772e-06
sam_encoder.blocks.3.norm2.bias grad: -1.7620950529817492e-06
sam_encoder.blocks.3.mlp.lin1.trainable_scale grad: -6.328165227387217e-07
sam_encoder.blocks.3.mlp.lin1.trainable_shift grad: 2.09737822842726e-06
sam_encoder.blocks.3.mlp.lin2.trainable_scale grad: -1.498387746323715e-06
sam_encoder.blocks.3.mlp.lin2.trainable_shift grad: 1.525509105704259e-07
sam_encoder.blocks.4.norm1.weight grad: 1.6604039032586115e-08
sam_encoder.blocks.4.norm1.bias grad: 1.461849024053663e-07
sam_encoder.blocks.4.attn.qkv.trainable_scale grad: -2.2906401682121214e-06
sam_encoder.blocks.4.attn.qkv.trainable_shift grad: -5.653118932968937e-07
sam_encoder.blocks.4.attn.proj.trainable_scale grad: -6.124322453615605e-07
sam_encoder.blocks.4.attn.proj.trainable_shift grad: -6.593292596335232e-07
sam_encoder.blocks.4.norm2.weight grad: -7.047257440717658e-06
sam_encoder.blocks.4.norm2.bias grad: -2.736277110670926e-06
sam_encoder.blocks.4.mlp.lin1.trainable_scale grad: -4.832930699194549e-06
sam_encoder.blocks.4.mlp.lin1.trainable_shift grad: -1.305211071667145e-06
sam_encoder.blocks.4.mlp.lin2.trainable_scale grad: -7.595744477839617e-07
sam_encoder.blocks.4.mlp.lin2.trainable_shift grad: 3.6675924519613545e-08
sam_encoder.blocks.5.norm1.weight grad: -7.721377187408507e-06
sam_encoder.blocks.5.norm1.bias grad: 6.339990932247019e-07
sam_encoder.blocks.5.attn.qkv.trainable_scale grad: -9.192371180688497e-06
sam_encoder.blocks.5.attn.qkv.trainable_shift grad: -3.067108991672285e-06
sam_encoder.blocks.5.attn.proj.trainable_scale grad: 1.187057364404609e-06
sam_encoder.blocks.5.attn.proj.trainable_shift grad: -2.8253041364223463e-06
sam_encoder.blocks.5.norm2.weight grad: -1.4461521459452342e-05
sam_encoder.blocks.5.norm2.bias grad: -1.0851969818759244e-05
sam_encoder.blocks.5.mlp.lin1.trainable_scale grad: -6.523825049953302e-06
sam_encoder.blocks.5.mlp.lin1.trainable_shift grad: -1.931036877067527e-06
sam_encoder.blocks.5.mlp.lin2.trainable_scale grad: -2.693428086786298e-06
sam_encoder.blocks.5.mlp.lin2.trainable_shift grad: -1.0100104645971442e-06
sam_encoder.blocks.6.norm1.weight grad: 2.1272760477586417e-06
sam_encoder.blocks.6.norm1.bias grad: 4.542146598396357e-06
sam_encoder.blocks.6.attn.qkv.trainable_scale grad: 1.938110017363215e-06
sam_encoder.blocks.6.attn.qkv.trainable_shift grad: 2.2261787080424256e-07
sam_encoder.blocks.6.attn.proj.trainable_scale grad: 1.2634084214369068e-06
sam_encoder.blocks.6.attn.proj.trainable_shift grad: 2.038104582879896e-07
sam_encoder.blocks.6.norm2.weight grad: -6.939711738596088e-07
sam_encoder.blocks.6.norm2.bias grad: 7.657254172954708e-07
sam_encoder.blocks.6.mlp.lin1.trainable_scale grad: -6.155088954074017e-07
sam_encoder.blocks.6.mlp.lin1.trainable_shift grad: 2.8269232643651776e-07
sam_encoder.blocks.6.mlp.lin2.trainable_scale grad: -2.185632411055849e-06
sam_encoder.blocks.6.mlp.lin2.trainable_shift grad: -5.34097125637345e-07
sam_encoder.blocks.7.norm1.weight grad: 2.823996283041197e-06
sam_encoder.blocks.7.norm1.bias grad: 2.364595275139436e-07
sam_encoder.blocks.7.attn.qkv.trainable_scale grad: 1.4280939240052248e-06
sam_encoder.blocks.7.attn.qkv.trainable_shift grad: 8.33689796309045e-07
sam_encoder.blocks.7.attn.proj.trainable_scale grad: 9.166615200228989e-08
sam_encoder.blocks.7.attn.proj.trainable_shift grad: -9.936729838955216e-07
sam_encoder.blocks.7.norm2.weight grad: 1.958622988240677e-06
sam_encoder.blocks.7.norm2.bias grad: 1.3180288078729063e-06
sam_encoder.blocks.7.mlp.lin1.trainable_scale grad: 4.052772965223994e-06
sam_encoder.blocks.7.mlp.lin1.trainable_shift grad: 2.130541361111682e-06
sam_encoder.blocks.7.mlp.lin2.trainable_scale grad: -1.0682504125725245e-06
sam_encoder.blocks.7.mlp.lin2.trainable_shift grad: -8.42978465698252e-07
sam_encoder.blocks.8.norm1.weight grad: 2.076616965496214e-06
sam_encoder.blocks.8.norm1.bias grad: -2.0257684809621423e-06
sam_encoder.blocks.8.attn.qkv.trainable_scale grad: -8.303940148834954e-07
sam_encoder.blocks.8.attn.qkv.trainable_shift grad: 4.7360877886148955e-08
sam_encoder.blocks.8.attn.proj.trainable_scale grad: 8.168856311385753e-07
sam_encoder.blocks.8.attn.proj.trainable_shift grad: 9.831576335272985e-07
sam_encoder.blocks.8.norm2.weight grad: 3.3702660857670708e-06
sam_encoder.blocks.8.norm2.bias grad: -6.314159577414102e-07
sam_encoder.blocks.8.mlp.lin1.trainable_scale grad: 4.786185854754876e-06
sam_encoder.blocks.8.mlp.lin1.trainable_shift grad: 2.678594455574057e-06
sam_encoder.blocks.8.mlp.lin2.trainable_scale grad: 5.642696123686619e-07
sam_encoder.blocks.8.mlp.lin2.trainable_shift grad: -6.715519589306496e-07
sam_encoder.blocks.9.norm1.weight grad: -4.564798473438714e-06
sam_encoder.blocks.9.norm1.bias grad: 3.9619862945983186e-07
sam_encoder.blocks.9.attn.qkv.trainable_scale grad: -3.3659557630016934e-06
sam_encoder.blocks.9.attn.qkv.trainable_shift grad: 2.821420252985263e-07
sam_encoder.blocks.9.attn.proj.trainable_scale grad: -1.0085389021696756e-06
sam_encoder.blocks.9.attn.proj.trainable_shift grad: -1.244993200089084e-06
sam_encoder.blocks.9.norm2.weight grad: 1.904332748381421e-06
sam_encoder.blocks.9.norm2.bias grad: 2.3141744520671637e-07
sam_encoder.blocks.9.mlp.lin1.trainable_scale grad: 1.7778934306988958e-06
sam_encoder.blocks.9.mlp.lin1.trainable_shift grad: 6.766555316062295e-07
sam_encoder.blocks.9.mlp.lin2.trainable_scale grad: -4.3560302742662316e-07
sam_encoder.blocks.9.mlp.lin2.trainable_shift grad: -6.284912501541839e-07
sam_encoder.blocks.10.norm1.weight grad: 1.644627445784863e-06
sam_encoder.blocks.10.norm1.bias grad: -6.109784180807765e-07
sam_encoder.blocks.10.attn.qkv.trainable_scale grad: 2.046752570095123e-06
sam_encoder.blocks.10.attn.qkv.trainable_shift grad: 1.202097223540477e-06
sam_encoder.blocks.10.attn.proj.trainable_scale grad: 8.692992992109794e-07
sam_encoder.blocks.10.attn.proj.trainable_shift grad: 1.1002855444530724e-06
sam_encoder.blocks.10.norm2.weight grad: 7.608218197674432e-07
sam_encoder.blocks.10.norm2.bias grad: -2.0290039515202807e-07
sam_encoder.blocks.10.mlp.lin1.trainable_scale grad: 3.8713545791324577e-07
sam_encoder.blocks.10.mlp.lin1.trainable_shift grad: -8.643123550200471e-08
sam_encoder.blocks.10.mlp.lin2.trainable_scale grad: 6.823037068670601e-08
sam_encoder.blocks.10.mlp.lin2.trainable_shift grad: -4.871322971666814e-07
sam_encoder.blocks.11.norm1.weight grad: -1.591645286680432e-06
sam_encoder.blocks.11.norm1.bias grad: -3.5112787344360186e-08
sam_encoder.blocks.11.attn.qkv.trainable_scale grad: -6.562770977325272e-06
sam_encoder.blocks.11.attn.qkv.trainable_shift grad: -1.5711048035882413e-06
sam_encoder.blocks.11.attn.proj.trainable_scale grad: -1.2507625797297806e-06
sam_encoder.blocks.11.attn.proj.trainable_shift grad: -1.0445805855852086e-06
sam_encoder.blocks.11.norm2.weight grad: -6.072220912756165e-07
sam_encoder.blocks.11.norm2.bias grad: -9.948437309503788e-07
sam_encoder.blocks.11.mlp.lin1.trainable_scale grad: 1.212953179674514e-06
sam_encoder.blocks.11.mlp.lin1.trainable_shift grad: -3.811637725448236e-07
sam_encoder.blocks.11.mlp.lin2.trainable_scale grad: -2.0274634948691528e-07
sam_encoder.blocks.11.mlp.lin2.trainable_shift grad: -2.3440956908871158e-07
sam_encoder.neck.conv1.trainable_scale grad: -6.501995812868699e-07
sam_encoder.neck.conv1.trainable_shift grad: -7.874532457208261e-06
sam_encoder.neck.conv2.trainable_scale grad: -1.5072237147251144e-06
sam_encoder.neck.conv2.trainable_shift grad: -2.0054398191859946e-05
mask_decoder.transformer.layers.0.norm1.weight grad: -0.00013631771435029805
mask_decoder.transformer.layers.0.norm1.bias grad: -8.632559911347926e-08
mask_decoder.transformer.layers.0.norm2.weight grad: -0.001687349984422326
mask_decoder.transformer.layers.0.norm2.bias grad: 0.00016847375081852078
mask_decoder.transformer.layers.0.norm3.weight grad: -0.00015178199100773782
mask_decoder.transformer.layers.0.norm3.bias grad: -6.98984949849546e-05
mask_decoder.transformer.layers.0.norm4.weight grad: 5.747492105001584e-05
mask_decoder.transformer.layers.0.norm4.bias grad: -7.333274879783858e-06
mask_decoder.transformer.layers.1.norm1.weight grad: 2.588160896266345e-05
mask_decoder.transformer.layers.1.norm1.bias grad: -1.115400664275512e-06
mask_decoder.transformer.layers.1.norm2.weight grad: -5.153955135028809e-05
mask_decoder.transformer.layers.1.norm2.bias grad: -1.5335273928940296e-05
mask_decoder.transformer.layers.1.norm3.weight grad: 4.154974521952681e-05
mask_decoder.transformer.layers.1.norm3.bias grad: 3.3162537874886766e-05
mask_decoder.transformer.layers.1.norm4.weight grad: 6.154983566375449e-06
mask_decoder.transformer.layers.1.norm4.bias grad: -0.00014543348515871912
mask_decoder.transformer.norm_final_attn.weight grad: 4.034502126160078e-06
mask_decoder.transformer.norm_final_attn.bias grad: 1.658885958022438e-05
Text_Embedding_Affine.0.weight grad: 1.0064128350140145e-11
Text_Embedding_Affine.0.bias grad: 4.370251660557045e-10
Text_Embedding_Affine.2.weight grad: 1.787278484932653e-11
Text_Embedding_Affine.2.bias grad: -3.499522790662013e-05
Epoch 39 finished with average loss: -56.1698
Final Validation
Validation Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s]Validation Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, Loss=0.69, Dice=0.557]Validation Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.73it/s, Loss=0.69, Dice=0.557]Validation Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.73it/s, Loss=0.691, Dice=0.417]/home/abdelrahman.elsayed/DIAS/masks
s5_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s5.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s5_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s17_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s17.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s17_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s12_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s12.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s12_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s2_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s2.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s2_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s21_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s21.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s21_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s1_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s1.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s1_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s7_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s7.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s7_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s23_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s23.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s23_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s22_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s22.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s22_mask.png
/home/abdelrahman.elsayed/DIAS/masks
s15_mask.png
Data point
Train:  False
Img: /home/abdelrahman.elsayed/DIAS/images/s15.png
Mask:  /home/abdelrahman.elsayed/DIAS/masks/s15_mask.png
                                                                                         
Debugging Raw model output:
Shape: torch.Size([8, 512, 512])
Contains NaN: False
Min value: 3.732424725654654e-31
Max value: 0.9999961853027344
Mean value: 0.04736889898777008

Debugging Processed model output:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 3.732424725654654e-31
Max value: 0.9999961853027344
Mean value: 0.04736889898777008

Debugging images:
Shape: torch.Size([8, 3, 512, 512])
Contains NaN: False
Min value: -2.316228151321411
Max value: 2.640000104904175
Mean value: 0.759333610534668

Debugging Ground truth:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.06787490844726562

Debugging predicted segs:
Shape: torch.Size([8, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.0410614013671875

Debugging Raw model output:
Shape: torch.Size([2, 512, 512])
Contains NaN: False
Min value: 2.8458044317184118e-21
Max value: 0.999634861946106
Mean value: 0.02356744557619095

Debugging Processed model output:
Shape: torch.Size([2, 1, 512, 512])
Contains NaN: False
Min value: 2.8458044317184118e-21
Max value: 0.999634861946106
Mean value: 0.02356744557619095

Debugging images:
Shape: torch.Size([2, 3, 512, 512])
Contains NaN: False
Min value: -2.316228151321411
Max value: 2.640000104904175
Mean value: 1.225735068321228

Debugging Ground truth:
Shape: torch.Size([2, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.059635162353515625

Debugging predicted segs:
Shape: torch.Size([2, 1, 512, 512])
Contains NaN: False
Min value: 0.0
Max value: 1.0
Mean value: 0.013769149780273438
Validation completed for Epoch 1:
Average Loss: 0.6911, Average Dice: 0.4167
